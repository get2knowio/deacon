#![cfg(feature = "full")]
//! Integration tests for features test JSON output
//!
//! These tests verify that the features test command produces correct JSON output
//! with proper structure (testName/result keys) and handles edge cases like
//! zero tests correctly.

use assert_cmd::Command;
use std::fs;
use tempfile::TempDir;

/// Helper function to extract JSON from mixed output (logs + JSON)
fn extract_json_from_output(output: &str) -> Result<serde_json::Value, serde_json::Error> {
    // Try to find JSON by looking for complete JSON objects or arrays
    // Skip lines that look like log messages (contain timestamp patterns)
    for line in output.lines() {
        let trimmed = line.trim();
        // Skip lines that contain log timestamps or ANSI codes
        if trimmed.contains("Z ") || trimmed.contains("\x1b[") || trimmed.is_empty() {
            continue;
        }
        // Try to parse arrays
        if trimmed.starts_with('[') && trimmed.ends_with(']') {
            if let Ok(json) = serde_json::from_str(trimmed) {
                return Ok(json);
            }
        }
        // Try to parse objects
        if trimmed.starts_with('{') && trimmed.ends_with('}') {
            if let Ok(json) = serde_json::from_str(trimmed) {
                return Ok(json);
            }
        }
    }

    // Last resort - try the whole output
    serde_json::from_str(output)
}

/// Test that zero tests produces exactly [] in JSON mode
#[test]
fn zero_tests_json_shape() {
    let temp_dir = TempDir::new().unwrap();
    let project_dir = temp_dir.path();

    // Create minimal collection structure with src/ and test/ directories
    // but NO features or test scenarios
    let src_dir = project_dir.join("src");
    let test_dir = project_dir.join("test");
    fs::create_dir_all(&src_dir).unwrap();
    fs::create_dir_all(&test_dir).unwrap();

    // Run deacon features test with --json flag
    let mut cmd = Command::cargo_bin("deacon").unwrap();
    cmd.args(["features", "test", project_dir.to_str().unwrap(), "--json"]);

    let output = cmd.output().unwrap();
    let stdout = String::from_utf8_lossy(&output.stdout);

    // Extract JSON from output
    let json =
        extract_json_from_output(&stdout).expect("Should produce valid JSON output for zero tests");

    // Verify it's an array
    assert!(
        json.is_array(),
        "Zero tests should produce JSON array, got: {}",
        json
    );

    // Verify the array is empty
    let results = json.as_array().unwrap();
    assert_eq!(
        results.len(),
        0,
        "Zero tests should produce empty array, got {} items",
        results.len()
    );

    // Verify exact string representation is "[]"
    let json_str = serde_json::to_string(&json).unwrap();
    assert_eq!(
        json_str, "[]",
        "Zero tests should serialize to exactly '[]', got: {}",
        json_str
    );

    // Additional verification: the raw stdout should contain [] somewhere
    // (allowing for potential log output before/after)
    assert!(
        stdout.contains("[]"),
        "Stdout should contain '[]' for zero tests, got: {}",
        stdout
    );
}

/// Test that non-zero tests produce correct JSON array shape with testName/result keys
#[test]
fn test_features_test_json_array_shape() {
    let temp_dir = TempDir::new().unwrap();
    let project_dir = temp_dir.path();

    // Create project structure with one feature that has an autogenerated test
    let src_dir = project_dir.join("src").join("test-feature");
    fs::create_dir_all(&src_dir).unwrap();

    // Create feature metadata and install script
    fs::write(
        src_dir.join("devcontainer-feature.json"),
        r#"{"id": "test-feature", "version": "1.0.0", "name": "Test Feature"}"#,
    )
    .unwrap();
    fs::write(
        src_dir.join("install.sh"),
        "#!/bin/bash\necho 'Installing test feature'\nexit 0",
    )
    .unwrap();

    // Make install.sh executable
    #[cfg(unix)]
    {
        use std::os::unix::fs::PermissionsExt;
        let mut perms = fs::metadata(src_dir.join("install.sh"))
            .unwrap()
            .permissions();
        perms.set_mode(0o755);
        fs::set_permissions(src_dir.join("install.sh"), perms).unwrap();
    }

    // Create test directory with autogenerated test.sh
    let test_dir = project_dir.join("test").join("test-feature");
    fs::create_dir_all(&test_dir).unwrap();

    // Create test.sh for autogenerated test
    fs::write(
        test_dir.join("test.sh"),
        "#!/bin/bash\necho 'Running test'\nexit 0",
    )
    .unwrap();

    #[cfg(unix)]
    {
        use std::os::unix::fs::PermissionsExt;
        let mut perms = fs::metadata(test_dir.join("test.sh"))
            .unwrap()
            .permissions();
        perms.set_mode(0o755);
        fs::set_permissions(test_dir.join("test.sh"), perms).unwrap();
    }

    // Run deacon features test with --json flag
    let mut cmd = Command::cargo_bin("deacon").unwrap();
    cmd.args(["features", "test", project_dir.to_str().unwrap(), "--json"]);

    let output = cmd.output().unwrap();

    // This test may fail if Docker is not available, which is acceptable
    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        if stderr.contains("Docker") || stderr.contains("Runtime unavailable") {
            eprintln!("Skipping test: Docker not available");
            return;
        }
        // Otherwise, fail the test with useful diagnostic info
        panic!(
            "Command failed unexpectedly:\nstdout: {}\nstderr: {}",
            String::from_utf8_lossy(&output.stdout),
            stderr
        );
    }

    let stdout = String::from_utf8_lossy(&output.stdout);

    // Parse JSON output - expect array of test results
    let json = extract_json_from_output(&stdout).expect("Should produce valid JSON output");

    assert!(
        json.is_array(),
        "Expected JSON array of test results, got: {}",
        json
    );

    let results = json.as_array().unwrap();
    assert!(
        !results.is_empty(),
        "Expected at least one test result, got empty array"
    );

    // Verify each result has the correct structure per DATA-STRUCTURES.md
    // Keys should be: testName (camelCase), result (boolean)
    for (i, result) in results.iter().enumerate() {
        assert!(
            result.is_object(),
            "Result #{} should be an object, got: {}",
            i,
            result
        );

        // Verify testName exists and is a string
        assert!(
            result.get("testName").is_some(),
            "Result #{} should have 'testName' field, got: {}",
            i,
            result
        );
        assert!(
            result["testName"].is_string(),
            "Result #{} testName should be string, got: {}",
            i,
            result["testName"]
        );

        // Verify result exists and is a boolean
        assert!(
            result.get("result").is_some(),
            "Result #{} should have 'result' field, got: {}",
            i,
            result
        );
        assert!(
            result["result"].is_boolean(),
            "Result #{} result should be boolean, got: {}",
            i,
            result["result"]
        );

        // Verify no snake_case keys (should be camelCase)
        assert!(
            result.get("test_name").is_none(),
            "Result #{} should not have snake_case 'test_name' field",
            i
        );
    }
}

/// Test that features test JSON output matches unit test expectations
/// This is a meta-test to ensure CLI and core model serialization are consistent
#[test]
fn test_json_output_matches_unit_test_shape() {
    // Create two mock results as in the unit test
    use deacon_core::features_test::model::TestResult;

    let results = vec![
        TestResult::new("feature1:scenario1".to_string(), true),
        TestResult::new("feature2:scenario2".to_string(), false),
    ];

    let json = serde_json::to_string(&results).expect("serialization failed");

    // Parse back to verify structure
    let parsed: Vec<serde_json::Value> = serde_json::from_str(&json).expect("parsing failed");

    assert_eq!(parsed.len(), 2);

    // Verify first result has correct shape
    assert_eq!(parsed[0]["testName"], "feature1:scenario1");
    assert_eq!(parsed[0]["result"], true);
    assert!(
        parsed[0].get("test_name").is_none(),
        "Should not have snake_case test_name"
    );

    // Verify second result has correct shape
    assert_eq!(parsed[1]["testName"], "feature2:scenario2");
    assert_eq!(parsed[1]["result"], false);
    assert!(
        parsed[1].get("test_name").is_none(),
        "Should not have snake_case test_name"
    );
}

/// Test that empty results array serializes to exactly "[]"
#[test]
fn test_empty_results_exact_serialization() {
    use deacon_core::features_test::model::TestResult;

    let results: Vec<TestResult> = vec![];
    let json = serde_json::to_string(&results).expect("serialization failed");

    assert_eq!(json, "[]", "Empty results should serialize to exactly '[]'");
}
