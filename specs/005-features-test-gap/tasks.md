---

description: "Task list to close gaps in 'features test' per SPEC"

---

# Tasks: Features Test GAP Closure

**Input**: Design documents from `/specs/005-features-test-gap/`
**Prerequisites**: plan.md (required), spec.md (required), research.md, data-model.md, contracts/

**Tests**: Tests are OPTIONAL in this plan (per template rules). Acceptance criteria and independent test checks are provided for each story.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions

## Path Conventions

- Single project Rust workspace: `crates/deacon/` (CLI entrypoint), `crates/core/` (shared logic)
- Specs and docs for this feature live under `specs/005-features-test-gap/`

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Establish core module skeleton and types for the `features test` workflow

- [ ] T001 Create module skeleton `crates/core/src/features_test/mod.rs`
- [ ] T002 [P] Add data model definitions per spec to `crates/core/src/features_test/model.rs`
- [ ] T003 [P] Create discovery module `crates/core/src/features_test/discovery.rs`
- [ ] T004 [P] Create runner module `crates/core/src/features_test/runner.rs`
- [ ] T005 [P] Create error enum and mapping in `crates/core/src/features_test/errors.rs`

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Wire CLI flags and output contracts; provide entrypoint and validations

**‚ö†Ô∏è CRITICAL**: No user story work can begin until this phase is complete

- [ ] T006 Update `FeatureCommands::Test` flags in `crates/deacon/src/cli.rs` (project-folder, features, filter, global-scenarios-only, skip-scenarios, skip-autogenerated, skip-duplicated, permit-randomization, base-image, remote-user, preserve-test-containers, quiet, log-level, json)
- [ ] T007 [P] Add argument validation for invalid combinations in `crates/deacon/src/commands/features.rs` (mutual exclusivity and requires rules)
- [ ] T008 [P] Add collection entrypoint `execute_features_test_collection(...)` in `crates/deacon/src/commands/features.rs`
- [ ] T009 [P] Implement strict JSON output `[ { "testName": string, "result": boolean } ]` in `crates/deacon/src/commands/features.rs` (stdout array; logs to stderr)

---

## Phase 3: User Story 1 - Run a complete features test suite (Priority: P1) üéØ MVP

**Goal**: Discover features and scenarios in a collection and execute autogenerated, scenario, and duplicate/idempotence tests with a clear per-test summary and overall status.

**Independent Test**: Given a valid collection (`src/` + `test/`), run with default options. Verify all selected autogenerated tests, scenarios, and duplicate checks execute; `_global` scenarios included only when no `--features` provided; exit code reflects overall pass/fail.

### Implementation for User Story 1

- [ ] T010 [P] [US1] Implement TestCollection discovery (`src/`, `test/` presence) in `crates/core/src/features_test/discovery.rs`
- [ ] T011 [P] [US1] Implement feature and scenario enumeration with case-sensitive name filtering in `crates/core/src/features_test/discovery.rs`
- [ ] T012 [US1] Implement autogenerated test executor using container runtime helpers in `crates/core/src/features_test/runner.rs`
- [ ] T013 [US1] Implement duplicate/idempotence test executor per feature in `crates/core/src/features_test/runner.rs`
- [ ] T014 [US1] Aggregate `TestResult[]` and compute overall status in `crates/deacon/src/commands/features.rs`

**Checkpoint**: User Story 1 fully functional; JSON/text output contracts respected; runs serially.

---

## Phase 4: User Story 2 - Control scope and behavior via flags (Priority: P1)

**Goal**: Precisely select features/scenarios and control cleanup/output to support deterministic CI runs.

**Independent Test**: Exercise flags: `--project-folder`, `--features`, `--filter`, `--global-scenarios-only`, `--skip-*`, `--base-image`, `--remote-user`, `--preserve-test-containers`, `--quiet`. Validate selection, filtering, cleanup, and zero-tests behavior.

### Implementation for User Story 2

- [ ] T015 [P] [US2] Enforce selection semantics for `--features` vs `_global` in `crates/deacon/src/commands/features.rs`
- [ ] T016 [P] [US2] Enforce invalid combinations (`--skip-scenarios` with `--filter`/`--global-scenarios-only`) in `crates/deacon/src/commands/features.rs`
- [ ] T017 [P] [US2] Implement labeled cleanup and `--preserve-test-containers` in `crates/core/src/features_test/runner.rs`
- [ ] T018 [US2] Honor `--base-image` and `--remote-user` in container exec in `crates/core/src/features_test/runner.rs`
- [ ] T019 [US2] Implement `--quiet`/`--log-level` handling for this subcommand in `crates/deacon/src/commands/features.rs`

**Checkpoint**: User Stories 1 and 2 independently usable; CI-friendly behavior established.

---

## Phase 5: User Story 3 - Clear failures and validations (Priority: P2)

**Goal**: Fast, actionable failures for missing structure, scripts, malformed scenarios, and runtime errors; no silent fallbacks.

**Independent Test**: Intentionally run with missing `src/`/`test/`, missing `test.sh`, malformed `scenarios.json(c)`, invalid flag combos, or no container runtime. Expect clear errors and non-zero exit.

### Implementation for User Story 3

- [ ] T020 [P] [US3] Validate structure: error when `src/` or `test/` missing in `crates/core/src/features_test/discovery.rs`
- [ ] T021 [P] [US3] Validate missing `test/<feature>/test.sh` when autogenerated tests enabled in `crates/core/src/features_test/discovery.rs`
- [ ] T022 [P] [US3] Parse scenario definitions (`scenarios.json`/JSONC) and surface parse errors in `crates/core/src/features_test/discovery.rs`
- [ ] T023 [US3] Propagate runtime unavailability as a clear error (non-zero) in `crates/core/src/features_test/runner.rs`

**Checkpoint**: All user stories independently functional with robust validations.

---

## Phase N: Polish & Cross-Cutting Concerns

**Purpose**: Hardening, docs, and observability

- [ ] T024 [P] Update subcommand help and SPEC notes in `docs/subcommand-specs/features-test/SPEC.md` (flags and output examples)
- [ ] T025 [P] Update feature quickstart example in `specs/005-features-test-gap/quickstart.md` (JSON mode, zero-tests behavior)
- [ ] T026 Add tracing spans (`feature.test`, `scenario.run`, `cleanup`) in `crates/core/src/features_test/runner.rs`
- [ ] T027 [P] Add rustdoc for public types and functions in `crates/core/src/features_test/*.rs`
- [ ] T028 Run fmt and clippy; fix warnings in `crates/**` (workspace-wide)

---

## Dependencies & Execution Order

### Phase Dependencies

- Setup (Phase 1): No dependencies
- Foundational (Phase 2): Depends on Setup completion ‚Äî BLOCKS all user stories
- User Stories (Phase 3+): Depend on Foundational; US1 and US2 are both P1 and can proceed in parallel after Phase 2
- Polish (Final): Depends on selected user stories being complete

### User Story Dependencies

- User Story 1 (P1): No dependency on other stories; starts after Phase 2
- User Story 2 (P1): Independent of US1; starts after Phase 2
- User Story 3 (P2): Starts after Phase 2; independent of US1/US2 implementation (validations are orthogonal)

### Within Each User Story

- Discovery (enumeration) before execution
- Execution before aggregation/output
- Validations applied pre-execution where applicable

### Parallel Opportunities

- Phase 1 files T002‚ÄìT005 can be created in parallel
- Phase 2 tasks T007‚ÄìT009 can be implemented in parallel with T006 finalized
- US1: T010 and T011 can be parallelized; T012/T013 can proceed once discovery scaffolds compile; T014 after executors
- US2: T015‚ÄìT017 can proceed in parallel; T018 then T019
- US3: T020‚ÄìT022 in parallel; T023 after runner wiring

---

## Parallel Example: User Story 1

```bash
# Parallelizable discovery work
Task: "T010 [US1] Implement TestCollection discovery in crates/core/src/features_test/discovery.rs"
Task: "T011 [US1] Implement feature and scenario enumeration with filtering in crates/core/src/features_test/discovery.rs"

# Then parallelize executors
Task: "T012 [US1] Autogenerated test executor in crates/core/src/features_test/runner.rs"
Task: "T013 [US1] Duplicate/idempotence executor in crates/core/src/features_test/runner.rs"
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. Complete Phase 1: Setup
2. Complete Phase 2: Foundational
3. Complete Phase 3: User Story 1
4. STOP and validate: JSON array output contract; serial execution; summary in text mode

### Incremental Delivery

1. Setup + Foundational ‚Üí Foundation ready
2. Add US1 ‚Üí Validate independently ‚Üí Demo (MVP)
3. Add US2 ‚Üí Validate independently ‚Üí Demo
4. Add US3 ‚Üí Validate independently ‚Üí Demo

### Parallel Team Strategy

1. Team completes Setup + Foundational together
2. After Phase 2:
   - Developer A: US1 discovery/execution
   - Developer B: US2 flag semantics/cleanup
   - Developer C: US3 validations and error paths

---

## Notes

- [P] tasks = different files, no dependencies
- [Story] label maps task to specific user story for traceability
- Each user story is independently completable and testable per acceptance criteria in `spec.md`
- In JSON mode, stdout must contain only `TestResult[]` (strict) and logs must go to stderr
