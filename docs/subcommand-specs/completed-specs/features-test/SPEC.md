# Features Test Subcommand Design Specification

## 1. Subcommand Overview
- Purpose: Execute automated tests for Dev Container Features in an isolated container environment. Supports per‑feature autogenerated tests, scenario tests, duplicate/idempotence tests, and global scenarios.
- User Personas:
  - Feature authors: Validate installation scripts, options, and behavior across scenarios.
  - CI engineers: Run feature test suites in pipelines with deterministic outcomes.
  - Maintainers: Reproduce and triage failures with clear logs and exit codes.
- Specification References:
  - Dev Container Features distribution and authoring: containers.dev implementors spec (Features)
  - Feature lifecycle and metadata fields (installsAfter, options, etc.): containers.dev implementors spec (Features Metadata)
  - Testing guidance (community docs) aligns with CLI behavior but is non‑normative.
- Related Commands:
  - `features package`: Package features once tests pass.
  - `features publish`: Publish tested packages to OCI.
  - `features info`: Inspect feature metadata and dependencies.

## 2. Command-Line Interface

### Full Syntax
```
devcontainer features test [TARGET] [--project-folder <path>] [options]
```

### Flags and Options

#### Project Selection
- `TARGET` (positional, **deprecated**): Path to collection directory (default: `.`). Use `--project-folder` instead.
- `--project-folder, -p <path>`: Collection root containing `src/` and `test/` (default: `.`). Overrides positional `TARGET`.

#### Test Selection
- `--features, -f <id...>`: Specific feature IDs to test (can be specified multiple times). Omit to test all features. Mutually exclusive with `--global-scenarios-only`.
- `--filter <string>`: Case-sensitive substring filter for scenario names. Only scenarios matching this filter will run. Mutually exclusive with `--skip-scenarios`.
- `--global-scenarios-only`: Only run global scenarios from `test/_global/`. Mutually exclusive with `--features`.

#### Test Skipping
- `--skip-scenarios`: Skip all scenario tests (both feature-specific and global). Mutually exclusive with `--global-scenarios-only` and `--filter`.
- `--skip-autogenerated`: Skip autogenerated `test.sh` tests for all features.
- `--skip-duplicated`: Skip duplicate/idempotence tests for all features.

#### Runtime Options
- `--base-image <ref>`: Base container image for autogenerated tests (default: `ubuntu:focal`). Used when no scenario config specifies an image.
- `--remote-user <name>`: Remote user for executing test scripts inside containers. Applied to both autogenerated and scenario tests unless overridden by scenario config.
- `--preserve-test-containers`: Do not remove test containers after execution. Useful for debugging failures. By default, all containers labeled `devcontainer.is_test_run=true` are removed.

#### Output Control
- `--quiet`: Suppress non-error output. Warnings and failures still appear.
- `--log-level <level>`: Set logging verbosity. Values: `info` (default), `debug`, `trace`. Applies to stderr output.
- `--json`: Output test results as strict JSON array to stdout; all logs and human-readable output go to stderr.

#### Experimental/Not Implemented
- `--permit-randomization`: Returns error "Not implemented yet: randomization". Reserved for future randomized test ordering.

### Flag Taxonomy

| Category | Flags |
|----------|-------|
| **Required** | None (all optional) |
| **Mutually Exclusive** | `--global-scenarios-only` ⊗ `--features`<br>`--skip-scenarios` ⊗ `--global-scenarios-only`<br>`--skip-scenarios` ⊗ `--filter` |
| **Deprecated** | `TARGET` (use `--project-folder`) |

### Argument Validation Rules

1. **Project Structure**: `--project-folder` must point to a directory containing both `src/` and `test/` subdirectories. Fails with clear error if either is missing.
2. **Feature IDs**: When `--features` is specified, each ID must correspond to a subdirectory under `test/<feature>/`. Missing test directories cause errors.
3. **Filter Matching**: `--filter` performs case-sensitive substring matching on scenario names (not feature IDs).
4. **Base Image**: `--base-image` format is not validated by the CLI; invalid image references surface as container runtime errors during test execution.
5. **Mutual Exclusivity**: Combining mutually exclusive flags fails immediately with a clear error message before test discovery.
6. **Autogenerated Tests**: When autogenerated tests are enabled (default) and a feature lacks `test/<feature>/test.sh`, execution fails with: `"Missing autogenerated test script for feature '<id>' - expected: <path>"`

## 3. Input Processing Pipeline

```pseudocode
FUNCTION parse_command_arguments(args) -> ParsedInput:
    input.project_folder = args['--project-folder'] OR args.positional('target') OR '.'
    input.features = to_array(args['--features']) OR undefined
    input.filter = args['--filter']
    input.global_only = args['--global-scenarios-only']
    input.skip_scenarios = args['--skip-scenarios']
    input.skip_autogenerated = args['--skip-autogenerated']
    input.skip_duplicate = args['--skip-duplicated']
    input.permit_random = args['--permit-randomization']
    input.base_image = args['--base-image'] OR 'ubuntu:focal'
    input.remote_user = args['--remote-user']
    input.log_level = map_log_level(args['--log-level'])
    input.preserve = args['--preserve-test-containers']
    input.quiet = args['--quiet']
    input.json = args['--json']

    // Validate exclusivity
    IF input.global_only AND input.features IS NOT UNDEFINED THEN ERROR('--global-scenarios-only and --features are mutually exclusive')
    IF input.skip_scenarios AND input.global_only THEN ERROR('--skip-scenarios cannot be combined with --global-scenarios-only')
    IF input.skip_scenarios AND input.filter THEN ERROR('--skip-scenarios cannot be combined with --filter')
    IF input.permit_random THEN ERROR('Not implemented yet: randomization')

    // Verify structure
    REQUIRE folder_exists(join(input.project_folder, 'src'))
    REQUIRE folder_exists(join(input.project_folder, 'test'))

    // Verify feature IDs map to existing test directories
    IF input.features IS NOT UNDEFINED THEN
        FOR EACH feature IN input.features DO
            test_dir = join(input.project_folder, 'test', feature)
            IF NOT folder_exists(test_dir) THEN
                ERROR('No matching features: ' + feature + ' → error. Expected test directory: ' + test_dir)
            END IF
        END FOR
    END IF

    RETURN input
END FUNCTION
```

### Behavior Rules

#### Global Scenarios (`_global`)
Global scenarios are included in two cases:
1. **`--global-scenarios-only` is set**: Only `_global` scenarios run; no feature tests execute.
2. **No `--features` flag provided**: All features AND `_global` scenarios run.

When `--features` is explicitly provided (even if it lists all features), `_global` scenarios are **excluded** unless `--global-scenarios-only` is also set.

#### Duplicate/Idempotence Tests
- **Enabled by default** for all features (unless `--skip-duplicated` is set)
- **Automatically disabled** when `--global-scenarios-only` is set (global scenarios have no features to test for idempotence)
- Tests that a feature's `install.sh` can run twice in the same container without errors

#### Zero Tests Behavior
When test selection results in zero tests (due to filters, skip flags, or empty collection):
- **Text mode**: Prints "No tests found" to stdout
- **JSON mode**: Outputs `[]` to stdout
- **Exit code**: 0 (zero tests is not an error)

#### Default Base Image
When `--base-image` is not provided:
- Defaults to `ubuntu:focal`
- Applied to autogenerated tests and scenarios that don't specify an image in their config

## 4. Configuration Resolution
- Sources and Precedence:
  - CLI flags only. No `devcontainer.json` configuration is read for test selection.
  - Scenario configs are read from the `test/` tree per feature or `_global`.
- Merge/Resolution:
  - Not applicable to CLI flags; scenario JSONC files are parsed as standalone devcontainer configs per scenario.
- Variable Substitution:
  - Scenario configs are parsed and used as input to environment creation; substitution follows normal config rules inside the test container creation helper (see containers.dev spec for variables). The test runner itself does not perform variable expansion.

## 5. Core Execution Logic

```pseudocode
FUNCTION execute_subcommand(input: ParsedInput) -> ExecutionResult:
    // Phase 1: Initialization
    cli_host = detect_cli_host(CWD)
    pkg = read_package_config()
    logger = create_logger(level=input.log_level)
    print_banner('Dev Container Features', pkg.version)

    // Phase 2: Pre-execution validation
    ASSERT exists(input.project_folder/src) AND exists(input.project_folder/test)

    // Phase 3: Main execution
    results = []
    IF input.global_only THEN
        // Only run global scenarios; no feature tests
        results += run_global_tests(input)
    ELSE
        // Run feature tests (for selected or all features)
        results += run_feature_tests(input)
        // Run global scenarios only if --features was NOT provided
        // (i.e., when testing all features implicitly, include _global)
        IF input.features IS UNDEFINED THEN
            results += run_global_tests(input)
        ELSE
            // Explicitly providing --features excludes _global scenarios
            // (unless --global-scenarios-only was set, handled above)
        END IF
    END IF

    IF NOT input.preserve THEN cleanup_test_containers(cli_host)

    // Phase 4: Post-execution
    all_passed = every(results, r => r.result == true)
    print_summary(results, all_passed)
    RETURN Success if all_passed ELSE Failure
END FUNCTION

FUNCTION run_feature_tests(input) -> [TestResult]:
    for feature in select_features(input):
        log_info("Starting '%s' tests", feature)
        feature_test_dir = join(input.project_folder, 'test', feature)
        if NOT input.skip_autogenerated:
            workspace = prepare_autotest_workspace(feature_test_dir)
            create_container_from_workspace(workspace, input)
            write_test_library(workspace)
            ok = exec_script_in_container('test.sh', workspace)
            results.push({ testName: feature, result: ok })
        if NOT input.skip_scenarios:
            do_scenarios(feature_test_dir, feature, input, results)
        if NOT input.skip_duplicate:
            ok = run_duplicate_install_test(feature, input)
            results.push({ testName: feature + ' (duplicate/idempotence)', result: ok })
    return results
END FUNCTION

FUNCTION run_global_tests(input) -> [TestResult]:
    path = join(input.project_folder, 'test', '_global')
    if exists(path):
        do_scenarios(path, '_global', input, results)
    return results
END FUNCTION
```

## 6. State Management
- Persistent State: None by default. Temporary workspaces created under system temp directory for scenarios and autogenerated tests.
- Cache Management: None specific; relies on Docker layer cache implicitly when building.
- Lock Files: None created.
- Idempotency: Safe to re‑run; containers are labeled `devcontainer.is_test_run=true` and removed unless `--preserve-test-containers`.

## 7. External System Interactions

### Docker/Container Runtime
```pseudocode
FUNCTION cleanup_test_containers(cli_host):
    ids = docker('ps -a --filter label=devcontainer.is_test_run=true --format {{.ID}}')
    FOR id IN ids: docker('rm -f', id)
END FUNCTION

FUNCTION create_container_from_workspace(params, workspace, input):
    // Uses devcontainers engine helpers to launch; honors base_image/remote_user where applicable
    launch_devcontainer(workspace, base_image=input.base_image, remote_user=input.remote_user)
END FUNCTION
```

### File System
- Reads `test/<feature>/test.sh`, optional `test/<feature>/scenarios.json`, and per‑scenario scripts `<scenario>.sh`.
- Copies test directories into ephemeral workspace folders for execution; writes a helper script `dev-container-features-test-lib` alongside.
- Scenario files are JSONC; parse with tolerant parser.

## 8. Data Flow Diagrams

```
┌───────────────┐
│ CLI Arguments │
└──────┬────────┘
       │
       ▼
┌───────────────────┐
│ Parse & Validate  │
└──────┬────────────┘
       │
       ▼
┌───────────────────┐      ┌──────────────┐
│ Select Tests      │◀────▶│ test/ layout │
└──────┬────────────┘      └──────────────┘
       │
       ▼
┌───────────────────┐  docker  ┌────────────────┐
│ Prepare Workspace │──────────▶│ Launch/Execute │
└──────┬────────────┘          └────────────────┘
       │                              │
       ▼                              ▼
┌───────────────────┐          ┌───────────────┐
│ Collect Results   │─────────▶│ Summarize/Exit│
└───────────────────┘          └───────────────┘
```

## 9. Error Handling Strategy

### User Errors

#### Missing Project Structure
- **Missing `src/` directory**:
  - Message: `"Collection directory missing required 'src' subdirectory. Expected: <path>/src"`
  - Exit code: 1
  - Fails before test discovery

- **Missing `test/` directory**:
  - Message: `"Collection directory missing required 'test' subdirectory. Expected: <path>/test"`
  - Exit code: 1
  - Fails before test discovery

#### Missing Test Scripts
- **Missing `test.sh` for feature** (when autogenerated tests enabled):
  - Message: `"Missing autogenerated test script for feature '<id>' - expected: <path>/test/<id>/test.sh"`
  - Exit code: 1
  - Fails during test discovery (after validating project structure)
  - To skip: Use `--skip-autogenerated`

#### Invalid Flag Combinations
- **`--global-scenarios-only` with `--features`**:
  - Message: `"--global-scenarios-only and --features are mutually exclusive"`
  - Exit code: 1
  - Fails immediately during argument parsing

- **`--skip-scenarios` with `--global-scenarios-only`**:
  - Message: `"--skip-scenarios cannot be combined with --global-scenarios-only"`
  - Exit code: 1
  - Fails immediately during argument parsing

- **`--skip-scenarios` with `--filter`**:
  - Message: `"--skip-scenarios cannot be combined with --filter"`
  - Exit code: 1
  - Fails immediately during argument parsing

#### Not Implemented Features
- **`--permit-randomization` flag**:
  - Message: `"Not implemented yet: randomization"`
  - Exit code: 1
  - Fails immediately during argument validation
  - Reserved for future randomized test ordering

### Configuration Errors

#### Scenario Parsing Errors
- **Malformed `scenarios.json` or `scenarios.jsonc`**:
  - Message: Lists parse errors with file path and (when available) line/column numbers
  - Example: `"Failed to parse scenarios.json at <path>: unexpected token at line 5, column 12"`
  - Exit code: 1
  - Fails during scenario discovery

- **Invalid scenario schema**:
  - Message: Describes validation failure (e.g., missing required fields)
  - Exit code: 1
  - Fails during scenario discovery

### System Errors

#### Container Runtime Errors
- **Docker/Podman unavailable**:
  - Message: Surfaces stderr from runtime (e.g., `"Cannot connect to Docker daemon"`)
  - Exit code: 1
  - Fails when attempting to create first test container

- **Image pull/build failures**:
  - Message: Surfaces docker error with image reference
  - Example: `"Failed to pull image 'nonexistent:tag': manifest not found"`
  - Exit code: 1
  - Fails during container creation for affected test

- **Container creation failures**:
  - Message: Surfaces runtime error with context (feature/scenario name)
  - Exit code: 1
  - Individual test marked as failed; other tests may continue

#### Test Execution Errors
- **Script execution failures** (non-zero exit from test script):
  - Test marked as `result: false` in results
  - stderr from script is logged
  - Does **not** halt execution; remaining tests continue
  - Final exit code: 1 (any failed test causes non-zero exit)

- **Cleanup failures** (when `--preserve-test-containers` not set):
  - Logged as warning to stderr: `"Warning: Failed to cleanup test containers: <error>"`
  - Does **not** affect exit code
  - Can be suppressed with `--quiet`

### Error Output Format

#### Text Mode
Errors are written to stderr with clear, actionable messages:
```
Error: <description>
Expected: <what was expected>
Got: <what was found (if applicable)>
```

#### JSON Mode
- Errors still go to stderr (never to stdout)
- stdout may contain partial results array if error occurs mid-execution
- Validation errors (flag conflicts, missing directories) may result in empty stdout
- Exit code always reflects error status (1 for any error)

### Fail-Fast vs. Continue-on-Error

#### Fail-Fast (halts immediately)
- Missing `src/` or `test/` directories
- Invalid flag combinations
- Missing required test scripts (when applicable)
- Scenario parsing errors
- Container runtime unavailable

#### Continue-on-Error (reports and continues)
- Individual test failures (script exits non-zero)
- Container creation failures for specific tests
- Cleanup failures (logged as warning)

### No Silent Fallbacks
The implementation follows a **no silent fallbacks** policy:
- Missing required resources → explicit error (not skipped silently)
- Invalid configuration → explicit error (not ignored with warning)
- Unimplemented features → explicit error (not logged as "not supported yet" and skipped)

## 10. Output Specifications

### Text Mode (Default)

#### Standard Output
Text mode writes human-readable output to stdout, including:
- **Banner**: CLI version and subcommand identification
- **Per-test logs**: Execution status with timestamps and formatted messages
- **Summary**: Final test results with pass/fail counts

#### Example: Successful Test Run
```
Running tests for feature 'my-feature'...
✓ my-feature (autogenerated)
✓ my-feature (duplicate/idempotence)
✓ my-feature:scenario-basic
✓ my-feature:scenario-advanced

Running global scenarios...
✓ _global:cross-feature-test

Test Summary:
  Passed: 5
  Failed: 0
  Total:  5

All tests passed!
```

#### Example: Failed Test Run
```
Running tests for feature 'my-feature'...
✓ my-feature (autogenerated)
✗ my-feature (duplicate/idempotence)
✓ my-feature:scenario-basic

Test Summary:
  Passed: 2
  Failed: 1
  Total:  3

Tests failed.
```

#### Example: Zero Tests Found
```
No tests found
```
Exit code: 0 (zero tests is not an error)

#### Quiet Mode
When `--quiet` is specified:
- Suppresses informational output and progress indicators
- Still displays failure messages and final summary
- Warnings (e.g., cleanup failures) are suppressed

### JSON Mode (`--json`)

#### Output Contract
When `--json` is specified:
- **stdout**: Contains **only** a strict JSON array of test results
- **stderr**: Contains all logs, diagnostics, and human-readable messages
- **Schema**: `[{ "test_name": string, "result": boolean }]`

#### JSON Schema
```typescript
type TestResult = {
  test_name: string;  // Test identifier (e.g., "feature:scenario" or "_global:scenario")
  result: boolean;    // true = passed (exit 0), false = failed (non-zero exit)
}

type TestOutput = TestResult[];
```

#### Example: Successful JSON Output
**stdout:**
```json
[
  {"test_name":"my-feature","result":true},
  {"test_name":"my-feature (duplicate/idempotence)","result":true},
  {"test_name":"my-feature:scenario-basic","result":true},
  {"test_name":"my-feature:scenario-advanced","result":true},
  {"test_name":"_global:cross-feature-test","result":true}
]
```

**stderr:**
```
2024-11-05T10:15:23Z INFO Discovered 1 features
2024-11-05T10:15:24Z INFO Running tests for feature 'my-feature'
2024-11-05T10:15:30Z INFO All tests passed
```

#### Example: Failed JSON Output
**stdout:**
```json
[
  {"test_name":"my-feature","result":true},
  {"test_name":"my-feature (duplicate/idempotence)","result":false},
  {"test_name":"my-feature:scenario-basic","result":true}
]
```

**stderr:**
```
2024-11-05T10:15:23Z INFO Discovered 1 features
2024-11-05T10:15:24Z INFO Running tests for feature 'my-feature'
2024-11-05T10:15:28Z ERROR Duplicate/idempotence test failed for 'my-feature'
2024-11-05T10:15:30Z ERROR Tests failed
```

#### Example: Zero Tests (JSON Mode)
**stdout:**
```json
[]
```

**stderr:**
```
2024-11-05T10:15:23Z INFO No tests found matching criteria
```
Exit code: 0

#### JSON Output Guarantees
1. **Purity**: stdout contains **only** the JSON array (no logs, banners, or diagnostics)
2. **Validity**: Output is always valid JSON (even on partial failures)
3. **Completeness**: Array includes results for all executed tests (autogenerated, duplicate, scenario)
4. **Order**: Results appear in execution order (autogenerated → duplicate → scenarios)
5. **Zero-tests**: Empty array `[]` for zero tests (not omitted or null)

### Standard Error (Both Modes)

stderr is used for:
- Log messages (controlled by `--log-level`)
- Warnings (e.g., cleanup failures, deprecated flag usage)
- Internal diagnostics
- Error messages from validation failures

stderr obeys `--log-level` and `--quiet` settings. In JSON mode, stderr is the **only** destination for human-readable output.

### Exit Codes

| Code | Meaning | Condition |
|------|---------|-----------|
| `0` | Success | All tests passed **OR** zero tests found |
| `1` | Failure | Any test failed **OR** validation error (e.g., missing `src/`, flag conflict) |

**Important**: Zero tests is **not** an error. The command exits 0 with "No tests found" (text) or `[]` (JSON).

### Output Examples by Scenario

#### Validation Error: Missing `src/` Directory
**Text Mode (stderr):**
```
Error: Collection directory missing required 'src' subdirectory
Expected: /path/to/collection/src
```
Exit code: 1

**JSON Mode (stderr):**
```
2024-11-05T10:15:23Z ERROR Collection directory missing required 'src' subdirectory
```
Exit code: 1 (stdout may be empty or contain partial results)

#### Validation Error: Flag Conflict
**Text Mode (stderr):**
```
Error: --global-scenarios-only and --features are mutually exclusive
```
Exit code: 1

#### Validation Error: Missing Autogenerated Test
**Text Mode (stderr):**
```
Error: Missing autogenerated test script for feature 'my-feature' - expected: /path/to/test/my-feature/test.sh
```
Exit code: 1

## 11. Performance Considerations
- Serial execution by default; scenario containers are launched sequentially.
- Potential optimization: parallelize independent scenarios with resource caps; ensure logs remain readable.
- Resource Limits: Constrained by Docker and host; no special tuning performed.

## 12. Security Considerations
- Running arbitrary test scripts; treat as untrusted code. Recommend sandboxing on CI and redacting secrets from logs.
- No secrets are read by default; environment comes from scenarios. Avoid mounting sensitive host paths.
- Containers are ephemeral and removed by default to limit footprint.

## 13. Cross-Platform Behavior

| Aspect | Linux | macOS | Windows | WSL2 |
|--------|-------|-------|---------|------|
| Path handling | POSIX paths | POSIX paths | Paths normalized via CLI host | POSIX within WSL |
| Docker socket | `/var/run/docker.sock` | Docker Desktop | Docker Desktop | WSL2 distro docker |
| User ID mapping | Uses `remoteUser` if provided | Same | `remoteUser` resolved in container | Same |

## 14. Edge Cases and Corner Cases

### Empty Test Collections
- **Empty `test/` directory**: Zero tests found → exit 0 with "No tests found" (text) or `[]` (JSON)
- **No matching features**: When `--features` lists non-existent IDs → error (not silently ignored)
- **Filter matches nothing**: When `--filter` matches no scenarios → zero tests found → exit 0

### Zero Tests Scenarios
All of the following exit 0 with appropriate zero-tests output:
- `--skip-scenarios --skip-autogenerated --skip-duplicated` (all test types skipped)
- `--filter "nonexistent"` (filter matches nothing)
- Empty collection with valid structure (`src/` and `test/` exist but are empty)
- `--global-scenarios-only` when `test/_global/` doesn't exist or is empty

### Global Scenarios Edge Cases
- **`test/_global/` missing**: Not an error; global scenarios silently skipped if directory doesn't exist
- **`test/_global/` empty**: Zero global scenarios discovered; other tests proceed normally
- **`--features` excludes globals**: When any `--features` list is provided, `_global` scenarios are excluded (even if listing all features)
- **Duplicate/idempotence with `--global-scenarios-only`**: Automatically disabled (global scenarios have no features to test)

### Scenario Discovery
- **Both `.json` and `.jsonc` present**: Prefers `scenarios.json` over `scenarios.jsonc` (deterministic precedence)
- **Scenario names colliding with filesystem reserved names**: Allowed; used as-is in test names (may cause issues on Windows with names like `CON`, `NUL`)
- **Scenarios with special characters**: Scenario names are used verbatim; no sanitization performed
- **Empty `scenarios.json`**: Valid; feature has zero scenarios

### Container and Runtime
- **Network partitions during image pulls**: Runtime error propagated; test fails with clear message
- **Container exits unexpectedly during test**: Test marked as failed; remaining tests continue
- **Out of disk space**: Runtime error; may affect current and subsequent tests
- **Container runtime restart mid-execution**: Tests fail; no automatic retry

### Filesystem
- **Read-only filesystem in ephemeral workspace**: Fail fast with filesystem error
- **Permissions issues on test scripts**: Runtime error when attempting to execute; test fails
- **Symlinks in `test/` or `src/`**: Followed transparently during discovery
- **Non-UTF8 filenames**: May cause discovery errors on some platforms

### Cleanup
- **Cleanup fails with `--preserve-test-containers`**: No cleanup attempted; no warnings
- **Cleanup fails without preserve flag**: Warning to stderr (unless `--quiet`); exit code unaffected
- **Containers already removed**: Cleanup succeeds silently (idempotent)
- **Permission denied on cleanup**: Warning logged; exit code unaffected

### Output and Logging
- **stdout/stderr not writable**: Process crashes with OS-level error
- **JSON mode with invalid UTF-8 in test output**: Test name may be sanitized; result still valid JSON
- **Extremely long test names**: No truncation; full name included in output
- **Concurrent writes to stdout/stderr**: Synchronized; no interleaving corruption

## 15. Testing Strategy

```pseudocode
TEST SUITE: features test
  TEST "happy path single feature":
    GIVEN valid feature test.sh
    WHEN run with --features <id>
    THEN exit 0 and show success summary

  TEST "scenario parsing error":
    GIVEN malformed scenarios.json
    WHEN run
    THEN exit 1 and list parse errors

  TEST "flag exclusivity":
    GIVEN --global-scenarios-only and -f provided
    THEN argument parser errors before execution

  TEST "cleanup behavior":
    GIVEN containers created
    WHEN run without --preserve-test-containers
    THEN no containers remain with test label
END SUITE
```

## 16. Migration Notes
- Deprecated Behavior: Positional `target` is deprecated in favor of `--project-folder`.
- Breaking Changes: None.
- Compatibility Shims: Continue to accept positional but prefer and document `--project-folder`.

### Selected Design Decisions

#### Design Decision: Dual test modalities (autogenerated + scenarios)
Implementation Behavior:
- Runs `test.sh` for each feature as a smoke test; also runs named scenarios from JSONC with separate scripts.

Specification Guidance:
- Spec defines feature composition; testing is out‑of‑scope but follows best practices for validating install hooks and options.

Rationale:
- Autogenerated tests catch basic regressions cheaply; scenarios capture complex dependency chains and options.

Alternatives Considered:
- Only scenario tests; slower to author and run.

Trade-offs:
- More moving parts; better coverage and developer ergonomics.

