This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.devcontainer/
  devcontainer.json
  Dockerfile
.github/
  workflows/
    dev-containers.yml
    publish-dev-containers.yml
    test-plan-item-validator.yml
    test-windows.yml
  dependabot.yml
docs/
  features/
    test.md
  templates/
    apply.md
    publish.md
example-usage/
  ci-app-build-script/
    build-application.sh
  image-build/
    build-image.sh
  tool-openvscode-server/
    server/
      init-openvscode-server.sh
    start.sh
  tool-vim-via-ssh/
    server/
      init-vim.sh
    start.sh
  tool-vscode-server/
    server/
      init-vscode-server.sh
    start.sh
  workspace/
    .devcontainer/
      devcontainer.json
      Dockerfile
    scripts/
      execute-app-build.sh
    go.mod
    main.go
  README.md
images/
  README.md
scripts/
  gitAskPass.sh
  updateUID.Dockerfile
src/
  spec-common/
    async.ts
    cliHost.ts
    commonUtils.ts
    dotfiles.ts
    errors.ts
    git.ts
    injectHeadless.ts
    proc.ts
    shellServer.ts
    tsconfig.json
    variableSubstitution.ts
  spec-configuration/
    configuration.ts
    configurationCommonUtils.ts
    containerCollectionsOCI.ts
    containerCollectionsOCIPush.ts
    containerFeaturesConfiguration.ts
    containerFeaturesOCI.ts
    containerFeaturesOrder.ts
    containerTemplatesConfiguration.ts
    containerTemplatesOCI.ts
    controlManifest.ts
    editableFiles.ts
    featureAdvisories.ts
    httpOCIRegistry.ts
    lockfile.ts
    tsconfig.json
  spec-node/
    collectionCommonUtils/
      generateDocsCommandImpl.ts
      package.ts
      packageCommandImpl.ts
      publish.ts
      publishCommandImpl.ts
    featuresCLI/
      generateDocs.ts
      info.ts
      package.ts
      packageCommandImpl.ts
      publish.ts
      resolveDependencies.ts
      test.ts
      testCommandImpl.ts
      utils.ts
    templatesCLI/
      apply.ts
      generateDocs.ts
      metadata.ts
      packageImpl.ts
      publish.ts
    typings/
      node-pty.d.ts
    configContainer.ts
    containerFeatures.ts
    devContainers.ts
    devContainersSpecCLI.ts
    disallowedFeatures.ts
    dockerCompose.ts
    dockerfileUtils.ts
    featureUtils.ts
    imageMetadata.ts
    singleContainer.ts
    tsconfig.json
    upgradeCommand.ts
    utils.ts
  spec-shutdown/
    dockerUtils.ts
    tsconfig.json
  spec-utils/
    event.ts
    httpRequest.ts
    pfs.ts
    product.ts
    strings.ts
    tsconfig.json
    workspaces.ts
  test/
    configs/
      compose-Dockerfile-alpine/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
          Dockerfile
      compose-Dockerfile-with-features/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
          Dockerfile
      compose-Dockerfile-with-target/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
          Dockerfile
      compose-Dockerfile-without-features/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
          Dockerfile
      compose-image-with-features/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-image-with-mounts/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-image-without-features/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-image-without-features-minimal/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-with-name/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-with-name-and-custom-yaml/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-with-name-using-env-var/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      compose-without-name/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      disallowed-features/
        .devcontainer/
          allowed/
            devcontainer.json
          disallowed/
            devcontainer.json
      dockerfile-with-features/
        .devcontainer.json
        Dockerfile
      dockerfile-with-parallel-commands/
        .devcontainer.json
        Dockerfile
      dockerfile-with-syntax/
        .devcontainer.json
        Dockerfile
      dockerfile-with-target/
        .devcontainer.json
        Dockerfile
      dockerfile-without-features/
        .devcontainer/
          subfolder/
            devcontainer.json
            Dockerfile
        .devcontainer.json
        Dockerfile
      example/
        .devcontainer.json
      image/
        .devcontainer.json
      image-containerEnv-issue/
        .devcontainer/
          devcontainer.json
          docker-compose.yml
      image-metadata/
        .devcontainer/
          localFeatureA/
            devcontainer-feature.json
            install.sh
          localFeatureB/
            devcontainer-feature.json
            install.sh
          devcontainer.json
        base-image/
          Dockerfile
      image-metadata-containerEnv/
        .devcontainer/
          devcontainer.json
      image-with-features/
        .devcontainer.json
      image-with-git-feature/
        .devcontainer.json
      image-with-local-feature/
        .devcontainer.json
      image-with-mounts/
        .devcontainer/
          devcontainer.json
      image-with-parallel-initialize-command/
        .devcontainer.json
      poetry-example/
        .devcontainer.json
      set-up-with-config/
        devcontainer.json
      set-up-with-metadata/
        Dockerfile
      updateUID/
        .devcontainer.json
        Dockerfile
      updateUIDamd64/
        .devcontainer.json
        Dockerfile
      updateUIDamd64-platform-option/
        .devcontainer.json
        Dockerfile
      updateUIDarm64/
        .devcontainer.json
        Dockerfile
      updateUIDarm64-platform-option/
        .devcontainer.json
        Dockerfile
      updateUIDarm64v8/
        .devcontainer.json
        Dockerfile
      updateUIDarm64v8-platform-option/
        .devcontainer.json
        Dockerfile
      updateUIDOnly/
        .devcontainer.json
        Dockerfile
      test-secrets.json
    container-features/
      configs/
        dockerfile-with-v2-local-features-config-inside-dev-container-folder/
          .devcontainer/
            localFeatureA/
              devcontainer-feature.json
              install.sh
            localFeatureB/
              devcontainer-feature.json
              install.sh
            devcontainer.json
            Dockerfile
        dockerfile-with-v2-local-features-config-outside-dev-container-folder/
          .devcontainer/
            localFeatureA/
              devcontainer-feature.json
              install.sh
            localFeatureB/
              devcontainer-feature.json
              install.sh
          .devcontainer.json
          Dockerfile
          README.md
        dockerfile-with-v2-oci-features/
          .devcontainer.json
          Dockerfile
        example-installsAfter/
          .devcontainer.json
        example-legacyIds/
          .devcontainer.json
        example-legacyIds-2/
          .devcontainer.json
        feature-dependencies/
          dependsOn/
            invalid-circular/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            local-simple/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            local-with-options/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                d/
                  devcontainer-feature.json
                  install.sh
                e/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            oci-ab/
              .devcontainer/
                devcontainer.json
            oci-fgh/
              .devcontainer/
                devcontainer.json
            oci-ij/
              .devcontainer/
                devcontainer.json
            tgz-ab/
              .devcontainer/
                devcontainer.json
          dependsOn-and-installsAfter/
            a/
              .devcontainer.json
            local-simple/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
          installsAfter/
            invalid-circular/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            local-simple/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
          overrideFeatureInstallOrder/
            image-with-v1-features-with-overrideFeatureInstallOrder/
              .devcontainer/
                devcontainer.json
            image-with-v2-features-with-overrideFeatureInstallOrder/
              .devcontainer/
                localFeatureA/
                  devcontainer-feature.json
                  install.sh
                localFeatureB/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            local-intermediate/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                d/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            local-roundPriority/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            local-simple/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                d/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
            mixed/
              .devcontainer/
                a/
                  devcontainer-feature.json
                  install.sh
                b/
                  devcontainer-feature.json
                  install.sh
                c/
                  devcontainer-feature.json
                  install.sh
                d/
                  devcontainer-feature.json
                  install.sh
                devcontainer.json
        image-with-v1-features-node-python-local-cache/
          .devcontainer.json
        image-with-v2-tarball/
          .devcontainer.json
        invalid-configs/
          dockerfile-with-v2-local-features-no-dev-container-folder/
            local-features/
              localFeatureA/
                devcontainer-feature.json
                install.sh
              localFeatureB/
                devcontainer-feature.json
                install.sh
            .devcontainer.json
            Dockerfile
          invalid-v1-features/
            .devcontainer.json
          invalid-v2-features/
            .devcontainer.json
        lifecycle-hooks-advanced/
          .devcontainer/
            otter/
              devcontainer-feature.json
              helper_script.sh
              install.sh
            rabbit/
              devcontainer-feature.json
              helper_script.sh
              install.sh
            devcontainer.json
            Dockerfile
            helper_script.sh
        lifecycle-hooks-inline-commands/
          .devcontainer/
            panda/
              devcontainer-feature.json
              install.sh
            tiger/
              devcontainer-feature.json
              install.sh
            createMarker.sh
            devcontainer.json
            Dockerfile
        lifecycle-hooks-resume-existing-container/
          .devcontainer/
            hippo/
              createMarker.sh
              devcontainer-feature.json
              install.sh
            devcontainer.json
            Dockerfile
        lockfile/
          .devcontainer.json
          .gitignore
          expected.devcontainer-lock.json
        lockfile-dependson/
          .devcontainer.json
          .gitignore
          expected.devcontainer-lock.json
        lockfile-frozen/
          .devcontainer-lock.json
          .devcontainer.json
        lockfile-generate-from-empty-file/
          .devcontainer/
            devcontainer.json
        lockfile-generate-from-empty-file-frozen/
          .devcontainer/
            devcontainer.json
        lockfile-oci-integrity/
          .devcontainer-lock.json
          .devcontainer.json
        lockfile-outdated/
          .devcontainer.json
          .gitignore
          expected.devcontainer-lock.json
          original.devcontainer-lock.json
        lockfile-outdated-command/
          .devcontainer-lock.json
          .devcontainer.json
        lockfile-tarball-integrity/
          .devcontainer-lock.json
          .devcontainer.json
        lockfile-upgrade-command/
          .devcontainer.json
          .gitignore
          outdated.devcontainer-lock.json
          upgraded.devcontainer-lock.json
        lockfile-upgrade-feature/
          .gitignore
          expected.devcontainer.json
          input.devcontainer.json
        registry-compatibility/
          azure-anonymous/
            .devcontainer.json
          azure-registry-scoped/
            .devcontainer.json
          github-anonymous/
            .devcontainer.json
          github-private/
            .devcontainer.json
      example-v2-features-sets/
        a-installs-after-b/
          src/
            a/
              devcontainer-feature.json
              install.sh
            b/
              devcontainer-feature.json
              install.sh
          test/
            a/
              test.sh
            b/
              test.sh
        autogenerated-set-flags/
          src/
            hey/
              devcontainer-feature.json
              install.sh
          test/
            hey/
              test.sh
        b-installs-after-a/
          src/
            a/
              devcontainer-feature.json
              install.sh
            b/
              devcontainer-feature.json
              install.sh
          test/
            a/
              test.sh
            b/
              test.sh
        dependsOn/
          src/
            A/
              devcontainer-feature.json
              install.sh
            B/
              devcontainer-feature.json
              install.sh
            C/
              devcontainer-feature.json
              install.sh
            D/
              devcontainer-feature.json
              install.sh
            E/
              devcontainer-feature.json
              install.sh
            F/
              devcontainer-feature.json
              install.sh
            G/
              devcontainer-feature.json
              install.sh
            H/
              devcontainer-feature.json
              install.sh
            I/
              devcontainer-feature.json
              install.sh
            J/
              devcontainer-feature.json
              install.sh
        dependsOn-and-installsAfter/
          src/
            A/
              devcontainer-feature.json
              install.sh
            B/
              devcontainer-feature.json
              install.sh
            C/
              devcontainer-feature.json
              install.sh
            D/
              devcontainer-feature.json
              install.sh
            E/
              devcontainer-feature.json
              install.sh
        dockerfile-scenario-test/
          src/
            smile/
              devcontainer-feature.json
              install.sh
          test/
            smile/
              frowning_with_a_dockerfile/
                Dockerfile
              frowning_with_a_dockerfile.sh
              frowning.sh
              scenarios.json
              smiling.sh
              test.sh
        failing-test/
          src/
            hello/
              devcontainer-feature.json
              install.sh
          test/
            hello/
              test.sh
        installs-after-advanced/
          src/
            zzz/
              devcontainer-feature.json
              install.sh
          test/
            zzz/
              scenarios.json
              with-node-is-versioned.sh
              with-node-un-versioned.sh
        lifecycle-hooks/
          src/
            a/
              devcontainer-feature.json
              install.sh
            b/
              devcontainer-feature.json
              install.sh
          test/
            a/
              test.sh
            b/
              test.sh
        remote-user/
          src/
            whoisremoteuser/
              devcontainer-feature.json
              install.sh
          test/
            whoisremoteuser/
              add_with_common_utils.sh
              from_image_metadata_label_flag_disabled.sh
              from_image_metadata_label_flag_enabled.sh
              scenarios.json
              test.sh
        renaming-feature/
          src/
            hello/
              devcontainer-feature.json
              install.sh
            new-color/
              devcontainer-feature.json
              install.sh
            not-a-feature/
              not-a-feature.sh
        sharing-test-scripts/
          src/
            util/
              devcontainer-feature.json
              install.sh
          test/
            util/
              a_different_script.sh
              a_helper_script_for_scenario.sh
              random_scenario.sh
              scenarios.json
              some_scenario_2.sh
              some_scenario.sh
              test.sh
        simple/
          src/
            color/
              devcontainer-feature.json
              install.sh
            hello/
              devcontainer-feature.json
              install.sh
            not-a-feature/
              not-a-feature.sh
          test/
            _global/
              custom_options.sh
              scenarios.json
              with_external_feature.sh
            color/
              duplicate.sh
              scenarios.json
              specific_color_scenario.sh
              test.sh
            hello/
              test.sh
      containerFeaturesOCI.test.ts
      containerFeaturesOCIPush.test.ts
      containerFeaturesOrder.test.ts
      e2e.test.ts
      featureAdvisories.test.ts
      featureHelpers.test.ts
      featuresCLICommands.test.ts
      generateFeaturesConfig.test.ts
      lifecycleHooks.test.ts
      lockfile.test.ts
      registryCompatibilityOCI.test.ts
    container-templates/
      example-templates-sets/
        simple/
          src/
            alpine/
              .devcontainer.json
              devcontainer-template.json
            cpp/
              .devcontainer/
                devcontainer.json
                Dockerfile
              devcontainer-template.json
            mytemplate/
              .devcontainer/
                devcontainer.json
              .github/
                dependabot.yml
              assets/
                hello.md
                hi.md
              example-projects/
                exampleA/
                  .github/
                    dependabot.yml
                  subFolderA/
                    a2.ts
                  a1.ts
                exampleB/
                  .github/
                    dependabot.yml
                  subFolderB/
                    b2.ts
              c1.ts
              c2.ts
              c3.ts
              devcontainer-template.json
            node-mongo/
              .devcontainer/
                devcontainer.json
                docker-compose.yml
              devcontainer-template.json
            not-a-template/
              not-a-template.sh
      containerTemplatesOCI.test.ts
      templatesCLICommands.test.ts
    cli.build.test.ts
    cli.exec.base.ts
    cli.exec.buildKit.1.test.ts
    cli.exec.buildKit.2.test.ts
    cli.exec.nonBuildKit.1.test.ts
    cli.exec.nonBuildKit.2.test.ts
    cli.podman.test.ts
    cli.set-up.test.ts
    cli.test.ts
    cli.up.test.ts
    disallowedFeatures.test.ts
    dockerComposeUtils.test.ts
    dockerfileUtils.test.ts
    dockerUtils.test.ts
    dotfiles.test.ts
    getEntPasswd.test.ts
    getHomeFolder.test.ts
    imageMetadata.test.ts
    testUtils.ts
    tsconfig.json
    updateUID.test.ts
    variableSubstitution.test.ts
.eslintignore
.eslintrc.js
.gitattributes
.gitignore
azure-pipelines.yml
CHANGELOG.md
CODEOWNERS
CONTRIBUTING.md
devcontainer.js
esbuild.js
LICENSE.txt
package.json
README.md
ThirdPartyNotices.txt
tsconfig.base.json
tsconfig.json
tsfmt.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".devcontainer/devcontainer.json">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/
{
	"name": "Dev Containers CLI",
	"build": {
		"dockerfile": "Dockerfile",
		"args": { 
			"VARIANT": "18-bookworm"
		}
	},
	"mounts": [
		// Keep command history across instances
		"source=dev-containers-cli-bashhistory,target=/home/node/commandhistory"
	],

	"postCreateCommand": "yarn install",

	"remoteUser": "node",
	
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {}
	},
	
	"customizations": {
		"vscode": {
			"extensions": [
				"dbaeumer.vscode-eslint",
				"GitHub.vscode-pull-request-github"
			]
		},
		"codespaces": {
			"repositories": {
				"devcontainers/features": {
					"permissions": {
						"contents": "write",
						"workflows": "write"
					}
				}
			}
		}
	}
}
</file>

<file path=".devcontainer/Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"
FROM mcr.microsoft.com/devcontainers/typescript-node:1-${VARIANT}

RUN mkdir -p /workspaces && chown node:node /workspaces

ARG USERNAME=node
USER $USERNAME

# Save command line history
RUN echo "export HISTFILE=/home/$USERNAME/commandhistory/.bash_history" >> "/home/$USERNAME/.bashrc" \
	&& echo "export PROMPT_COMMAND='history -a'" >> "/home/$USERNAME/.bashrc" \
	&& mkdir -p /home/$USERNAME/commandhistory \
	&& touch /home/$USERNAME/commandhistory/.bash_history \
	&& chown -R $USERNAME /home/$USERNAME/commandhistory
</file>

<file path=".github/workflows/dev-containers.yml">
name: Dev Containers CI

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'

jobs:
  cli:
    name: CLI
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v5
      with:
        node-version: '18.x'
        registry-url: 'https://npm.pkg.github.com'
        scope: '@microsoft'
    - name: Install Dependencies
      run: yarn install --frozen-lockfile
    - name: Type-Check
      run: yarn type-check
    - name: Lint
      run: yarn lint
    - name: Package
      run: yarn package
    - name: TGZ name
      run: |
        VERSION=$(jq -r '.version' < package.json)
        echo "TGZ=devcontainers-cli-${VERSION}.tgz" | tee -a $GITHUB_ENV
        echo "TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz" | tee -a $GITHUB_ENV
    - name: Store TGZ
      uses: actions/upload-artifact@v4
      with:
        name: ${{ env.TGZ_UPLOAD }}
        path: ${{ env.TGZ }}
  tests-matrix:
    name: Tests Matrix
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        mocha-args: [
          "src/test/container-features/containerFeaturesOrder.test.ts",
          "src/test/container-features/e2e.test.ts",
          "src/test/container-features/featuresCLICommands.test.ts",
          "src/test/cli.build.test.ts",
          "src/test/cli.exec.buildKit.1.test.ts",
          "src/test/cli.exec.buildKit.2.test.ts",
          "src/test/cli.exec.nonBuildKit.1.test.ts",
          "src/test/cli.exec.nonBuildKit.2.test.ts",
          "src/test/cli.podman.test.ts",
          "src/test/cli.test.ts",
          "src/test/cli.up.test.ts",
          "src/test/imageMetadata.test.ts",
          "src/test/container-features/containerFeaturesOCIPush.test.ts",
          # Run all except the above:
          "--exclude src/test/container-features/containerFeaturesOrder.test.ts --exclude src/test/container-features/registryCompatibilityOCI.test.ts --exclude src/test/container-features/containerFeaturesOCIPush.test.ts --exclude src/test/container-features/e2e.test.ts --exclude src/test/container-features/featuresCLICommands.test.ts --exclude src/test/cli.build.test.ts --exclude src/test/cli.exec.buildKit.1.test.ts --exclude src/test/cli.exec.buildKit.2.test.ts --exclude src/test/cli.exec.nonBuildKit.1.test.ts --exclude src/test/cli.exec.nonBuildKit.2.test.ts --exclude src/test/cli.podman.test.ts --exclude src/test/cli.test.ts --exclude src/test/cli.up.test.ts --exclude src/test/imageMetadata.test.ts 'src/test/**/*.test.ts'",
        ]
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: '18.x'
        registry-url: 'https://npm.pkg.github.com'
        scope: '@microsoft'
    - name: Tools Info
      run: |
        docker info
        docker buildx version
        podman info
        podman buildx version
    - name: Install Dependencies
      run: |
        yarn install --frozen-lockfile
        docker run --privileged --rm tonistiigi/binfmt --install all
    - name: Type-Check
      run: yarn type-check
    - name: Package
      run: yarn package
    - name: Run Tests
      run: yarn test-matrix --forbid-only ${{ matrix.mocha-args }}
      env:
        CI: true

  features-registry-compatibility:
    name: OCI Implementation Registry Compatibility
    # TODO: This should be expanded to run on different platforms
    #       Most notably to test platform-specific credential helper behavior
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: '18.x'
        registry-url: 'https://npm.pkg.github.com'
        scope: '@microsoft'
    - name: Install Dependencies
      run: yarn install --frozen-lockfile
    - name: Type-Check
      run: yarn type-check
    - name: Package
      run: yarn package
    - name: Run Tests
      run: yarn test-matrix --forbid-only src/test/container-features/registryCompatibilityOCI.test.ts
      env:
        CI: true
        # This variable should only be set in the parent `devcontainers/cli` repo.
        RUNNING_IN_DEVCONTAINERS_CLI_REPO_CI: ${{ vars.RUNNING_IN_DEVCONTAINERS_CLI_REPO_CI }}
        # Scoped to read private packages in the `devcontainers` org (for testing purposes)
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        # Pull-only credential for a test Azure CR instance
        FEATURES_TEST__AZURE_REGISTRY_SCOPED_CREDENTIAL: ${{ secrets.FEATURES_TEST__AZURE_REGISTRY_SCOPED_CREDENTIAL }}


  tests:
    name: Tests
    needs: [tests-matrix, features-registry-compatibility]
    runs-on: ubuntu-latest
    steps:
    - name: Done
      run: echo Test Matrix done.
</file>

<file path=".github/workflows/publish-dev-containers.yml">
name: Publish @devcontainers/cli

on:
  push:
    tags:
      - 'v*'

jobs:
  main:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: '18.x'
        registry-url: 'https://registry.npmjs.org'
        scope: '@devcontainers'
    - name: Verify Versions
      run: |
        node -e "
          const packageRef = 'refs/tags/v' + require('./package.json').version;
          const githubRef = '${{ github.ref }}';
          if (packageRef !== githubRef && packageRef + '-pre-release' != githubRef) {
            console.log('::error::' + 'Version Mismatch.', packageRef, githubRef);
            throw Error('Version Mismatch');
          }
        "
    - name: TGZ name
      run: |
        VERSION=$(jq -r '.version' < package.json)
        echo "TGZ=devcontainers-cli-${VERSION}.tgz" | tee -a $GITHUB_ENV
        echo "TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz" | tee -a $GITHUB_ENV
    - name: Download TGZ
      uses: dawidd6/action-download-artifact@ac66b43f0e6a346234dd65d4d0c8fbb31cb316e5 # v11
      with:
        workflow: dev-containers.yml
        workflow_conclusion: success
        commit: ${{ github.sha }}
        name: ${{ env.TGZ_UPLOAD }}
        path: .
    - name: Publish TGZ
      run: npm publish ${TGZ} --access public
      env:
        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}
</file>

<file path=".github/workflows/test-plan-item-validator.yml">
name: Test Plan Item Validator
on:
  issues:
    types: [edited]

jobs:
  main:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Actions
        if: contains(github.event.issue.labels.*.name, 'testplan-item') || contains(github.event.issue.labels.*.name, 'invalid-testplan-item')
        uses: actions/checkout@v4
        with:
          repository: 'microsoft/vscode-github-triage-actions'
          ref: stable
      - name: Install Actions
        if: contains(github.event.issue.labels.*.name, 'testplan-item') || contains(github.event.issue.labels.*.name, 'invalid-testplan-item')
        run: npm install --production
      - name: Run Test Plan Item Validator
        if: contains(github.event.issue.labels.*.name, 'testplan-item') || contains(github.event.issue.labels.*.name, 'invalid-testplan-item')
        uses: ./test-plan-item-validator
        with:
          label: testplan-item
          invalidLabel: invalid-testplan-item
          comment: Invalid test plan item. See errors below and the [test plan item spec](https://github.com/microsoft/vscode/wiki/Writing-Test-Plan-Items) for more information. This comment will go away when the issues are resolved.
</file>

<file path=".github/workflows/test-windows.yml">
name: Test (Windows)

defaults:
  run:
    shell: bash

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
jobs:
 tests-matrix:
    name: Tests Matrix (Windows)
    runs-on: windows-latest
    strategy:
      fail-fast: false
      matrix:
        mocha-args-windows: [
          # "src/test/cli.build.test.ts",
          # "src/test/cli.exec.buildKit.1.test.ts",
          # "src/test/cli.exec.buildKit.2.test.ts",
          # "src/test/cli.exec.nonBuildKit.1.test.ts",
          # "src/test/cli.exec.nonBuildKit.2.test.ts",
          # "src/test/cli.test.ts",
          # "src/test/cli.up.test.ts",
          "src/test/container-features/containerFeaturesOCI.test.ts",
          # "src/test/container-features/containerFeaturesOCIPush.test.ts",
          # "src/test/container-features/containerFeaturesOrder.test.ts",
          # "src/test/container-features/e2e.test.ts",
          # "src/test/container-features/featureHelpers.test.ts",
          # "src/test/container-features/featuresCLICommands.test.ts",
          "src/test/container-features/generateFeaturesConfig.test.ts",
          # "src/test/container-templates/containerTemplatesOCI.test.ts",
          # "src/test/container-templates/templatesCLICommands.test.ts",
          # "src/test/dockerComposeUtils.test.ts",
          # "src/test/dockerfileUtils.test.ts",
          # "src/test/dockerUtils.test.ts",
          # "src/test/imageMetadata.test.ts",
          # "src/test/variableSubstitution.test.ts",
          # "src/test/container-features/registryCompatibilityOCI.test.ts",
          # # Run all except the above:
          # "--exclude .....",
        ]
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: '18.x'
        registry-url: 'https://npm.pkg.github.com'
        scope: '@microsoft'
    - name: Install Dependencies
      run: yarn install --frozen-lockfile
    - name: Type-Check
      run: yarn type-check
    - name: Package
      run: yarn package
    - name: Run Tests
      run: yarn test-matrix --forbid-only ${{ matrix.mocha-args-windows }}
</file>

<file path=".github/dependabot.yml">
version: 2
updates:
  - package-ecosystem: "devcontainers"
    directory: "/"
    schedule:
      interval: "weekly"

  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"

  - package-ecosystem: "npm"
    directory: "/"
    groups:
      all:
        patterns:
          - "*"
    ignore:
      - dependency-name: "@stylistic/eslint-plugin"
        update-types: ["version-update:semver-major"] # stylistic 3 to avoid esm
      - dependency-name: "@types/chai"
        update-types: ["version-update:semver-major"] # chai 4 to avoid esm
      - dependency-name: "@types/node"
        update-types: ["version-update:semver-major"] # Keep Node 18 compatibility
      - dependency-name: "@types/tar"
        update-types: ["version-update:semver-major"] # tar 6 for source compatibility
      - dependency-name: "chai"
        update-types: ["version-update:semver-major"] # chai 4 to avoid esm
      - dependency-name: "eslint"
        update-types: ["version-update:semver-major"] # eslint 8 for `--rulesdir`
      - dependency-name: "rimraf"
        update-types: ["version-update:semver-major"] # rimraf 5 for Node 18 compatibility
      - dependency-name: "tar"
        update-types: ["version-update:semver-major"] # tar 6 for source compatibility
    schedule:
      interval: "weekly"
</file>

<file path="docs/features/test.md">
# Testing Dev Container Features

A built-in testing framework for Features is in active development.  This command helps you iterate on [self-authored Features](https://containers.dev/implementors/features-distribution/).

The `test` command utilizes the CLI's `build` and `exec` commands to test Features in your local source tree.  The command will look at the `target` path for mirrored `src` and `test` directories ([example](https://github.com/devcontainers/features).  Without any additional arguments, the `test` command will auto-generate a test for each Feature (pulling the source code directly from `src/<FEATURE>`), and exec `test/<FEATURE>/test.sh` inside of the running container.  

For the test to pass, the container must (1) build the generated dev container and start successfully, and (2) execute the `test.sh` with a success (zero) exit code.  Note that auto-generated tests will execute the given Feature with default options.

There are additional 'modes' that run an additional set of tests per Feature if the required assertion script is present.  The table below highlights other modes:

| Mode | Use Case |  Details | CLI Flag |
| ---- | ----------- | ---------------- | ----- |
| Auto-generated | Auto-generates a barebones dev container with (1) the target Features, (2) the `--base-image`, and the (3) `--remote-user`) | Quick way to assert the default behavior of a Feature  | `--skip-autogenerated`
| Scenarios | Define more complicated test scenarios.  Use a scenario to test Feature options or >1 Feature in a container.  | [Details](#scenarios)| `--skip-scenarios`
| Duplicate Tests | A mode that will generate a dev container installing the same Feature twice with different options | [Details](#duplicate-style-tests)| `--skip-duplicated`

The source code of the sub-command is [here](../../src/spec-node/featuresCLI/test.ts). An example of the command being used in CI can be [found in the `devcontainers/feature-starter` repo](https://github.com/devcontainers/feature-starter/blob/main/.github/workflows/test.yaml) and the [`devcontainers/features` repo](https://github.com/devcontainers/features).

For more information on the `test` command, run `devcontainer features test --help`.

An example project structure can be found below.

```
.
├── README.md
├── src
│   ├── dotnet
│   │   ├── devcontainer-feature.json
│   │   └── install.sh
│   ├── oryx
│   │   ├── devcontainer-feature.json
│   │   └── install.sh
|   ├── ...
│   │   ├── devcontainer-feature.json
│   │   └── install.sh
├── test
│   ├── _global
│	│	├── scenarios.json
│   │   └── some_test_scenario.sh
│   ├── dotnet
|   |   ├── duplicate.sh
│   │   └── test.sh
│   ├── oryx
|   |   ├── scenarios.json
|   |   ├── install_dotnet_and_oryx.sh
│   |   └── test.sh
|   ├── ...
│   │   └── test.sh
...
```

To run all the `dotnet` related tests from a repo structured above, the command would be:

```bash
devcontainer features test  -f dotnet --base-image ubuntu
```

## Scenarios 

Scenarios are an additional mode that augments the auto-generated test (that is asserted with the `test/<FEATURE>/test.sh` script).  

Scenarios are snippets of `devcontainer.json` configuration.  The scenario is a JSON object, where the key is the test name, and the object is a `devcontainer.json`.

> The following example references the [`oryx` Feature](https://github.com/devcontainers/features/tree/2d89dc301ed834d74b07350c7d8567eee78f966d/test/oryx).

The following `scenarios.json` defines a single test scenario named `install_dotnet_and_oryx`.  The scenario will install the `dotnet` and `oryx` Features in the target repo with the provided options. 


##### test/oryx/scenarios.json
```json
{
    "install_dotnet_and_oryx": {
        "image": "ubuntu:focal",
        "features": {
            "dotnet": {
                "version": "6",
                "installUsingApt": "false"
            },
            "oryx": {}
        }
    }
}
```

The test command will build a container with the config above, and then look for a `.sh` test file with the same name.  The test will pass if the container builds successfully and the `install_dotnet_and_oryx.sh` shell script exits will a successful exit code (0).

##### test/install_dotnet_and_oryx.sh
```shell
#!/bin/bash

set -e

# Import test library for `check` command
source dev-container-features-test-lib

check "Oryx version" oryx --version
check "Dotnet is not removed if it is not installed by the Oryx Feature" dotnet --version

# Install platforms with oryx build tool
check "oryx-install-dotnet-2.1" oryx prep --skip-detection --platforms-and-versions dotnet=2.1.30
check "dotnet-2-installed-by-oryx" ls /opt/dotnet/ | grep 2.1

....
....

# Replicates Oryx's behavior for universal image
mkdir -p /opt/oryx
echo "vso-focal" >> /opt/oryx/.imagetype

mkdir -p /opt/dotnet/lts
cp -R /usr/local/dotnet/current/dotnet /opt/dotnet/lts
cp -R /usr/local/dotnet/current/LICENSE.txt /opt/dotnet/lts
cp -R /usr/local/dotnet/current/ThirdPartyNotices.txt /opt/dotnet/lts

....
....

# Report result
reportResults
```

### Providing additional build files (Dockerfile, lifecycle scripts, etc...)

The pattern below can be used to provide additional files to the container build.  The `test` command will look for a `test/<FEATURE>/<SCENARIO_NAME>` directory, and copy the contents into the hidden, intermediate `.devcontainer` folder used for the build.  This can be used to provide additional files to the container, such as a `Dockerfile` or lifecycle scripts.

For example, given a scenario defined in a Feature's `scenarios.json`:

```jsonc
// ...
	"frowning_with_a_dockerfile": {
		"build": {
			"dockerfile": "Dockerfile"
		},
		"features": {
			"smile": {
				"shouldFrown": true
			}
		}
	}
// ... 
```

The following file structure can be used to correctly "wire in" the Dockerfile for the build of this scenario:

```
.
├── src
│   └── smile
│       ├── devcontainer-feature.json
│       └── install.sh
└── test
    └── smile
        ├── frowning.sh
        ├── frowning_with_a_dockerfile  <------------ new folder   
        │   └── Dockerfile              <----- gets copied over to generated .devcontainer
        ├── frowning_with_a_dockerfile.sh
        ├── scenarios.json
        ├── smiling.sh
        └── test.sh
```

The intermediate `.devcontainer` folder will look similar to this.  Notice that the Dockerfile will be correctly evaluated since it is placed into the `.devcontainer` folder.  A full example is codified as a [test in this repository](https://github.com/devcontainers/cli/tree/de6be379622554c5c15fa5a02403006575e087b3/src/test/container-features/example-v2-features-sets/dockerfile-scenario-test).

```
/tmp/devcontainercli/container-features-test/1667949592814 $ tree -a
.
├── .devcontainer
│   ├── devcontainer.json
│   ├── Dockerfile
│   └── smile
│       ├── devcontainer-feature.json
│       └── install.sh
│
├── dev-container-features-test-lib
├── frowning.sh
├── frowning_with_a_dockerfile
│   └── Dockerfile
├── frowning_with_a_dockerfile.sh
├── scenarios.json
├── smiling.sh
└── test.sh
```

> NOTE: The flags `--global-scenarios-only`, `--skip-scenarios`, and `--skip-autogenerated` can be passed to run a subset of tests.

### Global Scenarios

The `test/_global` directory is a special directory that holds scenario tests not tied to a specific Feature. This directory is useful for scenarios that broadly tests several Features in a given repository.

The `--global-scenarios-only` can be passed to only run the global scenarios.

### Duplicate-style Tests

When executing the command without the `--skip-duplicated` flag, each Feature with a `duplicate.sh` will generate a test installing a given Feature twice (with different options).  This is useful for asserting that a Feature can be installed multiple times without conflict (is idempotent). Additionally, the options used for each distinct Feature are passed into the assertion script, should that be useful to write an assertion.

For example, the `dotnet` Feature above provided a `duplicate.sh`, therefore the test command will generate a dev container test case installing `dotnet` twice.

The generated dev container could look something like this:

#### `devcontainer.json`
```jsonc
{
    "image": "ubuntu",
    "features": {
        "./dotnet": {
            "version": "5",
            "installUsingApt": "false"
        },
        "./dotnet-0": {} // Default
    }
}
```

#### `duplicate.sh`
```shell
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# The values of the randomized options will be set as environment variables.
if [ -z "${VERSION}" ]; then
	echo "Version of dotnet to install from randomized Feature not set!"
	exit 1
fi

if [ -z "${INSTALLUSINGAPT}" ]; then
	echo "Boolean to install using apt from randomized Feature not set!"
	exit 1
fi

# The values of the default options will be set as environment variables.
if [ -z "${VERSION__DEFAULT}" ]; then
	echo "Version of dotnet to install default Feature not set!"
	exit 1
fi

if [ -z "${INSTALLUSINGAPT__DEFAULT}" ]; then
	echo "oolean to install using apt from default Feature not set!"
	exit 1
fi

check "randomized version of dotnet installed"  bash -c "dotnet --list-sdks | ${VERSION}"
check "default version of dotnet installed"  bash -c "dotnet --list-sdks | ${VERSION__DEFAULT}"

# ...
# ...

# Report result
reportResults
```


## dev-container-features-test-lib

The `dev-container-features-test-lib` is convenience helper [defined in the CLI](https://github.com/devcontainers/cli/blob/1910ca41015c627b884ddd69ebc52d1e8cdd8cf0/src/spec-node/featuresCLI/utils.ts#L59) that adds several bash functions to organize test asserts. Note that using this libary **is not required**.

#### `check <LABEL> <cmd> [args...]`
Description: Executes `cmd` and prints success/failed depending on exit code (0 === success) of `cmd`.
Note: Use quotes to include whitespace in the label or individual arguments for the command.
Example: `check "python is available" python3 --version`

##### reportResults
Prints results of check and checkMultiple
</file>

<file path="docs/templates/apply.md">
# Applying a Dev Container Template to a folder with the CLI

## Summary

The CLI can be used to apply (download) a [Dev Container Template](https://containers.dev/implementors/templates) to a provided folder.  

Templates can be published via the `templates publish` command - see [the template-starter repo](https://github.com/devcontainers/template-starter) for more information.

To see all the available options, run `devcontainers templates apply --help`.

## Example

To apply the [debian template](https://github.com/devcontainers/templates/tree/main/src/debian) to a local folder with the CLI, execute the following steps.

```
[/tmp]$ mkdir my-project

[/tmp]$ devcontainer templates apply \
                 -t 'ghcr.io/devcontainers/templates/debian' \
                 -a '{"imageVariant": "buster"}' \
                 -w ./my-project

[0 ms] @devcontainers/cli 0.28.0. Node.js v19.3.0. darwin 21.6.0 arm64.
{"files":["./.devcontainer/devcontainer.json"]}

[/tmp]$ tree -a my-project

my-project
└── .devcontainer
    └── devcontainer.json

1 directory, 1 file

[/tmp]$ cat my-project/.devcontainer/devcontainer.json

{
	"name": "Debian",
	// Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile
	"image": "mcr.microsoft.com/devcontainers/base:buster"

	// Features to add to the dev container. More info: https://containers.dev/features.
	// "features": {},

	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [],

	// Configure tool-specific properties.
	// "customizations": {},

	// Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.
	// "remoteUser": "root"
}
```

Any omitted `templateArgs` will be substituted with the `default` value declared in the Template's `devcontainer-template.json`.
</file>

<file path="docs/templates/publish.md">
# Publishing Dev Container Templates

> NOTE: You may want to first check out our [templates-starter](https://github.com/devcontainers/template-starter), which includes an example [actions workflow](https://github.com/devcontainers/action) for publishing directly out of your GitHub repo!

## Summary

The CLI can be used to publish [Dev Container Template](https://containers.dev/implementors/templates/) artifacts to an OCI registry (that supports the [artifacts specification](https://oras.land/implementors/)).

To see all the available options, run `devcontainers templates publish --help`.

## Example

Given a directory that is organized according to the [Templates distribution specification](https://containers.dev/implementors/templates-distribution/) - for example:

```
├── src
│   ├── color
│   │   ├── devcontainer-template.json
│   │   └──| .devcontainer
│   │      └── devcontainer.json
│   ├── hello
│   │   ├── devcontainer-template.json
│   │   └──| .devcontainer
│   │      ├── devcontainer.json
│   │      └── Dockerfile
|   ├── ...
│   │   ├── devcontainer-template.json
│   │   └──| .devcontainer
│   │      └── devcontainer.json
├── test
│   ├── color
│   │   └── test.sh
│   ├── hello
│   │   └── test.sh
│   └──test-utils
│      └── test-utils.sh
...
```

The following command will publish each Template above (`color,hello`) to the registry `ghcr.io` with the following namespace (prefix) `devcontainers/templates`.

```
[/tmp]$  GITHUB_TOKEN="$CR_PAT" devcontainer templates publish -r ghcr.io -n devcontainers/templates ./src
```

To later apply a published Template (in the example below, the `color` template) with the CLI, the following [apply](../apply) command would be used:

```
[/tmp]$  devcontainer templates apply \
                 -t 'ghcr.io/devcontainers/templates/color' \
                 -a '{"favorite": "red"}'
```

### Authentication Methods

> NOTE: OS-specific docker credential helpers (Docker Desktop credential helper) are not currently recognized by the CLI.  

- Adding a $HOME/.docker/config.json with your credentials following [this commonly defined format](https://www.systutorials.com/docs/linux/man/5-docker-config-json/).
   - Your `docker login` command may write this file for you depending on your operating system.
- Using our custom env variable DEVCONTAINERS_OCI_AUTH
    - eg: `DEVCONTAINERS_OCI_AUTH=service1|user1|token1,service2|user2|token2`
    
For publishing to `ghcr.io`
- Using the `devcontainers/action` GitHub action to handle the `GITHUB_TOKEN` credential for you.
- Providing a GITHUB_TOKEN with permission to `write:packages`.
</file>

<file path="example-usage/ci-app-build-script/build-application.sh">
#!/bin/sh
set -e
cd "$(dirname $0)"

build_date="$(date +%s)"

# Create a label for use during cleanup since the devcontainer CLI does 
# not have a "remove" or "down" command yet (though this is planned).
id_label="ci-container=${build_date}"

# Run build
devcontainer up --id-label ${id_label} --workspace-folder ../workspace
set +e
devcontainer exec --id-label ${id_label} --workspace-folder ../workspace scripts/execute-app-build.sh
build_exit_code=$?
set -e

# Clean up. 
echo "\nCleaning up..."
docker rm -f $(docker ps -aq --filter label=${id_label})

exit ${build_exit_code}
</file>

<file path="example-usage/image-build/build-image.sh">
#!/bin/sh
set -e
cd "$(dirname $0)"

image_name="${1:-"devcontainer-cli-test-image"}"

# Push will upload the image to a registry when done (if logged in via docker CLI)
push_flag="${2:-false}"

# If more than one platform is specified, then push must be set.
platforms="${3:-linux/amd64}"

devcontainer build --image-name $image_name --platform "$platforms" --push $push_flag --workspace-folder ../workspace

echo "\nImage ${image_name} built successfully!"
</file>

<file path="example-usage/tool-openvscode-server/server/init-openvscode-server.sh">
#!/bin/bash
set -e
cd "$(dirname $0)"

if [ ! -e "$HOME/.openvscodeserver/bin" ]; then
    echo "Downloading openvscode-server..."
    curl -fsSL https://github.com/gitpod-io/openvscode-server/releases/download/openvscode-server-v1.72.2/openvscode-server-v1.72.2-linux-x64.tar.gz -o /tmp/openvscode-server.tar.gz
    mkdir -p "$HOME/.openvscodeserver"
    echo "Extracting..."
    tar --strip 1 -xzf /tmp/openvscode-server.tar.gz -C "$HOME/.openvscodeserver/"
    rm -f /tmp/openvscode-server.tar.gz
fi

if [ "$(ps -ef | grep '\.openvscode-server' | wc -l)" = "1" ]; then
    # Process customizations.openvscodeserver and features configuration
    # Logic could be simplified with https://github.com/devcontainers/cli/issues/113

    if ! type jq > /dev/null 2>&1; then
        sudo apt-get -y install jq
    fi
    tmp_dir="$(mktemp -d)"
    mkdir -p "${tmp_dir}" "$HOME"/.openvscode-server/data/Machine

    # Get list of extensions to install - [Optional] Also set of extensions from `vscode.extensions` property
    extensions=( $(jq -r -M '[
        .mergedConfiguration.customizations?.openvscodeserver[]?.extensions[]?,
        .mergedConfiguration.customizations?.vscode[]?.extensions[]?
        ] | .[]
    ' /server/configuration.json ) )
    # Install extensions
    if [ "${extensions[0]}" != "" ] && [ "${extensions[0]}" != "null" ] ; then 
        set +e
        for extension in "${extensions[@]}"; do
            "$HOME"/.openvscodeserver/bin/openvscode-server --install-extension ${extension}
        done
        set -e
    fi

    # Get openvscode-server machine settings.json - [Optional] Also settings from `vscode.settings` property
    settings="$(jq -M '[
        .mergedConfiguration.customizations?.openvscodeserver[]?.settings?,
        .mergedConfiguration.customizations?.vscode[]?.settings?
        ] | add
    ' /server/configuration.json)"
    # Place settings in right spot
    if [ "${settings}" != "" ] && [ "${settings}" != "null" ]; then
        echo "${settings}" >  "$HOME"/.openvscode-server/data/Machine/settings.json
    fi
    
    rm -rf "${tmp_dir}" /server/configuration.json

    # Start openvscode-server
    "$HOME"/.openvscodeserver/bin/openvscode-server serve-local --without-connection-token --host 0.0.0.0 --port 8000
else
    echo -e "\ncode-server is already running.\n\nConnect using: http://localhost:8000\n"
fi
</file>

<file path="example-usage/tool-openvscode-server/start.sh">
#!/bin/sh
set -e
cd "$(dirname $0)"

remove_flag=""
if [ "$1" = "true" ]; then
    remove_flag="--remove-existing-container"
fi

# Save off effective config for use in the container
devcontainer read-configuration --include-merged-configuration --log-format json --workspace-folder ../workspace 2>/dev/null > server/configuration.json

devcontainer up $remove_flag --mount "type=bind,source=$(pwd)/server,target=/server"  --workspace-folder ../workspace
devcontainer exec --workspace-folder ../workspace /server/init-openvscode-server.sh
</file>

<file path="example-usage/tool-vim-via-ssh/server/init-vim.sh">
#!/bin/sh
set -e
if ! type vim > /dev/null 2>&1; then
    echo "Installing vim..."
    sudo apt-get update
    sudo apt-get install -y vim
fi

# Copy generated keys
mkdir -p $HOME/.ssh
cat /server/temp-ssh-key.pub > $HOME/.ssh/authorized_keys
chmod 644 $HOME/.ssh/authorized_keys
chmod 700 $HOME/.ssh
</file>

<file path="example-usage/tool-vim-via-ssh/start.sh">
#!/bin/sh
set -e
cd "$(dirname $0)"

remove_flag=""
if [ "$1" = "true" ]; then
    remove_flag="--remove-existing-container"
fi

# Generate certificate
cd server
rm -f temp-ssh-key*
ssh-keygen -q -N '' -t rsa -f temp-ssh-key
cd ..

# Start container
devcontainer up $remove_flag --mount "type=bind,source=$(pwd)/server,target=/server" --workspace-folder ../workspace

# Install vim (if needed) and add pub key to SSH allow list
devcontainer exec --workspace-folder ../workspace /server/init-vim.sh

# Connect
ssh -t -i server/temp-ssh-key -o NoHostAuthenticationForLocalhost=yes -o UserKnownHostsFile=/dev/null -o GlobalKnownHostsFile=/dev/null -p 2222 vscode@localhost exec bash -c vim
</file>

<file path="example-usage/tool-vscode-server/server/init-vscode-server.sh">
#!/bin/bash
set -e
INSTALL_LOCATION="$HOME/.local/bin" 
INSTALL_TARGET=unknown-linux-gnu

if [ ! -e "$INSTALL_LOCATION"/code-server ]; then
    # Adapted from https://aka.ms/install-vscode-server/setup.sh
    install_arch=x86_64
    arch=$(uname -m)
    if [ $arch = "aarch64" ] || [ $arch = "arm64" ]; then
        install_arch=aarch64
    fi
    install_url=https://aka.ms/vscode-server-launcher/$install_arch-$INSTALL_TARGET
    echo "Installing from $install_url"
    mkdir -p "$INSTALL_LOCATION"
    if type curl > /dev/null 2>&1; then
        curl -sSLf $install_url -o "$INSTALL_LOCATION"/code-server
    elif type wget > /dev/null 2>&1; then
        wget -q $install_url -O "$INSTALL_LOCATION"/code-server
    else
        echo "Installation failed. Please install curl or wget in your container image."
        exit 1
    fi
    chmod +x "$INSTALL_LOCATION"/code-server
fi

if ! pidof code-server > /dev/null 2>&1; then
    # Process customizations.vscode and features configuration using jq
    # Logic could be simplified with https://github.com/devcontainers/cli/issues/113

    if ! type jq > /dev/null 2>&1; then
        sudo apt-get -y install jq
    fi
    tmp_dir="$(mktemp -d)"
    mkdir -p "${tmp_dir}" "$HOME"/.vscode-server/data/Machine

    # Get list of extensions - including legacy spots for backwards compatibility.
    extensions=( $(jq -r -M '[
        .mergedConfiguration.customizations?.vscode[]?.extensions[]?,
        .mergedConfiguration.extensions[]?
        ] | .[]
    ' /server/configuration.json ) )
    # Install extensions
    if [ "${extensions[0]}" != "" ] && [ "${extensions[0]}" != "null" ] ; then  
        set +e
        for extension in "${extensions[@]}"; do
            "$INSTALL_LOCATION/code-server" serve-local --accept-server-license-terms --install-extension "${extension}"
        done
        set -e
    fi

    # Get VS Code machine settings - including legacy spots for backwards compatibility.
    settings="$(jq -M '[
        .mergedConfiguration.customizations?.vscode[]?.settings?,
        .mergedConfiguration.settings?
        ] | add
    ' /server/configuration.json)"
    # Place settings in right spot
    if [ "${settings}" != "" ] && [ "${settings}" != "null" ]; then
        echo "${settings}" > "${HOME}"/.vscode-server/data/Machine/settings.json
    fi

    rm -rf "${tmp_dir}" /server/configuration.json

    # Start VS Code server
    "$INSTALL_LOCATION/code-server" serve-local --without-connection-token --accept-server-license-terms --host 0.0.0.0 --port 8000 
else
    echo -e "\ncode-server is already running.\n\nConnect using: http://localhost:8000\n"
fi
</file>

<file path="example-usage/tool-vscode-server/start.sh">
#!/bin/sh
set -e
cd "$(dirname $0)"

remove_flag=""
if [ "$1" = "true" ]; then
    remove_flag="--remove-existing-container"
fi

# Save off effective config for use in the container
devcontainer read-configuration --include-merged-configuration --log-format json --workspace-folder ../workspace 2>/dev/null > server/configuration.json

devcontainer up $remove_flag --mount "type=bind,source=$(pwd)/server,target=/server" --workspace-folder ../workspace

devcontainer exec --workspace-folder ../workspace /server/init-vscode-server.sh
</file>

<file path="example-usage/workspace/.devcontainer/devcontainer.json">
{
	"name": "devcontainer CLI Demo",
	"build": {
		"dockerfile": "Dockerfile"
	},

	"customizations": {
		// 👇 Config only used for VS Code Server
		"vscode": {
			"extensions": [
				"streetsidesoftware.code-spell-checker",
				"mutantdino.resourcemonitor"
			],
			"settings": {
				"resmon.show.battery": false,
				"resmon.show.cpufreq": false
			}
		},
		// 👇 Config only used for openvscode-server
		"openvscodeserver": {
			"extensions": [
				"streetsidesoftware.code-spell-checker"
			],
			"settings": { }
		}
	},
	
	// 👇 Dev Container Features - https://containers.dev/implementors/features/
	"features": {
		"ghcr.io/devcontainers/features/go:1": {
			"version": "1.18.4"
		},
		"ghcr.io/devcontainers/features/node:1": {
			"version": "16.15.1",
			"nodeGypDependencies": false
		},
		"ghcr.io/devcontainers/features/desktop-lite:1": { },
		"ghcr.io/devcontainers/features/docker-in-docker:2": { },
		// Optional - For tools that require SSH
		"ghcr.io/devcontainers/features/sshd:1": { }
	},

	// We are using appPort since forwardPorts not yet supported directly 
	// by the CLI. See https://github.com/devcontainers/cli/issues/22
	// A pre-processor can easily parse devcontainer.json and inject
	// these values as appropriate. We're omitting that for simplicity.
	"appPort": [
		// Expose SSH port for tools that need it (e.g. JetBrains)
		"127.0.0.1:2222:2222",
		// Port VS Code Server / openvscode-server is on
		8000,
		// Port for VNC web server contributed by the desktop-lite feature
		6080
	],

	"remoteUser": "vscode"
}
</file>

<file path="example-usage/workspace/.devcontainer/Dockerfile">
FROM mcr.microsoft.com/devcontainers/base:1-bookworm
</file>

<file path="example-usage/workspace/scripts/execute-app-build.sh">
#!/bin/sh
set -e
cd "$(dirname $0)/.."

mkdir -p dist
echo "\nStarting build..."
GOARCH="amd64" GOOS="linux" go build -o ./dist/hello-world-linux ./main.go
GOARCH="amd64" GOOS="darwin" go build -o ./dist/hello-world-darwin ./main.go
GOARCH="amd64" GOOS="windows" go build -o ./dist/hello-world-windows.exe ./main.go

echo "\nApplication build complete! Check out the result in the workspace/dist folder."
</file>

<file path="example-usage/workspace/go.mod">
module github.com/devcontainers/cli/hello-world

go 1.18
</file>

<file path="example-usage/workspace/main.go">
package main

import "fmt"

func main() {
	fmt.Println("Hello world!")
}
</file>

<file path="example-usage/README.md">
# Dev Container CLI Examples

This folder contains a set of basic examples that use the devcontainer CLI for different use cases. It includes example scripts to:

1. [Use three different tools from a development container](#tool-examples)
2. [Use a dev container as your CI build environment](#ci-build-environment-example) (even if your app is not deployed as a container)
3. [Build a container image](#building-an-image-from-devcontainerjson) from a devcontainer.json file that includes [dev container features](https://containers.dev/implementors/features/#devcontainer-json-properties)

Each should run on macOS or Linux. For Windows, you can use these scripts from WSL2.

## Pre-requisites

1. Install Node.js 16 (e.g., using [nvm](https://github.com/nvm-sh/nvm))
2. Install [node-gyp pre-requisites](https://github.com/nodejs/node-gyp):
   - **Linux/WSL2:** Use your distro's package manager. E.g. on Ubuntu/Debian: `sudo apt-get update && sudo apt-get install python3-minimal gcc g++ make`
   - **macOS:** Install the XCode Command Line Tools ([more info](https://github.com/nodejs/node-gyp/blob/main/README.md#on-macos))
3. Make sure you have an OpenSSH compliant `ssh` command available and in your path if you plan to use the `Vim via SSH` example (it should already be there on macOS, and in Linux/WSL, you can install `openssh-client` using your distro's package manager if its missing)
3. Install the latest dev container CLI: `npm install -g @devcontainers/cli`

## Using the examples

All examples use the contents of the `workspace` folder for their configuration, which is where you can make modifications if you'd like. The example scripts are then in different sub-folders. 

### Tool examples

You can use these examples by opening a terminal and typing one of the following:

- `tool-vscode-server/start.sh` - [VS Code Server](https://code.visualstudio.com/docs/remote/vscode-server) (official)
- `tool-openvscode-server/start.sh` - [openvscode-server](https://github.com/gitpod-io/openvscode-server)
- `tool-vim-via-ssh/start.sh` - Vim via an SSH connection. SSH is used primarily to demonstrate how this could be achieved from other SSH supporting client tools.

When switching between examples, pass `true` in as an argument to get the container recreated to avoid port conflicts. e.g., `./start.sh true`

In the first two examples, you'll be instructed to go to `http://localhost:8000` in a browser.

This also adds a desktop to the container that can be accessed from a web browser at `http://localhost:6080` and you can connect using the password `vscode`.

#### How the tool examples work

These examples demonstrate the use of the dev container CLI to:

1. Simplify setup using the "[dev container features](https://containers.dev/implementors/features/#devcontainer-json-properties)" concept. For example, SSH support is added just using a feature reference. See `workspace/.devcontainer/devcontainer.json` for more information.

2. How the dev container CLI can be used to inject tools without building them into the base image:

    1. Use `devcontainer up` to spin up the container and mount a `server` and `workspace` folder into the container.
    2. Use `devcontainer exec` to run a script from this mounted folder to set up the appropriate server (and apply tool specific settings/customizations).
    3. In the `vim` example, a temporary SSH key is set up and configured, and then SSH is used from the command line to connect to the container once it is up and running. See `tool-vim-via-ssh/start.sh` for details.

Currently the `appPort` property is used in `devcontainer.json` instead of `forwardPorts` due to a gap in the current dev container CLI ([see here](https://github.com/devcontainers/cli/issues/22)).

### CI build environment example

This example illustrates how you can use the dev container CLI to build your application in any CI system. (Note there is also a [GitHub Action](https://github.com/marketplace/actions/devcontainers-ci) and [Azure DevOps task](https://marketplace.visualstudio.com/items?itemName=devcontainers.ci) if you are using those automation systems, but this example will focus on direct use of the CLI.)

You can use the example by opening a terminal and typing the following:

```
ci-app-build-script/build-app.sh
```

After the build completes, you can find the built application in the `workspace/dist` folder.

The initial build can take a bit since it is building the dev container image, which is an example of where [pre-building an image](#building-an-image-from-devcontainerjson) helps.

#### How the CI example works

This example demonstrates the use of the dev container CLI to:

1. Simplify setup using the "[dev container features](https://containers.dev/implementors/features/#devcontainer-json-properties)" concept. For example, SSH support is added just using a feature reference. See `workspace/.devcontainer/devcontainer.json` for more information.

2. Execute an application build script inside a dev container as follows:

    1. Use `devcontainer up` to spin up the container and mount the the `workspace` folder into the container.
    2. Use `devcontainer exec` to run a build script from the mounted folder inside the development container.
    3. Delete the container when the build is finished.

All environment variables are automatically available from `exec`, including those that are are set in the non-root user's `.bashrc` file. The dev container CLI also automatically adjusts to UID/GID differences for the user inside the container on Linux to ensure the workspace folder is writable.

### Building an image from devcontainer.json

You can use the example by opening a terminal and typing the following:

```
image-build/build-image.sh
```

The resulting image name defaults to `devcontainer-cli-test-image`,  but you can change it with the first argument, and configure it to push to a registry by setting the second argument to true. The third argument allows you to build for multiple architectures.

```
image-build/build-image.sh ghcr.io/my-org/my-image-name-here true "linux/amd64 linux/arm64"
```

Ultimately, this script just calls the `devcontainer build` command to do all the work. Once built, you can refer to the specified image name directly in a devcontainer.json file using the `image` property.
</file>

<file path="images/README.md">
## Images

Images part of the dev container CLI repository.
</file>

<file path="scripts/gitAskPass.sh">
#!/bin/sh
echo "$GIT_TOKEN"
</file>

<file path="scripts/updateUID.Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG BASE_IMAGE
FROM $BASE_IMAGE

USER root

ARG REMOTE_USER
ARG NEW_UID
ARG NEW_GID
SHELL ["/bin/sh", "-c"]
RUN eval $(sed -n "s/${REMOTE_USER}:[^:]*:\([^:]*\):\([^:]*\):[^:]*:\([^:]*\).*/OLD_UID=\1;OLD_GID=\2;HOME_FOLDER=\3/p" /etc/passwd); \
	eval $(sed -n "s/\([^:]*\):[^:]*:${NEW_UID}:.*/EXISTING_USER=\1/p" /etc/passwd); \
	eval $(sed -n "s/\([^:]*\):[^:]*:${NEW_GID}:.*/EXISTING_GROUP=\1/p" /etc/group); \
	if [ -z "$OLD_UID" ]; then \
		echo "Remote user not found in /etc/passwd ($REMOTE_USER)."; \
	elif [ "$OLD_UID" = "$NEW_UID" -a "$OLD_GID" = "$NEW_GID" ]; then \
		echo "UIDs and GIDs are the same ($NEW_UID:$NEW_GID)."; \
	elif [ "$OLD_UID" != "$NEW_UID" -a -n "$EXISTING_USER" ]; then \
		echo "User with UID exists ($EXISTING_USER=$NEW_UID)."; \
	else \
		if [ "$OLD_GID" != "$NEW_GID" -a -n "$EXISTING_GROUP" ]; then \
			echo "Group with GID exists ($EXISTING_GROUP=$NEW_GID)."; \
			NEW_GID="$OLD_GID"; \
		fi; \
		echo "Updating UID:GID from $OLD_UID:$OLD_GID to $NEW_UID:$NEW_GID."; \
		sed -i -e "s/\(${REMOTE_USER}:[^:]*:\)[^:]*:[^:]*/\1${NEW_UID}:${NEW_GID}/" /etc/passwd; \
		if [ "$OLD_GID" != "$NEW_GID" ]; then \
			sed -i -e "s/\([^:]*:[^:]*:\)${OLD_GID}:/\1${NEW_GID}:/" /etc/group; \
		fi; \
		chown -R $NEW_UID:$NEW_GID $HOME_FOLDER; \
	fi;

ARG IMAGE_USER
USER $IMAGE_USER
</file>

<file path="src/spec-common/async.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

export async function delay(ms: number): Promise<void> {
	return new Promise<void>(resolve => setTimeout(resolve, ms));
}
</file>

<file path="src/spec-common/cliHost.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as net from 'net';
import * as os from 'os';

import { readLocalFile, writeLocalFile, mkdirpLocal, isLocalFile, renameLocal, readLocalDir, isLocalFolder } from '../spec-utils/pfs';
import { URI } from 'vscode-uri';
import { ExecFunction, getLocalUsername, plainExec, plainPtyExec, PtyExecFunction } from './commonUtils';
import { Abort, Duplex, Sink, Source, SourceCallback } from 'pull-stream';

const toPull = require('stream-to-pull-stream');


export type CLIHostType = 'local' | 'wsl' | 'container' | 'ssh';

export interface CLIHost {
	type: CLIHostType;
	platform: NodeJS.Platform;
	arch: NodeJS.Architecture;
	exec: ExecFunction;
	ptyExec: PtyExecFunction;
	cwd: string;
	env: NodeJS.ProcessEnv;
	path: typeof path.posix | typeof path.win32;
	homedir(): Promise<string>;
	tmpdir(): Promise<string>;
	isFile(filepath: string): Promise<boolean>;
	isFolder(filepath: string): Promise<boolean>;
	readFile(filepath: string): Promise<Buffer>;
	writeFile(filepath: string, content: Buffer): Promise<void>;
	rename(oldPath: string, newPath: string): Promise<void>;
	mkdirp(dirpath: string): Promise<void>;
	readDir(dirpath: string): Promise<string[]>;
	readDirWithTypes?(dirpath: string): Promise<[string, FileTypeBitmask][]>;
	getUsername(): Promise<string>;
	getuid?: () => Promise<number>;
	getgid?: () => Promise<number>;
	toCommonURI(filePath: string): Promise<URI | undefined>;
	connect: ConnectFunction;
	reconnect?(): Promise<void>;
	terminate?(): Promise<void>;
}

export type ConnectFunction = (socketPath: string) => Duplex<Buffer, Buffer>;

export enum FileTypeBitmask {
	Unknown = 0,
	File = 1,
	Directory = 2,
	SymbolicLink = 64
}

export async function getCLIHost(localCwd: string, loadNativeModule: <T>(moduleName: string) => Promise<T | undefined>, allowInheritTTY: boolean): Promise<CLIHost> {
	const exec = plainExec(localCwd);
	const ptyExec = await plainPtyExec(localCwd, loadNativeModule, allowInheritTTY);
	return createLocalCLIHostFromExecFunctions(localCwd, exec, ptyExec, connectLocal);
}

function createLocalCLIHostFromExecFunctions(localCwd: string, exec: ExecFunction, ptyExec: PtyExecFunction, connect: ConnectFunction): CLIHost {
	return {
		type: 'local',
		platform: process.platform,
		arch: process.arch,
		exec,
		ptyExec,
		cwd: localCwd,
		env: process.env,
		path: path,
		homedir: async () => os.homedir(),
		tmpdir: async () => os.tmpdir(),
		isFile: isLocalFile,
		isFolder: isLocalFolder,
		readFile: readLocalFile,
		writeFile: writeLocalFile,
		rename: renameLocal,
		mkdirp: async (dirpath) => {
			await mkdirpLocal(dirpath);
		},
		readDir: readLocalDir,
		getUsername: getLocalUsername,
		getuid: process.platform === 'linux' || process.platform === 'darwin' ? async () => process.getuid!() : undefined,
		getgid: process.platform === 'linux' || process.platform === 'darwin' ? async () => process.getgid!() : undefined,
		toCommonURI: async (filePath) => URI.file(filePath),
		connect,
	};
}

// Parse a Cygwin socket cookie string to a raw Buffer
function cygwinUnixSocketCookieToBuffer(cookie: string) {
	let bytes: number[] = [];

	cookie.split('-').map((number: string) => {
		const bytesInChar = number.match(/.{2}/g);
		if (bytesInChar !== null) {
			bytesInChar.reverse().map((byte) => {
				bytes.push(parseInt(byte, 16));
			});
		}
	});
	return Buffer.from(bytes);
}

// The cygwin/git bash ssh-agent server will reply us with the cookie back (16 bytes)
// + identifiers (12 bytes), skip them while forwarding data from ssh-agent to the client
function skipHeader(headerSize: number, err: Abort, data?: Buffer) {
	if (err || data === undefined) {
		return { headerSize, err };
	}

	if (headerSize === 0) {
		// Fast path avoiding data buffer manipulation
		// We don't need to modify the received data (handshake header
		// already removed)
		return { headerSize, data };
	} else if (data.length > headerSize) {
		// We need to remove part of the data to forward
		data = data.slice(headerSize, data.length);
		headerSize = 0;
		return { headerSize, data };
	} else {
		// We need to remove all forwarded data
		headerSize = headerSize - data.length;
		return { headerSize };
	}
}

// Function to handle the Cygwin/Gpg4win socket filtering
// These sockets need an handshake before forwarding client and server data
function handleUnixSocketOnWindows(socket: net.Socket, socketPath: string): Duplex<Buffer, Buffer> {
	let headerSize = 0;
	let pendingSourceCallbacks: { abort: Abort; cb: SourceCallback<Buffer> }[] = [];
	let pendingSinkCalls: Source<Buffer>[] = [];
	let connectionDuplex: Duplex<Buffer, Buffer> | undefined = undefined;

	let handleError = (err: Abort) => {
		if (err instanceof Error) {
			console.error(err);
		}
		socket.destroy();

		// Notify pending callbacks with the error
		for (let callback of pendingSourceCallbacks) {
			callback.cb(err, undefined);
		}
		pendingSourceCallbacks = [];

		for (let callback of pendingSinkCalls) {
			callback(err, (_abort, _data) => { });
		}
		pendingSinkCalls = [];
	};

	function doSource(abort: Abort, cb: SourceCallback<Buffer>) {
		(connectionDuplex as Duplex<Buffer, Buffer>).source(abort, function (err, data) {
			const res = skipHeader(headerSize, err, data);
			headerSize = res.headerSize;
			if (res.err || res.data) {
				cb(res.err || null, res.data);
			} else {
				doSource(abort, cb);
			}
		});
	}

	(async () => {
		const buf = await readLocalFile(socketPath);
		const str = buf.toString();

		// Try to parse cygwin socket data
		const cygwinSocketParameters = str.match(/!<socket >(\d+)( s)? ((([A-Fa-f0-9]{2}){4}-?){4})/);

		let port: number;
		let handshake: Buffer;

		if (cygwinSocketParameters !== null) {
			// Cygwin / MSYS / Git Bash unix socket on Windows
			const portStr = cygwinSocketParameters[1];
			const guidStr = cygwinSocketParameters[3];
			port = parseInt(portStr, 10);
			const guid = cygwinUnixSocketCookieToBuffer(guidStr);

			let identifierData = Buffer.alloc(12);
			identifierData.writeUInt32LE(process.pid, 0);

			handshake = Buffer.concat([guid, identifierData]);

			// Recv header size = GUID (16 bytes) + identifiers (3 * 4 bytes)
			headerSize = 16 + 3 * 4;
		} else {
			// Gpg4Win unix socket
			const i = buf.indexOf(0xa);
			port = parseInt(buf.slice(0, i).toString(), 10);
			handshake = buf.slice(i + 1);

			// No header will be received from Gpg4Win agent
			headerSize = 0;
		}

		// Handle connection errors and resets
		socket.on('error', err => {
			handleError(err);
		});

		socket.connect(port, '127.0.0.1', () => {
			// Write handshake data to the ssh-agent/gpg-agent server
			socket.write(handshake, err => {
				if (err) {
					// Error will be handled via the 'error' event
					return;
				}

				connectionDuplex = toPull.duplex(socket);

				// Call pending source calls, if the pull-stream connection was
				// pull-ed before we got connected to the ssh-agent/gpg-agent
				// server.
				// The received data from ssh-agent/gpg-agent server is filtered
				// to skip the handshake header.
				for (let callback of pendingSourceCallbacks) {
					doSource(callback.abort, callback.cb);
				}
				pendingSourceCallbacks = [];

				// Call pending sink calls after the handshake is completed
				// to send what the client sent to us
				for (let callback of pendingSinkCalls) {
					(connectionDuplex as Duplex<Buffer, Buffer>).sink(callback);
				}
				pendingSinkCalls = [];
			});
		});
	})()
		.catch(err => {
			handleError(err);
		});

	// pull-stream source that remove the first <headerSize> bytes
	let source: Source<Buffer> = function (abort: Abort, cb: SourceCallback<Buffer>) {
		if (connectionDuplex !== undefined) {
			doSource(abort, cb);
		} else {
			pendingSourceCallbacks.push({ abort: abort, cb: cb });
		}
	};

	// pull-stream sink. No filtering done, but we need to store calls in case
	// the connection to the upstram ssh-agent/gpg-agent is not yet connected
	let sink: Sink<Buffer> = function (source: Source<Buffer>) {
		if (connectionDuplex !== undefined) {
			connectionDuplex.sink(source);
		} else {
			pendingSinkCalls.push(source);
		}
	};

	return {
		source: source,
		sink: sink
	};
}

// Connect to a ssh-agent or gpg-agent, supporting multiple platforms
function connectLocal(socketPath: string) {
	if (process.platform !== 'win32' || socketPath.startsWith('\\\\.\\pipe\\')) {
		// Simple case: direct forwarding
		return toPull.duplex(net.connect(socketPath));
	}

	// More complex case: we need to do an handshake to support Cygwin / Git Bash
	// sockets or Gpg4Win sockets

	const socket = new net.Socket();

	return handleUnixSocketOnWindows(socket, socketPath);
}
</file>

<file path="src/spec-common/commonUtils.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { Writable, Readable } from 'stream';
import * as path from 'path';
import * as os from 'os';
import * as fs from 'fs';
import * as cp from 'child_process';
import * as ptyType from 'node-pty';
import { StringDecoder } from 'string_decoder';

import { toErrorText } from './errors';
import { Disposable, Event, NodeEventEmitter } from '../spec-utils/event';
import { isLocalFile } from '../spec-utils/pfs';
import { escapeRegExCharacters } from '../spec-utils/strings';
import { Log, nullLog } from '../spec-utils/log';
import { ShellServer } from './shellServer';

export { CLIHost, getCLIHost } from './cliHost';

export interface Exec {
	stdin: Writable;
	stdout: Readable;
	stderr: Readable;
	exit: Promise<{ code: number | null; signal: string | null }>;
	terminate(): Promise<void>;
}

export interface ExecParameters {
	env?: NodeJS.ProcessEnv;
	cwd?: string;
	cmd: string;
	args?: string[];
	stdio?: [cp.StdioNull | cp.StdioPipe, cp.StdioNull | cp.StdioPipe, cp.StdioNull | cp.StdioPipe];
	output: Log;
}

export interface ExecFunction {
	(params: ExecParameters): Promise<Exec>;
}

export type GoOS = { [OS in NodeJS.Platform]: OS extends 'win32' ? 'windows' : OS; }[NodeJS.Platform];
export type GoARCH = { [ARCH in NodeJS.Architecture]: ARCH extends 'x64' ? 'amd64' : ARCH; }[NodeJS.Architecture];

export interface PlatformInfo {
	os: GoOS;
	arch: GoARCH;
	variant?: string;
}

export interface PtyExec {
	onData: Event<string>;
	write?(data: string): void;
	resize(cols: number, rows: number): void;
	exit: Promise<{ code: number | undefined; signal: number | undefined }>;
	terminate(): Promise<void>;
}

export interface PtyExecParameters {
	env?: NodeJS.ProcessEnv;
	cwd?: string;
	cmd: string;
	args?: string[];
	cols?: number;
	rows?: number;
	output: Log;
}

export interface PtyExecFunction {
	(params: PtyExecParameters): Promise<PtyExec>;
}

export function equalPaths(platform: NodeJS.Platform, a: string, b: string) {
	if (platform === 'linux') {
		return a === b;
	}
	return a.toLowerCase() === b.toLowerCase();
}

export async function runCommandNoPty(options: {
	exec: ExecFunction;
	cmd: string;
	args?: string[];
	cwd?: string;
	env?: NodeJS.ProcessEnv;
	stdin?: Buffer | fs.ReadStream | Event<string>;
	output: Log;
	print?: boolean | 'continuous' | 'onerror';
}) {
	const { exec, cmd, args, cwd, env, stdin, output, print } = options;

	const p = await exec({
		cmd,
		args,
		cwd,
		env,
		output,
	});

	return new Promise<{ stdout: Buffer; stderr: Buffer }>((resolve, reject) => {
		const stdout: Buffer[] = [];
		const stderr: Buffer[] = [];

		const stdoutDecoder = print === 'continuous' ? new StringDecoder() : undefined;
		p.stdout.on('data', (chunk: Buffer) => {
			stdout.push(chunk);
			if (print === 'continuous') {
				output.write(stdoutDecoder!.write(chunk));
			}
		});
		p.stdout.on('error', (err: any) => {
			// ENOTCONN seen with missing executable in addition to ENOENT on child_process.
			if (err?.code !== 'ENOTCONN') {
				throw err;
			}
		});
		const stderrDecoder = print === 'continuous' ? new StringDecoder() : undefined;
		p.stderr.on('data', (chunk: Buffer) => {
			stderr.push(chunk);
			if (print === 'continuous') {
				output.write(toErrorText(stderrDecoder!.write(chunk)));
			}
		});
		p.stderr.on('error', (err: any) => {
			// ENOTCONN seen with missing executable in addition to ENOENT on child_process.
			if (err?.code !== 'ENOTCONN') {
				throw err;
			}
		});
		const subs: Disposable[] = [];
		p.exit.then(({ code, signal }) => {
			try {
				const failed = !!code || !!signal;
				subs.forEach(sub => sub.dispose());
				const stdoutBuf = Buffer.concat(stdout);
				const stderrBuf = Buffer.concat(stderr);
				if (print === true || (failed && print === 'onerror')) {
					output.write(stdoutBuf.toString().replace(/\r?\n/g, '\r\n'));
					output.write(toErrorText(stderrBuf.toString()));
				}
				if (print && code) {
					output.write(`Exit code ${code}`);
				}
				if (print && signal) {
					output.write(`Process signal ${signal}`);
				}
				if (failed) {
					reject({
						message: `Command failed: ${cmd} ${(args || []).join(' ')}`,
						stdout: stdoutBuf,
						stderr: stderrBuf,
						code,
						signal,
					});
				} else {
					resolve({
						stdout: stdoutBuf,
						stderr: stderrBuf,
					});
				}
			} catch (e) {
				reject(e);
			}
		}, reject);
		if (stdin instanceof Buffer) {
			p.stdin.write(stdin, err => {
				if (err) {
					reject(err);
				}
			});
			p.stdin.end();
		} else if (stdin instanceof fs.ReadStream) {
			stdin.pipe(p.stdin);
		} else if (typeof stdin === 'function') {
			subs.push(stdin(buf => p.stdin.write(buf)));
		}
	});
}

export async function runCommand(options: {
	ptyExec: PtyExecFunction;
	cmd: string;
	args?: string[];
	cwd?: string;
	env?: NodeJS.ProcessEnv;
	output: Log;
	resolveOn?: RegExp;
	onDidInput?: Event<string>;
	stdin?: string;
	print?: 'off' | 'continuous' | 'end';
}) {
	const { ptyExec, cmd, args, cwd, env, output, resolveOn, onDidInput, stdin } = options;
	const print = options.print || 'continuous';

	const p = await ptyExec({
		cmd,
		args,
		cwd,
		env,
		output: output,
	});

	return new Promise<{ cmdOutput: string }>((resolve, reject) => {
		let cmdOutput = '';

		const subs: Disposable[] = [];
		if (p.write) {
			if (stdin) {
				p.write(stdin);
			}
			if (onDidInput) {
				subs.push(onDidInput(data => p.write!(data)));
			}
		}

		p.onData(chunk => {
			cmdOutput += chunk;
			if (print === 'continuous') {
				output.raw(chunk);
			}
			if (resolveOn && resolveOn.exec(cmdOutput)) {
				resolve({ cmdOutput });
			}
		});
		p.exit.then(({ code, signal }) => {
			try {
				if (print === 'end') {
					output.raw(cmdOutput);
				}
				subs.forEach(sub => sub?.dispose());
				if (code || signal) {
					reject({
						message: `Command failed: ${cmd} ${(args || []).join(' ')}`,
						cmdOutput,
						code,
						signal,
					});
				} else {
					resolve({ cmdOutput });
				}
			} catch (e) {
				reject(e);
			}
		}, e => {
			subs.forEach(sub => sub?.dispose());
			reject(e);
		});
	});
}

// From https://man7.org/linux/man-pages/man7/signal.7.html:
export const processSignals: Record<string, number | undefined> = {
	SIGHUP: 1,
	SIGINT: 2,
	SIGQUIT: 3,
	SIGILL: 4,
	SIGTRAP: 5,
	SIGABRT: 6,
	SIGIOT: 6,
	SIGBUS: 7,
	SIGEMT: undefined,
	SIGFPE: 8,
	SIGKILL: 9,
	SIGUSR1: 10,
	SIGSEGV: 11,
	SIGUSR2: 12,
	SIGPIPE: 13,
	SIGALRM: 14,
	SIGTERM: 15,
	SIGSTKFLT: 16,
	SIGCHLD: 17,
	SIGCLD: undefined,
	SIGCONT: 18,
	SIGSTOP: 19,
	SIGTSTP: 20,
	SIGTTIN: 21,
	SIGTTOU: 22,
	SIGURG: 23,
	SIGXCPU: 24,
	SIGXFSZ: 25,
	SIGVTALRM: 26,
	SIGPROF: 27,
	SIGWINCH: 28,
	SIGIO: 29,
	SIGPOLL: 29,
	SIGPWR: 30,
	SIGINFO: undefined,
	SIGLOST: undefined,
	SIGSYS: 31,
	SIGUNUSED: 31,
};

export function plainExec(defaultCwd: string | undefined): ExecFunction {
	return async function (params: ExecParameters): Promise<Exec> {
		const { cmd, args, stdio, output } = params;

		const text = `Run: ${cmd} ${(args || []).join(' ').replace(/\n.*/g, '')}`;
		const start = output.start(text);

		const cwd = params.cwd || defaultCwd;
		const env = params.env ? { ...process.env, ...params.env } : process.env;
		const exec = await findLocalWindowsExecutable(cmd, cwd, env, output);
		const p = cp.spawn(exec, args, { cwd, env, stdio: stdio as any, windowsHide: true });

		return {
			stdin: p.stdin,
			stdout: p.stdout,
			stderr: p.stderr,
			exit: new Promise((resolve, reject) => {
				p.once('error', err => {
					output.stop(text, start);
					reject(err);
				});
				p.once('close', (code, signal) => {
					output.stop(text, start);
					resolve({ code, signal });
				});
			}),
			async terminate() {
				p.kill('SIGKILL');
			}
		};
	};
}

export async function plainPtyExec(defaultCwd: string | undefined, loadNativeModule: <T>(moduleName: string) => Promise<T | undefined>, allowInheritTTY: boolean): Promise<PtyExecFunction> {
	const pty = await loadNativeModule<typeof ptyType>('node-pty');
	if (!pty) {
		const plain = plainExec(defaultCwd);
		return plainExecAsPtyExec(plain, allowInheritTTY);
	}

	return async function (params: PtyExecParameters): Promise<PtyExec> {
		const { cmd, args, output } = params;

		const text = `Run: ${cmd} ${(args || []).join(' ').replace(/\n.*/g, '')}`;
		const start = output.start(text);

		const useConpty = false; // TODO: Investigate using a shell with ConPTY. https://github.com/Microsoft/vscode-remote/issues/1234#issuecomment-485501275
		const cwd = params.cwd || defaultCwd;
		const env = params.env ? { ...process.env, ...params.env } : process.env;
		const exec = await findLocalWindowsExecutable(cmd, cwd, env, output);
		const p = pty.spawn(exec, args || [], {
			cwd,
			env: env as any,
			cols: output.dimensions?.columns,
			rows: output.dimensions?.rows,
			useConpty,
		});
		const subs = [
			output.onDidChangeDimensions && output.onDidChangeDimensions(e => p.resize(e.columns, e.rows))
		];

		return {
			onData: p.onData.bind(p),
			write: p.write.bind(p),
			resize: p.resize.bind(p),
			exit: new Promise(resolve => {
				p.onExit(({ exitCode, signal }) => {
					subs.forEach(sub => sub?.dispose());
					output.stop(text, start);
					resolve({ code: exitCode, signal });
					if (process.platform === 'win32') {
						try {
							// In some cases the process hasn't cleanly exited on Windows and the winpty-agent gets left around
							// https://github.com/microsoft/node-pty/issues/333
							p.kill();
						} catch {
						}
					}
				});
			}),
			async terminate() {
				p.kill('SIGKILL');
			}
		};
	};
}

export function plainExecAsPtyExec(plain: ExecFunction, allowInheritTTY: boolean): PtyExecFunction {
	return async function (params: PtyExecParameters): Promise<PtyExec> {
		const p = await plain({
			...params,
			stdio: allowInheritTTY && params.output !== nullLog ? [
				process.stdin.isTTY ? 'inherit' : 'pipe',
				process.stdout.isTTY ? 'inherit' : 'pipe',
				process.stderr.isTTY ? 'inherit' : 'pipe',
			] : undefined,
		});
		const onDataEmitter = new NodeEventEmitter<string>();
		if (p.stdout) {
			const stdoutDecoder = new StringDecoder();
			p.stdout.on('data', data => onDataEmitter.fire(stdoutDecoder.write(data)));
			p.stdout.on('close', () => {
				const end = stdoutDecoder.end();
				if (end) {
					onDataEmitter.fire(end);
				}
			});
		}
		if (p.stderr) {
			const stderrDecoder = new StringDecoder();
			p.stderr.on('data', data => onDataEmitter.fire(stderrDecoder.write(data)));
			p.stderr.on('close', () => {
				const end = stderrDecoder.end();
				if (end) {
					onDataEmitter.fire(end);
				}
			});
		}
		return {
			onData: onDataEmitter.event,
			write: p.stdin ? p.stdin.write.bind(p.stdin) : undefined,
			resize: () => {},
			exit: p.exit.then(({ code, signal }) => ({
				code: typeof code === 'number' ? code : undefined,
				signal: typeof signal === 'string' ? processSignals[signal] : undefined,
			})),
			terminate: p.terminate.bind(p),
		};
	};
}

async function findLocalWindowsExecutable(command: string, cwd = process.cwd(), env: Record<string, string | undefined>, output: Log): Promise<string> {
	if (process.platform !== 'win32') {
		return command;
	}

	// From terminalTaskSystem.ts.

	// If we have an absolute path then we take it.
	if (path.isAbsolute(command)) {
		return await findLocalWindowsExecutableWithExtension(command) || command;
	}
	if (/[/\\]/.test(command)) {
		// We have a directory and the directory is relative (see above). Make the path absolute
		// to the current working directory.
		const fullPath = path.join(cwd, command);
		return await findLocalWindowsExecutableWithExtension(fullPath) || fullPath;
	}
	let pathValue: string | undefined = undefined;
	let paths: string[] | undefined = undefined;
	// The options can override the PATH. So consider that PATH if present.
	if (env) {
		// Path can be named in many different ways and for the execution it doesn't matter
		for (let key of Object.keys(env)) {
			if (key.toLowerCase() === 'path') {
				const value = env[key];
				if (typeof value === 'string') {
					pathValue = value;
					paths = value.split(path.delimiter)
						.filter(Boolean);
					paths.push(path.join(env.ProgramW6432 || 'C:\\Program Files', 'Docker\\Docker\\resources\\bin')); // Fall back when newly installed.
				}
				break;
			}
		}
	}
	// No PATH environment. Bail out.
	if (paths === void 0 || paths.length === 0) {
		output.write(`findLocalWindowsExecutable: No PATH to look up executable '${command}'.`);
		const err = new Error(`No PATH to look up executable '${command}'.`);
		(err as any).code = 'ENOENT';
		throw err;
	}
	// We have a simple file name. We get the path variable from the env
	// and try to find the executable on the path.
	for (let pathEntry of paths) {
		// The path entry is absolute.
		let fullPath: string;
		if (path.isAbsolute(pathEntry)) {
			fullPath = path.join(pathEntry, command);
		} else {
			fullPath = path.join(cwd, pathEntry, command);
		}
		const withExtension = await findLocalWindowsExecutableWithExtension(fullPath);
		if (withExtension) {
			return withExtension;
		}
	}
	// Not found in PATH. Bail out.
	output.write(`findLocalWindowsExecutable: Exectuable '${command}' not found on PATH '${pathValue}'.`);
	const err = new Error(`Exectuable '${command}' not found on PATH '${pathValue}'.`);
	(err as any).code = 'ENOENT';
	throw err;
}

const pathext = process.env.PATHEXT;
const executableExtensions = pathext ? pathext.toLowerCase().split(';') : ['.com', '.exe', '.bat', '.cmd'];

async function findLocalWindowsExecutableWithExtension(fullPath: string) {
	if (executableExtensions.indexOf(path.extname(fullPath)) !== -1) {
		return await isLocalFile(fullPath) ? fullPath : undefined;
	}
	for (const ext of executableExtensions) {
		const withExtension = fullPath + ext;
		if (await isLocalFile(withExtension)) {
			return withExtension;
		}
	}
	return undefined;
}

export function parseVersion(str: string) {
	const m = /^'?v?(\d+(\.\d+)*)/.exec(str);
	if (!m) {
		return undefined;
	}
	return m[1].split('.')
		.map(i => parseInt(i, 10));
}

export function isEarlierVersion(left: number[], right: number[]) {
	for (let i = 0, n = Math.max(left.length, right.length); i < n; i++) {
		const l = left[i] || 0;
		const r = right[i] || 0;
		if (l !== r) {
			return l < r;
		}
	}
	return false; // Equal.
}

export async function loadNativeModule<T>(moduleName: string): Promise<T | undefined> {
	// Check NODE_PATH for Electron. Do this first to avoid loading a binary-incompatible version from the local node_modules during development.
	if (process.env.NODE_PATH) {
		for (const nodePath of process.env.NODE_PATH.split(path.delimiter)) {
			if (nodePath) {
				try {
					return require(`${nodePath}/${moduleName}`);
				} catch (err) {
					// Not available.
				}
			}
		}
	}
	try {
		return require(moduleName);
	} catch (err) {
		// Not available.
	}
	return undefined;
}

export type PlatformSwitch<T> = T | { posix: T; win32: T };

export function platformDispatch<T>(platform: NodeJS.Platform, platformSwitch: PlatformSwitch<T>) {
	if (platformSwitch && typeof platformSwitch === 'object' && 'win32' in platformSwitch) {
		return platform === 'win32' ? platformSwitch.win32 : platformSwitch.posix;
	}
	return platformSwitch;
}

export async function isFile(shellServer: ShellServer, location: string) {
	return platformDispatch(shellServer.platform, {
		posix: async () => {
			try {
				await shellServer.exec(`test -f '${location}'`);
				return true;
			} catch (err) {
				return false;
			}
		},
		win32: async () => {
			return (await shellServer.exec(`Test-Path '${location}' -PathType Leaf`))
				.stdout.trim() === 'True';
		}
	})();
}

let localUsername: Promise<string>;
export async function getLocalUsername() {
	if (localUsername === undefined) {
		localUsername = (async () => {
			try {
				return os.userInfo().username;
			} catch (err) {
				if (process.platform !== 'linux') {
					throw err;
				}
				// os.userInfo() fails with VS Code snap install: https://github.com/microsoft/vscode-remote-release/issues/6913
				const result = await runCommandNoPty({ exec: plainExec(undefined), cmd: 'id', args: ['-u', '-n'], output: nullLog });
				return result.stdout.toString().trim();
			}
		})();
	}
	return localUsername;
}

export function getEntPasswdShellCommand(userNameOrId: string) {
	const escapedForShell = userNameOrId.replace(/['\\]/g, '\\$&');
	const escapedForRexExp = escapeRegExCharacters(userNameOrId)
		.replaceAll('\'', '\\\'');
	// Leading space makes sure we don't concatenate to arithmetic expansion (https://tldp.org/LDP/abs/html/dblparens.html).
	return ` (command -v getent >/dev/null 2>&1 && getent passwd '${escapedForShell}' || grep -E '^${escapedForRexExp}|^[^:]*:[^:]*:${escapedForRexExp}:' /etc/passwd || true)`;
}
</file>

<file path="src/spec-common/dotfiles.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import { LogLevel } from '../spec-utils/log';

import { ResolverParameters, ContainerProperties, createFileCommand } from './injectHeadless';

const installCommands = [
	'install.sh',
	'install',
	'bootstrap.sh',
	'bootstrap',
	'script/bootstrap',
	'setup.sh',
	'setup',
	'script/setup',
];

export async function installDotfiles(params: ResolverParameters, properties: ContainerProperties, dockerEnvP: Promise<Record<string, string>>, secretsP: Promise<Record<string, string>>) {
	let { repository, installCommand, targetPath } = params.dotfilesConfiguration;
	if (!repository) {
		return;
	}
	if (repository.indexOf(':') === -1 && !/^\.{0,2}\//.test(repository)) {
		repository = `https://github.com/${repository}.git`;
	}
	const shellServer = properties.shellServer;
	const markerFile = getDotfilesMarkerFile(properties);
	const dockerEnvAndSecrets = { ...await dockerEnvP, ...await secretsP };
	const allEnv = Object.keys(dockerEnvAndSecrets)
		.filter(key => !(key.startsWith('BASH_FUNC_') && key.endsWith('%%')))
		.reduce((env, key) => `${env}${key}=${quoteValue(dockerEnvAndSecrets[key])} `, '');
	try {
		params.output.event({
			type: 'progress',
			name: 'Installing Dotfiles',
			status: 'running',
		});
		if (installCommand) {
			await shellServer.exec(`# Clone & install dotfiles via '${installCommand}'
${createFileCommand(markerFile)} || (echo dotfiles marker found && exit 1) || exit 0
command -v git >/dev/null 2>&1 || (echo git not found && exit 1) || exit 0
[ -e ${targetPath} ] || ${allEnv}git clone --depth 1 ${repository} ${targetPath} || exit $?
echo Setting current directory to '${targetPath}'
cd ${targetPath}

if [ -f "./${installCommand}" ]
then
	if [ ! -x "./${installCommand}" ]
	then
		echo Setting './${installCommand}' as executable
		chmod +x "./${installCommand}"
	fi
	echo Executing command './${installCommand}'..\n
	${allEnv}"./${installCommand}"
elif [ -f "${installCommand}" ]
then
	if [ ! -x "${installCommand}" ]
	then
		echo Setting '${installCommand}' as executable
		chmod +x "${installCommand}"
	fi
	echo Executing command '${installCommand}'...\n
	${allEnv}"${installCommand}"
else
	echo Could not locate '${installCommand}'...\n
	exit 126
fi
`, { logOutput: 'continuous', logLevel: LogLevel.Info });
		} else {
			await shellServer.exec(`# Clone & install dotfiles
${createFileCommand(markerFile)} || (echo dotfiles marker found && exit 1) || exit 0
command -v git >/dev/null 2>&1 || (echo git not found && exit 1) || exit 0
[ -e ${targetPath} ] || ${allEnv}git clone --depth 1 ${repository} ${targetPath} || exit $?
echo Setting current directory to ${targetPath}
cd ${targetPath}
for f in ${installCommands.join(' ')}
do
	if [ -e $f ]
	then
		installCommand=$f
		break
	fi
done
if [ -z "$installCommand" ]
then
	dotfiles=$(ls -d ${targetPath}/.* 2>/dev/null | grep -v -E '/(.|..|.git)$')
	if [ ! -z "$dotfiles" ]
	then
		echo Linking dotfiles: $dotfiles
		ln -sf $dotfiles ~ 2>/dev/null
	else
		echo No dotfiles found.
	fi
else
	if [ ! -x "$installCommand" ]
	then
	   echo Setting '${targetPath}'/"$installCommand" as executable
	   chmod +x "$installCommand"
	fi

	echo Executing command '${targetPath}'/"$installCommand"...\n
	${allEnv}./"$installCommand"
fi
`, { logOutput: 'continuous', logLevel: LogLevel.Info });
		}
		params.output.event({
			type: 'progress',
			name: 'Installing Dotfiles',
			status: 'succeeded',
		});
	} catch (err) {
		params.output.event({
			type: 'progress',
			name: 'Installing Dotfiles',
			status: 'failed',
		});
	}
}

function quoteValue(value: string | undefined) {
	return `'${(value || '').replace(/'+/g, '\'"$&"\'')}'`;
}

function getDotfilesMarkerFile(properties: ContainerProperties) {
	return path.posix.join(properties.userDataFolder, '.dotfilesMarker');
}
</file>

<file path="src/spec-common/errors.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { ContainerProperties, CommonDevContainerConfig, ResolverParameters } from './injectHeadless';

export { toErrorText, toWarningText } from '../spec-utils/log';

export interface ContainerErrorAction {
	readonly id: string;
	readonly title: string;
	readonly isCloseAffordance?: boolean;
	readonly isLastAction: boolean;
	applicable: (err: ContainerError, primary: boolean) => boolean | Promise<boolean>;
	execute: (err: ContainerError) => Promise<void>;
}

interface ContainerErrorData {
	reload?: boolean;
	start?: boolean;
	attach?: boolean;
	fileWithError?: string;
	disallowedFeatureId?: string;
	didStopContainer?: boolean;
	learnMoreUrl?: string;
}

interface ContainerErrorInfo {
	description: string;
	originalError?: any;
	manageContainer?: boolean;
	params?: ResolverParameters;
	containerId?: string;
	dockerParams?: any; // TODO
	containerProperties?: ContainerProperties;
	actions?: ContainerErrorAction[];
	data?: ContainerErrorData;
}

export class ContainerError extends Error implements ContainerErrorInfo {
	description!: string;
	originalError?: any;
	manageContainer = false;
	params?: ResolverParameters;
	containerId?: string; // TODO
	dockerParams?: any; // TODO
	volumeName?: string;
	repositoryPath?: string;
	folderPath?: string;
	containerProperties?: ContainerProperties;
	config?: CommonDevContainerConfig;
	actions: ContainerErrorAction[] = [];
	data: ContainerErrorData = {};

	constructor(info: ContainerErrorInfo) {
		super(info.originalError && info.originalError.message || info.description);
		Object.assign(this, info);
		if (this.originalError?.stack) {
			this.stack = this.originalError.stack;
		}
	}
}
</file>

<file path="src/spec-common/git.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { runCommandNoPty, CLIHost } from './commonUtils';
import { Log } from '../spec-utils/log';
import { FileHost } from '../spec-utils/pfs';

export async function findGitRootFolder(cliHost: FileHost | CLIHost, folderPath: string, output: Log) {
	if (!('exec' in cliHost)) {
		for (let current = folderPath, previous = ''; current !== previous; previous = current, current = cliHost.path.dirname(current)) {
			if (await cliHost.isFile(cliHost.path.join(current, '.git', 'config'))) {
				return current;
			}
		}
		return undefined;
	}
	try {
		// Preserves symlinked paths (unlike --show-toplevel).
		const { stdout } = await runCommandNoPty({
			exec: cliHost.exec,
			cmd: 'git',
			args: ['rev-parse', '--show-cdup'],
			cwd: folderPath,
			output,
		});
		const cdup = stdout.toString().trim();
		return cliHost.path.resolve(folderPath, cdup);
	} catch {
		return undefined;
	}
}
</file>

<file path="src/spec-common/injectHeadless.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as fs from 'fs';
import { StringDecoder } from 'string_decoder';
import * as crypto from 'crypto';

import { ContainerError, toErrorText, toWarningText } from './errors';
import { launch, ShellServer } from './shellServer';
import { ExecFunction, CLIHost, PtyExecFunction, isFile, Exec, PtyExec, getEntPasswdShellCommand } from './commonUtils';
import { Disposable, Event, NodeEventEmitter } from '../spec-utils/event';
import { PackageConfiguration } from '../spec-utils/product';
import { URI } from 'vscode-uri';
import { containerSubstitute } from './variableSubstitution';
import { delay } from './async';
import { Log, LogEvent, LogLevel, makeLog, nullLog } from '../spec-utils/log';
import { buildProcessTrees, findProcesses, Process, processTreeToString } from './proc';
import { installDotfiles } from './dotfiles';

export enum ResolverProgress {
	Begin,
	CloningRepository,
	BuildingImage,
	StartingContainer,
	InstallingServer,
	StartingServer,
	End,
}

export interface ResolverParameters {
	prebuild?: boolean;
	computeExtensionHostEnv: boolean;
	package: PackageConfiguration;
	containerDataFolder: string | undefined;
	containerSystemDataFolder: string | undefined;
	appRoot: string | undefined;
	extensionPath: string;
	sessionId: string;
	sessionStart: Date;
	cliHost: CLIHost;
	env: NodeJS.ProcessEnv;
	cwd: string;
	isLocalContainer: boolean;
	dotfilesConfiguration: DotfilesConfiguration;
	progress: (current: ResolverProgress) => void;
	output: Log;
	allowSystemConfigChange: boolean;
	defaultUserEnvProbe: UserEnvProbe;
	lifecycleHook: LifecycleHook;
	getLogLevel: () => LogLevel;
	onDidChangeLogLevel: Event<LogLevel>;
	loadNativeModule: <T>(moduleName: string) => Promise<T | undefined>;
	allowInheritTTY: boolean;
	shutdowns: (() => Promise<void>)[];
	backgroundTasks: (Promise<void> | (() => Promise<void>))[];
	persistedFolder: string; // A path where config can be persisted and restored at a later time. Should default to tmpdir() folder if not provided.
	remoteEnv: Record<string, string>;
	buildxPlatform: string | undefined;
	buildxPush: boolean;
	buildxOutput: string | undefined;
	buildxCacheTo: string | undefined;
	skipFeatureAutoMapping: boolean;
	skipPostAttach: boolean;
	containerSessionDataFolder?: string;
	skipPersistingCustomizationsFromFeatures: boolean;
	omitConfigRemotEnvFromMetadata?: boolean;
	secretsP?: Promise<Record<string, string>>;
	omitSyntaxDirective?: boolean;
}

export interface LifecycleHook {
	enabled: boolean;
	skipNonBlocking: boolean;
	output: Log;
	onDidInput: Event<string>;
	done: () => void;
}

export type LifecycleHooksInstallMap = {
	[lifecycleHook in DevContainerLifecycleHook]: {
		command: LifecycleCommand;
		origin: string;
	}[]; // In installation order.
};

export function createNullLifecycleHook(enabled: boolean, skipNonBlocking: boolean, output: Log): LifecycleHook {
	function listener(data: Buffer) {
		emitter.fire(data.toString());
	}
	const emitter = new NodeEventEmitter<string>({
		on: () => {
			if (process.stdin.isTTY) {
				process.stdin.setRawMode(true);
			}
			process.stdin.on('data', listener);
		},
		off: () => process.stdin.off('data', listener),
	});
	return {
		enabled,
		skipNonBlocking,
		output: makeLog({
			...output,
			get dimensions() {
				return output.dimensions;
			},
			event: e => output.event({
				...e,
				channel: 'postCreate',
			}),
		}),
		onDidInput: emitter.event,
		done: () => { },
	};
}

export interface PortAttributes {
	label: string | undefined;
	onAutoForward: string | undefined;
	elevateIfNeeded: boolean | undefined;
}

export type UserEnvProbe = 'none' | 'loginInteractiveShell' | 'interactiveShell' | 'loginShell';

export type DevContainerLifecycleHook = 'initializeCommand' | 'onCreateCommand' | 'updateContentCommand' | 'postCreateCommand' | 'postStartCommand' | 'postAttachCommand';

const defaultWaitFor: DevContainerLifecycleHook = 'updateContentCommand';

export type LifecycleCommand = string | string[] | { [key: string]: string | string[] };

export interface CommonDevContainerConfig {
	configFilePath?: URI;
	remoteEnv?: Record<string, string | null>;
	forwardPorts?: (number | string)[];
	portsAttributes?: Record<string, PortAttributes>;
	otherPortsAttributes?: PortAttributes;
	features?: Record<string, string | boolean | Record<string, string | boolean>>;
	onCreateCommand?: LifecycleCommand | Record<string, LifecycleCommand>;
	updateContentCommand?: LifecycleCommand | Record<string, LifecycleCommand>;
	postCreateCommand?: LifecycleCommand | Record<string, LifecycleCommand>;
	postStartCommand?: LifecycleCommand | Record<string, LifecycleCommand>;
	postAttachCommand?: LifecycleCommand | Record<string, LifecycleCommand>;
	waitFor?: DevContainerLifecycleHook;
	userEnvProbe?: UserEnvProbe;
}

export interface CommonContainerMetadata {
	onCreateCommand?: string | string[];
	updateContentCommand?: string | string[];
	postCreateCommand?: string | string[];
	postStartCommand?: string | string[];
	postAttachCommand?: string | string[];
	waitFor?: DevContainerLifecycleHook;
	remoteEnv?: Record<string, string | null>;
	userEnvProbe?: UserEnvProbe;
}

export type CommonMergedDevContainerConfig = MergedConfig<CommonDevContainerConfig>;

type MergedConfig<T extends CommonDevContainerConfig> = Omit<T, typeof replaceProperties[number]> & UpdatedConfigProperties;

const replaceProperties = [
	'onCreateCommand',
	'updateContentCommand',
	'postCreateCommand',
	'postStartCommand',
	'postAttachCommand',
] as const;

interface UpdatedConfigProperties {
	onCreateCommands?: LifecycleCommand[];
	updateContentCommands?: LifecycleCommand[];
	postCreateCommands?: LifecycleCommand[];
	postStartCommands?: LifecycleCommand[];
	postAttachCommands?: LifecycleCommand[];
}

export interface OSRelease {
	hardware: string;
	id: string;
	version: string;
}

export interface ContainerProperties {
	createdAt: string | undefined;
	startedAt: string | undefined;
	osRelease: OSRelease;
	user: string;
	gid: string | undefined;
	env: NodeJS.ProcessEnv;
	shell: string;
	homeFolder: string;
	userDataFolder: string;
	remoteWorkspaceFolder?: string;
	remoteExec: ExecFunction;
	remotePtyExec: PtyExecFunction;
	remoteExecAsRoot?: ExecFunction;
	shellServer: ShellServer;
	launchRootShellServer?: () => Promise<ShellServer>;
}

export interface DotfilesConfiguration {
	repository: string | undefined;
	installCommand: string | undefined;
	targetPath: string;
}

export async function getContainerProperties(options: {
	params: ResolverParameters;
	createdAt: string | undefined;
	startedAt: string | undefined;
	remoteWorkspaceFolder: string | undefined;
	containerUser: string | undefined;
	containerGroup: string | undefined;
	containerEnv: NodeJS.ProcessEnv | undefined;
	remoteExec: ExecFunction;
	remotePtyExec: PtyExecFunction;
	remoteExecAsRoot: ExecFunction | undefined;
	rootShellServer: ShellServer | undefined;
}) {
	let { params, createdAt, startedAt, remoteWorkspaceFolder, containerUser, containerGroup, containerEnv, remoteExec, remotePtyExec, remoteExecAsRoot, rootShellServer } = options;
	let shellServer: ShellServer;
	if (rootShellServer && containerUser === 'root') {
		shellServer = rootShellServer;
	} else {
		shellServer = await launch(remoteExec, params.output, params.sessionId);
	}
	if (!containerEnv) {
		const PATH = (await shellServer.exec('echo $PATH')).stdout.trim();
		containerEnv = PATH ? { PATH } : {};
	}
	if (!containerUser) {
		containerUser = await getUser(shellServer);
	}
	if (!remoteExecAsRoot && containerUser === 'root') {
		remoteExecAsRoot = remoteExec;
	}
	const osRelease = await getOSRelease(shellServer);
	const passwdUser = await getUserFromPasswdDB(shellServer, containerUser);
	if (!passwdUser) {
		params.output.write(toWarningText(`User ${containerUser} not found with 'getent passwd'.`));
	}
	const shell = await getUserShell(containerEnv, passwdUser);
	const homeFolder = await getHomeFolder(shellServer, containerEnv, passwdUser);
	const userDataFolder = getUserDataFolder(homeFolder, params);
	let rootShellServerP: Promise<ShellServer> | undefined;
	if (rootShellServer) {
		rootShellServerP = Promise.resolve(rootShellServer);
	} else if (containerUser === 'root') {
		rootShellServerP = Promise.resolve(shellServer);
	}
	const containerProperties: ContainerProperties = {
		createdAt,
		startedAt,
		osRelease,
		user: containerUser,
		gid: containerGroup || passwdUser?.gid,
		env: containerEnv,
		shell,
		homeFolder,
		userDataFolder,
		remoteWorkspaceFolder,
		remoteExec,
		remotePtyExec,
		remoteExecAsRoot,
		shellServer,
	};
	if (rootShellServerP || remoteExecAsRoot) {
		containerProperties.launchRootShellServer = () => rootShellServerP || (rootShellServerP = launch(remoteExecAsRoot!, params.output));
	}
	return containerProperties;
}

export async function getUser(shellServer: ShellServer) {
	return (await shellServer.exec('id -un')).stdout.trim();
}

export async function getHomeFolder(shellServer: ShellServer, containerEnv: NodeJS.ProcessEnv, passwdUser: PasswdUser | undefined) {
	if (containerEnv.HOME) {
		if (containerEnv.HOME === passwdUser?.home || passwdUser?.uid === '0') {
			return containerEnv.HOME;
		}
		try {
			await shellServer.exec(`[ ! -e '${containerEnv.HOME}' ] || [ -w '${containerEnv.HOME}' ]`);
			return containerEnv.HOME;
		} catch {
			// Exists but not writable.
		}
	}
	return passwdUser?.home || '/root';
}

async function getUserShell(containerEnv: NodeJS.ProcessEnv, passwdUser: PasswdUser | undefined) {
	return containerEnv.SHELL || (passwdUser && passwdUser.shell) || '/bin/sh';
}

export async function getUserFromPasswdDB(shellServer: ShellServer, userNameOrId: string) {
	const { stdout } = await shellServer.exec(getEntPasswdShellCommand(userNameOrId), { logOutput: false });
	if (!stdout.trim()) {
		return undefined;
	}
	return parseUserInPasswdDB(stdout);
}

export interface PasswdUser {
	name: string;
	uid: string;
	gid: string;
	home: string;
	shell: string;
}

function parseUserInPasswdDB(etcPasswdLine: string): PasswdUser | undefined {
	const row = etcPasswdLine
		.replace(/\n$/, '')
		.split(':');
	return {
		name: row[0],
		uid: row[2],
		gid: row[3],
		home: row[5],
		shell: row[6]
	};
}

export function getUserDataFolder(homeFolder: string, params: ResolverParameters) {
	return path.posix.resolve(homeFolder, params.containerDataFolder || '.devcontainer');
}

export function getSystemVarFolder(params: ResolverParameters): string {
	return params.containerSystemDataFolder || '/var/devcontainer';
}

export async function setupInContainer(params: ResolverParameters, containerProperties: ContainerProperties, config: CommonDevContainerConfig, mergedConfig: CommonMergedDevContainerConfig, lifecycleCommandOriginMap: LifecycleHooksInstallMap) {
	await patchEtcEnvironment(params, containerProperties);
	await patchEtcProfile(params, containerProperties);
	const computeRemoteEnv = params.computeExtensionHostEnv || params.lifecycleHook.enabled;
	const updatedConfig = containerSubstitute(params.cliHost.platform, config.configFilePath, containerProperties.env, config);
	const updatedMergedConfig = containerSubstitute(params.cliHost.platform, mergedConfig.configFilePath, containerProperties.env, mergedConfig);
	const remoteEnv = computeRemoteEnv ? probeRemoteEnv(params, containerProperties, updatedMergedConfig) : Promise.resolve({});
	const secretsP = params.secretsP || Promise.resolve({});
	if (params.lifecycleHook.enabled) {
		await runLifecycleHooks(params, lifecycleCommandOriginMap, containerProperties, updatedMergedConfig, remoteEnv, secretsP, false);
	}
	return {
		remoteEnv: params.computeExtensionHostEnv ? await remoteEnv : {},
		updatedConfig,
		updatedMergedConfig,
	};
}

export function probeRemoteEnv(params: ResolverParameters, containerProperties: ContainerProperties, config: CommonMergedDevContainerConfig) {
	return probeUserEnv(params, containerProperties, config)
		.then<Record<string, string>>(shellEnv => ({
			...shellEnv,
			...params.remoteEnv,
			...config.remoteEnv,
		} as Record<string, string>));
}

export async function runLifecycleHooks(params: ResolverParameters, lifecycleHooksInstallMap: LifecycleHooksInstallMap, containerProperties: ContainerProperties, config: CommonMergedDevContainerConfig, remoteEnv: Promise<Record<string, string>>, secrets: Promise<Record<string, string>>, stopForPersonalization: boolean): Promise<'skipNonBlocking' | 'prebuild' | 'stopForPersonalization' | 'done'> {
	const skipNonBlocking = params.lifecycleHook.skipNonBlocking;
	const waitFor = config.waitFor || defaultWaitFor;
	if (skipNonBlocking && waitFor === 'initializeCommand') {
		return 'skipNonBlocking';
	}

	params.output.write('LifecycleCommandExecutionMap: ' + JSON.stringify(lifecycleHooksInstallMap, undefined, 4), LogLevel.Trace);

	await runPostCreateCommand(params, lifecycleHooksInstallMap, containerProperties, 'onCreateCommand', remoteEnv, secrets, false);
	if (skipNonBlocking && waitFor === 'onCreateCommand') {
		return 'skipNonBlocking';
	}

	await runPostCreateCommand(params, lifecycleHooksInstallMap, containerProperties, 'updateContentCommand', remoteEnv, secrets, !!params.prebuild);
	if (skipNonBlocking && waitFor === 'updateContentCommand') {
		return 'skipNonBlocking';
	}

	if (params.prebuild) {
		return 'prebuild';
	}

	await runPostCreateCommand(params, lifecycleHooksInstallMap, containerProperties, 'postCreateCommand', remoteEnv, secrets, false);
	if (skipNonBlocking && waitFor === 'postCreateCommand') {
		return 'skipNonBlocking';
	}

	if (params.dotfilesConfiguration) {
		await installDotfiles(params, containerProperties, remoteEnv, secrets);
	}

	if (stopForPersonalization) {
		return 'stopForPersonalization';
	}

	await runPostStartCommand(params, lifecycleHooksInstallMap, containerProperties, remoteEnv, secrets);
	if (skipNonBlocking && waitFor === 'postStartCommand') {
		return 'skipNonBlocking';
	}

	if (!params.skipPostAttach) {
		await runPostAttachCommand(params, lifecycleHooksInstallMap, containerProperties, remoteEnv, secrets);
	}
	return 'done';
}

export async function getOSRelease(shellServer: ShellServer) {
	let hardware = 'unknown';
	let id = 'unknown';
	let version = 'unknown';
	try {
		hardware = (await shellServer.exec('uname -m')).stdout.trim();
		const { stdout } = await shellServer.exec('(cat /etc/os-release || cat /usr/lib/os-release) 2>/dev/null');
		id = (stdout.match(/^ID=([^\u001b\r\n]*)/m) || [])[1] || 'notfound';
		version = (stdout.match(/^VERSION_ID=([^\u001b\r\n]*)/m) || [])[1] || 'notfound';
	} catch (err) {
		console.error(err);
		// Optimistically continue.
	}
	return { hardware, id, version };
}

async function runPostCreateCommand(params: ResolverParameters, lifecycleCommandOriginMap: LifecycleHooksInstallMap, containerProperties: ContainerProperties, postCommandName: 'onCreateCommand' | 'updateContentCommand' | 'postCreateCommand', remoteEnv: Promise<Record<string, string>>, secrets: Promise<Record<string, string>>, rerun: boolean) {
	const markerFile = path.posix.join(containerProperties.userDataFolder, `.${postCommandName}Marker`);
	const doRun = !!containerProperties.createdAt && await updateMarkerFile(containerProperties.shellServer, markerFile, containerProperties.createdAt) || rerun;
	await runLifecycleCommands(params, lifecycleCommandOriginMap, containerProperties, postCommandName, remoteEnv, secrets, doRun);
}

async function runPostStartCommand(params: ResolverParameters, lifecycleCommandOriginMap: LifecycleHooksInstallMap, containerProperties: ContainerProperties, remoteEnv: Promise<Record<string, string>>, secrets: Promise<Record<string, string>>) {
	const markerFile = path.posix.join(containerProperties.userDataFolder, '.postStartCommandMarker');
	const doRun = !!containerProperties.startedAt && await updateMarkerFile(containerProperties.shellServer, markerFile, containerProperties.startedAt);
	await runLifecycleCommands(params, lifecycleCommandOriginMap, containerProperties, 'postStartCommand', remoteEnv, secrets, doRun);
}

async function updateMarkerFile(shellServer: ShellServer, location: string, content: string) {
	try {
		await shellServer.exec(`mkdir -p '${path.posix.dirname(location)}' && CONTENT="$(cat '${location}' 2>/dev/null || echo ENOENT)" && [ "\${CONTENT:-${content}}" != '${content}' ] && echo '${content}' > '${location}'`);
		return true;
	} catch (err) {
		return false;
	}
}

async function runPostAttachCommand(params: ResolverParameters, lifecycleCommandOriginMap: LifecycleHooksInstallMap, containerProperties: ContainerProperties, remoteEnv: Promise<Record<string, string>>, secrets: Promise<Record<string, string>>) {
	await runLifecycleCommands(params, lifecycleCommandOriginMap, containerProperties, 'postAttachCommand', remoteEnv, secrets, true);
}


async function runLifecycleCommands(params: ResolverParameters, lifecycleCommandOriginMap: LifecycleHooksInstallMap, containerProperties: ContainerProperties, lifecycleHookName: 'onCreateCommand' | 'updateContentCommand' | 'postCreateCommand' | 'postStartCommand' | 'postAttachCommand', remoteEnv: Promise<Record<string, string>>, secrets: Promise<Record<string, string>>, doRun: boolean) {
	const commandsForHook = lifecycleCommandOriginMap[lifecycleHookName];
	if (commandsForHook.length === 0) {
		return;
	}

	for (const { command, origin } of commandsForHook) {
		const displayOrigin = origin ? (origin === 'devcontainer.json' ? origin : `Feature '${origin}'`) : '???'; /// '???' should never happen.
		await runLifecycleCommand(params, containerProperties, command, displayOrigin, lifecycleHookName, remoteEnv, secrets, doRun);
	}
}

async function runLifecycleCommand({ lifecycleHook }: ResolverParameters, containerProperties: ContainerProperties, userCommand: LifecycleCommand, userCommandOrigin: string, lifecycleHookName: 'onCreateCommand' | 'updateContentCommand' | 'postCreateCommand' | 'postStartCommand' | 'postAttachCommand', remoteEnv: Promise<Record<string, string>>, secrets: Promise<Record<string, string>>, doRun: boolean) {
	let hasCommand = false;
	if (typeof userCommand === 'string') {
		hasCommand = userCommand.trim().length > 0;
	} else if (Array.isArray(userCommand)) {
		hasCommand = userCommand.length > 0;
	} else if (typeof userCommand === 'object') {
		hasCommand = Object.keys(userCommand).length > 0;
	}
	if (doRun && userCommand && hasCommand) {
		const progressName = `Running ${lifecycleHookName}...`;
		const infoOutput = makeLog({
			event(e: LogEvent) {
				lifecycleHook.output.event(e);
				if (e.type === 'raw' && e.text.includes('::endstep::')) {
					lifecycleHook.output.event({
						type: 'progress',
						name: progressName,
						status: 'running',
						stepDetail: ''
					});
				}
				if (e.type === 'raw' && e.text.includes('::step::')) {
					lifecycleHook.output.event({
						type: 'progress',
						name: progressName,
						status: 'running',
						stepDetail: `${e.text.split('::step::')[1].split('\r\n')[0]}`
					});
				}
			},
			get dimensions() {
				return lifecycleHook.output.dimensions;
			},
			onDidChangeDimensions: lifecycleHook.output.onDidChangeDimensions,
		}, LogLevel.Info);
		const remoteCwd = containerProperties.remoteWorkspaceFolder || containerProperties.homeFolder;
		async function runSingleCommand(postCommand: string | string[], name?: string) {
			const progressDetails = typeof postCommand === 'string' ? postCommand : postCommand.join(' ');
			infoOutput.event({
				type: 'progress',
				name: progressName,
				status: 'running',
				stepDetail: progressDetails
			});
			// If we have a command name then the command is running in parallel and 
			// we need to hold output until the command is done so that the output
			// doesn't get interleaved with the output of other commands.
			const printMode = name ? 'off' : 'continuous';
			const env = { ...(await remoteEnv), ...(await secrets) };
			try {
				const { cmdOutput } = await runRemoteCommand({ ...lifecycleHook, output: infoOutput }, containerProperties, typeof postCommand === 'string' ? ['/bin/sh', '-c', postCommand] : postCommand, remoteCwd, { remoteEnv: env, pty: true, print: printMode });

				// 'name' is set when parallel execution syntax is used.
				if (name) {
					infoOutput.raw(`\x1b[1mRunning ${name} of ${lifecycleHookName} from ${userCommandOrigin}...\x1b[0m\r\n${cmdOutput}\r\n`);
				}
			} catch (err) {
				if (printMode === 'off' && err?.cmdOutput) {
					infoOutput.raw(`\r\n\x1b[1m${err.cmdOutput}\x1b[0m\r\n\r\n`);
				}
				if (err && (err.code === 130 || err.signal === 2)) { // SIGINT seen on darwin as code === 130, would also make sense as signal === 2.
					infoOutput.raw(`\r\n\x1b[1m${name ? `${name} of ${lifecycleHookName}` : lifecycleHookName} from ${userCommandOrigin} interrupted.\x1b[0m\r\n\r\n`);
				} else {
					if (err?.code) {
						infoOutput.write(toErrorText(`${name ? `${name} of ${lifecycleHookName}` : lifecycleHookName} from ${userCommandOrigin} failed with exit code ${err.code}. Skipping any further user-provided commands.`));
					}
					throw new ContainerError({
						description: `${name ? `${name} of ${lifecycleHookName}` : lifecycleHookName} from ${userCommandOrigin} failed.`,
						originalError: err
					});
				}
			}
		}

		infoOutput.raw(`\x1b[1mRunning the ${lifecycleHookName} from ${userCommandOrigin}...\x1b[0m\r\n\r\n`);

		try {
			let commands;
			if (typeof userCommand === 'string' || Array.isArray(userCommand)) {
				commands = [runSingleCommand(userCommand)];
			} else {
				commands = Object.keys(userCommand).map(name => {
					const command = userCommand[name];
					return runSingleCommand(command, name);
				});
			}

			const results = await Promise.allSettled(commands); // Wait for all commands to finish (successfully or not) before continuing.
			const rejection = results.find(p => p.status === 'rejected');
			if (rejection) {
				throw (rejection as PromiseRejectedResult).reason;
			}
			infoOutput.event({
				type: 'progress',
				name: progressName,
				status: 'succeeded',
			});
		} catch (err) {
			infoOutput.event({
				type: 'progress',
				name: progressName,
				status: 'failed',
			});
			throw err;
		}
	}
}

async function createFile(shellServer: ShellServer, location: string) {
	try {
		await shellServer.exec(createFileCommand(location));
		return true;
	} catch (err) {
		return false;
	}
}

export function createFileCommand(location: string) {
	return `test ! -f '${location}' && set -o noclobber && mkdir -p '${path.posix.dirname(location)}' && { > '${location}' ; } 2> /dev/null`;
}

export async function runRemoteCommand(params: { output: Log; onDidInput?: Event<string>; stdin?: NodeJS.ReadStream; stdout?: NodeJS.WriteStream; stderr?: NodeJS.WriteStream }, { remoteExec, remotePtyExec }: ContainerProperties, cmd: string[], cwd?: string, options: { remoteEnv?: NodeJS.ProcessEnv; pty?: boolean; print?: 'off' | 'continuous' | 'end' } = {}) {
	const print = options.print || 'end';
	let sub: Disposable | undefined;
	let pp: Exec | PtyExec;
	let cmdOutput = '';
	if (options.pty) {
		const p = pp = await remotePtyExec({
			env: options.remoteEnv,
			cwd,
			cmd: cmd[0],
			args: cmd.slice(1),
			output: params.output,
		});
		p.onData(chunk => {
			cmdOutput += chunk;
			if (print === 'continuous') {
				if (params.stdout) {
					params.stdout.write(chunk);
				} else {
					params.output.raw(chunk);
				}
			}
		});
		if (p.write && params.onDidInput) {
			params.onDidInput(data => p.write!(data));
		} else if (p.write && params.stdin) {
			const listener = (data: Buffer): void => p.write!(data.toString());
			const stdin = params.stdin;
			if (stdin.isTTY) {
				stdin.setRawMode(true);
			}
			stdin.on('data', listener);
			sub = { dispose: () => stdin.off('data', listener) };
		}
	} else {
		const p = pp = await remoteExec({
			env: options.remoteEnv,
			cwd,
			cmd: cmd[0],
			args: cmd.slice(1),
			output: params.output,
		});
		const stdout: Buffer[] = [];
		if (print === 'continuous' && params.stdout) {
			p.stdout.pipe(params.stdout);
		} else {
			p.stdout.on('data', chunk => {
				stdout.push(chunk);
				if (print === 'continuous') {
					params.output.raw(chunk.toString());
				}
			});
		}
		const stderr: Buffer[] = [];
		if (print === 'continuous' && params.stderr) {
			p.stderr.pipe(params.stderr);
		} else {
			p.stderr.on('data', chunk => {
				stderr.push(chunk);
				if (print === 'continuous') {
					params.output.raw(chunk.toString());
				}
			});
		}
		if (params.onDidInput) {
			params.onDidInput(data => p.stdin.write(data));
		} else if (params.stdin) {
			params.stdin.pipe(p.stdin);
		}
		await pp.exit;
		cmdOutput = `${Buffer.concat(stdout)}\n${Buffer.concat(stderr)}`;
	}
	const exit = await pp.exit;
	if (sub) {
		sub.dispose();
	}
	if (print === 'end') {
		params.output.raw(cmdOutput);
	}
	if (exit.code || exit.signal) {
		return Promise.reject({
			message: `Command failed: ${cmd.join(' ')}`,
			cmdOutput,
			code: exit.code,
			signal: exit.signal,
		});
	}
	return {
		cmdOutput,
	};
}

async function runRemoteCommandNoPty(params: { output: Log }, { remoteExec }: { remoteExec: ExecFunction }, cmd: string[], cwd?: string, options: { remoteEnv?: NodeJS.ProcessEnv; stdin?: Buffer | fs.ReadStream; silent?: boolean; print?: 'off' | 'continuous' | 'end'; resolveOn?: RegExp } = {}) {
	const print = options.print || (options.silent ? 'off' : 'end');
	const p = await remoteExec({
		env: options.remoteEnv,
		cwd,
		cmd: cmd[0],
		args: cmd.slice(1),
		output: options.silent ? nullLog : params.output,
	});
	const stdout: Buffer[] = [];
	const stderr: Buffer[] = [];
	const stdoutDecoder = new StringDecoder();
	const stderrDecoder = new StringDecoder();
	let stdoutStr = '';
	let stderrStr = '';
	let doResolveEarly: () => void;
	let doRejectEarly: (err: any) => void;
	const resolveEarly = new Promise<void>((resolve, reject) => {
		doResolveEarly = resolve;
		doRejectEarly = reject;
	});
	p.stdout.on('data', (chunk: Buffer) => {
		stdout.push(chunk);
		const str = stdoutDecoder.write(chunk);
		if (print === 'continuous') {
			params.output.write(str.replace(/\r?\n/g, '\r\n'));
		}
		stdoutStr += str;
		if (options.resolveOn && options.resolveOn.exec(stdoutStr)) {
			doResolveEarly();
		}
	});
	p.stderr.on('data', (chunk: Buffer) => {
		stderr.push(chunk);
		stderrStr += stderrDecoder.write(chunk);
	});
	if (options.stdin instanceof Buffer) {
		p.stdin.write(options.stdin, err => {
			if (err) {
				doRejectEarly(err);
			}
		});
		p.stdin.end();
	} else if (options.stdin instanceof fs.ReadStream) {
		options.stdin.pipe(p.stdin);
	}
	const exit = await Promise.race([p.exit, resolveEarly]);
	const stdoutBuf = Buffer.concat(stdout);
	const stderrBuf = Buffer.concat(stderr);
	if (print === 'end') {
		params.output.write(stdoutStr.replace(/\r?\n/g, '\r\n'));
		params.output.write(toErrorText(stderrStr));
	}
	const cmdOutput = `${stdoutStr}\n${stderrStr}`;
	if (exit && (exit.code || exit.signal)) {
		return Promise.reject({
			message: `Command failed: ${cmd.join(' ')}`,
			cmdOutput,
			stdout: stdoutBuf,
			stderr: stderrBuf,
			code: exit.code,
			signal: exit.signal,
		});
	}
	return {
		cmdOutput,
		stdout: stdoutBuf,
		stderr: stderrBuf,
	};
}

async function patchEtcEnvironment(params: ResolverParameters, containerProperties: ContainerProperties) {
	const markerFile = path.posix.join(getSystemVarFolder(params), `.patchEtcEnvironmentMarker`);
	if (params.allowSystemConfigChange && containerProperties.launchRootShellServer && !(await isFile(containerProperties.shellServer, markerFile))) {
		const rootShellServer = await containerProperties.launchRootShellServer();
		if (await createFile(rootShellServer, markerFile)) {
			await rootShellServer.exec(`cat >> /etc/environment <<'etcEnvironmentEOF'
${Object.keys(containerProperties.env).map(k => `\n${k}="${containerProperties.env[k]}"`).join('')}
etcEnvironmentEOF
`);
		}
	}
}

async function patchEtcProfile(params: ResolverParameters, containerProperties: ContainerProperties) {
	const markerFile = path.posix.join(getSystemVarFolder(params), `.patchEtcProfileMarker`);
	if (params.allowSystemConfigChange && containerProperties.launchRootShellServer && !(await isFile(containerProperties.shellServer, markerFile))) {
		const rootShellServer = await containerProperties.launchRootShellServer();
		if (await createFile(rootShellServer, markerFile)) {
			await rootShellServer.exec(`sed -i -E 's/((^|\\s)PATH=)([^\\$]*)$/\\1\${PATH:-\\3}/g' /etc/profile || true`);
		}
	}
}

async function probeUserEnv(params: { defaultUserEnvProbe: UserEnvProbe; allowSystemConfigChange: boolean; output: Log; containerSessionDataFolder?: string }, containerProperties: { shell: string; remoteExec: ExecFunction; installFolder?: string; env?: NodeJS.ProcessEnv; shellServer?: ShellServer; launchRootShellServer?: (() => Promise<ShellServer>); user?: string }, config?: CommonMergedDevContainerConfig) {
	let userEnvProbe = getUserEnvProb(config, params);
	if (!userEnvProbe || userEnvProbe === 'none') {
		return {};
	}

	let env = await readUserEnvFromCache(userEnvProbe, params, containerProperties.shellServer);
	if (env) {
		return env;
	}

	params.output.write('userEnvProbe: not found in cache');
	env = await runUserEnvProbe(userEnvProbe, params, containerProperties, 'cat /proc/self/environ', '\0');
	if (!env) {
		params.output.write('userEnvProbe: falling back to printenv');
		env = await runUserEnvProbe(userEnvProbe, params, containerProperties, 'printenv', '\n');
	}

	if (env) {
		await updateUserEnvCache(env, userEnvProbe, params, containerProperties.shellServer);
	}

	return env || {};
}

async function readUserEnvFromCache(userEnvProbe: UserEnvProbe, params: { output: Log; containerSessionDataFolder?: string }, shellServer?: ShellServer) {
	if (!shellServer || !params.containerSessionDataFolder) {
		return undefined;
	}

	const cacheFile = getUserEnvCacheFilePath(userEnvProbe, params.containerSessionDataFolder);
	try {
		if (await isFile(shellServer, cacheFile)) {
			const { stdout } = await shellServer.exec(`cat '${cacheFile}'`);
			return JSON.parse(stdout);
		}
	}
	catch (e) {
		params.output.write(`Failed to read/parse user env cache: ${e}`, LogLevel.Error);
	}

	return undefined;
}

async function updateUserEnvCache(env: Record<string, string>, userEnvProbe: UserEnvProbe, params: { output: Log; containerSessionDataFolder?: string }, shellServer?: ShellServer) {
	if (!shellServer || !params.containerSessionDataFolder) {
		return;
	}

	const cacheFile = getUserEnvCacheFilePath(userEnvProbe, params.containerSessionDataFolder);
	try {
		await shellServer.exec(`mkdir -p '${path.posix.dirname(cacheFile)}' && cat > '${cacheFile}' << 'envJSON'
${JSON.stringify(env, null, '\t')}
envJSON
`);
	}
	catch (e) {
		params.output.write(`Failed to cache user env: ${e}`, LogLevel.Error);
	}
}

function getUserEnvCacheFilePath(userEnvProbe: UserEnvProbe, cacheFolder: string): string {
	return path.posix.join(cacheFolder, `env-${userEnvProbe}.json`);
}

async function runUserEnvProbe(userEnvProbe: UserEnvProbe, params: { allowSystemConfigChange: boolean; output: Log }, containerProperties: { shell: string; remoteExec: ExecFunction; installFolder?: string; env?: NodeJS.ProcessEnv; shellServer?: ShellServer; launchRootShellServer?: (() => Promise<ShellServer>); user?: string }, cmd: string, sep: string) {
	if (userEnvProbe === 'none') {
		return {};
	}
	try {
		// From VS Code's shellEnv.ts

		const mark = crypto.randomUUID();
		const regex = new RegExp(mark + '([^]*)' + mark);
		const systemShellUnix = containerProperties.shell;
		params.output.write(`userEnvProbe shell: ${systemShellUnix}`);

		// handle popular non-POSIX shells
		const name = path.posix.basename(systemShellUnix);
		const command = `echo -n ${mark}; ${cmd}; echo -n ${mark}`;
		let shellArgs: string[];
		if (/^pwsh(-preview)?$/.test(name)) {
			shellArgs = userEnvProbe === 'loginInteractiveShell' || userEnvProbe === 'loginShell' ?
				['-Login', '-Command'] : // -Login must be the first option.
				['-Command'];
		} else {
			shellArgs = [
				userEnvProbe === 'loginInteractiveShell' ? '-lic' :
					userEnvProbe === 'loginShell' ? '-lc' :
						userEnvProbe === 'interactiveShell' ? '-ic' :
							'-c'
			];
		}

		const traceOutput = makeLog(params.output, LogLevel.Trace);
		const resultP = runRemoteCommandNoPty({ output: traceOutput }, { remoteExec: containerProperties.remoteExec }, [systemShellUnix, ...shellArgs, command], containerProperties.installFolder);
		Promise.race([resultP, delay(2000)])
			.then(async result => {
				if (!result) {
					let processes: Process[];
					const shellServer = containerProperties.shellServer || await launch(containerProperties.remoteExec, params.output);
					try {
						({ processes } = await findProcesses(shellServer));
					} finally {
						if (!containerProperties.shellServer) {
							await shellServer.process.terminate();
						}
					}
					const shell = processes.find(p => p.cmd.startsWith(systemShellUnix) && p.cmd.indexOf(mark) !== -1);
					if (shell) {
						const index = buildProcessTrees(processes);
						const tree = index[shell.pid];
						params.output.write(`userEnvProbe is taking longer than 2 seconds. Process tree:
${processTreeToString(tree)}`);
					} else {
						params.output.write(`userEnvProbe is taking longer than 2 seconds. Process not found.`);
					}
				}
			}, () => undefined)
			.catch(err => params.output.write(toErrorText(err && (err.stack || err.message) || 'Error reading process tree.')));
		const result = await Promise.race([resultP, delay(10000)]);
		if (!result) {
			params.output.write(toErrorText(`userEnvProbe is taking longer than 10 seconds. Avoid waiting for user input in your shell's startup scripts. Continuing.`));
			return {};
		}
		const raw = result.stdout.toString();
		const match = regex.exec(raw);
		const rawStripped = match ? match[1] : '';
		if (!rawStripped) {
			return undefined; // assume error
		}
		const env = rawStripped.split(sep)
			.reduce((env, e) => {
				const i = e.indexOf('=');
				if (i !== -1) {
					env[e.substring(0, i)] = e.substring(i + 1);
				}
				return env;
			}, {} as Record<string, string>);
		params.output.write(`userEnvProbe parsed: ${JSON.stringify(env, undefined, '  ')}`, LogLevel.Trace);
		delete env.PWD;

		const shellPath = env.PATH;
		const containerPath = containerProperties.env?.PATH;
		const doMergePaths = !(params.allowSystemConfigChange && containerProperties.launchRootShellServer) && shellPath && containerPath;
		if (doMergePaths) {
			const user = containerProperties.user;
			env.PATH = mergePaths(shellPath, containerPath!, user === 'root' || user === '0');
		}
		params.output.write(`userEnvProbe PATHs:
Probe:     ${typeof shellPath === 'string' ? `'${shellPath}'` : 'None'}
Container: ${typeof containerPath === 'string' ? `'${containerPath}'` : 'None'}${doMergePaths ? `
Merged:    ${typeof env.PATH === 'string' ? `'${env.PATH}'` : 'None'}` : ''}`);

		return env;
	} catch (err) {
		params.output.write(toErrorText(err && (err.stack || err.message) || 'Error reading shell environment.'));
		return {};
	}
}

function getUserEnvProb(config: CommonMergedDevContainerConfig | undefined, params: { defaultUserEnvProbe: UserEnvProbe; allowSystemConfigChange: boolean; output: Log }) {
	let userEnvProbe = config?.userEnvProbe;
	params.output.write(`userEnvProbe: ${userEnvProbe || params.defaultUserEnvProbe}${userEnvProbe ? '' : ' (default)'}`);
	if (!userEnvProbe) {
		userEnvProbe = params.defaultUserEnvProbe;
	}
	return userEnvProbe;
}

function mergePaths(shellPath: string, containerPath: string, rootUser: boolean) {
	const result = shellPath.split(':');
	let insertAt = 0;
	for (const entry of containerPath.split(':')) {
		const i = result.indexOf(entry);
		if (i === -1) {
			if (rootUser || !/\/sbin(\/|$)/.test(entry)) {
				result.splice(insertAt++, 0, entry);
			}
		} else {
			insertAt = i + 1;
		}
	}
	return result.join(':');
}

export async function finishBackgroundTasks(tasks: (Promise<void> | (() => Promise<void>))[]) {
	for (const task of tasks) {
		await (typeof task === 'function' ? task() : task);
	}
}
</file>

<file path="src/spec-common/proc.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { ShellServer } from './shellServer';

export interface Process {
	pid: string;
	ppid: string | undefined;
	pgrp: string | undefined;
	cwd: string;
	mntNS: string;
	cmd: string;
	env: Record<string, string>;
}

export async function findProcesses(shellServer: ShellServer) {
	const ps = 'for pid in `cd /proc && ls -d [0-9]*`; do { echo $pid ; readlink /proc/$pid/cwd ; readlink /proc/$pid/ns/mnt ; cat /proc/$pid/stat | tr "\n" " " ; echo ; xargs -0 < /proc/$pid/environ ; xargs -0 < /proc/$pid/cmdline ; } ; echo --- ; done ; readlink /proc/self/ns/mnt 2>/dev/null';
	const { stdout } = await shellServer.exec(ps, { logOutput: false });

	const n = 6;
	const sections = stdout.split('\n---\n');
	const mntNS = sections.pop()!.trim();
	const processes: Process[] = sections
		.map(line => line.split('\n'))
		.filter(parts => parts.length >= n)
		.map(([pid, cwd, mntNS, stat, env, cmd]) => {
			const statM: (string | undefined)[] = /.*\) [^ ]* ([^ ]*) ([^ ]*)/.exec(stat) || [];
			return {
				pid,
				ppid: statM[1],
				pgrp: statM[2],
				cwd,
				mntNS,
				cmd,
				env: env.split(' ')
					.reduce((env, current) => {
						const i = current.indexOf('=');
						if (i !== -1) {
							env[current.substr(0, i)] = current.substr(i + 1);
						}
						return env;
					}, {} as Record<string, string>),
			};
		});
	return {
		processes,
		mntNS,
	};
}

export interface ProcessTree {
	process: Process;
	childProcesses: ProcessTree[];
}

export function buildProcessTrees(processes: Process[]) {
	const index: Record<string, ProcessTree> = {};
	processes.forEach(process => index[process.pid] = { process, childProcesses: [] });
	processes.filter(p => p.ppid)
		.forEach(p => index[p.ppid!]?.childProcesses.push(index[p.pid]));
	return index;
}

export function processTreeToString(tree: ProcessTree, singleIndent = '  ', currentIndent = '  '): string {
	return `${currentIndent}${tree.process.pid}: ${tree.process.cmd}
${tree.childProcesses.map(p => processTreeToString(p, singleIndent, currentIndent + singleIndent))}`;
}
</file>

<file path="src/spec-common/shellServer.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';

import { StringDecoder } from 'string_decoder';
import { ExecFunction, Exec, PlatformSwitch, platformDispatch } from './commonUtils';
import { Log, LogLevel } from '../spec-utils/log';

export interface ShellServer {
	exec(cmd: PlatformSwitch<string>, options?: { logLevel?: LogLevel; logOutput?: boolean | 'continuous' | 'silent'; stdin?: Buffer }): Promise<{ stdout: string; stderr: string }>;
	process: Exec;
	platform: NodeJS.Platform;
	path: typeof path.posix | typeof path.win32;
}

export const EOT = '\u2404';

export async function launch(remoteExec: ExecFunction | Exec, output: Log, agentSessionId?: string, platform: NodeJS.Platform = 'linux', hostName: 'Host' | 'Container' = 'Container'): Promise<ShellServer> {
	const isExecFunction = typeof remoteExec === 'function';
	const isWindows = platform === 'win32';
	const p = isExecFunction ? await remoteExec({
		env: agentSessionId ? { VSCODE_REMOTE_CONTAINERS_SESSION: agentSessionId } : {},
		cmd: isWindows ? 'powershell' : '/bin/sh',
		args: isWindows ? ['-NoProfile', '-Command', '-'] : [],
		output,
	}) : remoteExec;
	if (!isExecFunction) {
		// TODO: Pass in agentSessionId.
		const stdinText = isWindows
			? `powershell -NoProfile -Command "powershell -NoProfile -Command -"\n` // Nested PowerShell (for some reason) avoids the echo of stdin on stdout.
			: `/bin/sh -c 'echo ${EOT}; /bin/sh'\n`;
		p.stdin.write(stdinText);
		const eot = new Promise<void>(resolve => {
			let stdout = '';
			const stdoutDecoder = new StringDecoder();
			p.stdout.on('data', function eotListener(chunk: Buffer) {
				stdout += stdoutDecoder.write(chunk);
				if (stdout.includes(stdinText)) {
					p.stdout.off('data', eotListener);
					resolve();
				}
			});
		});
		await eot;
	}

	const monitor = monitorProcess(p);

	let lastExec: Promise<any> | undefined;
	async function exec(cmd: PlatformSwitch<string>, options?: { logLevel?: LogLevel; logOutput?: boolean | 'continuous' | 'silent'; stdin?: Buffer }) {
		const currentExec = lastExec = (async () => {
			try {
				await lastExec;
			} catch (err) {
				// ignore
			}
			return _exec(platformDispatch(platform, cmd), options);
		})();
		try {
			return await Promise.race([currentExec, monitor.unexpectedExit]);
		} finally {
			monitor.disposeStdioListeners();
			if (lastExec === currentExec) {
				lastExec = undefined;
			}
		}
	}

	async function _exec(cmd: string, options?: { logLevel?: LogLevel; logOutput?: boolean | 'continuous' | 'silent'; stdin?: Buffer }) {
		const text = `Run in ${hostName.toLowerCase()}: ${cmd.replace(/\n.*/g, '')}`;
		let start: number;
		if (options?.logOutput !== 'silent') {
			start = output.start(text, options?.logLevel);
		}
		if (p.stdin.destroyed) {
			output.write('Stdin closed!');
			const { code, signal } = await p.exit;
			return Promise.reject({ message: `Shell server terminated (code: ${code}, signal: ${signal})`, code, signal });
		}
		if (platform === 'win32') {
			p.stdin.write(`[Console]::Write('${EOT}'); ( ${cmd} ); [Console]::Write("${EOT}$LastExitCode ${EOT}"); [Console]::Error.Write('${EOT}')\n`);
		} else {
			p.stdin.write(`echo -n ${EOT}; ( ${cmd} ); echo -n ${EOT}$?${EOT}; echo -n ${EOT} >&2\n`);
		}
		const [stdoutP0, stdoutP] = read(p.stdout, [1, 2], options?.logOutput === 'continuous' ? (str, i, j) => {
			if (i === 1 && j === 0) {
				output.write(str, options?.logLevel);
			}
		} : () => undefined);
		const stderrP = read(p.stderr, [1], options?.logOutput === 'continuous' ? (str, i, j) => {
			if (i === 0 && j === 0) {
				output.write(str, options?.logLevel); // TODO
			}
		} : () => undefined)[0];
		if (options?.stdin) {
			await stdoutP0; // Wait so `cmd` has its stdin set up.
			p.stdin.write(options?.stdin);
		}
		const [stdout, codeStr] = await stdoutP;
		const [stderr] = await stderrP;
		const code = parseInt(codeStr, 10) || 0;
		if (options?.logOutput === undefined || options?.logOutput === true) {
			output.write(stdout, options?.logLevel);
			output.write(stderr, options?.logLevel); // TODO
			if (code) {
				output.write(`Exit code ${code}`, options?.logLevel);
			}
		}
		if (options?.logOutput === 'continuous' && code) {
			output.write(`Exit code ${code}`, options?.logLevel);
		}
		if (options?.logOutput !== 'silent') {
			output.stop(text, start!, options?.logLevel);
		}
		if (code) {
			return Promise.reject({ message: `Command in ${hostName.toLowerCase()} failed: ${cmd}`, code, stdout, stderr });
		}
		return { stdout, stderr };
	}

	return { exec, process: p, platform, path: platformDispatch(platform, path) };
}

function read(stream: NodeJS.ReadableStream, numberOfResults: number[], log: (str: string, i: number, j: number) => void) {
	const promises = numberOfResults.map(() => {
		let cbs: { resolve: (value: string[]) => void; reject: () => void };
		const promise = new Promise<string[]>((resolve, reject) => cbs = { resolve, reject });
		return { promise, ...cbs! };
	});
	const decoder = new StringDecoder('utf8');
	const strings: string[] = [];

	let j = 0;
	let results: string[] = [];
	function data(chunk: Buffer) {
		const str = decoder.write(chunk);
		consume(str);
	}
	function consume(str: string) {
		// console.log(`consume ${numberOfResults}: '${str}'`);
		const i = str.indexOf(EOT);
		if (i !== -1) {
			const s = str.substr(0, i);
			strings.push(s);
			log(s, j, results.length);
			// console.log(`result ${numberOfResults}: '${strings.join('')}'`);
			results.push(strings.join(''));
			strings.length = 0;
			if (results.length === numberOfResults[j]) {
				promises[j].resolve(results);
				j++;
				results = [];
				if (j === numberOfResults.length) {
					stream.off('data', data);
				}
			}
			if (i + 1 < str.length) {
				consume(str.substr(i + 1));
			}
		} else {
			strings.push(str);
			log(str, j, results.length);
		}
	}
	stream.on('data', data);

	return promises.map(p => p.promise);
}

function monitorProcess(p: Exec) {
	let processExited: (err: any) => void;
	const unexpectedExit = new Promise<never>((_resolve, reject) => processExited = reject);
	const stdout: Buffer[] = [];
	const stderr: Buffer[] = [];
	const stdoutListener = (chunk: Buffer) => stdout.push(chunk);
	const stderrListener = (chunk: Buffer) => stderr.push(chunk);
	p.stdout.on('data', stdoutListener);
	p.stderr.on('data', stderrListener);
	p.exit.then(({ code, signal }) => {
		processExited(`Shell server terminated (code: ${code}, signal: ${signal})
${Buffer.concat(stdout).toString()}
${Buffer.concat(stderr).toString()}`);
	}, err => {
		processExited(`Shell server failed: ${err && (err.stack || err.message)}`);
	});
	const disposeStdioListeners = () => {
		p.stdout.off('data', stdoutListener);
		p.stderr.off('data', stderrListener);
		stdout.length = 0;
		stderr.length = 0;
	};
	return {
		unexpectedExit,
		disposeStdioListeners,
	};
}
</file>

<file path="src/spec-common/tsconfig.json">
{
	"extends": "../../tsconfig.base.json",
	"references": [
		{
			"path": "../spec-utils"
		}
	]
}
</file>

<file path="src/spec-common/variableSubstitution.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as crypto from 'crypto';

import { ContainerError } from './errors';
import { URI } from 'vscode-uri';

export interface SubstitutionContext {
	platform: NodeJS.Platform;
	configFile?: URI;
	localWorkspaceFolder?: string;
	containerWorkspaceFolder?: string;
	env: NodeJS.ProcessEnv;
}

export function substitute<T extends object>(context: SubstitutionContext, value: T): T {
	let env: NodeJS.ProcessEnv | undefined;
	const isWindows = context.platform === 'win32';
	const updatedContext = {
		...context,
		get env() {
			return env || (env = normalizeEnv(isWindows, context.env));
		}
	};
	const replace = replaceWithContext.bind(undefined, isWindows, updatedContext);
	if (context.containerWorkspaceFolder) {
		updatedContext.containerWorkspaceFolder = resolveString(replace, context.containerWorkspaceFolder);
	}
	return substitute0(replace, value);
}

export function beforeContainerSubstitute<T extends object>(idLabels: Record<string, string> | undefined, value: T): T {
	let devcontainerId: string | undefined;
	return substitute0(replaceDevContainerId.bind(undefined, () => devcontainerId || (idLabels && (devcontainerId = devcontainerIdForLabels(idLabels)))), value);
}

export function containerSubstitute<T extends object>(platform: NodeJS.Platform, configFile: URI | undefined, containerEnv: NodeJS.ProcessEnv, value: T): T {
	const isWindows = platform === 'win32';
	return substitute0(replaceContainerEnv.bind(undefined, isWindows, configFile, normalizeEnv(isWindows, containerEnv)), value);
}

type Replace = (match: string, variable: string, args: string[]) => string;

function substitute0(replace: Replace, value: any): any {
	if (typeof value === 'string') {
		return resolveString(replace, value);
	} else if (Array.isArray(value)) {
		return value.map(s => substitute0(replace, s));
	} else if (value && typeof value === 'object' && !URI.isUri(value)) {
		const result: any = Object.create(null);
		Object.keys(value).forEach(key => {
			result[key] = substitute0(replace, value[key]);
		});
		return result;
	}
	return value;
}

const VARIABLE_REGEXP = /\$\{(.*?)\}/g;

function normalizeEnv(isWindows: boolean, originalEnv: NodeJS.ProcessEnv): NodeJS.ProcessEnv {
	if (isWindows) {
		const env = Object.create(null);
		Object.keys(originalEnv).forEach(key => {
			env[key.toLowerCase()] = originalEnv[key];
		});
		return env;
	}
	return originalEnv;
}

function resolveString(replace: Replace, value: string): string {
	// loop through all variables occurrences in 'value'
	return value.replace(VARIABLE_REGEXP, evaluateSingleVariable.bind(undefined, replace));
}

function evaluateSingleVariable(replace: Replace, match: string, variable: string): string {

	// try to separate variable arguments from variable name
	let args: string[] = [];
	const parts = variable.split(':');
	if (parts.length > 1) {
		variable = parts[0];
		args = parts.slice(1);
	}

	return replace(match, variable, args);
}

function replaceWithContext(isWindows: boolean, context: SubstitutionContext, match: string, variable: string, args: string[]) {
	switch (variable) {
		case 'env':
		case 'localEnv':
			return lookupValue(isWindows, context.env, args, match, context.configFile);

		case 'localWorkspaceFolder':
			return context.localWorkspaceFolder !== undefined ? context.localWorkspaceFolder : match;

		case 'localWorkspaceFolderBasename':
			return context.localWorkspaceFolder !== undefined ? (isWindows ? path.win32 : path.posix).basename(context.localWorkspaceFolder) : match;

		case 'containerWorkspaceFolder':
			return context.containerWorkspaceFolder !== undefined ? context.containerWorkspaceFolder : match;

		case 'containerWorkspaceFolderBasename':
			return context.containerWorkspaceFolder !== undefined ? path.posix.basename(context.containerWorkspaceFolder) : match;

		default:
			return match;
	}
}

function replaceContainerEnv(isWindows: boolean, configFile: URI | undefined, containerEnvObj: NodeJS.ProcessEnv, match: string, variable: string, args: string[]) {
	switch (variable) {
		case 'containerEnv':
			return lookupValue(isWindows, containerEnvObj, args, match, configFile);

		default:
			return match;
	}
}

function replaceDevContainerId(getDevContainerId: () => string | undefined, match: string, variable: string) {
	switch (variable) {
		case 'devcontainerId':
			return getDevContainerId() || match;

		default:
			return match;
	}
}

function lookupValue(isWindows: boolean, envObj: NodeJS.ProcessEnv, args: string[], match: string, configFile: URI | undefined) {
	if (args.length > 0) {
		let envVariableName = args[0];
		if (isWindows) {
			envVariableName = envVariableName.toLowerCase();
		}
		const env = envObj[envVariableName];
		if (typeof env === 'string') {
			return env;
		}

		if (args.length > 1) {
			const defaultValue = args[1];
			return defaultValue;
		}

		// For `env` we should do the same as a normal shell does - evaluates missing envs to an empty string #46436
		return '';
	}
	throw new ContainerError({
		description: `'${match}'${configFile ? ` in ${path.posix.basename(configFile.path)}` : ''} can not be resolved because no environment variable name is given.`
	});
}

function devcontainerIdForLabels(idLabels: Record<string, string>): string {
	const stringInput = JSON.stringify(idLabels, Object.keys(idLabels).sort()); // sort properties
	const bufferInput = Buffer.from(stringInput, 'utf-8');
	const hash = crypto.createHash('sha256')
		.update(bufferInput)
		.digest();
	const uniqueId = BigInt(`0x${hash.toString('hex')}`)
		.toString(32)
		.padStart(52, '0');
	return uniqueId;
}
</file>

<file path="src/spec-configuration/configuration.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import { URI } from 'vscode-uri';
import { FileHost, parentURI, uriToFsPath } from './configurationCommonUtils';
import { Mount } from './containerFeaturesConfiguration';
import { RemoteDocuments } from './editableFiles';

export type DevContainerConfig = DevContainerFromImageConfig | DevContainerFromDockerfileConfig | DevContainerFromDockerComposeConfig;

export interface PortAttributes {
	label: string | undefined;
	onAutoForward: string | undefined;
	elevateIfNeeded: boolean | undefined;
}

export type UserEnvProbe = 'none' | 'loginInteractiveShell' | 'interactiveShell' | 'loginShell';

export type DevContainerConfigCommand = 'initializeCommand' | 'onCreateCommand' | 'updateContentCommand' | 'postCreateCommand' | 'postStartCommand' | 'postAttachCommand';

export interface HostGPURequirements {
	cores?: number;
	memory?: string;
}

export interface HostRequirements {
	cpus?: number;
	memory?: string;
	storage?: string;
	gpu?: boolean | 'optional' | HostGPURequirements;
}

export interface DevContainerFeature {
	userFeatureId: string;
	options: boolean | string | Record<string, boolean | string | undefined>;
}

export interface DevContainerFromImageConfig {
	configFilePath?: URI;
	image?: string; // Only optional when setting up an existing container as a dev container.
	name?: string;
	forwardPorts?: (number | string)[];
	appPort?: number | string | (number | string)[];
	portsAttributes?: Record<string, PortAttributes>;
	otherPortsAttributes?: PortAttributes;
	runArgs?: string[];
	shutdownAction?: 'none' | 'stopContainer';
	overrideCommand?: boolean;
	initializeCommand?: string | string[];
	onCreateCommand?: string | string[];
	updateContentCommand?: string | string[];
	postCreateCommand?: string | string[];
	postStartCommand?: string | string[];
	postAttachCommand?: string | string[];
	waitFor?: DevContainerConfigCommand;
	/** remote path to folder or workspace */
	workspaceFolder?: string;
	workspaceMount?: string;
	mounts?: (Mount | string)[];
	containerEnv?: Record<string, string>;
	containerUser?: string;
	init?: boolean;
	privileged?: boolean;
	capAdd?: string[];
	securityOpt?: string[];
	remoteEnv?: Record<string, string | null>;
	remoteUser?: string;
	updateRemoteUserUID?: boolean;
	userEnvProbe?: UserEnvProbe;
	features?: Record<string, string | boolean | Record<string, string | boolean>>;
	overrideFeatureInstallOrder?: string[];
	hostRequirements?: HostRequirements;
	customizations?: Record<string, any>;
}

export type DevContainerFromDockerfileConfig = {
	configFilePath: URI;
	name?: string;
	forwardPorts?: (number | string)[];
	appPort?: number | string | (number | string)[];
	portsAttributes?: Record<string, PortAttributes>;
	otherPortsAttributes?: PortAttributes;
	runArgs?: string[];
	shutdownAction?: 'none' | 'stopContainer';
	overrideCommand?: boolean;
	initializeCommand?: string | string[];
	onCreateCommand?: string | string[];
	updateContentCommand?: string | string[];
	postCreateCommand?: string | string[];
	postStartCommand?: string | string[];
	postAttachCommand?: string | string[];
	waitFor?: DevContainerConfigCommand;
	/** remote path to folder or workspace */
	workspaceFolder?: string;
	workspaceMount?: string;
	mounts?: (Mount | string)[];
	containerEnv?: Record<string, string>;
	containerUser?: string;
	init?: boolean;
	privileged?: boolean;
	capAdd?: string[];
	securityOpt?: string[];
	remoteEnv?: Record<string, string | null>;
	remoteUser?: string;
	updateRemoteUserUID?: boolean;
	userEnvProbe?: UserEnvProbe;
	features?: Record<string, string | boolean | Record<string, string | boolean>>;
	overrideFeatureInstallOrder?: string[];
	hostRequirements?: HostRequirements;
	customizations?: Record<string, any>;
} & (
		{
			dockerFile: string;
			context?: string;
			build?: {
				target?: string;
				args?: Record<string, string>;
				cacheFrom?: string | string[];
				options?: string[];
			};
		}
		|
		{
			build: {
				dockerfile: string;
				context?: string;
				target?: string;
				args?: Record<string, string>;
				cacheFrom?: string | string[];
				options?: string[];
			};
		}
	);

export interface DevContainerFromDockerComposeConfig {
	configFilePath: URI;
	dockerComposeFile: string | string[];
	service: string;
	workspaceFolder: string;
	name?: string;
	forwardPorts?: (number | string)[];
	portsAttributes?: Record<string, PortAttributes>;
	otherPortsAttributes?: PortAttributes;
	shutdownAction?: 'none' | 'stopCompose';
	overrideCommand?: boolean;
	initializeCommand?: string | string[];
	onCreateCommand?: string | string[];
	updateContentCommand?: string | string[];
	postCreateCommand?: string | string[];
	postStartCommand?: string | string[];
	postAttachCommand?: string | string[];
	waitFor?: DevContainerConfigCommand;
	runServices?: string[];
	mounts?: (Mount | string)[];
	containerEnv?: Record<string, string>;
	containerUser?: string;
	init?: boolean;
	privileged?: boolean;
	capAdd?: string[];
	securityOpt?: string[];
	remoteEnv?: Record<string, string | null>;
	remoteUser?: string;
	updateRemoteUserUID?: boolean;
	userEnvProbe?: UserEnvProbe;
	features?: Record<string, string | boolean | Record<string, string | boolean>>;
	overrideFeatureInstallOrder?: string[];
	hostRequirements?: HostRequirements;
	customizations?: Record<string, any>;
}

interface DevContainerVSCodeConfig {
	extensions?: string[];
	settings?: object;
	devPort?: number;
}

export interface VSCodeCustomizations {
	vscode?: DevContainerVSCodeConfig;
}

export function updateFromOldProperties<T extends DevContainerConfig & DevContainerVSCodeConfig & { customizations?: VSCodeCustomizations }>(original: T): T {
	// https://github.com/microsoft/dev-container-spec/issues/1
	if (!(original.extensions || original.settings || original.devPort !== undefined)) {
		return original;
	}
	const copy = { ...original };
	const customizations = copy.customizations || (copy.customizations = {});
	const vscode = customizations.vscode || (customizations.vscode = {});
	if (copy.extensions) {
		vscode.extensions = (vscode.extensions || []).concat(copy.extensions);
		delete copy.extensions;
	}
	if (copy.settings) {
		vscode.settings = {
			...copy.settings,
			...(vscode.settings || {}),
		};
		delete copy.settings;
	}
	if (copy.devPort !== undefined && vscode.devPort === undefined) {
		vscode.devPort = copy.devPort;
		delete copy.devPort;
	}
	return copy;
}

export function getConfigFilePath(cliHost: { platform: NodeJS.Platform }, config: { configFilePath: URI }, relativeConfigFilePath: string) {
	return resolveConfigFilePath(cliHost, config.configFilePath, relativeConfigFilePath);
}

export function resolveConfigFilePath(cliHost: { platform: NodeJS.Platform }, configFilePath: URI, relativeConfigFilePath: string) {
	const folder = parentURI(configFilePath);
	return configFilePath.with({
		path: path.posix.resolve(folder.path, (cliHost.platform === 'win32' && configFilePath.scheme !== RemoteDocuments.scheme) ? (path.win32.isAbsolute(relativeConfigFilePath) ? '/' : '') + relativeConfigFilePath.replace(/\\/g, '/') : relativeConfigFilePath)
	});
}

export function isDockerFileConfig(config: DevContainerConfig): config is DevContainerFromDockerfileConfig {
	return 'dockerFile' in config || ('build' in config && 'dockerfile' in config.build);
}

export function getDockerfilePath(cliHost: { platform: NodeJS.Platform }, config: DevContainerFromDockerfileConfig) {
	return getConfigFilePath(cliHost, config, getDockerfile(config));
}

export function getDockerfile(config: DevContainerFromDockerfileConfig) {
	return 'dockerFile' in config ? config.dockerFile : config.build.dockerfile;
}

export async function getDockerComposeFilePaths(cliHost: FileHost, config: DevContainerFromDockerComposeConfig, envForComposeFile: NodeJS.ProcessEnv, cwdForDefaultFiles: string) {
	if (Array.isArray(config.dockerComposeFile)) {
		if (config.dockerComposeFile.length) {
			return config.dockerComposeFile.map(composeFile => uriToFsPath(getConfigFilePath(cliHost, config, composeFile), cliHost.platform));
		}
	} else if (typeof config.dockerComposeFile === 'string') {
		return [uriToFsPath(getConfigFilePath(cliHost, config, config.dockerComposeFile), cliHost.platform)];
	}
	
	const envComposeFile = envForComposeFile?.COMPOSE_FILE;
	if (envComposeFile) {
		return envComposeFile.split(cliHost.path.delimiter)
			.map(composeFile => cliHost.path.resolve(cwdForDefaultFiles, composeFile));
	}

	try {
		const envPath = cliHost.path.join(cwdForDefaultFiles, '.env');
		const buffer = await cliHost.readFile(envPath);
		const match = /^COMPOSE_FILE=(.+)$/m.exec(buffer.toString());
		const envFileComposeFile = match && match[1].trim();
		if (envFileComposeFile) {
			return envFileComposeFile.split(cliHost.path.delimiter)
				.map(composeFile => cliHost.path.resolve(cwdForDefaultFiles, composeFile));
		}
	} catch (err) {
		if (!(err && (err.code === 'ENOENT' || err.code === 'EISDIR'))) {
			throw err;
		}
	}

	const defaultFiles = [cliHost.path.resolve(cwdForDefaultFiles, 'docker-compose.yml')];
	const override = cliHost.path.resolve(cwdForDefaultFiles, 'docker-compose.override.yml');
	if (await cliHost.isFile(override)) {
		defaultFiles.push(override);
	}
	return defaultFiles;
}
</file>

<file path="src/spec-configuration/configurationCommonUtils.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';

import { URI } from 'vscode-uri';

import { CLIHostDocuments } from './editableFiles';
import { FileHost } from '../spec-utils/pfs';

export { FileHost } from '../spec-utils/pfs';

const enum CharCode {
	Slash = 47,
	Colon = 58,
	A = 65,
	Z = 90,
	a = 97,
	z = 122,
}

export function uriToFsPath(uri: URI, platform: NodeJS.Platform): string {

	let value: string;
	if (uri.authority && uri.path.length > 1 && (uri.scheme === 'file' || uri.scheme === CLIHostDocuments.scheme)) {
		// unc path: file://shares/c$/far/boo
		value = `//${uri.authority}${uri.path}`;
	} else if (
		uri.path.charCodeAt(0) === CharCode.Slash
		&& (uri.path.charCodeAt(1) >= CharCode.A && uri.path.charCodeAt(1) <= CharCode.Z || uri.path.charCodeAt(1) >= CharCode.a && uri.path.charCodeAt(1) <= CharCode.z)
		&& uri.path.charCodeAt(2) === CharCode.Colon
	) {
		// windows drive letter: file:///c:/far/boo
		value = uri.path[1].toLowerCase() + uri.path.substr(2);
	} else {
		// other path
		value = uri.path;
	}
	if (platform === 'win32') {
		value = value.replace(/\//g, '\\');
	}
	return value;
}

export function getWellKnownDevContainerPaths(path_: typeof path.posix | typeof path.win32, folderPath: string): string[] {
	return [
		path_.join(folderPath, '.devcontainer', 'devcontainer.json'),
		path_.join(folderPath, '.devcontainer.json'),
	];
}

export function getDefaultDevContainerConfigPath(fileHost: FileHost, configFolderPath: string) {
	return URI.file(fileHost.path.join(configFolderPath, '.devcontainer', 'devcontainer.json'))
		.with({ scheme: CLIHostDocuments.scheme });
}

export async function getDevContainerConfigPathIn(fileHost: FileHost, configFolderPath: string) {
	const possiblePaths = getWellKnownDevContainerPaths(fileHost.path, configFolderPath);

	for (let possiblePath of possiblePaths) {
		if (await fileHost.isFile(possiblePath)) {
			return URI.file(possiblePath)
				.with({ scheme: CLIHostDocuments.scheme });
		}
	}

	return undefined;
}

export function parentURI(uri: URI) {
	const parent = path.posix.dirname(uri.path);
	return uri.with({ path: parent });
}
</file>

<file path="src/spec-configuration/containerCollectionsOCI.ts">
import path from 'path';
import * as semver from 'semver';
import * as tar from 'tar';
import * as jsonc from 'jsonc-parser';
import * as crypto from 'crypto';

import { Log, LogLevel } from '../spec-utils/log';
import { isLocalFile, mkdirpLocal, readLocalFile, writeLocalFile } from '../spec-utils/pfs';
import { requestEnsureAuthenticated } from './httpOCIRegistry';
import { GoARCH, GoOS, PlatformInfo } from '../spec-common/commonUtils';

export const DEVCONTAINER_MANIFEST_MEDIATYPE = 'application/vnd.devcontainers';
export const DEVCONTAINER_TAR_LAYER_MEDIATYPE = 'application/vnd.devcontainers.layer.v1+tar';
export const DEVCONTAINER_COLLECTION_LAYER_MEDIATYPE = 'application/vnd.devcontainers.collection.layer.v1+json';


export interface CommonParams {
	env: NodeJS.ProcessEnv;
	output: Log;
	cachedAuthHeader?: Record<string, string>; // <registry, authHeader>
}

// Represents the unique OCI identifier for a Feature or Template.
// eg:  ghcr.io/devcontainers/features/go:1.0.0
// eg:  ghcr.io/devcontainers/features/go@sha256:fe73f123927bd9ed1abda190d3009c4d51d0e17499154423c5913cf344af15a3
// Constructed by 'getRef()'
export interface OCIRef {
	registry: string; 		// 'ghcr.io'
	owner: string;			// 'devcontainers'
	namespace: string;		// 'devcontainers/features'
	path: string;			// 'devcontainers/features/go'
	resource: string;		// 'ghcr.io/devcontainers/features/go'
	id: string;				// 'go'

	version: string;		// (Either the contents of 'tag' or 'digest')
	tag?: string;			// '1.0.0'
	digest?: string; 		// 'sha256:fe73f123927bd9ed1abda190d3009c4d51d0e17499154423c5913cf344af15a3'
}

// Represents the unique OCI identifier for a Collection's Metadata artifact.
// eg:  ghcr.io/devcontainers/features:latest
// Constructed by 'getCollectionRef()'
export interface OCICollectionRef {
	registry: string;		// 'ghcr.io'
	path: string;			// 'devcontainers/features'
	resource: string;		// 'ghcr.io/devcontainers/features'
	tag: 'latest';			// 'latest' (always)
	version: 'latest';		// 'latest' (always)
}

export interface OCILayer {
	mediaType: string;
	digest: string;
	size: number;
	annotations: {
		'org.opencontainers.image.title': string;
	};
}

export interface OCIManifest {
	digest?: string;
	schemaVersion: number;
	mediaType: string;
	config: {
		digest: string;
		mediaType: string;
		size: number;
	};
	layers: OCILayer[];
	annotations?: {
		'dev.containers.metadata'?: string;
		'com.github.package.type'?: string;
	};
}

export interface ManifestContainer {
	manifestObj: OCIManifest;
	manifestBuffer: Buffer;
	contentDigest: string;
	canonicalId: string;
}


interface OCITagList {
	name: string;
	tags: string[];
}

interface OCIImageIndexEntry {
	mediaType: string;
	size: number;
	digest: string;
	platform: {
		architecture: string;
		variant?: string;
		os: string;
	};
}

// https://github.com/opencontainers/image-spec/blob/main/manifest.md#example-image-manifest
interface OCIImageIndex {
	schemaVersion: number;
	mediaType: string;
	manifests: OCIImageIndexEntry[];
}

// Following Spec:   https://github.com/opencontainers/distribution-spec/blob/main/spec.md#pulling-manifests
// Alternative Spec: https://docs.docker.com/registry/spec/api/#overview
//
// The path:
// 'namespace' in spec terminology for the given repository
// (eg: devcontainers/features/go)
const regexForPath = /^[a-z0-9]+([._-][a-z0-9]+)*(\/[a-z0-9]+([._-][a-z0-9]+)*)*$/;
// The reference:
// MUST be either (a) the digest of the manifest or (b) a tag
// MUST be at most 128 characters in length and MUST match the following regular expression:
const regexForVersionOrDigest = /^[a-zA-Z0-9_][a-zA-Z0-9._-]{0,127}$/;

// https://go.dev/doc/install/source#environment
// Expected by OCI Spec as seen here: https://github.com/opencontainers/image-spec/blob/main/image-index.md#image-index-property-descriptions
export function mapNodeArchitectureToGOARCH(arch: NodeJS.Architecture): GoARCH {
	switch (arch) {
		case 'x64':
			return 'amd64';
		default:
			return arch;
	}
}

// https://go.dev/doc/install/source#environment
// Expected by OCI Spec as seen here: https://github.com/opencontainers/image-spec/blob/main/image-index.md#image-index-property-descriptions
export function mapNodeOSToGOOS(os: NodeJS.Platform): GoOS {
	switch (os) {
		case 'win32':
			return 'windows';
		default:
			return os;
	}
}

// https://github.com/opencontainers/distribution-spec/blob/main/spec.md#pulling-manifests
// Attempts to parse the given string into an OCIRef
export function getRef(output: Log, input: string): OCIRef | undefined {
	// Normalize input by downcasing entire string
	input = input.toLowerCase();

	// Invalid if first character is a dot
	if (input.startsWith('.')) {
		output.write(`Input '${input}' failed validation.  Expected input to not start with '.'`, LogLevel.Error);
		return;
	}

	const indexOfLastColon = input.lastIndexOf(':');
	const indexOfLastAtCharacter = input.lastIndexOf('@');

	let resource = '';
	let tag: string | undefined = undefined;
	let digest: string | undefined = undefined;

	// -- Resolve version
	if (indexOfLastAtCharacter !== -1) {
		// The version is specified by digest
		// eg: ghcr.io/codspace/features/ruby@sha256:abcdefgh
		resource = input.substring(0, indexOfLastAtCharacter);
		const digestWithHashingAlgorithm = input.substring(indexOfLastAtCharacter + 1);
		const splitOnColon = digestWithHashingAlgorithm.split(':');
		if (splitOnColon.length !== 2) {
			output.write(`Failed to parse digest '${digestWithHashingAlgorithm}'.   Expected format: 'sha256:abcdefghijk'`, LogLevel.Error);
			return;
		}

		if (splitOnColon[0] !== 'sha256') {
			output.write(`Digest algorithm for input '${input}' failed validation.  Expected hashing algorithm to be 'sha256'.`, LogLevel.Error);
			return;
		}

		if (!regexForVersionOrDigest.test(splitOnColon[1])) {
			output.write(`Digest for input '${input}' failed validation.  Expected digest to match regex '${regexForVersionOrDigest}'.`, LogLevel.Error);
		}

		digest = digestWithHashingAlgorithm;
	} else if (indexOfLastColon !== -1 && indexOfLastColon > input.lastIndexOf('/')) {
		// The version is specified by tag
		// eg: ghcr.io/codspace/features/ruby:1.0.0

		//  1. The last colon is before the first slash (a port)
		//     eg:   ghcr.io:8081/codspace/features/ruby
		//  2. There is no tag at all
		//     eg:   ghcr.io/codspace/features/ruby
		resource = input.substring(0, indexOfLastColon);
		tag = input.substring(indexOfLastColon + 1);
	} else {
		// There is no tag or digest, so assume 'latest'
		resource = input;
		tag = 'latest';
	}


	if (tag && !regexForVersionOrDigest.test(tag)) {
		output.write(`Tag '${tag}' for input '${input}' failed validation.  Expected digest to match regex '${regexForVersionOrDigest}'.`, LogLevel.Error);
		return;
	}

	const splitOnSlash = resource.split('/');

	if (splitOnSlash[1] === 'devcontainers-contrib') {
		output.write(`Redirecting 'devcontainers-contrib' to 'devcontainers-extra'.`);
		splitOnSlash[1] = 'devcontainers-extra';
	}

	const id = splitOnSlash[splitOnSlash.length - 1]; // Aka 'featureName' - Eg: 'ruby'
	const owner = splitOnSlash[1];
	const registry = splitOnSlash[0];
	const namespace = splitOnSlash.slice(1, -1).join('/');

	const path = `${namespace}/${id}`;

	if (!regexForPath.exec(path)) {
		output.write(`Path '${path}' for input '${input}' failed validation.  Expected path to match regex '${regexForPath}'.`, LogLevel.Error);
		return;
	}

	const version = digest || tag || 'latest'; // The most specific version.

	output.write(`> input: ${input}`, LogLevel.Trace);
	output.write(`>`, LogLevel.Trace);
	output.write(`> resource: ${resource}`, LogLevel.Trace);
	output.write(`> id: ${id}`, LogLevel.Trace);
	output.write(`> owner: ${owner}`, LogLevel.Trace);
	output.write(`> namespace: ${namespace}`, LogLevel.Trace); // TODO: We assume 'namespace' includes at least one slash (eg: 'devcontainers/features')
	output.write(`> registry: ${registry}`, LogLevel.Trace);
	output.write(`> path: ${path}`, LogLevel.Trace);
	output.write(`>`, LogLevel.Trace);
	output.write(`> version: ${version}`, LogLevel.Trace);
	output.write(`> tag?: ${tag}`, LogLevel.Trace);
	output.write(`> digest?: ${digest}`, LogLevel.Trace);

	return {
		id,
		owner,
		namespace,
		registry,
		resource,
		path,
		version,
		tag,
		digest,
	};
}

export function getCollectionRef(output: Log, registry: string, namespace: string): OCICollectionRef | undefined {
	// Normalize input by downcasing entire string
	registry = registry.toLowerCase();
	namespace = namespace.toLowerCase();

	const path = namespace;
	const resource = `${registry}/${path}`;

	output.write(`> Inputs: registry='${registry}' namespace='${namespace}'`, LogLevel.Trace);
	output.write(`>`, LogLevel.Trace);
	output.write(`> resource: ${resource}`, LogLevel.Trace);

	if (!regexForPath.exec(path)) {
		output.write(`Parsed path '${path}' from input failed validation.`, LogLevel.Error);
		return undefined;
	}

	return {
		registry,
		path,
		resource,
		version: 'latest',
		tag: 'latest',
	};
}

// Validate if a manifest exists and is reachable about the declared feature/template.
// Specification: https://github.com/opencontainers/distribution-spec/blob/v1.0.1/spec.md#pulling-manifests
export async function fetchOCIManifestIfExists(params: CommonParams, ref: OCIRef | OCICollectionRef, manifestDigest?: string): Promise<ManifestContainer | undefined> {
	const { output } = params;

	// Simple mechanism to avoid making a DNS request for
	// something that is not a domain name.
	if (ref.registry.indexOf('.') < 0 && !ref.registry.startsWith('localhost')) {
		return;
	}

	// TODO: Always use the manifest digest (the canonical digest)
	//       instead of the `ref.version` by referencing some lock file (if available).
	let reference = ref.version;
	if (manifestDigest) {
		reference = manifestDigest;
	}
	const manifestUrl = `https://${ref.registry}/v2/${ref.path}/manifests/${reference}`;
	output.write(`manifest url: ${manifestUrl}`, LogLevel.Trace);
	const expectedDigest = manifestDigest || ('digest' in ref ? ref.digest : undefined);
	const manifestContainer = await getManifest(params, manifestUrl, ref, undefined, expectedDigest);

	if (!manifestContainer || !manifestContainer.manifestObj) {
		return;
	}

	const { manifestObj } = manifestContainer;

	if (manifestObj.config.mediaType !== DEVCONTAINER_MANIFEST_MEDIATYPE) {
		output.write(`(!) Unexpected manifest media type: ${manifestObj.config.mediaType}`, LogLevel.Error);
		return undefined;
	}

	return manifestContainer;
}

export async function getManifest(params: CommonParams, url: string, ref: OCIRef | OCICollectionRef, mimeType?: string, expectedDigest?: string): Promise<ManifestContainer | undefined> {
	const { output } = params;
	const res = await getBufferWithMimeType(params, url, ref, mimeType || 'application/vnd.oci.image.manifest.v1+json');
	if (!res) {
		return undefined;
	}

	const { body, headers } = res;

	// Per the specification:
	// https://github.com/opencontainers/distribution-spec/blob/v1.0.1/spec.md#pulling-manifests
	// The registry server SHOULD return the canonical content digest in a header, but it's not required to.
	// That is useful to have, so if the server doesn't provide it, recalculate it outselves.
	// Headers are always automatically downcased by node.
	let contentDigest = headers['docker-content-digest'];
	if (!contentDigest || expectedDigest) {
		if (!contentDigest) {
			output.write('Registry did not send a \'docker-content-digest\' header.  Recalculating...', LogLevel.Trace);
		}
		contentDigest = `sha256:${crypto.createHash('sha256').update(body).digest('hex')}`;
	}

	if (expectedDigest && contentDigest !== expectedDigest) {
		throw new Error(`Digest did not match for ${ref.resource}.`);
	}

	return {
		contentDigest,
		manifestObj: JSON.parse(body.toString()),
		manifestBuffer: body,
		canonicalId: `${ref.resource}@${contentDigest}`,
	};
}

// https://github.com/opencontainers/image-spec/blob/main/manifest.md
export async function getImageIndexEntryForPlatform(params: CommonParams, url: string, ref: OCIRef | OCICollectionRef, platformInfo: PlatformInfo, mimeType?: string): Promise<OCIImageIndexEntry | undefined> {
	const { output } = params;
	const response = await getJsonWithMimeType<OCIImageIndex>(params, url, ref, mimeType || 'application/vnd.oci.image.index.v1+json');
	if (!response) {
		return undefined;
	}

	const { body: imageIndex } = response;
	if (!imageIndex) {
		output.write(`Unwrapped response for image index is undefined.`, LogLevel.Error);
		return undefined;
	}

	// Find a manifest for the current architecture and OS.
	return imageIndex.manifests.find(m => {
		if (m.platform?.architecture === platformInfo.arch && m.platform?.os === platformInfo.os) {
			if (!platformInfo.variant || m.platform?.variant === platformInfo.variant) {
				return m;
			}
		}
		return undefined;
	});
}

async function getBufferWithMimeType(params: CommonParams, url: string, ref: OCIRef | OCICollectionRef, mimeType: string): Promise<{ body: Buffer; headers: Record<string, string> } | undefined> {
	const { output } = params;
	const headers = {
		'user-agent': 'devcontainer',
		'accept': mimeType,
	};

	const httpOptions = {
		type: 'GET',
		url: url,
		headers: headers
	};

	const res = await requestEnsureAuthenticated(params, httpOptions, ref);
	if (!res) {
		output.write(`Request '${url}' failed`, LogLevel.Error);
		return;
	}

	// NOTE: A 404 is expected here if the manifest does not exist on the remote.
	if (res.statusCode > 299) {
		// Get the error out.
		const errorMsg = res?.resBody?.toString();
		output.write(`Did not fetch target with expected mimetype '${mimeType}': ${errorMsg}`, LogLevel.Trace);
		return;
	}

	return {
		body: res.resBody,
		headers: res.resHeaders,
	};
}

async function getJsonWithMimeType<T>(params: CommonParams, url: string, ref: OCIRef | OCICollectionRef, mimeType: string): Promise<{ body: T; headers: Record<string, string> } | undefined> {
	const { output } = params;
	let body: string = '';
	try {
		const headers = {
			'user-agent': 'devcontainer',
			'accept': mimeType,
		};

		const httpOptions = {
			type: 'GET',
			url: url,
			headers: headers
		};

		const res = await requestEnsureAuthenticated(params, httpOptions, ref);
		if (!res) {
			output.write(`Request '${url}' failed`, LogLevel.Error);
			return;
		}

		const { resBody, statusCode, resHeaders } = res;
		body = resBody.toString();

		// NOTE: A 404 is expected here if the manifest does not exist on the remote.
		if (statusCode > 299) {
			output.write(`Did not fetch target with expected mimetype '${mimeType}': ${body}`, LogLevel.Trace);
			return;
		}
		const parsedBody: T = JSON.parse(body);
		output.write(`Fetched: ${JSON.stringify(parsedBody, undefined, 4)}`, LogLevel.Trace);
		return {
			body: parsedBody,
			headers: resHeaders,
		};
	} catch (e) {
		output.write(`Failed to parse JSON with mimeType '${mimeType}': ${body}`, LogLevel.Error);
		return;
	}
}

// Gets published tags and sorts them by ascending semantic version.
// Omits any tags (eg: 'latest', or major/minor tags '1','1.0') that are not semantic versions.
export async function getVersionsStrictSorted(params: CommonParams, ref: OCIRef): Promise<string[] | undefined> {
	const { output } = params;

	const publishedTags = await getPublishedTags(params, ref);
	if (!publishedTags) {
		return;
	}

	const sortedVersions = publishedTags
		.filter(f => semver.valid(f)) // Remove all major,minor,latest tags
		.sort((a, b) => semver.compare(a, b));

	output.write(`Published versions (sorted) for '${ref.id}': ${JSON.stringify(sortedVersions, undefined, 2)}`, LogLevel.Trace);

	return sortedVersions;
}

// Lists published tags of a Feature/Template
// Specification: https://github.com/opencontainers/distribution-spec/blob/v1.0.1/spec.md#content-discovery
export async function getPublishedTags(params: CommonParams, ref: OCIRef): Promise<string[] | undefined> {
	const { output } = params;
	try {
		const url = `https://${ref.registry}/v2/${ref.namespace}/${ref.id}/tags/list`;

		const headers = {
			'Accept': 'application/json',
		};

		const httpOptions = {
			type: 'GET',
			url: url,
			headers: headers
		};

		const res = await requestEnsureAuthenticated(params, httpOptions, ref);
		if (!res) {
			output.write('Request failed', LogLevel.Error);
			return;
		}

		const { statusCode, resBody } = res;
		const body = resBody.toString();

		// Expected when publishing for the first time
		if (statusCode === 404) {
			return [];
			// Unexpected Error
		} else if (statusCode > 299) {
			output.write(`(!) ERR: Could not fetch published tags for '${ref.namespace}/${ref.id}' : ${resBody ?? ''} `, LogLevel.Error);
			return;
		}

		const publishedVersionsResponse: OCITagList = JSON.parse(body);

		// Return published tags from the registry as-is, meaning:
		// - Not necessarily sorted
		// - *Including* major/minor/latest tags
		return publishedVersionsResponse.tags;
	} catch (e) {
		output.write(`Failed to parse published versions: ${e}`, LogLevel.Error);
		return;
	}
}

export async function getBlob(params: CommonParams, url: string, ociCacheDir: string, destCachePath: string, ociRef: OCIRef, expectedDigest: string, omitDuringExtraction: string[] = [], metadataFile?: string): Promise<{ files: string[]; metadata: {} | undefined } | undefined> {
	// TODO: Parallelize if multiple layers (not likely).
	// TODO: Seeking might be needed if the size is too large.

	const { output } = params;
	try {
		await mkdirpLocal(ociCacheDir);
		const tempTarballPath = path.join(ociCacheDir, 'blob.tar');

		const headers = {
			'Accept': 'application/vnd.oci.image.manifest.v1+json',
		};

		const httpOptions = {
			type: 'GET',
			url: url,
			headers: headers
		};

		const res = await requestEnsureAuthenticated(params, httpOptions, ociRef);
		if (!res) {
			output.write('Request failed', LogLevel.Error);
			return;
		}

		const { statusCode, resBody } = res;
		if (statusCode > 299) {
			output.write(`Failed to fetch blob (${url}): ${resBody}`, LogLevel.Error);
			return;
		}

		const actualDigest = `sha256:${crypto.createHash('sha256').update(resBody).digest('hex')}`;
		if (actualDigest !== expectedDigest) {
			throw new Error(`Digest did not match for ${ociRef.resource}.`);
		}

		await mkdirpLocal(destCachePath);
		await writeLocalFile(tempTarballPath, resBody);

		// https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-templates.md#the-optionalpaths-property
		const directoriesToOmit = omitDuringExtraction.filter(f => f.endsWith('/*')).map(f => f.slice(0, -1));
		const filesToOmit = omitDuringExtraction.filter(f => !f.endsWith('/*'));
		
		output.write(`omitDuringExtraction: '${omitDuringExtraction.join(', ')}`, LogLevel.Trace);
		output.write(`Files to omit: '${filesToOmit.join(', ')}'`, LogLevel.Info);
		if (directoriesToOmit.length) {
			output.write(`Dirs to omit : '${directoriesToOmit.join(', ')}'`, LogLevel.Info);
		}

		const files: string[] = [];
		await tar.x(
			{
				file: tempTarballPath,
				cwd: destCachePath,
				filter: (tPath: string, stat: tar.FileStat) => {
					output.write(`Testing '${tPath}'(${stat.type})`, LogLevel.Trace);
					const cleanedPath = tPath
						.replace(/\\/g, '/')
						.replace(/^\.\//, '');

					if (filesToOmit.includes(cleanedPath) || directoriesToOmit.some(d => cleanedPath.startsWith(d))) {
						output.write(`  Omitting '${tPath}'`, LogLevel.Trace);
						return false; // Skip
					}

					if (stat.type.toString() === 'File') {
						files.push(tPath);
					}

					return true; // Keep
				}
			}
		);
		output.write('Files extracted from blob: ' + files.join(', '), LogLevel.Trace);

		// No 'metadataFile' to look for.
		if (!metadataFile) {
			return { files, metadata: undefined };
		}

		// Attempt to extract 'metadataFile'
		await tar.x(
			{
				file: tempTarballPath,
				cwd: ociCacheDir,
				filter: (tPath: string, _: tar.FileStat) => {
					return tPath === `./${metadataFile}`;
				}
			});
		const pathToMetadataFile = path.join(ociCacheDir, metadataFile);
		let metadata = undefined;
		if (await isLocalFile(pathToMetadataFile)) {
			output.write(`Found metadata file '${metadataFile}' in blob`, LogLevel.Trace);
			metadata = jsonc.parse((await readLocalFile(pathToMetadataFile)).toString());
		}

		return {
			files, metadata
		};
	} catch (e) {
		output.write(`Error getting blob: ${e}`, LogLevel.Error);
		return;
	}
}
</file>

<file path="src/spec-configuration/containerCollectionsOCIPush.ts">
import * as path from 'path';
import * as fs from 'fs';
import * as crypto from 'crypto';
import { delay } from '../spec-common/async';
import { Log, LogLevel } from '../spec-utils/log';
import { isLocalFile } from '../spec-utils/pfs';
import { DEVCONTAINER_COLLECTION_LAYER_MEDIATYPE, DEVCONTAINER_TAR_LAYER_MEDIATYPE, fetchOCIManifestIfExists, OCICollectionRef, OCILayer, OCIManifest, OCIRef, CommonParams, ManifestContainer } from './containerCollectionsOCI';
import { requestEnsureAuthenticated } from './httpOCIRegistry';

// (!) Entrypoint function to push a single feature/template to a registry.
//     Devcontainer Spec (features) : https://containers.dev/implementors/features-distribution/#oci-registry
//     Devcontainer Spec (templates): https://github.com/devcontainers/spec/blob/main/proposals/devcontainer-templates-distribution.md#oci-registry
//     OCI Spec                     : https://github.com/opencontainers/distribution-spec/blob/main/spec.md#push
export async function pushOCIFeatureOrTemplate(params: CommonParams, ociRef: OCIRef, pathToTgz: string, tags: string[], collectionType: string, annotations: { [key: string]: string } = {}): Promise<string | undefined> {
	const { output } = params;

	output.write(`-- Starting push of ${collectionType} '${ociRef.id}' to '${ociRef.resource}' with tags '${tags.join(', ')}'`);
	output.write(`${JSON.stringify(ociRef, null, 2)}`, LogLevel.Trace);

	if (!(await isLocalFile(pathToTgz))) {
		output.write(`Blob ${pathToTgz} does not exist.`, LogLevel.Error);
		return;
	}

	const dataBytes = fs.readFileSync(pathToTgz);

	// Generate Manifest for given feature/template artifact.
	const manifest = await generateCompleteManifestForIndividualFeatureOrTemplate(output, dataBytes, pathToTgz, ociRef, collectionType, annotations);
	if (!manifest) {
		output.write(`Failed to generate manifest for ${ociRef.id}`, LogLevel.Error);
		return;
	}

	output.write(`Generated manifest: \n${JSON.stringify(manifest?.manifestObj, undefined, 4)}`, LogLevel.Trace);

	// If the exact manifest digest already exists in the registry, we don't need to push individual blobs (it's already there!) 
	const existingManifest = await fetchOCIManifestIfExists(params, ociRef, manifest.contentDigest);
	if (manifest.contentDigest && existingManifest) {
		output.write(`Not reuploading blobs, digest already exists.`, LogLevel.Trace);
		return await putManifestWithTags(params, manifest, ociRef, tags);
	}

	const blobsToPush = [
		{
			name: 'configLayer',
			digest: manifest.manifestObj.config.digest,
			size: manifest.manifestObj.config.size,
			contents: Buffer.from('{}'),
		},
		{
			name: 'tgzLayer',
			digest: manifest.manifestObj.layers[0].digest,
			size: manifest.manifestObj.layers[0].size,
			contents: dataBytes,
		}
	];


	for await (const blob of blobsToPush) {
		const { name, digest } = blob;
		const blobExistsConfigLayer = await checkIfBlobExists(params, ociRef, digest);
		output.write(`blob: '${name}'  ${blobExistsConfigLayer ? 'DOES exists' : 'DOES NOT exist'} in registry.`, LogLevel.Trace);

		// PUT blobs
		if (!blobExistsConfigLayer) {

			// Obtain session ID with `/v2/<namespace>/blobs/uploads/` 
			const blobPutLocationUriPath = await postUploadSessionId(params, ociRef);
			if (!blobPutLocationUriPath) {
				output.write(`Failed to get upload session ID`, LogLevel.Error);
				return;
			}

			if (!(await putBlob(params, blobPutLocationUriPath, ociRef, blob))) {
				output.write(`Failed to PUT blob '${name}' with digest '${digest}'`, LogLevel.Error);
				return;
			}
		}
	}

	// Send a final PUT to combine blobs and tag manifest properly.
	return await putManifestWithTags(params, manifest, ociRef, tags);
}

// (!) Entrypoint function to push a collection metadata/overview file for a set of features/templates to a registry.
//     Devcontainer Spec (features) : https://containers.dev/implementors/features-distribution/#oci-registry (see 'devcontainer-collection.json')
// 	   Devcontainer Spec (templates): https://github.com/devcontainers/spec/blob/main/proposals/devcontainer-templates-distribution.md#oci-registry  (see 'devcontainer-collection.json')
//     OCI Spec                     : https://github.com/opencontainers/distribution-spec/blob/main/spec.md#push
export async function pushCollectionMetadata(params: CommonParams, collectionRef: OCICollectionRef, pathToCollectionJson: string, collectionType: string): Promise<string | undefined> {
	const { output } = params;

	output.write(`Starting push of latest ${collectionType} collection for namespace '${collectionRef.path}' to '${collectionRef.registry}'`);
	output.write(`${JSON.stringify(collectionRef, null, 2)}`, LogLevel.Trace);

	if (!(await isLocalFile(pathToCollectionJson))) {
		output.write(`Collection Metadata was not found at expected location: ${pathToCollectionJson}`, LogLevel.Error);
		return;
	}

	const dataBytes = fs.readFileSync(pathToCollectionJson);

	// Generate Manifest for collection artifact.
	const manifest = await generateCompleteManifestForCollectionFile(output, dataBytes, collectionRef);
	if (!manifest) {
		output.write(`Failed to generate manifest for ${collectionRef.path}`, LogLevel.Error);
		return;
	}
	output.write(`Generated manifest: \n${JSON.stringify(manifest?.manifestObj, undefined, 4)}`, LogLevel.Trace);

	// If the exact manifest digest already exists in the registry, we don't need to push individual blobs (it's already there!) 
	const existingManifest = await fetchOCIManifestIfExists(params, collectionRef, manifest.contentDigest);
	if (manifest.contentDigest && existingManifest) {
		output.write(`Not reuploading blobs, digest already exists.`, LogLevel.Trace);
		return await putManifestWithTags(params, manifest, collectionRef, ['latest']);
	}

	const blobsToPush = [
		{
			name: 'configLayer',
			digest: manifest.manifestObj.config.digest,
			size: manifest.manifestObj.config.size,
			contents: Buffer.from('{}'),
		},
		{
			name: 'collectionLayer',
			digest: manifest.manifestObj.layers[0].digest,
			size: manifest.manifestObj.layers[0].size,
			contents: dataBytes,
		}
	];

	for await (const blob of blobsToPush) {
		const { name, digest } = blob;
		const blobExistsConfigLayer = await checkIfBlobExists(params, collectionRef, digest);
		output.write(`blob: '${name}' with digest '${digest}'  ${blobExistsConfigLayer ? 'already exists' : 'does not exist'} in registry.`, LogLevel.Trace);

		// PUT blobs
		if (!blobExistsConfigLayer) {

			// Obtain session ID with `/v2/<namespace>/blobs/uploads/` 
			const blobPutLocationUriPath = await postUploadSessionId(params, collectionRef);
			if (!blobPutLocationUriPath) {
				output.write(`Failed to get upload session ID`, LogLevel.Error);
				return;
			}

			if (!(await putBlob(params, blobPutLocationUriPath, collectionRef, blob))) {
				output.write(`Failed to PUT blob '${name}' with digest '${digest}'`, LogLevel.Error);
				return;
			}
		}
	}

	// Send a final PUT to combine blobs and tag manifest properly.
	// Collections are always tagged 'latest'
	return await putManifestWithTags(params, manifest, collectionRef, ['latest']);
}

// --- Helper Functions

// Spec: https://github.com/opencontainers/distribution-spec/blob/main/spec.md#pushing-manifests (PUT /manifests/<ref>)
async function putManifestWithTags(params: CommonParams, manifest: ManifestContainer, ociRef: OCIRef | OCICollectionRef, tags: string[]): Promise<string | undefined> {
	const { output } = params;

	output.write(`Tagging manifest with tags: ${tags.join(', ')}`, LogLevel.Trace);

	const { manifestBuffer, contentDigest } = manifest;

	for await (const tag of tags) {
		const url = `https://${ociRef.registry}/v2/${ociRef.path}/manifests/${tag}`;
		output.write(`PUT -> '${url}'`, LogLevel.Trace);

		const httpOptions = {
			type: 'PUT',
			url,
			headers: {
				'content-type': 'application/vnd.oci.image.manifest.v1+json',
			},
			data: manifestBuffer,
		};

		let res = await requestEnsureAuthenticated(params, httpOptions, ociRef);
		if (!res) {
			output.write('Request failed', LogLevel.Error);
			return;
		}

		// Retry logic: when request fails with HTTP 429: too many requests
		// TODO: Wrap into `requestEnsureAuthenticated`?
		if (res.statusCode === 429) {
			output.write(`Failed to PUT manifest for tag ${tag} due to too many requests. Retrying...`, LogLevel.Warning);
			await delay(2000);

			res = await requestEnsureAuthenticated(params, httpOptions, ociRef);
			if (!res) {
				output.write('Request failed', LogLevel.Error);
				return;
			}
		}

		const { statusCode, resBody, resHeaders } = res;

		if (statusCode !== 201) {
			const parsed = JSON.parse(resBody?.toString() || '{}');
			output.write(`Failed to PUT manifest for tag ${tag}\n${JSON.stringify(parsed, undefined, 4)}`, LogLevel.Error);
			return;
		}

		const dockerContentDigestResponseHeader = resHeaders['docker-content-digest'];
		const locationResponseHeader = resHeaders['location'] || resHeaders['Location'];
		output.write(`Tagged: ${tag} -> ${locationResponseHeader}`, LogLevel.Info);
		output.write(`Returned Content-Digest: ${dockerContentDigestResponseHeader}`, LogLevel.Trace);
	}
	return contentDigest;
}

// Spec: https://github.com/opencontainers/distribution-spec/blob/main/spec.md#post-then-put (PUT <location>?digest=<digest>)
async function putBlob(params: CommonParams, blobPutLocationUriPath: string, ociRef: OCIRef | OCICollectionRef, blob: { name: string; digest: string; size: number; contents: Buffer }): Promise<boolean> {

	const { output } = params;
	const { name, digest, size, contents } = blob;

	output.write(`Starting PUT of ${name} blob '${digest}' (size=${size})`, LogLevel.Info);

	const headers = {
		'content-type': 'application/octet-stream',
		'content-length': `${size}`
	};

	// OCI distribution spec is ambiguous on whether we get back an absolute or relative path.
	let url = '';
	if (blobPutLocationUriPath.startsWith('https://') || blobPutLocationUriPath.startsWith('http://')) {
		url = blobPutLocationUriPath;
	} else {
		url = `https://${ociRef.registry}${blobPutLocationUriPath}`;
	}

	// The <location> MAY contain critical query parameters.
	//  Additionally, it SHOULD match exactly the <location> obtained from the POST request.
	// It SHOULD NOT be assembled manually by clients except where absolute/relative conversion is necessary.
	const queryParamsStart = url.indexOf('?');
	if (queryParamsStart === -1) {
		// Just append digest to the end.
		url += `?digest=${digest}`;
	} else {
		url = url.substring(0, queryParamsStart) + `?digest=${digest}` + '&' + url.substring(queryParamsStart + 1);
	}

	output.write(`PUT blob to ->  ${url}`, LogLevel.Trace);

	const res = await requestEnsureAuthenticated(params, { type: 'PUT', url, headers, data: contents }, ociRef);
	if (!res) {
		output.write('Request failed', LogLevel.Error);
		return false;
	}

	const { statusCode, resBody } = res;

	if (statusCode !== 201) {
		const parsed = JSON.parse(resBody?.toString() || '{}');
		output.write(`${statusCode}: Failed to upload blob '${digest}' to '${url}' \n${JSON.stringify(parsed, undefined, 4)}`, LogLevel.Error);
		return false;
	}

	return true;
}

// Generate a layer that follows the `application/vnd.devcontainers.layer.v1+tar` mediaType as defined in
//     Devcontainer Spec (features) : https://containers.dev/implementors/features-distribution/#oci-registry
//     Devcontainer Spec (templates): https://github.com/devcontainers/spec/blob/main/proposals/devcontainer-templates-distribution.md#oci-registry
async function generateCompleteManifestForIndividualFeatureOrTemplate(output: Log, dataBytes: Buffer, pathToTgz: string, ociRef: OCIRef, collectionType: string, annotations: { [key: string]: string } = {}): Promise<ManifestContainer | undefined> {
	const tgzLayer = await calculateDataLayer(output, dataBytes, path.basename(pathToTgz), DEVCONTAINER_TAR_LAYER_MEDIATYPE);
	if (!tgzLayer) {
		output.write(`Failed to calculate tgz layer.`, LogLevel.Error);
		return undefined;
	}

	// Specific registries look for certain optional metadata 
	// in the manifest, in this case for UI presentation.
	if (ociRef.registry === 'ghcr.io') {
		annotations = {
			...annotations,
			'com.github.package.type': `devcontainer_${collectionType}`,
		};
	}

	return await calculateManifestAndContentDigest(output, ociRef, tgzLayer, annotations);
}

// Generate a layer that follows the `application/vnd.devcontainers.collection.layer.v1+json` mediaType as defined in
//     Devcontainer Spec (features) : https://containers.dev/implementors/features-distribution/#oci-registry
//     Devcontainer Spec (templates): https://github.com/devcontainers/spec/blob/main/proposals/devcontainer-templates-distribution.md#oci-registry
async function generateCompleteManifestForCollectionFile(output: Log, dataBytes: Buffer, collectionRef: OCICollectionRef): Promise<ManifestContainer | undefined> {
	const collectionMetadataLayer = await calculateDataLayer(output, dataBytes, 'devcontainer-collection.json', DEVCONTAINER_COLLECTION_LAYER_MEDIATYPE);
	if (!collectionMetadataLayer) {
		output.write(`Failed to calculate collection file layer.`, LogLevel.Error);
		return undefined;
	}

	let annotations: { [key: string]: string } | undefined = undefined;
	// Specific registries look for certain optional metadata 
	// in the manifest, in this case for UI presentation.
	if (collectionRef.registry === 'ghcr.io') {
		annotations = {
			'com.github.package.type': 'devcontainer_collection',
		};
	}
	return await calculateManifestAndContentDigest(output, collectionRef, collectionMetadataLayer, annotations);
}

// Generic construction of a layer in the manifest and digest for the generated layer.
export async function calculateDataLayer(output: Log, data: Buffer, basename: string, mediaType: string): Promise<OCILayer | undefined> {
	output.write(`Creating manifest from data`, LogLevel.Trace);

	const algorithm = 'sha256';
	const tarSha256 = crypto.createHash(algorithm).update(data).digest('hex');
	const digest = `${algorithm}:${tarSha256}`;
	output.write(`Data layer digest: ${digest} (archive size: ${data.byteLength})`, LogLevel.Info);

	return {
		mediaType,
		digest,
		size: data.byteLength,
		annotations: {
			'org.opencontainers.image.title': basename,
		}
	};
}

// Spec: https://github.com/opencontainers/distribution-spec/blob/main/spec.md#checking-if-content-exists-in-the-registry
//       Requires registry auth token.
export async function checkIfBlobExists(params: CommonParams, ociRef: OCIRef | OCICollectionRef, digest: string): Promise<boolean> {
	const { output } = params;
	
	const url = `https://${ociRef.registry}/v2/${ociRef.path}/blobs/${digest}`;
	const res = await requestEnsureAuthenticated(params, { type: 'HEAD', url, headers: {} }, ociRef);
	if (!res) {
		output.write('Request failed', LogLevel.Error);
		return false;
	}

	const statusCode = res.statusCode;
	output.write(`checkIfBlobExists: ${url}: ${statusCode}`, LogLevel.Trace);
	return statusCode === 200;
}

// Spec: https://github.com/opencontainers/distribution-spec/blob/main/spec.md#post-then-put
//       Requires registry auth token.
async function postUploadSessionId(params: CommonParams, ociRef: OCIRef | OCICollectionRef): Promise<string | undefined> {
	const { output } = params;

	const url = `https://${ociRef.registry}/v2/${ociRef.path}/blobs/uploads/`;
	output.write(`Generating Upload URL -> ${url}`, LogLevel.Trace);
	const res = await requestEnsureAuthenticated(params, { type: 'POST', url, headers: {} }, ociRef);

	if (!res) {
		output.write('Request failed', LogLevel.Error);
		return;
	}

	const { statusCode, resBody, resHeaders } = res;

	output.write(`${url}: ${statusCode}`, LogLevel.Trace);
	if (statusCode === 202) {
		const locationHeader = resHeaders['location'] || resHeaders['Location'];
		if (!locationHeader) {
			output.write(`${url}: Got 202 status code, but no location header found.`, LogLevel.Error);
			return undefined;
		}
		output.write(`Generated Upload URL: ${locationHeader}`, LogLevel.Trace);
		return locationHeader;
	} else {
		// Any other statusCode besides 202 is unexpected
		// https://github.com/opencontainers/distribution-spec/blob/main/spec.md#error-codes
		const parsed = JSON.parse(resBody?.toString() || '{}');
		output.write(`${url}: Unexpected status code '${statusCode}' \n${JSON.stringify(parsed, undefined, 4)}`, LogLevel.Error);
		return undefined;
	}
}

export async function calculateManifestAndContentDigest(output: Log, ociRef: OCIRef | OCICollectionRef, dataLayer: OCILayer, annotations: { [key: string]: string } | undefined): Promise<ManifestContainer> {
	// A canonical manifest digest is the sha256 hash of the JSON representation of the manifest, without the signature content.
	// See: https://docs.docker.com/registry/spec/api/#content-digests
	// Below is an example of a serialized manifest that should resolve to 'dd328c25cc7382aaf4e9ee10104425d9a2561b47fe238407f6c0f77b3f8409fc'
	// {"schemaVersion":2,"mediaType":"application/vnd.oci.image.manifest.v1+json","config":{"mediaType":"application/vnd.devcontainers","digest":"sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","size":2},"layers":[{"mediaType":"application/vnd.devcontainers.layer.v1+tar","digest":"sha256:0bb92d2da46d760c599d0a41ed88d52521209408b529761417090b62ee16dfd1","size":3584,"annotations":{"org.opencontainers.image.title":"devcontainer-feature-color.tgz"}}],"annotations":{"dev.containers.metadata":"{\"id\":\"color\",\"version\":\"1.0.0\",\"name\":\"A feature to remind you of your favorite color\",\"options\":{\"favorite\":{\"type\":\"string\",\"enum\":[\"red\",\"gold\",\"green\"],\"default\":\"red\",\"description\":\"Choose your favorite color.\"}}}","com.github.package.type":"devcontainer_feature"}}

	let manifest: OCIManifest = {
		schemaVersion: 2,
		mediaType: 'application/vnd.oci.image.manifest.v1+json',
		config: {
			mediaType: 'application/vnd.devcontainers',
			digest: 'sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', // A empty json byte digest for the devcontainer mediaType.
			size: 2
		},
		layers: [
			dataLayer
		],
	};

	if (annotations) {
		manifest.annotations = annotations;
	}

	const manifestBuffer = Buffer.from(JSON.stringify(manifest));
	const algorithm = 'sha256';
	const manifestHash = crypto.createHash(algorithm).update(manifestBuffer).digest('hex');
	const contentDigest = `${algorithm}:${manifestHash}`;
	output.write(`Computed content digest from manifest: ${contentDigest}`, LogLevel.Info);

	return {
		manifestBuffer,
		manifestObj: manifest,
		contentDigest,
		canonicalId: `${ociRef.resource}@sha256:${manifestHash}`
	};
}
</file>

<file path="src/spec-configuration/containerFeaturesConfiguration.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as jsonc from 'jsonc-parser';
import * as path from 'path';
import * as URL from 'url';
import * as tar from 'tar';
import * as crypto from 'crypto';
import * as semver from 'semver';
import * as os from 'os';

import { DevContainerConfig, DevContainerFeature, VSCodeCustomizations } from './configuration';
import { mkdirpLocal, readLocalFile, rmLocal, writeLocalFile, cpDirectoryLocal, isLocalFile } from '../spec-utils/pfs';
import { Log, LogLevel, nullLog } from '../spec-utils/log';
import { request } from '../spec-utils/httpRequest';
import { fetchOCIFeature, tryGetOCIFeatureSet, fetchOCIFeatureManifestIfExistsFromUserIdentifier } from './containerFeaturesOCI';
import { uriToFsPath } from './configurationCommonUtils';
import { CommonParams, ManifestContainer, OCIManifest, OCIRef, getRef, getVersionsStrictSorted } from './containerCollectionsOCI';
import { Lockfile, generateLockfile, readLockfile, writeLockfile } from './lockfile';
import { computeDependsOnInstallationOrder } from './containerFeaturesOrder';
import { logFeatureAdvisories } from './featureAdvisories';
import { getEntPasswdShellCommand } from '../spec-common/commonUtils';
import { ContainerError } from '../spec-common/errors';

// v1
const V1_ASSET_NAME = 'devcontainer-features.tgz';
export const V1_DEVCONTAINER_FEATURES_FILE_NAME = 'devcontainer-features.json';

// v2
export const DEVCONTAINER_FEATURE_FILE_NAME = 'devcontainer-feature.json';

export type Feature = SchemaFeatureBaseProperties & SchemaFeatureLifecycleHooks & DeprecatedSchemaFeatureProperties & InternalFeatureProperties;

export const FEATURES_CONTAINER_TEMP_DEST_FOLDER = '/tmp/dev-container-features';

export interface SchemaFeatureLifecycleHooks {
	onCreateCommand?: string | string[];
	updateContentCommand?: string | string[];
	postCreateCommand?: string | string[];
	postStartCommand?: string | string[];
	postAttachCommand?: string | string[];
}

// Properties who are members of the schema
export interface SchemaFeatureBaseProperties {
	id: string;
	version?: string;
	name?: string;
	description?: string;
	documentationURL?: string;
	licenseURL?: string;
	options?: Record<string, FeatureOption>;
	containerEnv?: Record<string, string>;
	mounts?: Mount[];
	init?: boolean;
	privileged?: boolean;
	capAdd?: string[];
	securityOpt?: string[];
	entrypoint?: string;
	customizations?: VSCodeCustomizations;
	installsAfter?: string[];
	deprecated?: boolean;
	legacyIds?: string[];
	dependsOn?: Record<string, string | boolean | Record<string, string | boolean>>;
}

// Properties that are set programmatically for book-keeping purposes
export interface InternalFeatureProperties {
	cachePath?: string;
	internalVersion?: string;
	consecutiveId?: string;
	value: boolean | string | Record<string, boolean | string | undefined>;
	currentId?: string;
	included: boolean;
}

// Old or deprecated properties maintained for backwards compatibility
export interface DeprecatedSchemaFeatureProperties {
	buildArg?: string;
	include?: string[];
	exclude?: string[];
}

export type FeatureOption = {
	type: 'boolean';
	default?: boolean;
	description?: string;
} | {
	type: 'string';
	enum?: string[];
	default?: string;
	description?: string;
} | {
	type: 'string';
	proposals?: string[];
	default?: string;
	description?: string;
};
export interface Mount {
	type: 'bind' | 'volume';
	source?: string;
	target: string;
	external?: boolean;
}

const normalizedMountKeys: Record<string, string> = {
	src: 'source',
	destination: 'target',
	dst: 'target',
};

export function parseMount(str: string): Mount {
	return str.split(',')
		.map(s => s.split('='))
		.reduce((acc, [key, value]) => ({ ...acc, [(normalizedMountKeys[key] || key)]: value }), {}) as Mount;
}

export type SourceInformation = GithubSourceInformation | DirectTarballSourceInformation | FilePathSourceInformation | OCISourceInformation;

interface BaseSourceInformation {
	type: string;
	userFeatureId: string; // Dictates how a supporting tool will locate and download a given feature. See https://github.com/devcontainers/spec/blob/main/proposals/devcontainer-features.md#referencing-a-feature
	userFeatureIdWithoutVersion?: string;
}

export interface OCISourceInformation extends BaseSourceInformation {
	type: 'oci';
	featureRef: OCIRef;
	manifest: OCIManifest;
	manifestDigest: string;
	userFeatureIdWithoutVersion: string;
}

export interface DirectTarballSourceInformation extends BaseSourceInformation {
	type: 'direct-tarball';
	tarballUri: string;
}

export interface FilePathSourceInformation extends BaseSourceInformation {
	type: 'file-path';
	resolvedFilePath: string; // Resolved, absolute file path
}

// deprecated
export interface GithubSourceInformation extends BaseSourceInformation {
	type: 'github-repo';
	apiUri: string;
	unauthenticatedUri: string;
	owner: string;
	repo: string;
	isLatest: boolean; // 'true' indicates user didn't supply a version tag, thus we implicitly pull latest.
	tag?: string;
	ref?: string;
	sha?: string;
	userFeatureIdWithoutVersion: string;
}

export interface FeatureSet {
	features: Feature[];
	internalVersion?: string;
	sourceInformation: SourceInformation;
	computedDigest?: string;
}

export interface FeaturesConfig {
	featureSets: FeatureSet[];
	dstFolder?: string; // set programatically
}

export interface GitHubApiReleaseInfo {
	assets: GithubApiReleaseAsset[];
	name: string;
	tag_name: string;
}

export interface GithubApiReleaseAsset {
	url: string;
	name: string;
	content_type: string;
	size: number;
	download_count: number;
	updated_at: string;
}

export interface ContainerFeatureInternalParams {
	extensionPath: string;
	cacheFolder: string;
	cwd: string;
	output: Log;
	env: NodeJS.ProcessEnv;
	skipFeatureAutoMapping: boolean;
	platform: NodeJS.Platform;
	experimentalLockfile?: boolean;
	experimentalFrozenLockfile?: boolean;
}

// TODO: Move to node layer.
export function getContainerFeaturesBaseDockerFile(contentSourceRootPath: string) {
	return `

#{nonBuildKitFeatureContentFallback}

FROM $_DEV_CONTAINERS_BASE_IMAGE AS dev_containers_feature_content_normalize
USER root
COPY --from=dev_containers_feature_content_source ${path.posix.join(contentSourceRootPath, 'devcontainer-features.builtin.env')} /tmp/build-features/
RUN chmod -R 0755 /tmp/build-features/

FROM $_DEV_CONTAINERS_BASE_IMAGE AS dev_containers_target_stage

USER root

RUN mkdir -p ${FEATURES_CONTAINER_TEMP_DEST_FOLDER}
COPY --from=dev_containers_feature_content_normalize /tmp/build-features/ ${FEATURES_CONTAINER_TEMP_DEST_FOLDER}

#{featureLayer}

#{containerEnv}

ARG _DEV_CONTAINERS_IMAGE_USER=root
USER $_DEV_CONTAINERS_IMAGE_USER

#{devcontainerMetadata}

#{containerEnvMetadata}
`;
}

export function getFeatureInstallWrapperScript(feature: Feature, featureSet: FeatureSet, options: string[]): string {
	const id = escapeQuotesForShell(featureSet.sourceInformation.userFeatureIdWithoutVersion ?? 'Unknown');
	const name = escapeQuotesForShell(feature.name ?? 'Unknown');
	const description = escapeQuotesForShell(feature.description ?? '');
	const version = escapeQuotesForShell(feature.version ?? '');
	const documentation = escapeQuotesForShell(feature.documentationURL ?? '');
	const optionsIndented = escapeQuotesForShell(options.map(x => `    ${x}`).join('\n'));

	let warningHeader = '';
	if (feature.deprecated) {
		warningHeader += `(!) WARNING: Using the deprecated Feature "${escapeQuotesForShell(feature.id)}". This Feature will no longer receive any further updates/support.\n`;
	}

	if (feature?.legacyIds && feature.legacyIds.length > 0 && feature.currentId && feature.id !== feature.currentId) {
		warningHeader += `(!) WARNING: This feature has been renamed. Please update the reference in devcontainer.json to "${escapeQuotesForShell(feature.currentId)}".`;
	}

	const echoWarning = warningHeader ? `echo '${warningHeader}'` : '';
	const errorMessage = `ERROR: Feature "${name}" (${id}) failed to install!`;
	const troubleshootingMessage = documentation
		? ` Look at the documentation at ${documentation} for help troubleshooting this error.`
		: '';

	return `#!/bin/sh
set -e

on_exit () {
	[ $? -eq 0 ] && exit
	echo '${errorMessage}${troubleshootingMessage}'
}

trap on_exit EXIT

echo ===========================================================================
${echoWarning}
echo 'Feature       : ${name}'
echo 'Description   : ${description}'
echo 'Id            : ${id}'
echo 'Version       : ${version}'
echo 'Documentation : ${documentation}'
echo 'Options       :'
echo '${optionsIndented}'
echo ===========================================================================

set -a
. ../devcontainer-features.builtin.env
. ./devcontainer-features.env
set +a

chmod +x ./install.sh
./install.sh
`;
}

function escapeQuotesForShell(input: string) {
	// The `input` is expected to be a string which will be printed inside single quotes
	// by the caller. This means we need to escape any nested single quotes within the string.
	// We can do this by ending the first string with a single quote ('), printing an escaped
	// single quote (\'), and then opening a new string (').
	return input.replace(new RegExp(`'`, 'g'), `'\\''`);
}

export function getFeatureLayers(featuresConfig: FeaturesConfig, containerUser: string, remoteUser: string, useBuildKitBuildContexts = false, contentSourceRootPath = '/tmp/build-features') {

	const builtinsEnvFile = `${path.posix.join(FEATURES_CONTAINER_TEMP_DEST_FOLDER, 'devcontainer-features.builtin.env')}`;
	let result = `RUN \\
echo "_CONTAINER_USER_HOME=$(${getEntPasswdShellCommand(containerUser)} | cut -d: -f6)" >> ${builtinsEnvFile} && \\
echo "_REMOTE_USER_HOME=$(${getEntPasswdShellCommand(remoteUser)} | cut -d: -f6)" >> ${builtinsEnvFile}

`;

	// Features version 1
	const folders = (featuresConfig.featureSets || []).filter(y => y.internalVersion !== '2').map(x => x.features[0].consecutiveId);
	folders.forEach(folder => {
		const source = path.posix.join(contentSourceRootPath, folder!);
		const dest = path.posix.join(FEATURES_CONTAINER_TEMP_DEST_FOLDER, folder!);
		if (!useBuildKitBuildContexts) {
			result += `COPY --chown=root:root --from=dev_containers_feature_content_source ${source} ${dest}
RUN chmod -R 0755 ${dest} \\
&& cd ${dest} \\
&& chmod +x ./install.sh \\
&& ./install.sh

`;
		} else {
			result += `RUN --mount=type=bind,from=dev_containers_feature_content_source,source=${source},target=/tmp/build-features-src/${folder} \\
    cp -ar /tmp/build-features-src/${folder} ${FEATURES_CONTAINER_TEMP_DEST_FOLDER} \\
 && chmod -R 0755 ${dest} \\
 && cd ${dest} \\
 && chmod +x ./install.sh \\
 && ./install.sh \\
 && rm -rf ${dest}

`;
		}
	});
	// Features version 2
	featuresConfig.featureSets.filter(y => y.internalVersion === '2').forEach(featureSet => {
		featureSet.features.forEach(feature => {
			result += generateContainerEnvs(feature.containerEnv);
			const source = path.posix.join(contentSourceRootPath, feature.consecutiveId!);
			const dest = path.posix.join(FEATURES_CONTAINER_TEMP_DEST_FOLDER, feature.consecutiveId!);
			if (!useBuildKitBuildContexts) {
				result += `
COPY --chown=root:root --from=dev_containers_feature_content_source ${source} ${dest}
RUN chmod -R 0755 ${dest} \\
&& cd ${dest} \\
&& chmod +x ./devcontainer-features-install.sh \\
&& ./devcontainer-features-install.sh

`;
			} else {
				result += `
RUN --mount=type=bind,from=dev_containers_feature_content_source,source=${source},target=/tmp/build-features-src/${feature.consecutiveId} \\
    cp -ar /tmp/build-features-src/${feature.consecutiveId} ${FEATURES_CONTAINER_TEMP_DEST_FOLDER} \\
 && chmod -R 0755 ${dest} \\
 && cd ${dest} \\
 && chmod +x ./devcontainer-features-install.sh \\
 && ./devcontainer-features-install.sh \\
 && rm -rf ${dest}

`;
			}
		});
	});
	return result;
}

// Features version two export their environment variables as part of the Dockerfile to make them available to subsequent features.
export function generateContainerEnvs(containerEnv: Record<string, string> | undefined, escapeDollar = false): string {
	if (!containerEnv) {
		return '';
	}
	const keys = Object.keys(containerEnv);
	// https://docs.docker.com/engine/reference/builder/#envs
	const r = escapeDollar ? /(?=["\\$])/g : /(?=["\\])/g; // escape double quotes, back slash, and optionally dollar sign
	return keys.map(k => `ENV ${k}="${containerEnv[k]
		.replace(r, '\\')
		}"`).join('\n');
}

const allowedFeatureIdRegex = new RegExp('^[a-zA-Z0-9_-]*$');

// Parses a declared feature in user's devcontainer file into
// a usable URI to download remote features.
// RETURNS
// {
//  "id",              <----- The ID of the feature in the feature set.
//  sourceInformation  <----- Source information (is this locally cached, a GitHub remote feature, etc..), including tarballUri if applicable.
// }
//

const cleanupIterationFetchAndMerge = async (tempTarballPath: string, output: Log) => {
	// Non-fatal, will just get overwritten if we don't do the cleaned up.
	try {
		await rmLocal(tempTarballPath, { force: true });
	} catch (e) {
		output.write(`Didn't remove temporary tarball from disk with caught exception: ${e?.Message} `, LogLevel.Trace);
	}
};

function getRequestHeaders(params: CommonParams, sourceInformation: SourceInformation) {
	const { env, output } = params;
	let headers: { 'user-agent': string; 'Authorization'?: string; 'Accept'?: string } = {
		'user-agent': 'devcontainer'
	};

	const isGitHubUri = (srcInfo: DirectTarballSourceInformation) => {
		const uri = srcInfo.tarballUri;
		return uri.startsWith('https://github.com') || uri.startsWith('https://api.github.com');
	};

	if (sourceInformation.type === 'github-repo' || (sourceInformation.type === 'direct-tarball' && isGitHubUri(sourceInformation))) {
		const githubToken = env['GITHUB_TOKEN'];
		if (githubToken) {
			output.write('Using environment GITHUB_TOKEN.');
			headers.Authorization = `Bearer ${githubToken}`;
		} else {
			output.write('No environment GITHUB_TOKEN available.');
		}
	}
	return headers;
}

async function askGitHubApiForTarballUri(sourceInformation: GithubSourceInformation, feature: Feature, headers: { 'user-agent': string; 'Authorization'?: string; 'Accept'?: string }, output: Log) {
	const options = {
		type: 'GET',
		url: sourceInformation.apiUri,
		headers
	};

	const apiInfo: GitHubApiReleaseInfo = JSON.parse(((await request(options, output)).toString()));
	if (apiInfo) {
		const asset =
			apiInfo.assets.find(a => a.name === `${feature.id}.tgz`)  // v2
			|| apiInfo.assets.find(a => a.name === V1_ASSET_NAME) // v1
			|| undefined;

		if (asset && asset.url) {
			output.write(`Found url to fetch release artifact '${asset.name}'. Asset of size ${asset.size} has been downloaded ${asset.download_count} times and was last updated at ${asset.updated_at}`);
			return asset.url;
		} else {
			output.write('Unable to fetch release artifact URI from GitHub API', LogLevel.Error);
			return undefined;
		}
	}
	return undefined;
}

function updateFromOldProperties<T extends { features: (Feature & { extensions?: string[]; settings?: object; customizations?: VSCodeCustomizations })[] }>(original: T): T {
	// https://github.com/microsoft/dev-container-spec/issues/1
	if (!original.features.find(f => f.extensions || f.settings)) {
		return original;
	}
	return {
		...original,
		features: original.features.map(f => {
			if (!(f.extensions || f.settings)) {
				return f;
			}
			const copy = { ...f };
			const customizations = copy.customizations || (copy.customizations = {});
			const vscode = customizations.vscode || (customizations.vscode = {});
			if (copy.extensions) {
				vscode.extensions = (vscode.extensions || []).concat(copy.extensions);
				delete copy.extensions;
			}
			if (copy.settings) {
				vscode.settings = {
					...copy.settings,
					...(vscode.settings || {}),
				};
				delete copy.settings;
			}
			return copy;
		}),
	};
}

// Generate a base featuresConfig object with the set of locally-cached features, 
// as well as downloading and merging in remote feature definitions.
export async function generateFeaturesConfig(params: ContainerFeatureInternalParams, dstFolder: string, config: DevContainerConfig, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>) {
	const { output } = params;

	const workspaceRoot = params.cwd;
	output.write(`workspace root: ${workspaceRoot}`, LogLevel.Trace);

	const userFeatures = updateDeprecatedFeaturesIntoOptions(userFeaturesToArray(config, additionalFeatures), output);
	if (!userFeatures) {
		return undefined;
	}

	let configPath = config.configFilePath && uriToFsPath(config.configFilePath, params.platform);
	output.write(`configPath: ${configPath}`, LogLevel.Trace);

	const ociCacheDir = await prepareOCICache(dstFolder);

	const { lockfile, initLockfile } = await readLockfile(config);

	const processFeature = async (_userFeature: DevContainerFeature) => {
		return await processFeatureIdentifier(params, configPath, workspaceRoot, _userFeature, lockfile);
	};

	output.write('--- Processing User Features ----', LogLevel.Trace);
	const featureSets = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config, lockfile);
	if (!featureSets) {
		throw new Error('Failed to compute Feature installation order!');
	}

	// Create the featuresConfig object.
	const featuresConfig: FeaturesConfig = {
		featureSets,
		dstFolder
	};

	// Fetch features, stage into the appropriate build folder, and read the feature's devcontainer-feature.json
	output.write('--- Fetching User Features ----', LogLevel.Trace);
	await fetchFeatures(params, featuresConfig, dstFolder, ociCacheDir, lockfile);

	await logFeatureAdvisories(params, featuresConfig);
	await writeLockfile(params, config, await generateLockfile(featuresConfig), initLockfile);
	return featuresConfig;
}

export async function loadVersionInfo(params: ContainerFeatureInternalParams, config: DevContainerConfig) {
	const userFeatures = userFeaturesToArray(config);
	if (!userFeatures) {
		return { features: {} };
	}

	const { lockfile } = await readLockfile(config);

	const resolved: Record<string, any> = {};

	await Promise.all(userFeatures.map(async userFeature => {
		const userFeatureId = userFeature.userFeatureId;
		const featureRef = getRef(nullLog, userFeatureId); // Filters out Feature identifiers that cannot be versioned (e.g. local paths, deprecated, etc..)
		if (featureRef) {
			const versions = (await getVersionsStrictSorted(params, featureRef))
				?.reverse() || [];
			if (versions) {
				const lockfileVersion = lockfile?.features[userFeatureId]?.version;
				let wanted = lockfileVersion;
				const tag = featureRef.tag;
				if (tag) {
					if (tag === 'latest') {
						wanted = versions[0];
					} else {
						wanted = versions.find(version => semver.satisfies(version, tag));
					}
				} else if (featureRef.digest && !wanted) {
					const { type, manifest } = await getFeatureIdType(params, userFeatureId, undefined);
					if (type === 'oci' && manifest) {
						const wantedFeature = await findOCIFeatureMetadata(params, manifest);
						wanted = wantedFeature?.version;
					}
				}
				resolved[userFeatureId] = {
					current: lockfileVersion || wanted,
					wanted,
					wantedMajor: wanted && semver.major(wanted)?.toString(),
					latest: versions[0],
					latestMajor: versions[0] && semver.major(versions[0])?.toString(),
				};
			}
		}
	}));

	// Reorder Features to match the order in which they were specified in config
	return {
		features: userFeatures.reduce((acc, userFeature) => {
			const r = resolved[userFeature.userFeatureId];
			if (r) {
				acc[userFeature.userFeatureId] = r;
			}
			return acc;
		}, {} as Record<string, any>)
	};
}

async function findOCIFeatureMetadata(params: ContainerFeatureInternalParams, manifest: ManifestContainer) {
	const annotation = manifest.manifestObj.annotations?.['dev.containers.metadata'];
	if (annotation) {
		return jsonc.parse(annotation) as Feature;
	}

	// Backwards compatibility.
	const featureSet = tryGetOCIFeatureSet(params.output, manifest.canonicalId, {}, manifest, manifest.canonicalId);
	if (!featureSet) {
		return undefined;
	}

	const tmp = path.join(os.tmpdir(), crypto.randomUUID());
	const f = await fetchOCIFeature(params, featureSet, tmp, tmp, DEVCONTAINER_FEATURE_FILE_NAME);
	return f.metadata as Feature | undefined;
}

async function prepareOCICache(dstFolder: string) {
	const ociCacheDir = path.join(dstFolder, 'ociCache');
	await mkdirpLocal(ociCacheDir);

	return ociCacheDir;
}

export function userFeaturesToArray(config: DevContainerConfig, additionalFeatures?: Record<string, string | boolean | Record<string, string | boolean>>): DevContainerFeature[] | undefined {
	if (!Object.keys(config.features || {}).length && !Object.keys(additionalFeatures || {}).length) {
		return undefined;
	}

	const userFeatures: DevContainerFeature[] = [];
	const userFeatureKeys = new Set<string>();

	if (config.features) {
		for (const userFeatureKey of Object.keys(config.features)) {
			const userFeatureValue = config.features[userFeatureKey];
			const feature: DevContainerFeature = {
				userFeatureId: userFeatureKey,
				options: userFeatureValue
			};
			userFeatures.push(feature);
			userFeatureKeys.add(userFeatureKey);
		}
	}

	if (additionalFeatures) {
		for (const userFeatureKey of Object.keys(additionalFeatures)) {
			// add the additional feature if it hasn't already been added from the config features
			if (!userFeatureKeys.has(userFeatureKey)) {
				const userFeatureValue = additionalFeatures[userFeatureKey];
				const feature: DevContainerFeature = {
					userFeatureId: userFeatureKey,
					options: userFeatureValue
				};
				userFeatures.push(feature);
			}
		}
	}

	return userFeatures;
}

const deprecatedFeaturesIntoOptions: Record<string, { mapTo: string; withOptions: any }> = {
	gradle: {
		mapTo: 'java',
		withOptions: {
			installGradle: true
		}
	},
	maven: {
		mapTo: 'java',
		withOptions: {
			installMaven: true
		}
	},
	jupyterlab: {
		mapTo: 'python',
		withOptions: {
			installJupyterlab: true
		}
	},
};

export function updateDeprecatedFeaturesIntoOptions(userFeatures: DevContainerFeature[] | undefined, output: Log) {
	if (!userFeatures) {
		output.write('No user features to update', LogLevel.Trace);
		return;
	}

	const newFeaturePath = 'ghcr.io/devcontainers/features';
	const versionBackwardComp = '1';
	for (const update of userFeatures.filter(feature => deprecatedFeaturesIntoOptions[feature.userFeatureId])) {
		const { mapTo, withOptions } = deprecatedFeaturesIntoOptions[update.userFeatureId];
		output.write(`(!) WARNING: Using the deprecated '${update.userFeatureId}' Feature. It is now part of the '${mapTo}' Feature. See https://github.com/devcontainers/features/tree/main/src/${mapTo}#options for the updated Feature.`, LogLevel.Warning);
		const qualifiedMapToId = `${newFeaturePath}/${mapTo}`;
		let userFeature = userFeatures.find(feature => feature.userFeatureId === mapTo || feature.userFeatureId === qualifiedMapToId || feature.userFeatureId.startsWith(`${qualifiedMapToId}:`));
		if (userFeature) {
			userFeature.options = {
				...(
					typeof userFeature.options === 'object' ? userFeature.options :
						typeof userFeature.options === 'string' ? { version: userFeature.options } :
							{}
				),
				...withOptions,
			};
		} else {
			userFeature = {
				userFeatureId: `${qualifiedMapToId}:${versionBackwardComp}`,
				options: withOptions
			};
			userFeatures.push(userFeature);
		}
	}
	const updatedUserFeatures = userFeatures.filter(feature => !deprecatedFeaturesIntoOptions[feature.userFeatureId]);
	return updatedUserFeatures;
}

export async function getFeatureIdType(params: CommonParams, userFeatureId: string, lockfile: Lockfile | undefined) {
	const { output } = params;
	// See the specification for valid feature identifiers:
	//   > https://github.com/devcontainers/spec/blob/main/proposals/devcontainer-features.md#referencing-a-feature
	//
	// Additionally, we support the following deprecated syntaxes for backwards compatibility:
	//      (0)  A 'local feature' packaged with the CLI.
	//			 Syntax:   <feature>
	//
	//      (1)  A feature backed by a GitHub Release
	//			 Syntax:   <repoOwner>/<repoName>/<featureId>[@version]

	// Legacy feature-set ID
	if (!userFeatureId.includes('/') && !userFeatureId.includes('\\')) {
		const errorMessage = `Legacy feature '${userFeatureId}' not supported. Please check https://containers.dev/features for replacements.
If you were hoping to use local Features, remember to prepend your Feature name with "./". Please check https://containers.dev/implementors/features-distribution/#addendum-locally-referenced for more information.`;
		output.write(errorMessage, LogLevel.Error);
		throw new ContainerError({
			description: errorMessage
		});
	}

	// Direct tarball reference
	if (userFeatureId.startsWith('https://')) {
		return { type: 'direct-tarball', manifest: undefined };
	}

	// Local feature on disk
	// !! NOTE: The ability for paths outside the project file tree will soon be removed.
	if (userFeatureId.startsWith('./') || userFeatureId.startsWith('../') || userFeatureId.startsWith('/')) {
		return { type: 'file-path', manifest: undefined };
	}

	const manifest = await fetchOCIFeatureManifestIfExistsFromUserIdentifier(params, userFeatureId, lockfile?.features[userFeatureId]?.integrity);
	if (manifest) {
		return { type: 'oci', manifest: manifest };
	} else {
		output.write(`Could not resolve Feature manifest for '${userFeatureId}'.  If necessary, provide registry credentials with 'docker login <registry>'.`, LogLevel.Warning);
		output.write(`Falling back to legacy GitHub Releases mode to acquire Feature.`, LogLevel.Trace);

		// DEPRECATED: This is a legacy feature-set ID
		return { type: 'github-repo', manifest: undefined };
	}
}

export function getBackwardCompatibleFeatureId(output: Log, id: string) {
	const migratedfeatures = ['aws-cli', 'azure-cli', 'desktop-lite', 'docker-in-docker', 'docker-from-docker', 'dotnet', 'git', 'git-lfs', 'github-cli', 'java', 'kubectl-helm-minikube', 'node', 'powershell', 'python', 'ruby', 'rust', 'sshd', 'terraform'];
	const renamedFeatures = new Map();
	renamedFeatures.set('golang', 'go');
	renamedFeatures.set('common', 'common-utils');

	const deprecatedFeaturesIntoOptions = new Map();
	deprecatedFeaturesIntoOptions.set('gradle', 'java');
	deprecatedFeaturesIntoOptions.set('maven', 'java');
	deprecatedFeaturesIntoOptions.set('jupyterlab', 'python');

	const newFeaturePath = 'ghcr.io/devcontainers/features';
	// Note: Pin the versionBackwardComp to '1' to avoid breaking changes.
	const versionBackwardComp = '1';

	// Mapping feature references (old shorthand syntax) from "microsoft/vscode-dev-containers" to "ghcr.io/devcontainers/features"
	if (migratedfeatures.includes(id)) {
		output.write(`(!) WARNING: Using the deprecated '${id}' Feature. See https://github.com/devcontainers/features/tree/main/src/${id}#example-usage for the updated Feature.`, LogLevel.Warning);
		return `${newFeaturePath}/${id}:${versionBackwardComp}`;
	}

	// Mapping feature references (renamed old shorthand syntax) from "microsoft/vscode-dev-containers" to "ghcr.io/devcontainers/features"
	if (renamedFeatures.get(id) !== undefined) {
		output.write(`(!) WARNING: Using the deprecated '${id}' Feature. See https://github.com/devcontainers/features/tree/main/src/${renamedFeatures.get(id)}#example-usage for the updated Feature.`, LogLevel.Warning);
		return `${newFeaturePath}/${renamedFeatures.get(id)}:${versionBackwardComp}`;
	}

	if (deprecatedFeaturesIntoOptions.get(id) !== undefined) {
		output.write(`(!) WARNING: Falling back to the deprecated '${id}' Feature. It is now part of the '${deprecatedFeaturesIntoOptions.get(id)}' Feature. See https://github.com/devcontainers/features/tree/main/src/${deprecatedFeaturesIntoOptions.get(id)}#options for the updated Feature.`, LogLevel.Warning);
	}

	// Deprecated and all other features references (eg. fish, ghcr.io/devcontainers/features/go, ghcr.io/owner/repo/id etc)
	return id;
}

// Strictly processes the user provided feature identifier to determine sourceInformation type.
// Returns a featureSet per feature.
export async function processFeatureIdentifier(params: CommonParams, configPath: string | undefined, _workspaceRoot: string, userFeature: DevContainerFeature, lockfile?: Lockfile, skipFeatureAutoMapping?: boolean): Promise<FeatureSet | undefined> {
	const { output } = params;

	output.write(`* Processing feature: ${userFeature.userFeatureId}`);

	// id referenced by the user before the automapping from old shorthand syntax to "ghcr.io/devcontainers/features"
	const originalUserFeatureId = userFeature.userFeatureId;
	// Adding backward compatibility
	if (!skipFeatureAutoMapping) {
		userFeature.userFeatureId = getBackwardCompatibleFeatureId(output, userFeature.userFeatureId);
	}

	const { type, manifest } = await getFeatureIdType(params, userFeature.userFeatureId, lockfile);

	// remote tar file
	if (type === 'direct-tarball') {
		output.write(`Remote tar file found.`);
		const tarballUri = new URL.URL(userFeature.userFeatureId);

		const fullPath = tarballUri.pathname;
		const tarballName = fullPath.substring(fullPath.lastIndexOf('/') + 1);
		output.write(`tarballName = ${tarballName}`, LogLevel.Trace);

		const regex = new RegExp('devcontainer-feature-(.*).tgz');
		const matches = regex.exec(tarballName);

		if (!matches || matches.length !== 2) {
			output.write(`Expected tarball name to follow 'devcontainer-feature-<feature-id>.tgz' format.  Received '${tarballName}'`, LogLevel.Error);
			return undefined;
		}
		const id = matches[1];

		if (id === '' || !allowedFeatureIdRegex.test(id)) {
			output.write(`Parse error. Specify a feature id with alphanumeric, dash, or underscore characters. Received ${id}.`, LogLevel.Error);
			return undefined;
		}

		let feat: Feature = {
			id: id,
			name: userFeature.userFeatureId,
			value: userFeature.options,
			included: true,
		};

		let newFeaturesSet: FeatureSet = {
			sourceInformation: {
				type: 'direct-tarball',
				tarballUri: tarballUri.toString(),
				userFeatureId: originalUserFeatureId
			},
			features: [feat],
		};

		return newFeaturesSet;
	}

	// Spec: https://containers.dev/implementors/features-distribution/#addendum-locally-referenced
	if (type === 'file-path') {
		output.write(`Local disk feature.`);

		const id = path.basename(userFeature.userFeatureId);

		// Fail on Absolute paths.
		if (path.isAbsolute(userFeature.userFeatureId)) {
			output.write('An Absolute path to a local feature is not allowed.', LogLevel.Error);
			return undefined;
		}

		// Local-path features are expected to be a sub-folder of the '$WORKSPACE_ROOT/.devcontainer' folder.
		if (!configPath) {
			output.write('A local feature requires a configuration path.', LogLevel.Error);
			return undefined;
		}
		const featureFolderPath = path.join(path.dirname(configPath), userFeature.userFeatureId);

		// Ensure we aren't escaping .devcontainer folder
		const parent = path.join(_workspaceRoot, '.devcontainer');
		const child = featureFolderPath;
		const relative = path.relative(parent, child);
		output.write(`${parent} -> ${child}:   Relative Distance = '${relative}'`, LogLevel.Trace);
		if (relative.indexOf('..') !== -1) {
			output.write(`Local file path parse error. Resolved path must be a child of the .devcontainer/ folder.  Parsed: ${featureFolderPath}`, LogLevel.Error);
			return undefined;
		}

		output.write(`Resolved: ${userFeature.userFeatureId}  ->  ${featureFolderPath}`, LogLevel.Trace);

		// -- All parsing and validation steps complete at this point.

		output.write(`Parsed feature id: ${id}`, LogLevel.Trace);
		let feat: Feature = {
			id,
			name: userFeature.userFeatureId,
			value: userFeature.options,
			included: true,
		};

		let newFeaturesSet: FeatureSet = {
			sourceInformation: {
				type: 'file-path',
				resolvedFilePath: featureFolderPath,
				userFeatureId: originalUserFeatureId
			},
			features: [feat],
		};

		return newFeaturesSet;
	}

	// (6) Oci Identifier
	if (type === 'oci' && manifest) {
		return tryGetOCIFeatureSet(output, userFeature.userFeatureId, userFeature.options, manifest, originalUserFeatureId);
	}

	output.write(`Github feature.`);
	// Github repository source.
	let version = 'latest';
	let splitOnAt = userFeature.userFeatureId.split('@');
	if (splitOnAt.length > 2) {
		output.write(`Parse error. Use the '@' symbol only to designate a version tag.`, LogLevel.Error);
		return undefined;
	}
	if (splitOnAt.length === 2) {
		output.write(`[${userFeature.userFeatureId}] has version ${splitOnAt[1]}`, LogLevel.Trace);
		version = splitOnAt[1];
	}

	// Remaining info must be in the first part of the split.
	const featureBlob = splitOnAt[0];
	const splitOnSlash = featureBlob.split('/');
	// We expect all GitHub/registry features to follow the triple slash pattern at this point
	//  eg: <publisher>/<feature-set>/<feature>
	if (splitOnSlash.length !== 3 || splitOnSlash.some(x => x === '') || !allowedFeatureIdRegex.test(splitOnSlash[2])) {
		// This is the final fallback. If we end up here, we weren't able to resolve the Feature
		output.write(`Could not resolve Feature '${userFeature.userFeatureId}'.  Ensure the Feature is published and accessible from your current environment.`, LogLevel.Error);
		return undefined;
	}
	const owner = splitOnSlash[0];
	const repo = splitOnSlash[1];
	const id = splitOnSlash[2];

	let feat: Feature = {
		id: id,
		name: userFeature.userFeatureId,
		value: userFeature.options,
		included: true,
	};

	const userFeatureIdWithoutVersion = originalUserFeatureId.split('@')[0];
	if (version === 'latest') {
		let newFeaturesSet: FeatureSet = {
			sourceInformation: {
				type: 'github-repo',
				apiUri: `https://api.github.com/repos/${owner}/${repo}/releases/latest`,
				unauthenticatedUri: `https://github.com/${owner}/${repo}/releases/latest/download`, // v1/v2 implementations append name of relevant asset
				owner,
				repo,
				isLatest: true,
				userFeatureId: originalUserFeatureId,
				userFeatureIdWithoutVersion
			},
			features: [feat],
		};
		return newFeaturesSet;
	} else {
		// We must have a tag, return a tarball URI for the tagged version. 
		let newFeaturesSet: FeatureSet = {
			sourceInformation: {
				type: 'github-repo',
				apiUri: `https://api.github.com/repos/${owner}/${repo}/releases/tags/${version}`,
				unauthenticatedUri: `https://github.com/${owner}/${repo}/releases/download/${version}`, // v1/v2 implementations append name of relevant asset
				owner,
				repo,
				tag: version,
				isLatest: false,
				userFeatureId: originalUserFeatureId,
				userFeatureIdWithoutVersion
			},
			features: [feat],
		};
		return newFeaturesSet;
	}

	// TODO: Handle invalid source types better by refactoring this function.
	// throw new Error(`Unsupported feature source type: ${type}`);
}

async function fetchFeatures(params: { extensionPath: string; cwd: string; output: Log; env: NodeJS.ProcessEnv }, featuresConfig: FeaturesConfig, dstFolder: string, ociCacheDir: string, lockfile: Lockfile | undefined) {
	const featureSets = featuresConfig.featureSets;
	for (let idx = 0; idx < featureSets.length; idx++) { // Index represents the previously computed installation order.
		const featureSet = featureSets[idx];
		try {
			if (!featureSet || !featureSet.features || !featureSet.sourceInformation) {
				continue;
			}

			const { output } = params;

			const feature = featureSet.features[0];
			const consecutiveId = `${feature.id}_${idx}`;
			// Calculate some predictable caching paths.
			const featCachePath = path.join(dstFolder, consecutiveId);
			const sourceInfoType = featureSet.sourceInformation?.type;

			feature.cachePath = featCachePath;
			feature.consecutiveId = consecutiveId;

			if (!feature.consecutiveId || !feature.id || !featureSet?.sourceInformation || !featureSet.sourceInformation.userFeatureId) {
				const err = 'Internal Features error. Missing required attribute(s).';
				throw new Error(err);
			}

			const featureDebugId = `${feature.consecutiveId}_${sourceInfoType}`;
			output.write(`* Fetching feature: ${featureDebugId}`);

			if (sourceInfoType === 'oci') {
				output.write(`Fetching from OCI`, LogLevel.Trace);
				await mkdirpLocal(featCachePath);
				const res = await fetchOCIFeature(params, featureSet, ociCacheDir, featCachePath);
				if (!res) {
					const err = `Could not download OCI feature: ${featureSet.sourceInformation.featureRef.id}`;
					throw new Error(err);
				}

				if (!(await applyFeatureConfigToFeature(output, featureSet, feature, featCachePath, featureSet.sourceInformation.manifestDigest))) {
					const err = `Failed to parse feature '${featureDebugId}'. Please check your devcontainer.json 'features' attribute.`;
					throw new Error(err);
				}
				output.write(`* Fetched feature: ${featureDebugId} version ${feature.version}`);

				continue;
			}

			if (sourceInfoType === 'file-path') {
				output.write(`Detected local file path`, LogLevel.Trace);
				await mkdirpLocal(featCachePath);
				const executionPath = featureSet.sourceInformation.resolvedFilePath;
				await cpDirectoryLocal(executionPath, featCachePath);

				if (!(await applyFeatureConfigToFeature(output, featureSet, feature, featCachePath, undefined))) {
					const err = `Failed to parse feature '${featureDebugId}'. Please check your devcontainer.json 'features' attribute.`;
					throw new Error(err);
				}
				continue;
			}

			output.write(`Detected tarball`, LogLevel.Trace);
			const headers = getRequestHeaders(params, featureSet.sourceInformation);

			// Ordered list of tarballUris to attempt to fetch from.
			let tarballUris: (string | { uri: string; digest?: string })[] = [];

			if (sourceInfoType === 'github-repo') {
				output.write('Determining tarball URI for provided github repo.', LogLevel.Trace);
				if (headers.Authorization && headers.Authorization !== '') {
					output.write('GITHUB_TOKEN available. Attempting to fetch via GH API.', LogLevel.Info);
					const authenticatedGithubTarballUri = await askGitHubApiForTarballUri(featureSet.sourceInformation, feature, headers, output);

					if (authenticatedGithubTarballUri) {
						tarballUris.push(authenticatedGithubTarballUri);
					} else {
						output.write('Failed to generate autenticated tarball URI for provided feature, despite a GitHub token present', LogLevel.Warning);
					}
					headers.Accept = 'Accept: application/octet-stream';
				}

				// Always add the unauthenticated URIs as fallback options.
				output.write('Appending unauthenticated URIs for v2 and then v1', LogLevel.Trace);
				tarballUris.push(`${featureSet.sourceInformation.unauthenticatedUri}/${feature.id}.tgz`);
				tarballUris.push(`${featureSet.sourceInformation.unauthenticatedUri}/${V1_ASSET_NAME}`);

			} else {
				// We have a plain ol' tarball URI, since we aren't in the github-repo case.
				const uri = featureSet.sourceInformation.tarballUri;
				const digest = lockfile?.features[uri]?.integrity;
				tarballUris.push({ uri, digest });
			}

			// Attempt to fetch from 'tarballUris' in order, until one succeeds.
			let res: { computedDigest: string } | undefined;
			for (const tarballUri of tarballUris) {
				const uri = typeof tarballUri === 'string' ? tarballUri : tarballUri.uri;
				const digest = typeof tarballUri === 'string' ? undefined : tarballUri.digest;
				res = await fetchContentsAtTarballUri(params, uri, digest, featCachePath, headers, dstFolder);

				if (res) {
					output.write(`Succeeded fetching ${uri}`, LogLevel.Trace);
					if (!(await applyFeatureConfigToFeature(output, featureSet, feature, featCachePath, res.computedDigest))) {
						const err = `Failed to parse feature '${featureDebugId}'. Please check your devcontainer.json 'features' attribute.`;
						throw new Error(err);
					}
					break;
				}
			}

			if (!res) {
				const msg = `(!) Failed to fetch tarball for ${featureDebugId} after attempting ${tarballUris.length} possibilities.`;
				throw new Error(msg);
			}
		}
		catch (e) {
			params.output.write(`(!) ERR: Failed to fetch feature: ${e?.message ?? ''} `, LogLevel.Error);
			throw e;
		}
	}
}

export async function fetchContentsAtTarballUri(params: { output: Log; env: NodeJS.ProcessEnv }, tarballUri: string, expectedDigest: string | undefined, featCachePath: string, headers: { 'user-agent': string; 'Authorization'?: string; 'Accept'?: string } | undefined, dstFolder: string, metadataFile?: string): Promise<{ computedDigest: string; metadata: {} | undefined } | undefined> {
	const { output } = params;
	const tempTarballPath = path.join(dstFolder, 'temp.tgz');
	try {
		const options = {
			type: 'GET',
			url: tarballUri,
			headers: headers ?? getRequestHeaders(params, { tarballUri, userFeatureId: tarballUri, type: 'direct-tarball' })
		};

		output.write(`Fetching tarball at ${options.url}`);
		output.write(`Headers: ${JSON.stringify(options)}`, LogLevel.Trace);
		const tarball = await request(options, output);

		if (!tarball || tarball.length === 0) {
			output.write(`Did not receive a response from tarball download URI: ${tarballUri}`, LogLevel.Trace);
			return undefined;
		}

		const computedDigest = `sha256:${crypto.createHash('sha256').update(tarball).digest('hex')}`;
		if (expectedDigest && computedDigest !== expectedDigest) {
			throw new Error(`Digest did not match for ${tarballUri}.`);
		}

		// Filter what gets emitted from the tar.extract().
		const filter = (file: string, _: tar.FileStat) => {
			// Don't include .dotfiles or the archive itself.
			if (file.startsWith('./.') || file === `./${V1_ASSET_NAME}` || file === './.') {
				return false;
			}
			return true;
		};

		output.write(`Preparing to unarchive received tgz from ${tempTarballPath} -> ${featCachePath}.`, LogLevel.Trace);
		// Create the directory to cache this feature-set in.
		await mkdirpLocal(featCachePath);
		await writeLocalFile(tempTarballPath, tarball);
		await tar.x(
			{
				file: tempTarballPath,
				cwd: featCachePath,
				filter
			}
		);

		// No 'metadataFile' to look for.
		if (!metadataFile) {
		await cleanupIterationFetchAndMerge(tempTarballPath, output);
			return { computedDigest, metadata: undefined };
		}

		// Attempt to extract 'metadataFile'
		await tar.x(
			{
				file: tempTarballPath,
				cwd: featCachePath,
				filter: (path: string, _: tar.FileStat) => {
					return path === `./${metadataFile}`;
				}
			});
		const pathToMetadataFile = path.join(featCachePath, metadataFile);
		let metadata = undefined;
		if (await isLocalFile(pathToMetadataFile)) {
			output.write(`Found metadata file '${metadataFile}' in tgz`, LogLevel.Trace);
			metadata = jsonc.parse((await readLocalFile(pathToMetadataFile)).toString());
		}

		await cleanupIterationFetchAndMerge(tempTarballPath, output);
		return { computedDigest, metadata };
	} catch (e) {
		output.write(`Caught failure when fetching from URI '${tarballUri}': ${e}`, LogLevel.Trace);
		await cleanupIterationFetchAndMerge(tempTarballPath, output);
		return undefined;
	}
}

// Reads the feature's 'devcontainer-feature.json` and applies any attributes to the in-memory Feature object.
// NOTE:
// 		Implements the latest ('internalVersion' = '2') parsing logic, 
// 		Falls back to earlier implementation(s) if requirements not present.
// 		Returns a boolean indicating whether the feature was successfully parsed.
async function applyFeatureConfigToFeature(output: Log, featureSet: FeatureSet, feature: Feature, featCachePath: string, computedDigest: string | undefined): Promise<boolean> {
	const innerJsonPath = path.join(featCachePath, DEVCONTAINER_FEATURE_FILE_NAME);

	if (!(await isLocalFile(innerJsonPath))) {
		output.write(`Feature ${feature.id} is not a 'v2' feature. Attempting fallback to 'v1' implementation.`, LogLevel.Trace);
		output.write(`For v2, expected devcontainer-feature.json at ${innerJsonPath}`, LogLevel.Trace);
		return await parseDevContainerFeature_v1Impl(output, featureSet, feature, featCachePath);
	}

	featureSet.internalVersion = '2';
	featureSet.computedDigest = computedDigest;
	feature.cachePath = featCachePath;
	const jsonString: Buffer = await readLocalFile(innerJsonPath);
	const featureJson = jsonc.parse(jsonString.toString());


	feature = {
		...featureJson,
		...feature
	};

	featureSet.features[0] = updateFromOldProperties({ features: [feature] }).features[0];

	return true;
}

async function parseDevContainerFeature_v1Impl(output: Log, featureSet: FeatureSet, feature: Feature, featCachePath: string): Promise<boolean> {

	const pathToV1DevContainerFeatureJson = path.join(featCachePath, V1_DEVCONTAINER_FEATURES_FILE_NAME);

	if (!(await isLocalFile(pathToV1DevContainerFeatureJson))) {
		output.write(`Failed to find ${V1_DEVCONTAINER_FEATURES_FILE_NAME} metadata file (v1)`, LogLevel.Error);
		return false;
	}
	featureSet.internalVersion = '1';
	feature.cachePath = featCachePath;
	const jsonString: Buffer = await readLocalFile(pathToV1DevContainerFeatureJson);
	const featureJson: FeatureSet = jsonc.parse(jsonString.toString());

	const seekedFeature = featureJson?.features.find(f => f.id === feature.id);
	if (!seekedFeature) {
		output.write(`Failed to find feature '${feature.id}' in provided v1 metadata file`, LogLevel.Error);
		return false;
	}

	feature = {
		...seekedFeature,
		...feature
	};

	featureSet.features[0] = updateFromOldProperties({ features: [feature] }).features[0];


	return true;
}

export function getFeatureMainProperty(feature: Feature) {
	return feature.options?.version ? 'version' : undefined;
}

export function getFeatureMainValue(feature: Feature) {
	const defaultProperty = getFeatureMainProperty(feature);
	if (!defaultProperty) {
		return !!feature.value;
	}
	if (typeof feature.value === 'object') {
		const value = feature.value[defaultProperty];
		if (value === undefined && feature.options) {
			return feature.options[defaultProperty]?.default;
		}
		return value;
	}
	if (feature.value === undefined && feature.options) {
		return feature.options[defaultProperty]?.default;
	}
	return feature.value;
}

export function getFeatureValueObject(feature: Feature) {
	if (typeof feature.value === 'object') {
		return {
			...getFeatureValueDefaults(feature),
			...feature.value
		};
	}
	const mainProperty = getFeatureMainProperty(feature);
	if (!mainProperty) {
		return getFeatureValueDefaults(feature);
	}
	return {
		...getFeatureValueDefaults(feature),
		[mainProperty]: feature.value,
	};
}

function getFeatureValueDefaults(feature: Feature) {
	const options = feature.options || {};
	return Object.keys(options)
		.reduce((defaults, key) => {
			if ('default' in options[key]) {
				defaults[key] = options[key].default;
			}
			return defaults;
		}, {} as Record<string, string | boolean | undefined>);
}
</file>

<file path="src/spec-configuration/containerFeaturesOCI.ts">
import { Log, LogLevel } from '../spec-utils/log';
import { Feature, FeatureSet } from './containerFeaturesConfiguration';
import { CommonParams, fetchOCIManifestIfExists, getBlob, getRef, ManifestContainer } from './containerCollectionsOCI';

export function tryGetOCIFeatureSet(output: Log, identifier: string, options: boolean | string | Record<string, boolean | string | undefined>, manifest: ManifestContainer, originalUserFeatureId: string): FeatureSet | undefined {
	const featureRef = getRef(output, identifier);
	if (!featureRef) {
		output.write(`Unable to parse '${identifier}'`, LogLevel.Error);
		return undefined;
	}

	const feat: Feature = {
		id: featureRef.id,
		included: true,
		value: options
	};

	const userFeatureIdWithoutVersion = getFeatureIdWithoutVersion(originalUserFeatureId);
	let featureSet: FeatureSet = {
		sourceInformation: {
			type: 'oci',
			manifest: manifest.manifestObj,
			manifestDigest: manifest.contentDigest,
			featureRef: featureRef,
			userFeatureId: originalUserFeatureId,
			userFeatureIdWithoutVersion

		},
		features: [feat],
	};

	return featureSet;
}

const lastDelimiter = /[:@][^/]*$/;
export function getFeatureIdWithoutVersion(featureId: string) {
	const m = lastDelimiter.exec(featureId);
	return m ? featureId.substring(0, m.index) : featureId;
}

export async function fetchOCIFeatureManifestIfExistsFromUserIdentifier(params: CommonParams, identifier: string, manifestDigest?: string): Promise<ManifestContainer | undefined> {
	const { output } = params;

	const featureRef = getRef(output, identifier);
	if (!featureRef) {
		return undefined;
	}
	return await fetchOCIManifestIfExists(params, featureRef, manifestDigest);
}

// Download a feature from which a manifest was previously downloaded.
// Specification: https://github.com/opencontainers/distribution-spec/blob/v1.0.1/spec.md#pulling-blobs
export async function fetchOCIFeature(params: CommonParams, featureSet: FeatureSet, ociCacheDir: string, featCachePath: string, metadataFile?: string) {
	const { output } = params;

	if (featureSet.sourceInformation.type !== 'oci') {
		output.write(`FeatureSet is not an OCI featureSet.`, LogLevel.Error);
		throw new Error('FeatureSet is not an OCI featureSet.');
	}

	const { featureRef } = featureSet.sourceInformation;

	const layerDigest = featureSet.sourceInformation.manifest?.layers[0].digest;
	const blobUrl = `https://${featureSet.sourceInformation.featureRef.registry}/v2/${featureSet.sourceInformation.featureRef.path}/blobs/${layerDigest}`;
	output.write(`blob url: ${blobUrl}`, LogLevel.Trace);

	const blobResult = await getBlob(params, blobUrl, ociCacheDir, featCachePath, featureRef, layerDigest, undefined, metadataFile);

	if (!blobResult) {
		throw new Error(`Failed to download package for ${featureSet.sourceInformation.featureRef.resource}`);
	}

	return blobResult;
}
</file>

<file path="src/spec-configuration/containerFeaturesOrder.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as jsonc from 'jsonc-parser';
import * as os from 'os';
import * as crypto from 'crypto';

import { DEVCONTAINER_FEATURE_FILE_NAME, DirectTarballSourceInformation, Feature, FeatureSet, FilePathSourceInformation, OCISourceInformation, fetchContentsAtTarballUri } from '../spec-configuration/containerFeaturesConfiguration';
import { LogLevel } from '../spec-utils/log';
import { DevContainerFeature } from './configuration';
import { CommonParams, OCIRef } from './containerCollectionsOCI';
import { isLocalFile, readLocalFile } from '../spec-utils/pfs';
import { fetchOCIFeature } from './containerFeaturesOCI';
import { Lockfile } from './lockfile';

interface FNode {
	type: 'user-provided' | 'override' | 'resolved';
	userFeatureId: string;
	options: string | boolean | Record<string, string | boolean | undefined>;

	// FeatureSet contains 'sourceInformation', useful for:
	//      Providing information on if Feature is an OCI Feature, Direct HTTPS Feature, or Local Feature.
	//      Additionally, contains 'ref' and 'manifestDigest' for OCI Features - useful for sorting.
	// Property set programatically when discovering all the nodes in the graph.
	featureSet?: FeatureSet;

	// Graph directed adjacency lists.
	dependsOn: FNode[];
	installsAfter: FNode[];

	// If a Feature was renamed, this property will contain:
	// [<currentId>, <...allPreviousIds>]
	// See: https://containers.dev/implementors/features/#steps-to-rename-a-feature
	// Eg: ['node', 'nodejs', 'nodejs-feature']
	featureIdAliases?: string[];

	// Round Order Priority
	// Effective value is always the max
	roundPriority: number;
}

interface DependencyGraph {
	worklist: FNode[];
}

function equals(params: CommonParams, a: FNode, b: FNode): boolean {
	const { output } = params;

	const aSourceInfo = a.featureSet?.sourceInformation;
	let bSourceInfo = b.featureSet?.sourceInformation; // Mutable only for type-casting.

	if (!aSourceInfo || !bSourceInfo) {
		output.write(`Missing sourceInfo: equals(${aSourceInfo?.userFeatureId}, ${bSourceInfo?.userFeatureId})`, LogLevel.Trace);
		throw new Error('ERR: Failure resolving Features.');
	}

	if (aSourceInfo.type !== bSourceInfo.type) {
		return false;
	}

	return compareTo(params, a, b) === 0;
}

function satisfiesSoftDependency(params: CommonParams, node: FNode, softDep: FNode): boolean {
	const { output } = params;

	const nodeSourceInfo = node.featureSet?.sourceInformation;
	let softDepSourceInfo = softDep.featureSet?.sourceInformation; // Mutable only for type-casting.

	if (!nodeSourceInfo || !softDepSourceInfo) {
		output.write(`Missing sourceInfo: satisifiesSoftDependency(${nodeSourceInfo?.userFeatureId}, ${softDepSourceInfo?.userFeatureId})`, LogLevel.Trace);
		throw new Error('ERR: Failure resolving Features.');
	}

	if (nodeSourceInfo.type !== softDepSourceInfo.type) {
		return false;
	}

	switch (nodeSourceInfo.type) {
		case 'oci':
			softDepSourceInfo = softDepSourceInfo as OCISourceInformation;
			const nodeFeatureRef = nodeSourceInfo.featureRef;
			const softDepFeatureRef = softDepSourceInfo.featureRef;
			const softDepFeatureRefPrefix = `${softDepFeatureRef.registry}/${softDepFeatureRef.namespace}`;

			return nodeFeatureRef.resource === softDepFeatureRef.resource // Same resource
				|| softDep.featureIdAliases?.some(legacyId => `${softDepFeatureRefPrefix}/${legacyId}` === nodeFeatureRef.resource) // Handle 'legacyIds'
				|| false;

		case 'file-path':
			softDepSourceInfo = softDepSourceInfo as FilePathSourceInformation;
			return nodeSourceInfo.resolvedFilePath === softDepSourceInfo.resolvedFilePath;

		case 'direct-tarball':
			softDepSourceInfo = softDepSourceInfo as DirectTarballSourceInformation;
			return nodeSourceInfo.tarballUri === softDepSourceInfo.tarballUri;

		default:
			// Legacy
			const softDepId = softDepSourceInfo.userFeatureIdWithoutVersion || softDepSourceInfo.userFeatureId;
			const nodeId = nodeSourceInfo.userFeatureIdWithoutVersion || nodeSourceInfo.userFeatureId;
			return softDepId === nodeId;

	}
}

function optionsCompareTo(a: string | boolean | Record<string, string | boolean | undefined>, b: string | boolean | Record<string, string | boolean | undefined>): number {
	if (typeof a === 'string' && typeof b === 'string') {
		return a.localeCompare(b);
	}

	if (typeof a === 'boolean' && typeof b === 'boolean') {
		return a === b ? 0 : a ? 1 : -1;
	}

	if (typeof a === 'object' && typeof b === 'object') {
		// Compare lengths
		const aKeys = Object.keys(a);
		const bKeys = Object.keys(b);
		if (aKeys.length !== bKeys.length) {
			return aKeys.length - bKeys.length;
		}

		aKeys.sort();
		bKeys.sort();

		for (let i = 0; i < aKeys.length; i++) {
			// Compare keys
			if (aKeys[i] !== bKeys[i]) {
				return aKeys[i].localeCompare(bKeys[i]);
			}
			// Compare values
			const aVal = a[aKeys[i]];
			const bVal = b[bKeys[i]];
			if (typeof aVal === 'string' && typeof bVal === 'string') {
				const v = aVal.localeCompare(bVal);
				if (v !== 0) {
					return v;
				}
			}
			if (typeof aVal === 'boolean' && typeof bVal === 'boolean') {
				const v = aVal === bVal ? 0 : aVal ? 1 : -1;
				if (v !== 0) {
					return v;
				}
			}
			if (typeof aVal === 'undefined' || typeof bVal === 'undefined') {
				const v = aVal === bVal ? 0 : (aVal === undefined) ? 1 : -1;
				if (v !== 0) {
					return v;
				}
			}
		}
		// Object is piece-wise equal
		return 0;
	}
	return (typeof a).localeCompare(typeof b);
}

function ociResourceCompareTo(a: { featureRef: OCIRef; aliases?: string[] }, b: { featureRef: OCIRef; aliases?: string[] }): number {

	// Left Side
	const aFeatureRef = a.featureRef;
	const aRegistryAndNamespace = `${aFeatureRef.registry}/${aFeatureRef.namespace}`;

	// Right Side
	const bFeatureRef = b.featureRef;
	const bRegistryAndNamespace = `${bFeatureRef.registry}/${bFeatureRef.namespace}`;

	// If the registry+namespace are different, sort by them
	if (aRegistryAndNamespace !== bRegistryAndNamespace) {
		return aRegistryAndNamespace.localeCompare(bRegistryAndNamespace);
	}

	let commonId: string | undefined = undefined;
	// Determine if any permutation of the set of valid Ids are equal
	// Prefer the the canonical/non-legacy Id.
	// https://containers.dev/implementors/features/#steps-to-rename-a-feature
	for (const aId of a.aliases || [aFeatureRef.id]) {
		if (commonId) {
			break;
		}
		for (const bId of b.aliases || [bFeatureRef.id]) {
			if (aId === bId) {
				commonId = aId;
				break;
			}
		}
	}

	if (!commonId) {
		// Sort by canonical id
		return aFeatureRef.id.localeCompare(bFeatureRef.id);
	}

	// The (registry + namespace + id) are equal.
	return 0;
}

// If the two features are equal, return 0.
// If the sorting algorithm should place A _before_ B, return negative number.
// If the sorting algorithm should place A _after_  B, return positive number.
function compareTo(params: CommonParams, a: FNode, b: FNode): number {
	const { output } = params;

	const aSourceInfo = a.featureSet?.sourceInformation;
	let bSourceInfo = b.featureSet?.sourceInformation; // Mutable only for type-casting.

	if (!aSourceInfo || !bSourceInfo) {
		output.write(`Missing sourceInfo: compareTo(${aSourceInfo?.userFeatureId}, ${bSourceInfo?.userFeatureId})`, LogLevel.Trace);
		throw new Error('ERR: Failure resolving Features.');
	}

	if (aSourceInfo.type !== bSourceInfo.type) {
		return aSourceInfo.userFeatureId.localeCompare(bSourceInfo.userFeatureId);
	}

	switch (aSourceInfo.type) {
		case 'oci':
			bSourceInfo = bSourceInfo as OCISourceInformation;

			const aDigest = aSourceInfo.manifestDigest;
			const bDigest = bSourceInfo.manifestDigest;

			// Short circuit if the digests and options are equal
			if (aDigest === bDigest && optionsCompareTo(a.options, b.options) === 0) {
				return 0;
			}

			// Compare two OCI Features by their 
			// resource accounting for legacy id aliases
			const ociResourceVal = ociResourceCompareTo(
				{ featureRef: aSourceInfo.featureRef, aliases: a.featureIdAliases },
				{ featureRef: bSourceInfo.featureRef, aliases: b.featureIdAliases }
			);

			if (ociResourceVal !== 0) {
				return ociResourceVal;
			}

			const aTag = aSourceInfo.featureRef.tag;
			const bTag = bSourceInfo.featureRef.tag;
			// Sort by tags (if both have tags)
			// Eg: 1.9.9, 2.0.0, 2.0.1, 3, latest
			if ((aTag && bTag) && (aTag !== bTag)) {
				return aTag.localeCompare(bTag);
			}

			// Sort by options
			const optionsVal = optionsCompareTo(a.options, b.options);
			if (optionsVal !== 0) {
				return optionsVal;
			}

			// Sort by manifest digest hash
			if (aDigest !== bDigest) {
				return aDigest.localeCompare(bDigest);
			}

			// Consider these two OCI Features equal.
			return 0;

		case 'file-path':
			bSourceInfo = bSourceInfo as FilePathSourceInformation;
			const pathCompare = aSourceInfo.resolvedFilePath.localeCompare(bSourceInfo.resolvedFilePath);
			if (pathCompare !== 0) {
				return pathCompare;
			}
			return optionsCompareTo(a.options, b.options);

		case 'direct-tarball':
			bSourceInfo = bSourceInfo as DirectTarballSourceInformation;
			const urlCompare = aSourceInfo.tarballUri.localeCompare(bSourceInfo.tarballUri);
			if (urlCompare !== 0) {
				return urlCompare;
			}
			return optionsCompareTo(a.options, b.options);

		default:
			// Legacy
			const aId = aSourceInfo.userFeatureIdWithoutVersion || aSourceInfo.userFeatureId;
			const bId = bSourceInfo.userFeatureIdWithoutVersion || bSourceInfo.userFeatureId;
			const userIdCompare = aId.localeCompare(bId);
			if (userIdCompare !== 0) {
				return userIdCompare;
			}
			return optionsCompareTo(a.options, b.options);
	}
}

async function applyOverrideFeatureInstallOrder(
	params: CommonParams,
	processFeature: (userFeature: DevContainerFeature) => Promise<FeatureSet | undefined>,
	worklist: FNode[],
	config: { overrideFeatureInstallOrder?: string[] },
) {
	const { output } = params;

	if (!config.overrideFeatureInstallOrder) {
		return worklist;
	}

	// Create an override node for each Feature in the override property.
	const originalLength = config.overrideFeatureInstallOrder.length;
	for (let i = config.overrideFeatureInstallOrder.length - 1; i >= 0; i--) {
		const overrideFeatureId = config.overrideFeatureInstallOrder[i];

		// First element == N, last element == 1
		const roundPriority = originalLength - i;

		const tmpOverrideNode: FNode = {
			type: 'override',
			userFeatureId: overrideFeatureId,
			options: {},
			roundPriority,
			installsAfter: [],
			dependsOn: [],
			featureSet: undefined,
		};

		const processed = await processFeature(tmpOverrideNode);
		if (!processed) {
			throw new Error(`Feature '${tmpOverrideNode.userFeatureId}' in 'overrideFeatureInstallOrder' could not be processed.`);
		}

		tmpOverrideNode.featureSet = processed;

		// Scan the worklist, incrementing the priority of each Feature that matches the override.
		for (const node of worklist) {
			if (satisfiesSoftDependency(params, node, tmpOverrideNode)) {
				// Increase the priority of this node to install it sooner.
				output.write(`[override]: '${node.userFeatureId}' has override priority of ${roundPriority}`, LogLevel.Trace);
				node.roundPriority = Math.max(node.roundPriority, roundPriority);
			}
		}
	}

	// Return the modified worklist.
	return worklist;
}

async function _buildDependencyGraph(
	params: CommonParams,
	processFeature: (userFeature: DevContainerFeature) => Promise<FeatureSet | undefined>,
	worklist: FNode[],
	acc: FNode[],
	lockfile: Lockfile | undefined): Promise<DependencyGraph> {
	const { output } = params;

	while (worklist.length > 0) {
		const current = worklist.shift()!;

		output.write(`Resolving Feature dependencies for '${current.userFeatureId}'...`, LogLevel.Info);

		const processedFeature = await processFeature(current);
		if (!processedFeature) {
			throw new Error(`ERR: Feature '${current.userFeatureId}' could not be processed.  You may not have permission to access this Feature, or may not be logged in.  If the issue persists, report this to the Feature author.`);
		}

		// Set the processed FeatureSet object onto Node.
		current.featureSet = processedFeature;

		// If the current Feature is already in the accumulator, skip it.
		// This stops cycles but doesn't report them.  
		// Cycles/inconsistencies are thrown as errors in the next stage (rounds).
		if (acc.some(f => equals(params, f, current))) {
			continue;
		}

		const type = processedFeature.sourceInformation.type;
		let metadata: Feature | undefined;
		// Switch on the source type of the provided Feature.
		// Retrieving the metadata for the Feature (the contents of 'devcontainer-feature.json')
		switch (type) {
			case 'oci':
				metadata = await getOCIFeatureMetadata(params, current);
				break;

			case 'file-path':
				const filePath = (current.featureSet.sourceInformation as FilePathSourceInformation).resolvedFilePath;
				const metadataFilePath = path.join(filePath, DEVCONTAINER_FEATURE_FILE_NAME);
				if (!isLocalFile(filePath)) {
					throw new Error(`Metadata file '${metadataFilePath}' cannot be read for Feature '${current.userFeatureId}'.`);
				}
				const serialized = (await readLocalFile(metadataFilePath)).toString();
				if (serialized) {
					metadata = jsonc.parse(serialized) as Feature;
				}
				break;

			case 'direct-tarball':
				const tarballUri = (processedFeature.sourceInformation as DirectTarballSourceInformation).tarballUri;
				const expectedDigest = lockfile?.features[tarballUri]?.integrity;
				metadata = await getTgzFeatureMetadata(params, current, expectedDigest);
				break;

			default:
				// Legacy
				// No dependency metadata to retrieve.
				break;
		}

		// Resolve dependencies given the current Feature's metadata.
		if (metadata) {
			current.featureSet.features[0] = {
				...current.featureSet.features[0],
				...metadata,
			};

			// Dependency-related properties
			const dependsOn = metadata.dependsOn || {};
			const installsAfter = metadata.installsAfter || [];

			// Remember legacyIds
			const legacyIds = (metadata.legacyIds || []);
			const currentId = metadata.currentId || metadata.id;
			current.featureIdAliases = [currentId, ...legacyIds];

			// Add a new node for each 'dependsOn' dependency onto the 'current' node.
			// **Add this new node to the worklist to process recursively**
			for (const [userFeatureId, options] of Object.entries(dependsOn)) {
				const dependency: FNode = {
					type: 'resolved',
					userFeatureId,
					options,
					featureSet: undefined,
					dependsOn: [],
					installsAfter: [],
					roundPriority: 0,
				};
				current.dependsOn.push(dependency);
				worklist.push(dependency);
			}

			// Add a new node for each 'installsAfter' soft-dependency onto the 'current' node.
			// Soft-dependencies are NOT recursively processed - do *not* add to worklist.
			for (const userFeatureId of installsAfter) {
				const dependency: FNode = {
					type: 'resolved',
					userFeatureId,
					options: {},
					featureSet: undefined,
					dependsOn: [],
					installsAfter: [],
					roundPriority: 0,
				};
				const processedFeatureSet = await processFeature(dependency);
				if (!processedFeatureSet) {
					throw new Error(`installsAfter dependency '${userFeatureId}' of Feature '${current.userFeatureId}' could not be processed.`);
				}

				dependency.featureSet = processedFeatureSet;

				// Resolve and add all 'legacyIds' as aliases for the soft dependency relationship.
				// https://containers.dev/implementors/features/#steps-to-rename-a-feature
				const softDepMetadata = await getOCIFeatureMetadata(params, dependency);
				if (softDepMetadata) {
					const legacyIds = softDepMetadata.legacyIds || [];
					const currentId = softDepMetadata.currentId || softDepMetadata.id;
					dependency.featureIdAliases = [currentId, ...legacyIds];
				}

				current.installsAfter.push(dependency);
			}
		}

		acc.push(current);
	}

	// Return the accumulated collection of dependencies.
	return {
		worklist: acc,
	};
}

async function getOCIFeatureMetadata(params: CommonParams, node: FNode): Promise<Feature | undefined> {
	const { output } = params;

	// TODO: Implement a caching layer here!
	//       This can be optimized to share work done here
	//       with the 'fetchFeatures()` stage later on.
	const srcInfo = node?.featureSet?.sourceInformation;
	if (!node.featureSet || !srcInfo || srcInfo.type !== 'oci') {
		return;
	}

	const manifest = srcInfo.manifest;
	const annotation = manifest?.annotations?.['dev.containers.metadata'];

	if (annotation) {
		return jsonc.parse(annotation) as Feature;
	} else {
		// For backwards compatibility,
		// If the metadata is not present on the manifest, we have to fetch the entire blob
		// to extract the 'installsAfter' property.
		// TODO: Cache this smarter to reuse later!
		const tmp = path.join(os.tmpdir(), crypto.randomUUID());
		const f = await fetchOCIFeature(params, node.featureSet, tmp, tmp, DEVCONTAINER_FEATURE_FILE_NAME);

		if (f && f.metadata) {
			return f.metadata as Feature;
		}
	}
	output.write('No metadata found for Feature', LogLevel.Trace);
	return;
}

async function getTgzFeatureMetadata(params: CommonParams, node: FNode, expectedDigest: string | undefined): Promise<Feature | undefined> {
	const { output } = params;

	// TODO: Implement a caching layer here!
	//       This can be optimized to share work done here
	//       with the 'fetchFeatures()` stage later on.
	const srcInfo = node?.featureSet?.sourceInformation;
	if (!node.featureSet || !srcInfo || srcInfo.type !== 'direct-tarball') {
		return;
	}

	const tmp = path.join(os.tmpdir(), crypto.randomUUID());
	const result = await fetchContentsAtTarballUri(params, srcInfo.tarballUri, expectedDigest, tmp, undefined, tmp, DEVCONTAINER_FEATURE_FILE_NAME);
	if (!result || !result.metadata) {
		output.write(`No metadata for Feature '${node.userFeatureId}' from '${srcInfo.tarballUri}'`, LogLevel.Trace);
		return;
	}

	const metadata = result.metadata as Feature;
	return metadata;

}

// Creates the directed acyclic graph (DAG) of Features and their dependencies.
export async function buildDependencyGraph(
	params: CommonParams,
	processFeature: (userFeature: DevContainerFeature) => Promise<FeatureSet | undefined>,
	userFeatures: DevContainerFeature[],
	config: { overrideFeatureInstallOrder?: string[] },
	lockfile: Lockfile | undefined): Promise<DependencyGraph | undefined> {

	const { output } = params;

	const rootNodes =
		userFeatures.map<FNode>(f => {
			return {
				type: 'user-provided', // This Feature was provided by the user in the 'features' object of devcontainer.json.
				userFeatureId: f.userFeatureId,
				options: f.options,
				dependsOn: [],
				installsAfter: [],
				roundPriority: 0,
			};
		});

	output.write(`[* user-provided] ${rootNodes.map(n => n.userFeatureId).join(', ')}`, LogLevel.Trace);

	const { worklist } = await _buildDependencyGraph(params, processFeature, rootNodes, [], lockfile);

	output.write(`[* resolved worklist] ${worklist.map(n => n.userFeatureId).join(', ')}`, LogLevel.Trace);

	// Apply the 'overrideFeatureInstallOrder' to the worklist.
	if (config?.overrideFeatureInstallOrder) {
		await applyOverrideFeatureInstallOrder(params, processFeature, worklist, config);
	}

	return { worklist };
}

// Returns the ordered list of FeatureSets to fetch and install, or undefined on error.
export async function computeDependsOnInstallationOrder(
	params: CommonParams,
	processFeature: (userFeature: DevContainerFeature) => Promise<FeatureSet | undefined>,
	userFeatures: DevContainerFeature[],
	config: { overrideFeatureInstallOrder?: string[] },
	lockfile?: Lockfile,
	precomputedGraph?: DependencyGraph): Promise<FeatureSet[] | undefined> {

	const { output } = params;

	// Build dependency graph and resolves all to FeatureSets.
	const graph = precomputedGraph ?? await buildDependencyGraph(params, processFeature, userFeatures, config, lockfile);
	if (!graph) {
		return;
	}

	const { worklist } = graph;

	if (worklist.length === 0) {
		output.write('Zero length or undefined worklist.', LogLevel.Error);
		return;
	}

	output.write(`${JSON.stringify(worklist, null, 2)}`, LogLevel.Trace);

	// Sanity check
	if (worklist.some(node => !node.featureSet)) {
		output.write('Feature dependency worklist contains one or more undefined entries.', LogLevel.Error);
		throw new Error(`ERR: Failure resolving Features.`);
	}

	output.write(`[raw worklist]: ${worklist.map(n => n.userFeatureId).join(', ')}`, LogLevel.Trace);

	// For each node in the worklist, remove all 'soft-dependency' graph edges that are irrelevant
	// i.e. the node is not a 'soft match' for any node in the worklist itself
	for (let i = 0; i < worklist.length; i++) {
		const node = worklist[i];
		// reverse iterate
		for (let j = node.installsAfter.length - 1; j >= 0; j--) {
			const softDep = node.installsAfter[j];
			if (!worklist.some(n => satisfiesSoftDependency(params, n, softDep))) {
				output.write(`Soft-dependency '${softDep.userFeatureId}' is not required.  Removing from installation order...`, LogLevel.Info);
				// Delete that soft-dependency
				node.installsAfter.splice(j, 1);
			}
		}
	}

	output.write(`[worklist-without-dangling-soft-deps]: ${worklist.map(n => n.userFeatureId).join(', ')}`, LogLevel.Trace);
	output.write('Starting round-based Feature install order calculation from worklist...', LogLevel.Trace);

	const installationOrder: FNode[] = [];
	while (worklist.length > 0) {
		const round = worklist.filter(node =>
			// If the node has no hard/soft dependencies, the node can always be installed.
			(node.dependsOn.length === 0 && node.installsAfter.length === 0)
			// OR, every hard-dependency (dependsOn) AND soft-dependency (installsAfter) has been satified in prior rounds
			|| node.dependsOn.every(dep =>
				installationOrder.some(installed => equals(params, installed, dep)))
			&& node.installsAfter.every(dep =>
				installationOrder.some(installed => satisfiesSoftDependency(params, installed, dep))));

		output.write(`\n[round] ${round.map(r => r.userFeatureId).join(', ')}`, LogLevel.Trace);
		if (round.length === 0) {
			output.write('Circular dependency detected!', LogLevel.Error);
			output.write(`Nodes remaining: ${worklist.map(n => n.userFeatureId!).join(', ')}`, LogLevel.Error);
			return;
		}

		output.write(`[round-candidates] ${round.map(r => `${r.userFeatureId} (${r.roundPriority})`).join(', ')}`, LogLevel.Trace);

		// Given the set of eligible nodes to install this round,
		// determine the highest 'roundPriority' present of the nodes in this
		//  round, and exclude nodes from this round with a lower priority.
		// This ensures that both:
		//  -  The pre-computed graph derived from dependOn/installsAfter is honored
		//  -  The overrideFeatureInstallOrder property (more generically, 'roundPriority') is honored
		const maxRoundPriority = Math.max(...round.map(r => r.roundPriority));
		round.splice(0, round.length, ...round.filter(node => node.roundPriority === maxRoundPriority));
		output.write(`[round-after-filter-priority] (maxPriority=${maxRoundPriority}) ${round.map(r => `${r.userFeatureId} (${r.roundPriority})`).join(', ')}`, LogLevel.Trace);

		// Delete all nodes present in this round from the worklist.
		worklist.splice(0, worklist.length, ...worklist.filter(node => !round.some(r => equals(params, r, node))));

		// Sort rounds lexicographically by id.
		round.sort((a, b) => compareTo(params, a, b));
		output.write(`[round-after-comparesTo] ${round.map(r => r.userFeatureId).join(', ')}`, LogLevel.Trace);

		// Commit round
		installationOrder.push(...round);
	}

	return installationOrder.map(n => n.featureSet!);
}

// Pretty-print the calculated graph in the mermaid flowchart format.
// Viewable by copy-pasting the output string to a live editor, i.e: https://mermaid.live/
export function generateMermaidDiagram(params: CommonParams, graph: FNode[]) {
	// Output dependency graph in a mermaid flowchart format
	const roots = graph?.filter(f => f.type === 'user-provided')!;
	let str = 'flowchart\n';
	for (const root of roots) {
		str += `${generateMermaidNode(root)}\n`;
		str += `${generateMermaidSubtree(params, root, graph).reduce((p, c) => p + c + '\n', '')}`;
	}
	return str;
}

function generateMermaidSubtree(params: CommonParams, current: FNode, worklist: FNode[], acc: string[] = []) {
	for (const child of current.dependsOn) {
		// For each corresponding member of the worklist that satisfies this hard-dependency
		for (const w of worklist) {
			if (equals(params, w, child)) {
				acc.push(`${generateMermaidNode(current)} --> ${generateMermaidNode(w)}`);
			}
		}
		generateMermaidSubtree(params, child, worklist, acc);
	}
	for (const softDep of current.installsAfter) {
		// For each corresponding member of the worklist that satisfies this soft-dependency
		for (const w of worklist) {
			if (satisfiesSoftDependency(params, w, softDep)) {
				acc.push(`${generateMermaidNode(current)} -.-> ${generateMermaidNode(w)}`);
			}
		}
		generateMermaidSubtree(params, softDep, worklist, acc);
	}
	return acc;
}

function generateMermaidNode(node: FNode) {
	const hasher = crypto.createHash('sha256', { encoding: 'hex' });
	const hash = hasher.update(JSON.stringify(node)).digest('hex').slice(0, 6);
	const aliases = node.featureIdAliases && node.featureIdAliases.length > 0 ? `<br>aliases: ${node.featureIdAliases.join(', ')}` : '';
	return `${hash}[${node.userFeatureId}<br/><${node.roundPriority}>${aliases}]`;
}
</file>

<file path="src/spec-configuration/containerTemplatesConfiguration.ts">
export interface Template {
	id: string;
	version?: string;
	name?: string;
	description?: string;
	documentationURL?: string;
	licenseURL?: string;
	type?: string;             // Added programatically during packaging
	fileCount?: number;        // Added programatically during packaging
	featureIds?: string[];
	options?: Record<string, TemplateOption>;
	platforms?: string[];
	publisher?: string;
	keywords?: string[];
	optionalPaths?: string[];
	files: string[];           // Added programatically during packaging
}

export type TemplateOption = {
	type: 'boolean';
	default?: boolean;
	description?: string;
} | {
	type: 'string';
	enum?: string[];
	default?: string;
	description?: string;
} | {
	type: 'string';
	default?: string;
	proposals?: string[];
	description?: string;
};
</file>

<file path="src/spec-configuration/containerTemplatesOCI.ts">
import { Log, LogLevel } from '../spec-utils/log';
import * as os from 'os';
import * as path from 'path';
import * as jsonc from 'jsonc-parser';
import { CommonParams, fetchOCIManifestIfExists, getBlob, getRef, ManifestContainer } from './containerCollectionsOCI';
import { isLocalFile, readLocalFile, writeLocalFile } from '../spec-utils/pfs';
import { DevContainerConfig } from './configuration';
import { Template } from './containerTemplatesConfiguration';

export interface TemplateOptions {
	[name: string]: string;
}
export interface TemplateFeatureOption {
	id: string;
	options: Record<string, boolean | string | undefined>;
}

export interface SelectedTemplate {
	id: string;
	options: TemplateOptions;
	features: TemplateFeatureOption[];
	omitPaths: string[];
}

export async function fetchTemplate(params: CommonParams, selectedTemplate: SelectedTemplate, templateDestPath: string, userProvidedTmpDir?: string): Promise<string[] | undefined> {
	const { output } = params;

	let { id: userSelectedId, options: userSelectedOptions, omitPaths } = selectedTemplate;
	const templateRef = getRef(output, userSelectedId);
	if (!templateRef) {
		output.write(`Failed to parse template ref for ${userSelectedId}`, LogLevel.Error);
		return;
	}

	const ociManifest = await fetchOCITemplateManifestIfExistsFromUserIdentifier(params, userSelectedId);
	if (!ociManifest) {
		output.write(`Failed to fetch template manifest for ${userSelectedId}`, LogLevel.Error);
		return;
	}
	const blobDigest = ociManifest?.manifestObj?.layers[0]?.digest;
	if (!blobDigest) {
		output.write(`Failed to fetch template manifest for ${userSelectedId}`, LogLevel.Error);
		return;
	}

	const blobUrl = `https://${templateRef.registry}/v2/${templateRef.path}/blobs/${blobDigest}`;
	output.write(`blob url: ${blobUrl}`, LogLevel.Trace);

	const tmpDir = userProvidedTmpDir || path.join(os.tmpdir(), 'vsch-template-temp', `${Date.now()}`);
	const blobResult = await getBlob(params, blobUrl, tmpDir, templateDestPath, templateRef, blobDigest, [...omitPaths, 'devcontainer-template.json', 'README.md', 'NOTES.md'], 'devcontainer-template.json');

	if (!blobResult) {
		output.write(`Failed to download package for ${templateRef.resource}`, LogLevel.Error);
		return;
	}

	const { files, metadata } = blobResult;

	// Auto-replace default values for values not provided by user.
	if (metadata) {
		const templateMetadata = metadata as Template;
		if (templateMetadata.options) {
			const templateOptions = templateMetadata.options;
			for (const templateOptionKey of Object.keys(templateOptions)) {
				if (userSelectedOptions[templateOptionKey] === undefined) {
					// If the user didn't provide a value for this option, use the default if there is one in the extracted metadata.
					const templateOption = templateOptions[templateOptionKey];

					if (templateOption.type === 'string') {
						const _default = templateOption.default;
						if (_default) {
							output.write(`Using default value for ${templateOptionKey} --> ${_default}`, LogLevel.Trace);
							userSelectedOptions[templateOptionKey] = _default;
						}
					}
					else if (templateOption.type === 'boolean') {
						const _default = templateOption.default;
						if (_default) {
							output.write(`Using default value for ${templateOptionKey} --> ${_default}`, LogLevel.Trace);
							userSelectedOptions[templateOptionKey] = _default.toString();
						}
					}
				}
			}
		}
	}

	// Scan all template files and replace any templated values.
	for (const f of files) {
		output.write(`Scanning file '${f}'`, LogLevel.Trace);
		const filePath = path.join(templateDestPath, f);
		if (await isLocalFile(filePath)) {
			const fileContents = await readLocalFile(filePath);
			const fileContentsReplaced = replaceTemplatedValues(output, fileContents.toString(), userSelectedOptions);
			await writeLocalFile(filePath, Buffer.from(fileContentsReplaced));
		} else {
			output.write(`Could not find templated file '${f}'.`, LogLevel.Error);
		}
	}

	// Get the config.  A template should not have more than one devcontainer.json.
	const config = async (files: string[]) => {
		const p = files.find(f => f.endsWith('devcontainer.json'));
		if (p) {
			const configPath = path.join(templateDestPath, p);
			if (await isLocalFile(configPath)) {
				const configContents = await readLocalFile(configPath);
				return {
					configPath,
					configText: configContents.toString(),
					configObject: jsonc.parse(configContents.toString()) as DevContainerConfig,
				};
			}
		}
		return undefined;
	};

	if (selectedTemplate.features.length !== 0) {
		const configResult = await config(files);
		if (configResult) {
			await addFeatures(output, selectedTemplate.features, configResult);
		} else {
			output.write(`Could not find a devcontainer.json to apply selected Features onto.`, LogLevel.Error);
		}
	}

	return files;
}


async function fetchOCITemplateManifestIfExistsFromUserIdentifier(params: CommonParams, identifier: string, manifestDigest?: string): Promise<ManifestContainer | undefined> {
	const { output } = params;

	const templateRef = getRef(output, identifier);
	if (!templateRef) {
		return undefined;
	}
	return await fetchOCIManifestIfExists(params, templateRef, manifestDigest);
}

function replaceTemplatedValues(output: Log, template: string, options: TemplateOptions) {
	const pattern = /\${templateOption:\s*(\w+?)\s*}/g; // ${templateOption:XXXX}
	return template.replace(pattern, (_, token) => {
		output.write(`Replacing ${token} with ${options[token]}`);
		return options[token] || '';
	});
}

async function addFeatures(output: Log, newFeatures: TemplateFeatureOption[], configResult: { configPath: string; configText: string; configObject: DevContainerConfig }) {
	const { configPath, configText, configObject } = configResult;
	if (newFeatures) {
		let previousText = configText;
		let updatedText = configText;

		// Add the features property if it doesn't exist.
		if (!configObject.features) {
			const edits = jsonc.modify(updatedText, ['features'], {}, { formattingOptions: {} });
			updatedText = jsonc.applyEdits(updatedText, edits);
		}

		for (const newFeature of newFeatures) {
			let edits: jsonc.Edit[] = [];
			const propertyPath = ['features', newFeature.id];

			edits = edits.concat(
				jsonc.modify(updatedText, propertyPath, newFeature.options ?? {}, { formattingOptions: {} }
				));

			updatedText = jsonc.applyEdits(updatedText, edits);
		}

		if (previousText !== updatedText) {
			output.write(`Updating ${configPath} with ${newFeatures.length} Features`, LogLevel.Trace);
			await writeLocalFile(configPath, Buffer.from(updatedText));
		}
	}
}
</file>

<file path="src/spec-configuration/controlManifest.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *--------------------------------------------------------------------------------------------*/

import { promises as fs } from 'fs';
import * as path from 'path';
import * as jsonc from 'jsonc-parser';

import { request } from '../spec-utils/httpRequest';
import * as crypto from 'crypto';
import { Log, LogLevel } from '../spec-utils/log';

export interface DisallowedFeature {
	featureIdPrefix: string;
	documentationURL?: string;
}

export interface FeatureAdvisory {
	featureId: string;
	introducedInVersion: string;
	fixedInVersion: string;
	description: string;
	documentationURL?: string;

}

export interface DevContainerControlManifest {
	disallowedFeatures: DisallowedFeature[];
	featureAdvisories: FeatureAdvisory[];
}

const controlManifestFilename = 'control-manifest.json';

const emptyControlManifest: DevContainerControlManifest = {
	disallowedFeatures: [],
	featureAdvisories: [],
};

const cacheTimeoutMillis = 5 * 60 * 1000; // 5 minutes

export async function getControlManifest(cacheFolder: string, output: Log): Promise<DevContainerControlManifest> {
	const controlManifestPath = path.join(cacheFolder, controlManifestFilename);
	const cacheStat = await fs.stat(controlManifestPath)
		.catch(err => {
			if (err?.code !== 'ENOENT') {
				throw err;
			}
		});
	const cacheBuffer = cacheStat?.isFile() ? await fs.readFile(controlManifestPath)
		.catch(err => {
			if (err?.code !== 'ENOENT') {
				throw err;
			}
		}) : undefined;
	const cachedManifest = cacheBuffer ? sanitizeControlManifest(jsonc.parse(cacheBuffer.toString())) : undefined;
	if (cacheStat && cachedManifest && cacheStat.mtimeMs + cacheTimeoutMillis > Date.now()) {
		return cachedManifest;
	}
	return updateControlManifest(controlManifestPath, cachedManifest, output);
}

async function updateControlManifest(controlManifestPath: string, oldManifest: DevContainerControlManifest | undefined, output: Log): Promise<DevContainerControlManifest> {
	let manifestBuffer: Buffer;
	try {
		manifestBuffer = await fetchControlManifest(output);
	} catch (error) {
		output.write(`Failed to fetch control manifest: ${error.message}`, LogLevel.Error);
		if (oldManifest) {
			// Keep old manifest to not lose existing information and update timestamp to avoid flooding the server.
			const now = new Date();
			await fs.utimes(controlManifestPath, now, now);
			return oldManifest;
		}
		manifestBuffer = Buffer.from(JSON.stringify(emptyControlManifest, undefined, 2));
	}

	const controlManifestTmpPath = `${controlManifestPath}-${crypto.randomUUID()}`;
	await fs.mkdir(path.dirname(controlManifestPath), { recursive: true });
	await fs.writeFile(controlManifestTmpPath, manifestBuffer);
	await fs.rename(controlManifestTmpPath, controlManifestPath);
	return sanitizeControlManifest(jsonc.parse(manifestBuffer.toString()));
}

async function fetchControlManifest(output: Log) {
	return request({
		type: 'GET',
		url: 'https://containers.dev/static/devcontainer-control-manifest.json',
		headers: {
			'user-agent': 'devcontainers-vscode',
			'accept': 'application/json',
		},
	}, output);
}

function sanitizeControlManifest(manifest: any): DevContainerControlManifest {
	if (!manifest || typeof manifest !== 'object') {
		return emptyControlManifest;
	}
	const disallowedFeatures = manifest.disallowedFeatures as DisallowedFeature[] | undefined;
	const featureAdvisories = manifest.featureAdvisories as FeatureAdvisory[] | undefined;
	return {
		disallowedFeatures: Array.isArray(disallowedFeatures) ? disallowedFeatures.filter(f => typeof f.featureIdPrefix === 'string') : [],
		featureAdvisories: Array.isArray(featureAdvisories) ? featureAdvisories.filter(f =>
			typeof f.featureId === 'string' &&
			typeof f.introducedInVersion === 'string' &&
			typeof f.fixedInVersion === 'string' &&
			typeof f.description === 'string'
		) : [],
	};
}
</file>

<file path="src/spec-configuration/editableFiles.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as crypto from 'crypto';
import * as jsonc from 'jsonc-parser';
import { URI } from 'vscode-uri';
import { uriToFsPath, FileHost } from './configurationCommonUtils';
import { readLocalFile, writeLocalFile } from '../spec-utils/pfs';

export type Edit = jsonc.Edit;

export interface Documents {
	readDocument(uri: URI): Promise<string | undefined>;
	applyEdits(uri: URI, edits: Edit[], content: string): Promise<void>;
}

export const fileDocuments: Documents = {

	async readDocument(uri: URI) {
		switch (uri.scheme) {
			case 'file':
				try {
					const buffer = await readLocalFile(uri.fsPath);
					return buffer.toString();
				} catch (err) {
					if (err && err.code === 'ENOENT') {
						return undefined;
					}
					throw err;
				}
			default:
				throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
	},

	async applyEdits(uri: URI, edits: Edit[], content: string) {
		switch (uri.scheme) {
			case 'file':
				const result = jsonc.applyEdits(content, edits);
				await writeLocalFile(uri.fsPath, result);
				break;
			default:
				throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
	}
};

export class CLIHostDocuments implements Documents {

	static scheme = 'vscode-fileHost';

	constructor(private fileHost: FileHost) {
	}

	async readDocument(uri: URI) {
		switch (uri.scheme) {
			case CLIHostDocuments.scheme:
				try {
					return (await this.fileHost.readFile(uriToFsPath(uri, this.fileHost.platform))).toString();
				} catch (err) {
					return undefined;
				}
			default:
				throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
	}

	async applyEdits(uri: URI, edits: Edit[], content: string) {
		switch (uri.scheme) {
			case CLIHostDocuments.scheme:
				const result = jsonc.applyEdits(content, edits);
				await this.fileHost.writeFile(uriToFsPath(uri, this.fileHost.platform), Buffer.from(result));
				break;
			default:
				throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
	}
}

export class RemoteDocuments implements Documents {

	static scheme = 'vscode-remote';

	private static nonce: string | undefined;

	constructor(private shellServer: ShellServer) {
	}

	async readDocument(uri: URI) {
		switch (uri.scheme) {
			case RemoteDocuments.scheme:
				try {
					const { stdout } = await this.shellServer.exec(`cat ${uri.path}`);
					return stdout;
				} catch (err) {
					return undefined;
				}
			default:
				throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
	}

	async applyEdits(uri: URI, edits: Edit[], content: string) {
		switch (uri.scheme) {
			case RemoteDocuments.scheme:
				try {
					if (!RemoteDocuments.nonce) {
						RemoteDocuments.nonce = crypto.randomUUID();
					}
					const result = jsonc.applyEdits(content, edits);
					const eof = `EOF-${RemoteDocuments.nonce}`;
					await this.shellServer.exec(`cat <<'${eof}' >${uri.path}
${result}
${eof}
`);
				} catch (err) {
					console.log(err); // XXX
				}
				break;
			default:
				throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
	}
}

export class AllDocuments implements Documents {

	constructor(private documents: Record<string, Documents>) {
	}

	async readDocument(uri: URI) {
		const documents = this.documents[uri.scheme];
		if (!documents) {
			throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
		return documents.readDocument(uri);
	}

	async applyEdits(uri: URI, edits: Edit[], content: string) {
		const documents = this.documents[uri.scheme];
		if (!documents) {
			throw new Error(`Unsupported scheme: ${uri.toString()}`);
		}
		return documents.applyEdits(uri, edits, content);
	}
}

export function createDocuments(fileHost: FileHost, shellServer?: ShellServer): Documents {
	const documents: Record<string, Documents> = {
		file: fileDocuments,
		[CLIHostDocuments.scheme]: new CLIHostDocuments(fileHost),
	};
	if (shellServer) {
		documents[RemoteDocuments.scheme] = new RemoteDocuments(shellServer);
	}
	return new AllDocuments(documents);
}

export interface ShellServer {
	exec(cmd: string, options?: { logOutput?: boolean; stdin?: Buffer }): Promise<{ stdout: string; stderr: string }>;
}
</file>

<file path="src/spec-configuration/featureAdvisories.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { FeatureSet, FeaturesConfig, OCISourceInformation } from './containerFeaturesConfiguration';
import { FeatureAdvisory, getControlManifest } from './controlManifest';
import { parseVersion, isEarlierVersion } from '../spec-common/commonUtils';
import { Log, LogLevel } from '../spec-utils/log';

export async function fetchFeatureAdvisories(params: { cacheFolder: string; output: Log }, featuresConfig: FeaturesConfig) {

	const features = featuresConfig.featureSets
		.map(f => [f, f.sourceInformation] as const)
		.filter((tup): tup is [FeatureSet, OCISourceInformation] => tup[1].type === 'oci')
		.map(([set, source]) => ({
			id: `${source.featureRef.registry}/${source.featureRef.path}`,
			version: set.features[0].version!,
		}))
		.sort((a, b) => a.id.localeCompare(b.id));
	if (!features.length) {
		return [];
	}

	const controlManifest = await getControlManifest(params.cacheFolder, params.output);
	if (!controlManifest.featureAdvisories.length) {
		return [];
	}

	const featureAdvisories = controlManifest.featureAdvisories.reduce((acc, cur) => {
		const list = acc.get(cur.featureId);
		if (list) {
			list.push(cur);
		} else {
			acc.set(cur.featureId, [cur]);
		}
		return acc;
	}, new Map<string, FeatureAdvisory[]>());

	const parsedVersions = new Map<string, number[] | undefined>();
	function lookupParsedVersion(version: string) {
		if (!parsedVersions.has(version)) {
			parsedVersions.set(version, parseVersion(version));
		}
		return parsedVersions.get(version);
	}
	const featuresWithAdvisories = features.map(feature => {
		const advisories = featureAdvisories.get(feature.id);
		const featureVersion = lookupParsedVersion(feature.version);
		if (!featureVersion) {
			params.output.write(`Unable to parse version for feature ${feature.id}: ${feature.version}`, LogLevel.Warning);
			return {
				feature,
				advisories: [],
			};
		}
		return {
			feature,
			advisories: advisories?.filter(advisory => {
				const introducedInVersion = lookupParsedVersion(advisory.introducedInVersion);
				const fixedInVersion = lookupParsedVersion(advisory.fixedInVersion);
				if (!introducedInVersion || !fixedInVersion) {
					return false;
				}
				return !isEarlierVersion(featureVersion, introducedInVersion) && isEarlierVersion(featureVersion, fixedInVersion);
			}) || [],
		};
	}).filter(f => f.advisories.length);

	return featuresWithAdvisories;
}

export async function logFeatureAdvisories(params: { cacheFolder: string; output: Log }, featuresConfig: FeaturesConfig) {

	const featuresWithAdvisories = await fetchFeatureAdvisories(params, featuresConfig);
	if (!featuresWithAdvisories.length) {
		return;
	}

	params.output.write(`

-----------------------------------------------------------------------------------------------------------
FEATURE ADVISORIES:${featuresWithAdvisories.map(f => `
- ${f.feature.id}:${f.feature.version}:${f.advisories.map(a => `
  - ${a.description} (introduced in ${a.introducedInVersion}, fixed in ${a.fixedInVersion}${a.documentationURL ? `, see ${a.documentationURL}` : ''})`)
  .join('')}`)
.join('')}

It is recommended that you update your configuration to versions of these features with the fixes applied.
-----------------------------------------------------------------------------------------------------------

`, LogLevel.Warning);
}
</file>

<file path="src/spec-configuration/httpOCIRegistry.ts">
import * as os from 'os';
import * as path from 'path';
import * as jsonc from 'jsonc-parser';

import { runCommandNoPty, plainExec } from '../spec-common/commonUtils';
import { requestResolveHeaders } from '../spec-utils/httpRequest';
import { LogLevel } from '../spec-utils/log';
import { isLocalFile, readLocalFile } from '../spec-utils/pfs';
import { CommonParams, OCICollectionRef, OCIRef } from './containerCollectionsOCI';

export type HEADERS = { 'authorization'?: string; 'user-agent'?: string; 'content-type'?: string; 'Accept'?: string; 'content-length'?: string };

interface DockerConfigFile {
	auths: {
		[registry: string]: {
			auth: string;
			identitytoken?: string; // Used by Azure Container Registry
		};
	};
	credHelpers: {
		[registry: string]: string;
	};
	credsStore: string;
}

interface CredentialHelperResult {
	Username: string;
	Secret: string;
}

// WWW-Authenticate Regex
// realm="https://auth.docker.io/token",service="registry.docker.io",scope="repository:samalba/my-app:pull,push"
// realm="https://ghcr.io/token",service="ghcr.io",scope="repository:devcontainers/features:pull"
const realmRegex = /realm="([^"]+)"/;
const serviceRegex = /service="([^"]+)"/;
const scopeRegex = /scope="([^"]+)"/;

// https://docs.docker.com/registry/spec/auth/token/#how-to-authenticate
export async function requestEnsureAuthenticated(params: CommonParams, httpOptions: { type: string; url: string; headers: HEADERS; data?: Buffer }, ociRef: OCIRef | OCICollectionRef) {
	// If needed, Initialize the Authorization header cache.
	if (!params.cachedAuthHeader) {
		params.cachedAuthHeader = {};
	}
	const { output, cachedAuthHeader } = params;

	// -- Update headers
	httpOptions.headers['user-agent'] = 'devcontainer';
	// If the user has a cached auth token, attempt to use that first.
	const maybeCachedAuthHeader = cachedAuthHeader[ociRef.registry];
	if (maybeCachedAuthHeader) {
		output.write(`[httpOci] Applying cachedAuthHeader for registry ${ociRef.registry}...`, LogLevel.Trace);
		httpOptions.headers.authorization = maybeCachedAuthHeader;
	}

	const initialAttemptRes = await requestResolveHeaders(httpOptions, output);

	// For anything except a 401 (invalid/no token) or 403 (insufficient scope)
	// response simply return the original response to the caller.
	if (initialAttemptRes.statusCode !== 401 && initialAttemptRes.statusCode !== 403) {
		output.write(`[httpOci] ${initialAttemptRes.statusCode} (${maybeCachedAuthHeader ? 'Cached' : 'NoAuth'}): ${httpOptions.url}`, LogLevel.Trace);
		return initialAttemptRes;
	}

	// -- 'responseAttempt' status code was 401 or 403 at this point.

	// Attempt to authenticate via WWW-Authenticate Header.
	const wwwAuthenticate = initialAttemptRes.resHeaders['WWW-Authenticate'] || initialAttemptRes.resHeaders['www-authenticate'];
	if (!wwwAuthenticate) {
		output.write(`[httpOci] ERR: Server did not provide instructions to authentiate! (Required: A 'WWW-Authenticate' Header)`, LogLevel.Error);
		return;
	}

	const authenticationMethod = wwwAuthenticate.split(' ')[0];
	switch (authenticationMethod.toLowerCase()) {
		// Basic realm="localhost"
		case 'basic':

			output.write(`[httpOci] Attempting to authenticate via 'Basic' auth.`, LogLevel.Trace);

			const credential = await getCredential(params, ociRef);
			const basicAuthCredential = credential?.base64EncodedCredential;
			if (!basicAuthCredential) {
				output.write(`[httpOci] ERR: No basic auth credentials to send for registry service '${ociRef.registry}'`, LogLevel.Error);
				return;
			}

			httpOptions.headers.authorization = `Basic ${basicAuthCredential}`;
			break;

		// Bearer realm="https://auth.docker.io/token",service="registry.docker.io",scope="repository:samalba/my-app:pull,push"
		case 'bearer':

			output.write(`[httpOci] Attempting to authenticate via 'Bearer' auth.`, LogLevel.Trace);

			const realmGroup = realmRegex.exec(wwwAuthenticate);
			const serviceGroup = serviceRegex.exec(wwwAuthenticate);
			const scopeGroup = scopeRegex.exec(wwwAuthenticate);

			if (!realmGroup || !serviceGroup) {
				output.write(`[httpOci] WWW-Authenticate header is not in expected format. Got:  ${wwwAuthenticate}`, LogLevel.Trace);
				return;
			}

			const wwwAuthenticateData = {
				realm: realmGroup[1],
				service: serviceGroup[1],
				scope: scopeGroup ? scopeGroup[1] : '',
			};

			const bearerToken = await fetchRegistryBearerToken(params, ociRef, wwwAuthenticateData);
			if (!bearerToken) {
				output.write(`[httpOci] ERR: Failed to fetch Bearer token from registry.`, LogLevel.Error);
				return;
			}

			httpOptions.headers.authorization = `Bearer ${bearerToken}`;
			break;

		default:
			output.write(`[httpOci] ERR: Unsupported authentication mode '${authenticationMethod}'`, LogLevel.Error);
			return;
	}

	// Retry the request with the updated authorization header.
	const reattemptRes = await requestResolveHeaders(httpOptions, output);
	output.write(`[httpOci] ${reattemptRes.statusCode} on reattempt after auth: ${httpOptions.url}`, LogLevel.Trace);

	// Cache the auth header if the request did not result in an unauthorized response.
	if (reattemptRes.statusCode !== 401) {
		params.cachedAuthHeader[ociRef.registry] = httpOptions.headers.authorization;
	}

	return reattemptRes;
}

// Attempts to get the Basic auth credentials for the provided registry.
// This credential is used to offer the registry in exchange for a Bearer token.
// These may be:
//   - parsed out of a special DEVCONTAINERS_OCI_AUTH environment variable
//   - Read from a docker credential helper (https://docs.docker.com/engine/reference/commandline/login/#credentials-store)
//   - Read from a docker config file
//   - Crafted from the GITHUB_TOKEN environment variable
//  Returns:
//   - undefined: No credential was found.
//   - object:    A credential was found.
// 					- based64EncodedCredential: The base64 encoded credential, if any.
// 					- refreshToken: The refresh token, if any.
async function getCredential(params: CommonParams, ociRef: OCIRef | OCICollectionRef): Promise<{ base64EncodedCredential: string | undefined; refreshToken: string | undefined } | undefined> {
	const { output, env } = params;
	const { registry } = ociRef;

	if (!!env['DEVCONTAINERS_OCI_AUTH']) {
		// eg: DEVCONTAINERS_OCI_AUTH=service1|user1|token1,service2|user2|token2
		const authContexts = env['DEVCONTAINERS_OCI_AUTH'].split(',');
		const authContext = authContexts.find(a => a.split('|')[0] === registry);

		if (authContext) {
			output.write(`[httpOci] Using match from DEVCONTAINERS_OCI_AUTH for registry '${registry}'`, LogLevel.Trace);
			const split = authContext.split('|');
			const userToken = `${split[1]}:${split[2]}`;
			return {
				base64EncodedCredential: Buffer.from(userToken).toString('base64'),
				refreshToken: undefined,
			};
		}
	}

	// Attempt to use the docker config file or available credential helper(s).
	const credentialFromDockerConfig = await getCredentialFromDockerConfigOrCredentialHelper(params, registry);
	if (credentialFromDockerConfig) {
		return credentialFromDockerConfig;
	}

	const githubToken = env['GITHUB_TOKEN'];
	const githubHost = env['GITHUB_HOST'];
	if (githubHost) {
		output.write(`[httpOci] Environment GITHUB_HOST is set to '${githubHost}'`, LogLevel.Trace);
	}
	if (registry === 'ghcr.io' && githubToken && (!githubHost || githubHost === 'github.com')) {
		output.write('[httpOci] Using environment GITHUB_TOKEN for auth', LogLevel.Trace);
		const userToken = `USERNAME:${env['GITHUB_TOKEN']}`;
		return {
			base64EncodedCredential: Buffer.from(userToken).toString('base64'),
			refreshToken: undefined,
		};
	}

	// Represents anonymous access.
	output.write(`[httpOci] No authentication credentials found for registry '${registry}'. Accessing anonymously.`, LogLevel.Trace);
	return;
}

async function existsInPath(filename: string): Promise<boolean> {
	if (!process.env.PATH) {
		return false;
	}
	const paths = process.env.PATH.split(':');
	for (const path of paths) {
		const fullPath = `${path}/${filename}`;
		if (await isLocalFile(fullPath)) {
			return true;
		}
	}
	return false;
}

async function getCredentialFromDockerConfigOrCredentialHelper(params: CommonParams, registry: string) {
	const { output } = params;

	let configContainsAuth = false;
	try {
		// https://docs.docker.com/engine/reference/commandline/cli/#change-the-docker-directory
		const customDockerConfigPath = process.env.DOCKER_CONFIG;
		if (customDockerConfigPath) {
			output.write(`[httpOci] Environment DOCKER_CONFIG is set to '${customDockerConfigPath}'`, LogLevel.Trace);
		}
		const dockerConfigRootDir = customDockerConfigPath || path.join(os.homedir(), '.docker');
		const dockerConfigFilePath = path.join(dockerConfigRootDir, 'config.json');
		if (await isLocalFile(dockerConfigFilePath)) {
			const dockerConfig: DockerConfigFile = jsonc.parse((await readLocalFile(dockerConfigFilePath)).toString());

			configContainsAuth = Object.keys(dockerConfig.credHelpers || {}).length > 0 || !!dockerConfig.credsStore || Object.keys(dockerConfig.auths || {}).length > 0;
			// https://docs.docker.com/engine/reference/commandline/login/#credential-helpers
			if (dockerConfig.credHelpers && dockerConfig.credHelpers[registry]) {
				const credHelper = dockerConfig.credHelpers[registry];
				output.write(`[httpOci] Found credential helper '${credHelper}' in '${dockerConfigFilePath}' registry '${registry}'`, LogLevel.Trace);
				const auth = await getCredentialFromHelper(params, registry, credHelper);
				if (auth) {
					return auth;
				}
			// https://docs.docker.com/engine/reference/commandline/login/#credentials-store
			} else if (dockerConfig.credsStore) {
				output.write(`[httpOci] Invoking credsStore credential helper '${dockerConfig.credsStore}'`, LogLevel.Trace);
				const auth = await getCredentialFromHelper(params, registry, dockerConfig.credsStore);
				if (auth) {
					return auth;
				}
			}
			if (dockerConfig.auths && dockerConfig.auths[registry]) {
				output.write(`[httpOci] Found auths entry in '${dockerConfigFilePath}' for registry '${registry}'`, LogLevel.Trace);
				const auth = dockerConfig.auths[registry].auth;
				const identityToken = dockerConfig.auths[registry].identitytoken; // Refresh token, seen when running: 'az acr login -n <registry>'

				if (identityToken) {
					return {
						refreshToken: identityToken,
						base64EncodedCredential: undefined,
					};
				}

				// Without the presence of an `identityToken`, assume auth is a base64-encoded 'user:token'.
				return {
					base64EncodedCredential: auth,
					refreshToken: undefined,
				};
			}
		}
	} catch (err) {
		output.write(`[httpOci] Failed to read docker config.json: ${err}`, LogLevel.Trace);
		return;
	}

	if (!configContainsAuth) {
		let defaultCredHelper = '';
		// Try platform-specific default credential helper
		if (process.platform === 'linux') {
			if (await existsInPath('pass')) {
				defaultCredHelper = 'pass';
			} else {
				defaultCredHelper = 'secret';
			}
		} else if (process.platform === 'win32') {
			defaultCredHelper = 'wincred';
		} else if (process.platform === 'darwin') {
			defaultCredHelper = 'osxkeychain';
		}
		if (defaultCredHelper !== '') {
			output.write(`[httpOci] Invoking platform default credential helper '${defaultCredHelper}'`, LogLevel.Trace);
			const auth = await getCredentialFromHelper(params, registry, defaultCredHelper);
			if (auth) {
				output.write('[httpOci] Found auth from platform default credential helper', LogLevel.Trace);
				return auth;
			}
		}
	}

	// No auth found from docker config or credential helper.
	output.write(`[httpOci] No authentication credentials found for registry '${registry}' via docker config or credential helper.`, LogLevel.Trace);
	return;
}

async function getCredentialFromHelper(params: CommonParams, registry: string, credHelperName: string): Promise<{ base64EncodedCredential: string | undefined; refreshToken: string | undefined } | undefined> {
	const { output } = params;

	let helperOutput: Buffer;
	try {
		const { stdout } = await runCommandNoPty({
			exec: plainExec(undefined),
			cmd: 'docker-credential-' + credHelperName,
			args: ['get'],
			stdin: Buffer.from(registry, 'utf-8'),
			output,
		});
		helperOutput = stdout;
	} catch (err) {
		output.write(`[httpOci] Failed to query for '${registry}' credential from 'docker-credential-${credHelperName}': ${err}`, LogLevel.Trace);
		return undefined;
	}
	if (helperOutput.length === 0) {
		return undefined;
	}

	let errors: jsonc.ParseError[] = [];
	const creds: CredentialHelperResult = jsonc.parse(helperOutput.toString(), errors);
	if (errors.length !== 0) {
		output.write(`[httpOci] Credential helper ${credHelperName} returned non-JSON response "${helperOutput.toString()}" for registry '${registry}'`, LogLevel.Warning);
		return undefined;
	}

	if (creds.Username === '<token>') {
		return {
			refreshToken: creds.Secret,
			base64EncodedCredential: undefined,
		};
	}
	const userToken = `${creds.Username}:${creds.Secret}`;
	return {
		base64EncodedCredential: Buffer.from(userToken).toString('base64'),
		refreshToken: undefined,
	};
}

// https://docs.docker.com/registry/spec/auth/token/#requesting-a-token
async function fetchRegistryBearerToken(params: CommonParams, ociRef: OCIRef | OCICollectionRef, wwwAuthenticateData: { realm: string; service: string; scope: string }): Promise<string | undefined> {
	const { output } = params;
	const { realm, service, scope } = wwwAuthenticateData;

	// TODO: Remove this.
	if (realm.includes('mcr.microsoft.com')) {
		return undefined;
	}

	const headers: HEADERS = {
		'user-agent': 'devcontainer'
	};

	// The token server should first attempt to authenticate the client using any authentication credentials provided with the request.
	// From Docker 1.11 the Docker engine supports both Basic Authentication and OAuth2 for getting tokens. 
	// Docker 1.10 and before, the registry client in the Docker Engine only supports Basic Authentication. 
	// If an attempt to authenticate to the token server fails, the token server should return a 401 Unauthorized response 
	// indicating that the provided credentials are invalid.
	// > https://docs.docker.com/registry/spec/auth/token/#requesting-a-token
	const userCredential = await getCredential(params, ociRef);
	const basicAuthCredential = userCredential?.base64EncodedCredential;
	const refreshToken = userCredential?.refreshToken;

	let httpOptions: { type: string; url: string; headers: Record<string, string>; data?: Buffer };

	// There are several different ways registries expect to handle the oauth token exchange. 
	// Depending on the type of credential available, use the most reasonable method.
	if (refreshToken) {
		const form_url_encoded = new URLSearchParams();
		form_url_encoded.append('client_id', 'devcontainer');
		form_url_encoded.append('grant_type', 'refresh_token');
		form_url_encoded.append('service', service);
		form_url_encoded.append('scope', scope);
		form_url_encoded.append('refresh_token', refreshToken);

		headers['content-type'] = 'application/x-www-form-urlencoded';

		const url = realm;
		output.write(`[httpOci] Attempting to fetch bearer token from:  ${url}`, LogLevel.Trace);

		httpOptions = {
			type: 'POST',
			url,
			headers: headers,
			data: Buffer.from(form_url_encoded.toString())
		};
	} else {
		if (basicAuthCredential) {
			headers['authorization'] = `Basic ${basicAuthCredential}`;
		}

		// realm="https://auth.docker.io/token"
		// service="registry.docker.io"
		// scope="repository:samalba/my-app:pull,push"
		// Example:
		// https://auth.docker.io/token?service=registry.docker.io&scope=repository:samalba/my-app:pull,push
		const url = `${realm}?service=${service}&scope=${scope}`;
		output.write(`[httpOci] Attempting to fetch bearer token from:  ${url}`, LogLevel.Trace);

		httpOptions = {
			type: 'GET',
			url: url,
			headers: headers,
		};
	}

	let res = await requestResolveHeaders(httpOptions, output);
	if (res && res.statusCode === 401 || res.statusCode === 403) {
		output.write(`[httpOci] ${res.statusCode}: Credentials for '${service}' may be expired. Attempting request anonymously.`, LogLevel.Info);
		const body = res.resBody?.toString();
		if (body) {
			output.write(`${res.resBody.toString()}.`, LogLevel.Info);
		}

		// Try again without user credentials. If we're here, their creds are likely expired.
		delete headers['authorization'];
		res = await requestResolveHeaders(httpOptions, output);
	}

	if (!res || res.statusCode > 299 || !res.resBody) {
		output.write(`[httpOci] ${res.statusCode}: Failed to fetch bearer token for '${service}': ${res.resBody.toString()}`, LogLevel.Error);
		return;
	}

	let scopeToken: string | undefined;
	try {
		const json = JSON.parse(res.resBody.toString());
		scopeToken = json.token || json.access_token; // ghcr uses 'token', acr uses 'access_token'
	} catch {
		// not JSON
	}
	if (!scopeToken) {
		output.write(`[httpOci] Unexpected bearer token response format for '${service}: ${res.resBody.toString()}'`, LogLevel.Error);
		return;
	}

	return scopeToken;
}
</file>

<file path="src/spec-configuration/lockfile.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import { DevContainerConfig } from './configuration';
import { readLocalFile, writeLocalFile } from '../spec-utils/pfs';
import { ContainerFeatureInternalParams, DirectTarballSourceInformation, FeatureSet, FeaturesConfig, OCISourceInformation } from './containerFeaturesConfiguration';


export interface Lockfile {
	features: Record<string, { version: string; resolved: string; integrity: string }>;
}

export async function generateLockfile(featuresConfig: FeaturesConfig): Promise<Lockfile> {
	return featuresConfig.featureSets
		.map(f => [f, f.sourceInformation] as const)
		.filter((tup): tup is [FeatureSet, OCISourceInformation | DirectTarballSourceInformation] => ['oci', 'direct-tarball'].indexOf(tup[1].type) !== -1)
		.map(([set, source]) => {
			const dependsOn = Object.keys(set.features[0].dependsOn || {});
			return {
				id: source.userFeatureId,
				version: set.features[0].version!,
				resolved: source.type === 'oci' ?
					`${source.featureRef.registry}/${source.featureRef.path}@${set.computedDigest}` :
					source.tarballUri,
				integrity: set.computedDigest!,
				dependsOn: dependsOn.length ? dependsOn : undefined,
			};
		})
		.sort((a, b) => a.id.localeCompare(b.id))
		.reduce((acc, cur) => {
			const feature = { ...cur };
			delete (feature as any).id;
			acc.features[cur.id] = feature;
			return acc;
		}, {
			features: {} as Record<string, { version: string; resolved: string; integrity: string }>,
		});
}

export async function writeLockfile(params: ContainerFeatureInternalParams, config: DevContainerConfig, lockfile: Lockfile, forceInitLockfile?: boolean): Promise<string | undefined> {
	const lockfilePath = getLockfilePath(config);
	const oldLockfileContent = await readLocalFile(lockfilePath)
		.catch(err => {
			if (err?.code !== 'ENOENT') {
				throw err;
			}
		});

	if (!forceInitLockfile && !oldLockfileContent && !params.experimentalLockfile && !params.experimentalFrozenLockfile) {
		return;
	}

	const newLockfileContentString = JSON.stringify(lockfile, null, 2);
	const newLockfileContent = Buffer.from(newLockfileContentString);
	if (params.experimentalFrozenLockfile && !oldLockfileContent) {
		throw new Error('Lockfile does not exist.');
	}
	if (!oldLockfileContent || !newLockfileContent.equals(oldLockfileContent)) {
		if (params.experimentalFrozenLockfile) {
			throw new Error('Lockfile does not match.');
		}
		await writeLocalFile(lockfilePath, newLockfileContent);
	}
	return;
}

export async function readLockfile(config: DevContainerConfig): Promise<{ lockfile?: Lockfile; initLockfile?: boolean }> {
	try {
		const content = await readLocalFile(getLockfilePath(config));
		// If empty file, use as marker to initialize lockfile when build completes.
		if (content.toString().trim() === '') {
			return { initLockfile: true };
		}
		return { lockfile: JSON.parse(content.toString()) as Lockfile };
	} catch (err) {
		if (err?.code === 'ENOENT') {
			return {};
		}
		throw err;
	}
}

export function getLockfilePath(configOrPath: DevContainerConfig | string) {
	const configPath = typeof configOrPath === 'string' ? configOrPath : configOrPath.configFilePath!.fsPath;
	return path.join(path.dirname(configPath), path.basename(configPath).startsWith('.') ? '.devcontainer-lock.json' : 'devcontainer-lock.json');  
}
</file>

<file path="src/spec-configuration/tsconfig.json">
{
	"extends": "../../tsconfig.base.json",
	"references": [
		{
			"path": "../spec-common"
		},
		{
			"path": "../spec-utils"
		}
	]
}
</file>

<file path="src/spec-node/collectionCommonUtils/generateDocsCommandImpl.ts">
import * as fs from 'fs';
import * as path from 'path';
import * as jsonc from 'jsonc-parser';
import { Log, LogLevel } from '../../spec-utils/log';

const FEATURES_README_TEMPLATE = `
# #{Name}

#{Description}

## Example Usage

\`\`\`json
"features": {
    "#{Registry}/#{Namespace}/#{Id}:#{Version}": {}
}
\`\`\`

#{OptionsTable}
#{Customizations}
#{Notes}

---

_Note: This file was auto-generated from the [devcontainer-feature.json](#{RepoUrl}).  Add additional notes to a \`NOTES.md\`._
`;

const TEMPLATE_README_TEMPLATE = `
# #{Name}

#{Description}

#{OptionsTable}

#{Notes}

---

_Note: This file was auto-generated from the [devcontainer-template.json](#{RepoUrl}).  Add additional notes to a \`NOTES.md\`._
`;

export async function generateFeaturesDocumentation(
    basePath: string,
    ociRegistry: string,
    namespace: string,
    gitHubOwner: string,
    gitHubRepo: string,
    output: Log
) {
    await _generateDocumentation(output, basePath, FEATURES_README_TEMPLATE,
        'devcontainer-feature.json', ociRegistry, namespace, gitHubOwner, gitHubRepo);
}

export async function generateTemplatesDocumentation(
    basePath: string,
    gitHubOwner: string,
    gitHubRepo: string,
    output: Log
) {
    await _generateDocumentation(output, basePath, TEMPLATE_README_TEMPLATE,
        'devcontainer-template.json', '', '', gitHubOwner, gitHubRepo);
}

async function _generateDocumentation(
    output: Log,
    basePath: string,
    readmeTemplate: string,
    metadataFile: string,
    ociRegistry: string = '',
    namespace: string = '',
    gitHubOwner: string = '',
    gitHubRepo: string = ''
) {
    const directories = fs.readdirSync(basePath);

    await Promise.all(
        directories.map(async (f: string) => {
            if (!f.startsWith('.')) {
                const readmePath = path.join(basePath, f, 'README.md');
                output.write(`Generating ${readmePath}...`, LogLevel.Info);

                const jsonPath = path.join(basePath, f, metadataFile);

                if (!fs.existsSync(jsonPath)) {
                    output.write(`(!) Warning: ${metadataFile} not found at path '${jsonPath}'. Skipping...`, LogLevel.Warning);
                    return;
                }

                let parsedJson: any | undefined = undefined;
                try {
                    parsedJson = jsonc.parse(fs.readFileSync(jsonPath, 'utf8'));
                } catch (err) {
                    output.write(`Failed to parse ${jsonPath}: ${err}`, LogLevel.Error);
                    return;
                }

                if (!parsedJson || !parsedJson?.id) {
                    output.write(`${metadataFile} for '${f}' does not contain an 'id'`, LogLevel.Error);
                    return;
                }

                // Add version
                let version = 'latest';
                const parsedVersion: string = parsedJson?.version;
                if (parsedVersion) {
                    // example - 1.0.0
                    const splitVersion = parsedVersion.split('.');
                    version = splitVersion[0];
                }

                const generateOptionsMarkdown = () => {
                    const options = parsedJson?.options;
                    if (!options) {
                        return '';
                    }

                    const keys = Object.keys(options);
                    const contents = keys
                        .map(k => {
                            const val = options[k];

                            const desc = val.description || '-';
                            const type = val.type || '-';
                            const def = val.default !== '' ? val.default : '-';

                            return `| ${k} | ${desc} | ${type} | ${def} |`;
                        })
                        .join('\n');

                    return '## Options\n\n' + '| Options Id | Description | Type | Default Value |\n' + '|-----|-----|-----|-----|\n' + contents;
                };

                const generateNotesMarkdown = () => {
                    const notesPath = path.join(basePath, f, 'NOTES.md');
                    return fs.existsSync(notesPath) ? fs.readFileSync(path.join(notesPath), 'utf8') : '';
                };

                let urlToConfig = `${metadataFile}`;
                const basePathTrimmed = basePath.startsWith('./') ? basePath.substring(2) : basePath;
                if (gitHubOwner !== '' && gitHubRepo !== '') {
                    urlToConfig = `https://github.com/${gitHubOwner}/${gitHubRepo}/blob/main/${basePathTrimmed}/${f}/${metadataFile}`;
                }

                let header;
                const isDeprecated = parsedJson?.deprecated;
                const hasLegacyIds = parsedJson?.legacyIds && parsedJson?.legacyIds.length > 0;

                if (isDeprecated || hasLegacyIds) {
                    header = '### **IMPORTANT NOTE**\n';

                    if (isDeprecated) {
                        header += `- **This Feature is deprecated, and will no longer receive any further updates/support.**\n`;
                    }

                    if (hasLegacyIds) {
                        const formattedLegacyIds = parsedJson.legacyIds.map((legacyId: string) => `'${legacyId}'`);
                        header += `- **Ids used to publish this Feature in the past - ${formattedLegacyIds.join(', ')}**\n`;
                    }
                }

                let extensions = '';
                if (parsedJson?.customizations?.vscode?.extensions) {
                    const extensionsList = parsedJson.customizations.vscode.extensions;
                    if (extensionsList && extensionsList.length > 0) {
                        extensions =
                            '\n## Customizations\n\n### VS Code Extensions\n\n' + extensionsList.map((ext: string) => `- \`${ext}\``).join('\n') + '\n';
                    }
                }

                let newReadme = readmeTemplate
                    // Templates & Features
                    .replace('#{Id}', parsedJson.id)
                    .replace('#{Name}', parsedJson.name ? `${parsedJson.name} (${parsedJson.id})` : `${parsedJson.id}`)
                    .replace('#{Description}', parsedJson.description ?? '')
                    .replace('#{OptionsTable}', generateOptionsMarkdown())
                    .replace('#{Notes}', generateNotesMarkdown())
                    .replace('#{RepoUrl}', urlToConfig)
                    // Features Only
                    .replace('#{Registry}', ociRegistry)
                    .replace('#{Namespace}', namespace)
                    .replace('#{Version}', version)
                    .replace('#{Customizations}', extensions);

                if (header) {
                    newReadme = header + newReadme;
                }

                // Remove previous readme
                if (fs.existsSync(readmePath)) {
                    fs.unlinkSync(readmePath);
                }

                // Write new readme
                fs.writeFileSync(readmePath, newReadme);
            }
        })
    );
}
</file>

<file path="src/spec-node/collectionCommonUtils/package.ts">
import { Argv } from 'yargs';
import { CLIHost } from '../../spec-common/cliHost';
import { Log } from '../../spec-utils/log';

const targetPositionalDescription = (collectionType: string) => `
Package ${collectionType}s at provided [target] (default is cwd), where [target] is either:
   1. A path to the src folder of the collection with [1..n] ${collectionType}s.
   2. A path to a single ${collectionType} that contains a devcontainer-${collectionType}.json.
   
   Additionally, a 'devcontainer-collection.json' will be generated in the output directory.
`;

export function PackageOptions(y: Argv, collectionType: string) {
	return y
		.options({
			'output-folder': { type: 'string', alias: 'o', default: './output', description: 'Path to output directory. Will create directories as needed.' },
			'force-clean-output-folder': { type: 'boolean', alias: 'f', default: false, description: 'Automatically delete previous output directory before packaging' },
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
		})
		.positional('target', { type: 'string', default: '.', description: targetPositionalDescription(collectionType) })
		.check(_argv => {
			return true;
		});
}

export interface PackageCommandInput {
	cliHost: CLIHost;
	targetFolder: string;
	outputDir: string;
	output: Log;
	disposables: (() => Promise<unknown> | undefined)[];
	isSingle?: boolean; // Packaging a collection of many features/templates. Should autodetect.
	forceCleanOutputDir?: boolean;
}
</file>

<file path="src/spec-node/collectionCommonUtils/packageCommandImpl.ts">
import tar from 'tar';
import * as jsonc from 'jsonc-parser';
import * as os from 'os';
import * as recursiveDirReader from 'recursive-readdir';
import { PackageCommandInput } from './package';
import { cpDirectoryLocal, isLocalFile, isLocalFolder, mkdirpLocal, readLocalDir, readLocalFile, rmLocal, writeLocalFile } from '../../spec-utils/pfs';
import { Log, LogLevel } from '../../spec-utils/log';
import path from 'path';
import { DevContainerConfig, isDockerFileConfig } from '../../spec-configuration/configuration';
import { Template } from '../../spec-configuration/containerTemplatesConfiguration';
import { Feature } from '../../spec-configuration/containerFeaturesConfiguration';
import { getRef } from '../../spec-configuration/containerCollectionsOCI';

export interface SourceInformation {
	source: string;
	owner?: string;
	repo?: string;
	tag?: string;
	ref?: string;
	sha?: string;
}

export const OCICollectionFileName = 'devcontainer-collection.json';

export async function prepPackageCommand(args: PackageCommandInput, collectionType: string): Promise<PackageCommandInput> {
	const { cliHost, targetFolder, outputDir, forceCleanOutputDir, output, disposables } = args;

	const targetFolderResolved = cliHost.path.resolve(targetFolder);
	if (!(await isLocalFolder(targetFolderResolved))) {
		throw new Error(`Target folder '${targetFolderResolved}' does not exist`);
	}

	const outputDirResolved = cliHost.path.resolve(outputDir);
	if (await isLocalFolder(outputDirResolved)) {
		// Output dir exists. Delete it automatically if '-f' is true
		if (forceCleanOutputDir) {
			await rmLocal(outputDirResolved, { recursive: true, force: true });
		}
		else {
			output.write(`(!) ERR: Output directory '${outputDirResolved}' already exists. Manually delete, or pass '-f' to continue.`, LogLevel.Error);
			process.exit(1);
		}
	}

	// Detect if we're packaging a collection or a single feature/template
	const isValidFolder = await isLocalFolder(cliHost.path.join(targetFolderResolved));
	const isSingle = await isLocalFile(cliHost.path.join(targetFolderResolved, `devcontainer-${collectionType}.json`));

	if (!isValidFolder) {
		throw new Error(`Target folder '${targetFolderResolved}' does not exist`);
	}

	// Generate output folder.
	await mkdirpLocal(outputDirResolved);

	return {
		cliHost,
		targetFolder: targetFolderResolved,
		outputDir: outputDirResolved,
		forceCleanOutputDir,
		output,
		disposables,
		isSingle
	};
}

async function tarDirectory(folder: string, archiveName: string, outputDir: string) {
	return new Promise<void>((resolve) => resolve(tar.create({ file: path.join(outputDir, archiveName), cwd: folder }, ['.'])));
}

export const getArchiveName = (f: string, collectionType: string) => `devcontainer-${collectionType}-${f}.tgz`;

export async function packageSingleFeatureOrTemplate(args: PackageCommandInput, collectionType: string) {
	const { output, targetFolder, outputDir } = args;
	let metadatas = [];

	const devcontainerJsonName = `devcontainer-${collectionType}.json`;
	const tmpSrcDir = path.join(os.tmpdir(), `/templates-src-output-${Date.now()}`);
	await cpDirectoryLocal(targetFolder, tmpSrcDir);

	const jsonPath = path.join(tmpSrcDir, devcontainerJsonName);
	if (!(await isLocalFile(jsonPath))) {
		output.write(`${collectionType} is missing a ${devcontainerJsonName}`, LogLevel.Error);
		return;
	}

	if (collectionType === 'template') {
		if (!(await addsAdditionalTemplateProps(tmpSrcDir, jsonPath, output))) {
			return;
		}
	} else if (collectionType === 'feature') {
		await addsAdditionalFeatureProps(jsonPath, output);
	}

	const metadata = jsonc.parse(await readLocalFile(jsonPath, 'utf-8'));
	if (!metadata.id || !metadata.version || !metadata.name) {
		output.write(`${collectionType} is missing one of the following required properties in its devcontainer-${collectionType}.json: 'id', 'version', 'name'.`, LogLevel.Error);
		return;
	}

	const archiveName = getArchiveName(metadata.id, collectionType);

	await tarDirectory(tmpSrcDir, archiveName, outputDir);
	output.write(`Packaged ${collectionType} '${metadata.id}'`, LogLevel.Info);

	metadatas.push(metadata);
	await rmLocal(tmpSrcDir, { recursive: true, force: true });
	return metadatas;
}

async function addsAdditionalTemplateProps(srcFolder: string, devcontainerTemplateJsonPath: string, output: Log): Promise<boolean> {
	const devcontainerFilePath = await getDevcontainerFilePath(srcFolder);

	if (!devcontainerFilePath) {
		output.write(`Template is missing a devcontainer.json`, LogLevel.Error);
		return false;
	}

	const devcontainerJsonString: Buffer = await readLocalFile(devcontainerFilePath);
	const config: DevContainerConfig = jsonc.parse(devcontainerJsonString.toString());

	let type = undefined;
	const devcontainerTemplateJsonString: Buffer = await readLocalFile(devcontainerTemplateJsonPath);
	let templateData: Template = jsonc.parse(devcontainerTemplateJsonString.toString());

	if ('image' in config) {
		type = 'image';
	} else if (isDockerFileConfig(config)) {
		type = 'dockerfile';
	} else if ('dockerComposeFile' in config) {
		type = 'dockerCompose';
	} else {
		output.write(`Dev container config (${devcontainerFilePath}) is missing one of "image", "dockerFile" or "dockerComposeFile" properties.`, LogLevel.Error);
		return false;
	}

	const fileNames = (await recursiveDirReader.default(srcFolder))?.map((f) => path.relative(srcFolder, f)) ?? [];

	templateData.type = type;
	templateData.files = fileNames;
	templateData.fileCount = fileNames.length;
	templateData.featureIds =
		config.features
			? Object.keys(config.features)
				.map((f) => getRef(output, f)?.resource)
				.filter((f) => f !== undefined) as string[]
			: [];

	// If the Template is omitting a folder and that folder contains just a single file, 
	// replace the entry in the metadata with the full file name,
	// as that provides a better user experience when tools consume the metadata.
	// Eg: If the template is omitting ".github/*" and the Template source contains just a single file
	//     "workflow.yml", replace ".github/*" with ".github/workflow.yml"
	if (templateData.optionalPaths && templateData.optionalPaths?.length) {
		const optionalPaths = templateData.optionalPaths;
		for (const optPath of optionalPaths) {
			// Skip if not a directory
			if (!optPath.endsWith('/*') || optPath.length < 3) {
				continue;
			}
			const dirPath = optPath.slice(0, -2);
			const dirFiles = fileNames.filter((f) => f.startsWith(dirPath));
			output.write(`Given optionalPath starting with '${dirPath}' has ${dirFiles.length} files`, LogLevel.Trace);
			if (dirFiles.length === 1) {
				// If that one item is a file and not a directory
				const f = dirFiles[0];
				output.write(`Checking if optionalPath '${optPath}' with lone contents '${f}' is a file `, LogLevel.Trace);
				const localPath = path.join(srcFolder, f);
				if (await isLocalFile(localPath)) {
					output.write(`Checked path '${localPath}' on disk is a file. Replacing optionalPaths entry '${optPath}' with '${f}'`, LogLevel.Trace);
					templateData.optionalPaths[optionalPaths.indexOf(optPath)] = f;
				}
			}
		}
	}

	await writeLocalFile(devcontainerTemplateJsonPath, JSON.stringify(templateData, null, 4));

	return true;
}

// Programmatically adds 'currentId' if 'legacyIds' exist.
async function addsAdditionalFeatureProps(devcontainerFeatureJsonPath: string, output: Log): Promise<void> {
	const devcontainerFeatureJsonString: Buffer = await readLocalFile(devcontainerFeatureJsonPath);
	let featureData: Feature = jsonc.parse(devcontainerFeatureJsonString.toString());

	if (featureData.legacyIds && featureData.legacyIds.length > 0) {
		featureData.currentId = featureData.id;
		output.write(`Programmatically adding currentId:${featureData.currentId}...`, LogLevel.Trace);

		await writeLocalFile(devcontainerFeatureJsonPath, JSON.stringify(featureData, null, 4));
	}
}

async function getDevcontainerFilePath(srcFolder: string): Promise<string | undefined> {
	const devcontainerFile = path.join(srcFolder, '.devcontainer.json');
	const devcontainerFileWithinDevcontainerFolder = path.join(srcFolder, '.devcontainer/devcontainer.json');

	if (await isLocalFile(devcontainerFile)) {
		return devcontainerFile;
	} else if (await isLocalFile(devcontainerFileWithinDevcontainerFolder)) {
		return devcontainerFileWithinDevcontainerFolder;
	}

	return undefined;
}

// Packages collection of Features or Templates
export async function packageCollection(args: PackageCommandInput, collectionType: string) {
	const { output, targetFolder: srcFolder, outputDir } = args;

	const collectionDirs = await readLocalDir(srcFolder);
	let metadatas = [];

	for await (const c of collectionDirs) {
		output.write(`Processing ${collectionType}: ${c}...`, LogLevel.Info);
		if (!c.startsWith('.')) {
			const folder = path.join(srcFolder, c);

			// Validate minimal folder structure
			const devcontainerJsonName = `devcontainer-${collectionType}.json`;

			if (!(await isLocalFile(path.join(folder, devcontainerJsonName)))) {
				output.write(`(!) WARNING: ${collectionType} '${c}' is missing a ${devcontainerJsonName}. Skipping... `, LogLevel.Warning);
				continue;
			}

			const tmpSrcDir = path.join(os.tmpdir(), `/templates-src-output-${Date.now()}`);
			await cpDirectoryLocal(folder, tmpSrcDir);

			const archiveName = getArchiveName(c, collectionType);

			const jsonPath = path.join(tmpSrcDir, devcontainerJsonName);

			if (collectionType === 'feature') {
				const installShPath = path.join(tmpSrcDir, 'install.sh');
				if (!(await isLocalFile(installShPath))) {
					output.write(`Feature '${c}' is missing an install.sh`, LogLevel.Error);
					return;
				}

				await addsAdditionalFeatureProps(jsonPath, output);
			} else if (collectionType === 'template') {
				if (!(await addsAdditionalTemplateProps(tmpSrcDir, jsonPath, output))) {
					return;
				}
			}

			await tarDirectory(tmpSrcDir, archiveName, outputDir);

			const metadata = jsonc.parse(await readLocalFile(jsonPath, 'utf-8'));
			if (!metadata.id || !metadata.version || !metadata.name) {
				output.write(`${collectionType} '${c}' is missing one of the following required properties in its ${devcontainerJsonName}: 'id', 'version', 'name'.`, LogLevel.Error);
				return;
			}
			metadatas.push(metadata);
			await rmLocal(tmpSrcDir, { recursive: true, force: true });
		}
	}

	if (metadatas.length === 0) {
		return;
	}

	output.write(`Packaged ${metadatas.length} ${collectionType}s!`, LogLevel.Info);
	return metadatas;
}
</file>

<file path="src/spec-node/collectionCommonUtils/publish.ts">
import { Argv } from 'yargs';

const targetPositionalDescription = (collectionType: string) => `
Package and publish ${collectionType}s at provided [target] (default is cwd), where [target] is either:
   1. A path to the src folder of the collection with [1..n] ${collectionType}s.
   2. A path to a single ${collectionType} that contains a devcontainer-${collectionType}.json.
`;

export function publishOptions(y: Argv, collectionType: string) {
    return y
        .options({
            'registry': { type: 'string', alias: 'r', default: 'ghcr.io', description: 'Name of the OCI registry.' },
            'namespace': { type: 'string', alias: 'n', require: true, description: `Unique indentifier for the collection of ${collectionType}s. Example: <owner>/<repo>` },
            'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' }
        })
        .positional('target', { type: 'string', default: '.', description: targetPositionalDescription(collectionType) })
        .check(_argv => {
            return true;
        });
}
</file>

<file path="src/spec-node/collectionCommonUtils/publishCommandImpl.ts">
import path from 'path';
import * as semver from 'semver';
import { Log, LogLevel } from '../../spec-utils/log';
import { CommonParams, getPublishedTags, OCICollectionRef, OCIRef } from '../../spec-configuration/containerCollectionsOCI';
import { OCICollectionFileName } from './packageCommandImpl';
import { pushCollectionMetadata, pushOCIFeatureOrTemplate } from '../../spec-configuration/containerCollectionsOCIPush';

let semanticVersions: string[] = [];
function updateSemanticTagsList(publishedTags: string[], version: string, range: string, publishVersion: string) {
	// Reference: https://github.com/npm/node-semver#ranges-1
	const publishedMaxVersion = semver.maxSatisfying(publishedTags, range);
	if (publishedMaxVersion === null || semver.compare(version, publishedMaxVersion) === 1) {
		semanticVersions.push(publishVersion);
	}
	return;
}

export function getSemanticTags(version: string, tags: string[], output: Log) {
	if (tags.includes(version)) {
		output.write(`(!) WARNING: Version ${version} already exists, skipping ${version}...`, LogLevel.Warning);
		return undefined;
	}

	const parsedVersion = semver.parse(version);
	if (!parsedVersion) {
		output.write(`(!) ERR: Version ${version} is not a valid semantic version, skipping ${version}...`, LogLevel.Error);
		process.exit(1);
	}

	semanticVersions = [];

	// Adds semantic versions depending upon the existings (published) versions
	// eg. 1.2.3 --> [1, 1.2, 1.2.3, latest]
	updateSemanticTagsList(tags, version, `${parsedVersion.major}.x.x`, `${parsedVersion.major}`);
	updateSemanticTagsList(tags, version, `${parsedVersion.major}.${parsedVersion.minor}.x`, `${parsedVersion.major}.${parsedVersion.minor}`);
	semanticVersions.push(version);
	updateSemanticTagsList(tags, version, `x.x.x`, 'latest');

	return semanticVersions;
}

export async function doPublishCommand(params: CommonParams, version: string, ociRef: OCIRef, outputDir: string, collectionType: string, archiveName: string, annotations: { [key: string]: string } = {}) {
	const { output } = params;

	output.write(`Fetching published versions...`, LogLevel.Info);
	const publishedTags = await getPublishedTags(params, ociRef);

	if (!publishedTags) {
		return;
	}

	const semanticTags: string[] | undefined = getSemanticTags(version, publishedTags, output);

	if (!!semanticTags) {
		output.write(`Publishing tags: ${semanticTags.toString()}...`, LogLevel.Info);
		const pathToTgz = path.join(outputDir, archiveName);
		const digest = await pushOCIFeatureOrTemplate(params, ociRef, pathToTgz, semanticTags, collectionType, annotations);
		if (!digest) {
			output.write(`(!) ERR: Failed to publish ${collectionType}: '${ociRef.resource}'`, LogLevel.Error);
			return;
		}
		output.write(`Published ${collectionType}: '${ociRef.id}'`, LogLevel.Info);
		return { publishedTags: semanticTags, digest };
	}

	return {}; // Not an error if no versions were published, likely they just already existed and were skipped.
}

export async function doPublishMetadata(params: CommonParams, collectionRef: OCICollectionRef, outputDir: string, collectionType: string): Promise<string | undefined> {
	const { output } = params;

	// Publishing Feature/Template Collection Metadata
	output.write('Publishing collection metadata...', LogLevel.Info);

	const pathToCollectionFile = path.join(outputDir, OCICollectionFileName);
	const publishedDigest = await pushCollectionMetadata(params, collectionRef, pathToCollectionFile, collectionType);
	if (!publishedDigest) {
		output.write(`(!) ERR: Failed to publish collection metadata: ${OCICollectionFileName}`, LogLevel.Error);
		return;
	}
	output.write('Published collection metadata.', LogLevel.Info);
	return publishedDigest;
}
</file>

<file path="src/spec-node/featuresCLI/generateDocs.ts">
import { Argv } from 'yargs';
import { UnpackArgv } from '../devContainersSpecCLI';
import { generateFeaturesDocumentation } from '../collectionCommonUtils/generateDocsCommandImpl';
import { createLog } from '../devContainers';
import { mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { runAsyncHandler } from '../utils';

// -- 'features generate-docs' command
export function featuresGenerateDocsOptions(y: Argv) {
	return y
		.options({
			'project-folder': { type: 'string', alias: 'p', default: '.', description: 'Path to folder containing \'src\' and \'test\' sub-folders. This is likely the git root of the project.' },
			'registry': { type: 'string', alias: 'r', default: 'ghcr.io', description: 'Name of the OCI registry.' },
			'namespace': { type: 'string', alias: 'n', require: true, description: `Unique indentifier for the collection of features. Example: <owner>/<repo>` },
			'github-owner': { type: 'string', default: '', description: `GitHub owner for docs.` },
			'github-repo': { type: 'string', default: '', description: `GitHub repo for docs.` },
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' }
		})
		.check(_argv => {
			return true;
		});
}

export type FeaturesGenerateDocsArgs = UnpackArgv<ReturnType<typeof featuresGenerateDocsOptions>>;

export function featuresGenerateDocsHandler(args: FeaturesGenerateDocsArgs) {
	runAsyncHandler(featuresGenerateDocs.bind(null, args));
}

export async function featuresGenerateDocs({
	'project-folder': collectionFolder,
	'registry': registry,
	'namespace': namespace,
	'github-owner': gitHubOwner,
	'github-repo': gitHubRepo,
	'log-level': inputLogLevel,
}: FeaturesGenerateDocsArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables);

	await generateFeaturesDocumentation(collectionFolder, registry, namespace, gitHubOwner, gitHubRepo, output);

	// Cleanup
	await dispose();
	process.exit();
}
</file>

<file path="src/spec-node/featuresCLI/info.ts">
import { Argv } from 'yargs';
import { OCIManifest, OCIRef, fetchOCIManifestIfExists, getPublishedTags, getRef } from '../../spec-configuration/containerCollectionsOCI';
import { Log, LogLevel, mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import { UnpackArgv } from '../devContainersSpecCLI';
import { buildDependencyGraph, generateMermaidDiagram } from '../../spec-configuration/containerFeaturesOrder';
import { DevContainerFeature } from '../../spec-configuration/configuration';
import { processFeatureIdentifier } from '../../spec-configuration/containerFeaturesConfiguration';
import { runAsyncHandler } from '../utils';

export function featuresInfoOptions(y: Argv) {
	return y
		.options({
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
			'output-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text', description: 'Output format.' },
		})
		.positional('mode', { choices: ['manifest' as 'manifest', 'tags' as 'tags', 'dependencies' as 'dependencies', 'verbose' as 'verbose'], description: 'Data to query. Select \'verbose\' to return everything.' })
		.positional('feature', { type: 'string', demandOption: true, description: 'Feature Identifier' });
}

export type FeaturesInfoArgs = UnpackArgv<ReturnType<typeof featuresInfoOptions>>;

export function featuresInfoHandler(args: FeaturesInfoArgs) {
	runAsyncHandler(featuresInfo.bind(null, args));
}

interface InfoJsonOutput {
	manifest?: OCIManifest;
	canonicalId?: string;
	publishedTags?: string[];
}

async function featuresInfo({
	'mode': mode,
	'feature': featureId,
	'log-level': inputLogLevel,
	'output-format': outputFormat,
}: FeaturesInfoArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables, true);

	const params = { output, env: process.env, outputFormat };

	const jsonOutput: InfoJsonOutput = {};

	// Parse the provided Feature Id
	const featureRef = getRef(output, featureId);
	if (!featureRef) {
		if (outputFormat === 'json') {
			console.log(JSON.stringify({}), LogLevel.Info);
		} else {
			console.log(`Failed to parse Feature identifier '${featureId}'\n`, LogLevel.Error);
		}
		process.exit(1);
	}

	const manifestContainer = await getManifest(params, featureRef);
	if (!manifestContainer) {
		process.exit(1);
	}

	// -- Display the manifest
	if (mode === 'manifest' || mode === 'verbose') {
		const { manifestObj, canonicalId } = manifestContainer;
		if (outputFormat === 'text') {
			console.log(encloseStringInBox('Manifest'));
			console.log(`${JSON.stringify(manifestObj, undefined, 2)}\n`);
			console.log(encloseStringInBox('Canonical Identifier'));
			console.log(`${canonicalId}\n`);
		} else {
			jsonOutput.manifest = manifestObj;
			jsonOutput.canonicalId = canonicalId;
		}
	}

	// --- Get all published tags for resource
	if (mode === 'tags' || mode === 'verbose') {
		const publishedTags = await getTags(params, featureRef);
		if (outputFormat === 'text') {
			console.log(encloseStringInBox('Published Tags'));
			console.log(`${publishedTags.join('\n   ')}`);
		} else {
			jsonOutput.publishedTags = publishedTags;
		}
	}

	if ((mode === 'dependencies' || mode === 'verbose') && outputFormat === 'text') {
		output.write(`Building dependency graph for '${featureId}'...`, LogLevel.Info);
		if (!featureRef) {
			output.write(`Provide Feature reference '${featureId}' is invalid.`, LogLevel.Error);
			process.exit(1);
		}

		const processFeature = async (_userFeature: DevContainerFeature) => {
			return await processFeatureIdentifier(params, undefined, '', _userFeature);
		};
		const graph = await buildDependencyGraph(params, processFeature, [{ userFeatureId: featureId, options: {} }], { overrideFeatureInstallOrder: undefined }, undefined);
		output.write(JSON.stringify(graph, undefined, 4), LogLevel.Trace);
		if (!graph) {
			output.write(`Could not build dependency graph.`, LogLevel.Error);
			process.exit(1);
		}

		if (outputFormat === 'text') {
			console.log(encloseStringInBox('Dependency Tree (Render with https://mermaid.live/)'));
			const diagram = generateMermaidDiagram(params, graph.worklist);
			console.log(diagram);
		}
	}

	// -- Output and clean up
	if (outputFormat === 'json') {
		console.log(JSON.stringify(jsonOutput, undefined, 4));
	}
	await dispose();
	process.exit();
}


async function getManifest(params: { output: Log; env: NodeJS.ProcessEnv; outputFormat: string }, featureRef: OCIRef) {
	const { outputFormat } = params;

	const manifestContainer = await fetchOCIManifestIfExists(params, featureRef, undefined);
	if (!manifestContainer) {
		if (outputFormat === 'json') {
			console.log(JSON.stringify({}));
		} else {
			console.log('No manifest found! If this manifest requires authentication, please login.');
		}
		return process.exit(1);
	}
	return manifestContainer;
}

async function getTags(params: { output: Log; env: NodeJS.ProcessEnv; outputFormat: string }, featureRef: OCIRef) {
	const { outputFormat } = params;
	const publishedTags = await getPublishedTags(params, featureRef);
	if (!publishedTags || publishedTags.length === 0) {
		if (outputFormat === 'json') {
			console.log(JSON.stringify({}));
		} else {
			console.log(`No published versions found for feature '${featureRef.resource}'\n`);
		}
		process.exit(1);
	}
	return publishedTags;
}

function encloseStringInBox(str: string, indent: number = 0) {
	const lines = str.split('\n');
	lines[0] = `\u001b[1m${lines[0]}\u001b[22m`; // Bold
	const maxWidth = Math.max(...lines.map(l => l.length - (l.includes('\u001b[1m') ? 9 : 0)));
	const box = [
		'┌' + '─'.repeat(maxWidth) + '┐',
		...lines.map(l => '│' + l.padEnd(maxWidth + (lines.length > 1 && l.includes('\u001b[1m') ? 9 : 0)) + '│'),
		'└' + '─'.repeat(maxWidth) + '┘',
	];
	return box.map(t => `${' '.repeat(indent)}${t}`).join('\n');
}
</file>

<file path="src/spec-node/featuresCLI/package.ts">
import { Argv } from 'yargs';
import { getCLIHost } from '../../spec-common/cliHost';
import { loadNativeModule } from '../../spec-common/commonUtils';
import { mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import { UnpackArgv } from '../devContainersSpecCLI';
import { doFeaturesPackageCommand } from './packageCommandImpl';
import { PackageCommandInput, PackageOptions } from '../collectionCommonUtils/package';
import { runAsyncHandler } from '../utils';

export function featuresPackageOptions(y: Argv) {
	return PackageOptions(y, 'feature');
}

export type FeaturesPackageArgs = UnpackArgv<ReturnType<typeof featuresPackageOptions>>;
export function featuresPackageHandler(args: FeaturesPackageArgs) {
	runAsyncHandler(featuresPackage.bind(null, args));
}

async function featuresPackage({
	'target': targetFolder,
	'log-level': inputLogLevel,
	'output-folder': outputDir,
	'force-clean-output-folder': forceCleanOutputDir,
}: FeaturesPackageArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const cwd = process.cwd();
	const cliHost = await getCLIHost(cwd, loadNativeModule, true);
	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables);


	const args: PackageCommandInput = {
		cliHost,
		targetFolder,
		outputDir,
		output,
		disposables,
		forceCleanOutputDir: forceCleanOutputDir
	};

	const exitCode = !!(await doFeaturesPackageCommand(args)) ? 0 : 1;

	await dispose();
	process.exit(exitCode);
}
</file>

<file path="src/spec-node/featuresCLI/packageCommandImpl.ts">
import path from 'path';
import { Feature } from '../../spec-configuration/containerFeaturesConfiguration';
import { LogLevel } from '../../spec-utils/log';
import { writeLocalFile } from '../../spec-utils/pfs';
import { PackageCommandInput } from '../collectionCommonUtils/package';
import { SourceInformation, prepPackageCommand, packageCollection, packageSingleFeatureOrTemplate, OCICollectionFileName } from '../collectionCommonUtils/packageCommandImpl';

interface DevContainerCollectionMetadata {
	sourceInformation: SourceInformation;
	features: Feature[];
}

const collectionType = 'feature';

export async function doFeaturesPackageCommand(args: PackageCommandInput): Promise<DevContainerCollectionMetadata | undefined> {
	args = await prepPackageCommand(args, collectionType);
	const { output, outputDir } = args;
	const isSingleFeature = args.isSingle;

	// For each feature, package each feature and write to 'outputDir/{f}.tgz'
	// Returns an array of feature metadata from each processed feature

	let metadataOutput: Feature[] | undefined = [];
	if (isSingleFeature) {
		// Package individual features
		output.write('Packaging single feature...', LogLevel.Info);
		metadataOutput = await packageSingleFeature(args);
	} else {
		output.write('Packaging feature collection...', LogLevel.Info);
		metadataOutput = await packageFeatureCollection(args);
	}

	if (!metadataOutput) {
		output.write('Failed to package features', LogLevel.Error);
		return undefined;
	}

	const collection: DevContainerCollectionMetadata = {
		sourceInformation: {
			source: 'devcontainer-cli',
		},
		features: metadataOutput,
	};

	// Write the metadata to a file
	const metadataOutputPath = path.join(outputDir, OCICollectionFileName);
	await writeLocalFile(metadataOutputPath, JSON.stringify(collection, null, 4));
	return collection;
}

export async function packageSingleFeature(args: PackageCommandInput): Promise<Feature[] | undefined> {
	return await packageSingleFeatureOrTemplate(args, collectionType);
}

export async function packageFeatureCollection(args: PackageCommandInput): Promise<Feature[] | undefined> {
	return await packageCollection(args, collectionType);
}
</file>

<file path="src/spec-node/featuresCLI/publish.ts">
import path from 'path';
import * as os from 'os';
import { Argv } from 'yargs';
import { LogLevel, mapLogLevel } from '../../spec-utils/log';
import { rmLocal } from '../../spec-utils/pfs';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import { UnpackArgv } from '../devContainersSpecCLI';
import { doFeaturesPackageCommand } from './packageCommandImpl';
import { getCLIHost } from '../../spec-common/cliHost';
import { loadNativeModule } from '../../spec-common/commonUtils';
import { PackageCommandInput } from '../collectionCommonUtils/package';
import { getArchiveName, OCICollectionFileName } from '../collectionCommonUtils/packageCommandImpl';
import { publishOptions } from '../collectionCommonUtils/publish';
import { getCollectionRef, getRef, OCICollectionRef } from '../../spec-configuration/containerCollectionsOCI';
import { doPublishCommand, doPublishMetadata } from '../collectionCommonUtils/publishCommandImpl';
import { runAsyncHandler } from '../utils';

const collectionType = 'feature';
export function featuresPublishOptions(y: Argv) {
    return publishOptions(y, 'feature');
}

export type FeaturesPublishArgs = UnpackArgv<ReturnType<typeof featuresPublishOptions>>;

export function featuresPublishHandler(args: FeaturesPublishArgs) {
	runAsyncHandler(featuresPublish.bind(null, args));
}

async function featuresPublish({
    'target': targetFolder,
    'log-level': inputLogLevel,
    'registry': registry,
    'namespace': namespace
}: FeaturesPublishArgs) {
    const disposables: (() => Promise<unknown> | undefined)[] = [];
    const dispose = async () => {
        await Promise.all(disposables.map(d => d()));
    };

    const pkg = getPackageConfig();

    const cwd = process.cwd();
    const cliHost = await getCLIHost(cwd, loadNativeModule, true);
    const output = createLog({
        logLevel: mapLogLevel(inputLogLevel),
        logFormat: 'text',
        log: (str) => process.stderr.write(str),
        terminalDimensions: undefined,
    }, pkg, new Date(), disposables);

    const params = { output, env: process.env };

    // Package features
    const outputDir = path.join(os.tmpdir(), `/features-output-${Date.now()}`);

    const packageArgs: PackageCommandInput = {
        cliHost,
        targetFolder,
        outputDir,
        output,
        disposables,
        forceCleanOutputDir: true,
    };

    const metadata = await doFeaturesPackageCommand(packageArgs);

    if (!metadata) {
        output.write(`(!) ERR: Failed to fetch ${OCICollectionFileName}`, LogLevel.Error);
        process.exit(1);
    }

    let result = {};

    for (const f of metadata.features) {
        output.write(`Processing feature: ${f.id}...`, LogLevel.Info);

        if (!f.version) {
            output.write(`(!) WARNING: Version does not exist, skipping ${f.id}...`, LogLevel.Warning);
            continue;
        }

        const resource = `${registry}/${namespace}/${f.id}`;
        const featureRef = getRef(output, resource);
        if (!featureRef) {
            output.write(`(!) Could not parse provided Feature identifier: '${resource}'`, LogLevel.Error);
            process.exit(1);
        }

        const archiveName = getArchiveName(f.id, collectionType);

        // Properties here are available on the manifest without needing to download the full Feature archive.
        const featureAnnotations = {
            'dev.containers.metadata': JSON.stringify(f),
        };
        output.write(`Feature Annotations: ${JSON.stringify(featureAnnotations)}`, LogLevel.Debug);

        const publishResult = await doPublishCommand(params, f.version, featureRef, outputDir, collectionType, archiveName, featureAnnotations);
        if (!publishResult) {
            output.write(`(!) ERR: Failed to publish '${resource}'`, LogLevel.Error);
            process.exit(1);
        }

        const isPublished = (publishResult?.digest && publishResult?.publishedTags.length > 0);
        let thisResult = isPublished ? {
            ...publishResult,
            version: f.version,
        } : {};

        if (isPublished && f.legacyIds) {
            output.write(`Processing legacyIds for '${f.id}'...`, LogLevel.Info);

            let publishedLegacyIds: string[] = [];
            for await (const legacyId of f.legacyIds) {
                output.write(`Processing legacyId: '${legacyId}'...`, LogLevel.Info);
                let legacyResource = `${registry}/${namespace}/${legacyId}`;
                const legacyFeatureRef = getRef(output, legacyResource);

                if (!legacyFeatureRef) {
                    output.write(`(!) Could not parse provided Feature identifier: '${legacyResource}'`, LogLevel.Error);
                    process.exit(1);
                }

                const publishResult = await doPublishCommand(params, f.version, legacyFeatureRef, outputDir, collectionType, archiveName, featureAnnotations);
                if (!publishResult) {
                    output.write(`(!) ERR: Failed to publish '${legacyResource}'`, LogLevel.Error);
                    process.exit(1);
                }

                if (publishResult?.digest && publishResult?.publishedTags.length > 0) {
                    publishedLegacyIds.push(legacyId);
                }
            }

            if (publishedLegacyIds.length > 0) {
                thisResult = {
                    ...thisResult,
                    publishedLegacyIds,
                };
            }
        }

        result = {
            ...result,
            [f.id]: thisResult,
        };
    }

    const featureCollectionRef: OCICollectionRef | undefined = getCollectionRef(output, registry, namespace);
    if (!featureCollectionRef) {
        output.write(`(!) Could not parse provided collection identifier with registry '${registry}' and namespace '${namespace}'`, LogLevel.Error);
        process.exit(1);
    }

    if (! await doPublishMetadata(params, featureCollectionRef, outputDir, collectionType)) {
        output.write(`(!) ERR: Failed to publish '${featureCollectionRef.registry}/${featureCollectionRef.path}'`, LogLevel.Error);
        process.exit(1);
    }

    console.log(JSON.stringify(result));

    // Cleanup
    await rmLocal(outputDir, { recursive: true, force: true });
    await dispose();
    process.exit();
}
</file>

<file path="src/spec-node/featuresCLI/resolveDependencies.ts">
import * as path from 'path';
import { Argv } from 'yargs';
import { LogLevel, mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import { UnpackArgv } from '../devContainersSpecCLI';
import { isLocalFile } from '../../spec-utils/pfs';
import { DevContainerFeature } from '../../spec-configuration/configuration';
import { buildDependencyGraph, computeDependsOnInstallationOrder, generateMermaidDiagram } from '../../spec-configuration/containerFeaturesOrder';
import { OCISourceInformation, processFeatureIdentifier, userFeaturesToArray } from '../../spec-configuration/containerFeaturesConfiguration';
import { readLockfile } from '../../spec-configuration/lockfile';
import { runAsyncHandler } from '../utils';
import { loadNativeModule } from '../../spec-common/commonUtils';
import { getCLIHost } from '../../spec-common/cliHost';
import { ContainerError } from '../../spec-common/errors';
import { uriToFsPath } from '../../spec-configuration/configurationCommonUtils';
import { workspaceFromPath } from '../../spec-utils/workspaces';
import { readDevContainerConfigFile } from '../configContainer';
import { URI } from 'vscode-uri';


interface JsonOutput {
	installOrder?: {
		id: string;
		options: string | boolean | Record<string, string | boolean | undefined>;
	}[];
}

export function featuresResolveDependenciesOptions(y: Argv) {
	return y
		.options({
			'log-level': { choices: ['error' as 'error', 'info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'error' as 'error', description: 'Log level.' },
			'workspace-folder': { type: 'string', description: 'Workspace folder to use for the configuration.', demandOption: true },
		});
}

export type featuresResolveDependenciesArgs = UnpackArgv<ReturnType<typeof featuresResolveDependenciesOptions>>;

export function featuresResolveDependenciesHandler(args: featuresResolveDependenciesArgs) {
	runAsyncHandler(featuresResolveDependencies.bind(null, args));
}

async function featuresResolveDependencies({
	'workspace-folder': workspaceFolder,
	'log-level': inputLogLevel,
}: featuresResolveDependenciesArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables, true);

	// const params = { output, env: process.env, outputFormat };

	let jsonOutput: JsonOutput = {};

	// Detect path to dev container config
	let configPath = path.join(workspaceFolder, '.devcontainer.json');
	if (!(await isLocalFile(configPath))) {
		configPath = path.join(workspaceFolder, '.devcontainer', 'devcontainer.json');
	}

	const params = {
		output,
		env: process.env,
	};

	const cwd = workspaceFolder || process.cwd();
	const cliHost = await getCLIHost(cwd, loadNativeModule, true);
	const workspace = workspaceFromPath(cliHost.path, workspaceFolder);
	const configFile: URI = URI.file(path.resolve(process.cwd(), configPath));
	const configs = await readDevContainerConfigFile(cliHost, workspace, configFile, false, output, undefined, undefined);	

	if (configFile && !configs) {
		throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile, cliHost.platform)}) not found.` });
	}
	const configWithRaw = configs!.config;
	const { config } = configWithRaw;

	const userFeaturesConfig = userFeaturesToArray(config);
	if (!userFeaturesConfig) {
		output.write(`Could not parse features object in configuration '${configPath}'`, LogLevel.Error);
		process.exit(1);
	}

	const { lockfile } = await readLockfile(config);
	const processFeature = async (_userFeature: DevContainerFeature) => {
		return await processFeatureIdentifier(params, configPath, workspaceFolder, _userFeature, lockfile);
	};

	const graph = await buildDependencyGraph(params, processFeature, userFeaturesConfig, config, lockfile);
	const worklist = graph?.worklist!;
	console.log(generateMermaidDiagram(params, worklist));

	const installOrder = await computeDependsOnInstallationOrder(params, processFeature, userFeaturesConfig, config, lockfile, graph);

	if (!installOrder) {
		// Bold
		output.write(`\u001b[1mNo viable installation order!\u001b[22m`, LogLevel.Error);
		process.exit(1);
	}

	// Output the install order, if one exists.
	// JSON
	jsonOutput = {
		...jsonOutput,
		installOrder: installOrder.map(f => {
			const sourceInfo = f?.sourceInformation;
			switch (sourceInfo.type) {
				case 'oci':
					const featureRef = (sourceInfo as OCISourceInformation).featureRef;
					return {
						id: `${featureRef.resource}@${sourceInfo.manifestDigest}`,
						options: f?.features[0].value
					};
				default:
					return {
						id: f.sourceInformation.userFeatureId,
						options: f?.features[0].value
					};
			}
		})
	};


	console.log(JSON.stringify(jsonOutput, undefined, 2));
	await dispose();
	process.exit();
}
</file>

<file path="src/spec-node/featuresCLI/test.ts">
import { Argv } from 'yargs';
import { CLIHost, getCLIHost } from '../../spec-common/cliHost';
import { loadNativeModule } from '../../spec-common/commonUtils';
import { LogLevel, mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig, PackageConfiguration } from '../../spec-utils/product';
import { UnpackArgv } from '../devContainersSpecCLI';
import { doFeaturesTestCommand } from './testCommandImpl';
import { runAsyncHandler } from '../utils';

// -- 'features test' command
export function featuresTestOptions(y: Argv) {
	return y
		.options({
			'project-folder': { type: 'string', alias: 'p', default: '.', description: 'Path to folder containing \'src\' and \'test\' sub-folders. This is likely the git root of the project.' },
			'features': { array: true, alias: 'f', describe: 'Feature(s) to test as space-separated parameters. Omit to run all tests.  Cannot be combined with \'--global-scenarios-only\'.' },
			'filter': { type: 'string', describe: 'Filter current tests to only run scenarios containing this string.  Cannot be combined with \'--skip-scenarios\'.' },
			'global-scenarios-only': { type: 'boolean', default: false, description: 'Run only scenario tests under \'tests/_global\' .  Cannot be combined with \'-f\'.' },
			'skip-scenarios': { type: 'boolean', default: false, description: 'Skip all \'scenario\' style tests.  Cannot be combined with \'--global--scenarios-only\'.' },
			'skip-autogenerated': { type: 'boolean', default: false, description: 'Skip all \'autogenerated\' style tests (test.sh).' },
			'skip-duplicated': { type: 'boolean', default: false, description: 'Skip all \'duplicate\' style tests (duplicate.sh).' },
			'permit-randomization': { type: 'boolean', default: false, description: 'Allow an element of randomness in test cases.' },
			'base-image': { type: 'string', alias: 'i', default: 'ubuntu:focal', description: 'Base Image. Not used for scenarios.' },  // TODO: Optionally replace 'scenario' configs with this value?
			'remote-user': { type: 'string', alias: 'u', describe: 'Remote user.  Not used for scenarios.', },  // TODO: Optionally replace 'scenario' configs with this value?
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
			'preserve-test-containers': { type: 'boolean', default: false, description: 'Do not remove test containers after running tests.' },
			'quiet': { type: 'boolean', alias: 'q', default: false, description: 'Quiets output' },
		})
		// DEPRECATED: Positional arguments don't play nice with the variadic/array --features option.
		// Pass target directory with '--project-folder' instead.
		// This will still continue to work, but any value provided by --project-folder will be preferred.
		// Omitting both will default to the current working directory.
		.deprecateOption('target', 'Use --project-folder instead')
		.positional('target', { type: 'string', default: '.', description: 'Path to folder containing \'src\' and \'test\' sub-folders.', })
		// Validation
		.check(argv => {
			if (argv['global-scenarios-only'] && argv['features']) {
				throw new Error('Cannot combine --global-scenarios-only and --features');
			}
			if (argv['skip-scenarios'] && argv['global-scenarios-only']) {
				throw new Error('Cannot combine --skip-scenarios and --global-scenarios-only');
			}
			if (argv['filter-scenarios'] && argv['skip-scenarios']) {
				throw new Error('Cannot combine --filter-scenarios and --skip-scenarios');
			}
			return true;

		});
}

export type FeaturesTestArgs = UnpackArgv<ReturnType<typeof featuresTestOptions>>;
export interface FeaturesTestCommandInput {
	cliHost: CLIHost;
	pkg: PackageConfiguration;
	collectionFolder: string;
	features?: string[];
	filter: string | undefined;
	globalScenariosOnly: boolean;
	skipScenarios: boolean;
	skipAutogenerated: boolean;
	skipDuplicateTest: boolean;
	permitRandomization: boolean;
	baseImage: string;
	remoteUser: string | undefined;
	logLevel: LogLevel;
	preserveTestContainers: boolean;
	quiet: boolean;
	disposables: (() => Promise<unknown> | undefined)[];
}

export function featuresTestHandler(args: FeaturesTestArgs) {
	runAsyncHandler(featuresTest.bind(null, args));
}

async function featuresTest({
	'base-image': baseImage,
	'target': collectionFolder_deprecated,
	'project-folder': collectionFolder,
	features,
	filter,
	'global-scenarios-only': globalScenariosOnly,
	'skip-scenarios': skipScenarios,
	'skip-autogenerated': skipAutogenerated,
	'skip-duplicated': skipDuplicateTest,
	'permit-randomization': permitRandomization,
	'remote-user': remoteUser,
	'log-level': inputLogLevel,
	'preserve-test-containers': preserveTestContainers,
	quiet,
}: FeaturesTestArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const cwd = process.cwd();
	const cliHost = await getCLIHost(cwd, loadNativeModule, true);
	const pkg = getPackageConfig();

	const logLevel = mapLogLevel(inputLogLevel);

	// Prefer the new --project-folder option over the deprecated positional argument.
	const targetProject = collectionFolder !== '.' ? collectionFolder : collectionFolder_deprecated;

	const args: FeaturesTestCommandInput = {
		baseImage,
		cliHost,
		logLevel,
		quiet,
		pkg,
		collectionFolder: cliHost.path.resolve(targetProject),
		features: features ? (Array.isArray(features) ? features as string[] : [features]) : undefined,
		filter,
		globalScenariosOnly,
		skipScenarios,
		skipAutogenerated,
		skipDuplicateTest,
		permitRandomization,
		remoteUser,
		preserveTestContainers,
		disposables
	};

	const exitCode = await doFeaturesTestCommand(args);

	await dispose();
	process.exit(exitCode);
}
</file>

<file path="src/spec-node/featuresCLI/testCommandImpl.ts">
import path from 'path';
import chalk from 'chalk';
import { tmpdir } from 'os';
import * as jsonc from 'jsonc-parser';
import { CLIHost } from '../../spec-common/cliHost';
import { launch, ProvisionOptions, createDockerParams } from '../devContainers';
import { doExec } from '../devContainersSpecCLI';
import { LaunchResult, staticExecParams, staticProvisionParams, testLibraryScript } from './utils';
import { DockerResolverParameters } from '../utils';
import { DevContainerConfig } from '../../spec-configuration/configuration';
import { FeaturesTestCommandInput } from './test';
import { cpDirectoryLocal, rmLocal } from '../../spec-utils/pfs';
import { nullLog } from '../../spec-utils/log';
import { runCommandNoPty } from '../../spec-common/commonUtils';
import { Feature } from '../../spec-configuration/containerFeaturesConfiguration';
import { getSafeId } from '../containerFeatures';

const TEST_LIBRARY_SCRIPT_NAME = 'dev-container-features-test-lib';

function fail(msg: string) {
	log(msg, { prefix: '[-]', error: true });
	process.exit(1);
}

type Scenarios = { [key: string]: DevContainerConfig };
type TestResult = { testName: string; result: boolean };

function log(msg: string, options?: { omitPrefix?: boolean; prefix?: string; info?: boolean; error?: boolean }) {

	const prefix = options?.prefix || '> ';
	const output = `${options?.omitPrefix ? '' : `${prefix} `}${msg}\n`;

	if (options?.error) {
		process.stdout.write(chalk.red(output));
	} else if (options?.info) {
		process.stdout.write(chalk.bold.blue(output));
	} else {
		process.stdout.write(chalk.blue(output));
	}
}

export async function doFeaturesTestCommand(args: FeaturesTestCommandInput): Promise<number> {
	const { pkg, globalScenariosOnly, features, collectionFolder, cliHost } = args;

	process.stdout.write(`
┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐
|    Dev Container Features   |   
│           v${pkg.version}           │
└ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘\n\n`);


	const srcDir = `${collectionFolder}/src`;
	const testsDir = `${collectionFolder}/test`;

	if (! await cliHost.isFolder(srcDir) || ! await cliHost.isFolder(testsDir)) {
		fail(`Folder '${collectionFolder}' does not contain the required 'src' and 'test' folders.`);
	}

	let testResults: TestResult[] = [];
	if (globalScenariosOnly) {
		await runGlobalFeatureTests(args, testResults);
	} else {
		await runFeatureTests(args, testResults);

		// If any features were explicitly set to run,
		// we know we don't want to run the global tests.
		if (!features) {
			await runGlobalFeatureTests(args, testResults);
		}
	}

	// Clean up test containers
	if (!args.preserveTestContainers) {
		await cleanup(cliHost);
	}

	// Pretty-print test results and exit with 0 or 1 exit code.
	return analyzeTestResults(testResults);
}

async function cleanup(cliHost: CLIHost) {
	// Delete any containers that have the 'devcontainer.is_test_run=true' label set.
	const filterForContainerIdArgs = ['ps', '-a', '--filter', 'label=devcontainer.is_test_run=true', '--format', '{{.ID}}'];
	const { stdout } = (await runCommandNoPty({ cmd: 'docker', args: filterForContainerIdArgs, output: nullLog, exec: cliHost.exec }));
	const containerIds = stdout.toString().split('\n').filter(id => id !== '').map(s => s.trim());
	log(`Cleaning up ${containerIds.length} test containers...`, { prefix: '🧹', info: true });
	for (const containerId of containerIds) {
		log(`Removing container ${containerId}...`, { prefix: '🧹', info: true });
		await cliHost.exec({ cmd: 'docker', args: ['rm', '-f', containerId], output: nullLog });
	}
}

async function runGlobalFeatureTests(args: FeaturesTestCommandInput, testResults: TestResult[] = []): Promise<TestResult[]> {
	const { collectionFolder } = args;

	const globalTestsFolder = `${collectionFolder}/test/_global`;

	log(`Scenarios:         ${globalTestsFolder}\n`, { prefix: '\n📊', info: true });
	testResults = await doScenario(globalTestsFolder, '_global', args, testResults);
	if (!testResults) {
		fail(`Failed to run scenarios in ${globalTestsFolder}`);
		return []; // We never reach here, we exit via fail().
	}

	return testResults;
}

// Executes the same Feature twice with randomized options to ensure Feature can be installed >1.
async function runDuplicateTest(args: FeaturesTestCommandInput, feature: string, testResults: TestResult[] = []): Promise<TestResult[]> {
	const { collectionFolder, cliHost } = args;
	const scenarioName = `${feature} executed twice with randomized options`;

	const featureTestFolder = path.join(collectionFolder, 'test', feature);
	const testFileName = 'duplicate.sh';
	const testFilePath = path.join(featureTestFolder, testFileName);
	if (!(await cliHost.isFile(testFilePath))) {
		log(`Skipping duplicate test for ${feature} because '${testFilePath}' does not exist.`, { prefix: '⚠️', });
		return testResults;
	}

	//Read Feature's metadata
	const featureMetadata = await readFeatureMetadata(args, feature);
	const options = featureMetadata.options || {};

	// For each possible option, generate a random value for each Feature
	const nonDefaultOptions: { [key: string]: string | boolean } = {};
	Object.entries(options).forEach(([key, value]) => {
		if (value.type === 'boolean') {
			nonDefaultOptions[key] = !value.default;
		}
		if (value.type === 'string' && 'proposals' in value && value?.proposals?.length) {

			// Get an index for the default value
			let defaultValueIdx = value.default ? value.proposals.indexOf(value.default) : 0;
			let idx = 0;
			if (args.permitRandomization) {
				// Select a random value that isn't the default
				idx = Math.floor(Math.random() * value.proposals.length);
			}

			if (idx === defaultValueIdx) {
				idx = (idx + 1) % value.proposals.length;
			}

			nonDefaultOptions[key] = value.proposals[idx];
		}
		if (value.type === 'string' && 'enum' in value && value?.enum?.length) {
			// Get an index for the default value
			let defaultValueIdx = value.default ? value.enum.indexOf(value.default) : 0;
			let idx = 0;
			if (args.permitRandomization) {
				// Select a random value that isn't the default
				idx = Math.floor(Math.random() * value.enum.length);
			}

			if (idx === defaultValueIdx) {
				idx = (idx + 1) % value.enum.length;
			}

			nonDefaultOptions[key] = value.enum[idx];
		}
	});

	// Default values
	const defaultOptions = Object.entries(options).reduce((acc, [key, value]) => {
		if (value.default === undefined) {
			return acc;
		}
		acc[`${key}__DEFAULT`] = value.default;
		return acc;
	}, {} as { [key: string]: string | boolean });

	const config: DevContainerConfig = {
		image: args.baseImage,
		remoteUser: args.remoteUser,
		features: {
			[feature]: nonDefaultOptions, // Set of non-default option values (when possible)
		}
	};

	// Create Container
	const workspaceFolder = await generateProjectFromScenario(
		cliHost,
		collectionFolder,
		scenarioName,
		config,
		undefined,
		[{ featureId: feature, featureValue: {} }] // Default option values
	);
	const params = await generateDockerParams(workspaceFolder, args);
	await createContainerFromWorkingDirectory(params, workspaceFolder, args);

	// Move the entire test directory for the given Feature into the workspaceFolder
	await cpDirectoryLocal(featureTestFolder, workspaceFolder);

	// // Move the test library script into the workspaceFolder
	await cliHost.writeFile(path.join(workspaceFolder, TEST_LIBRARY_SCRIPT_NAME), Buffer.from(testLibraryScript));

	// Execute Test
	testResults.push({
		testName: scenarioName,
		result: await execTest(testFileName, workspaceFolder, cliHost, { ...nonDefaultOptions, ...defaultOptions })
	});
	return testResults;
}

async function readFeatureMetadata(args: FeaturesTestCommandInput, feature: string): Promise<Feature> {
	const { cliHost, collectionFolder } = args;
	const featureSrcFolder = path.join(collectionFolder, 'src', feature);

	const metadataFile = path.join(featureSrcFolder, 'devcontainer-feature.json');
	if (!await (cliHost.isFile(metadataFile))) {
		fail(`Feature '${feature}' does not contain a 'devcontainer-feature.json' file.`);
	}
	const buf = await cliHost.readFile(metadataFile);
	if (!buf || buf.length === 0) {
		fail(`Failed to read 'devcontainer-feature.json' file for feature '${feature}'`);
	}

	return jsonc.parse(buf.toString()) as Feature;
}

async function runFeatureTests(args: FeaturesTestCommandInput, testResults: TestResult[] = []): Promise<TestResult[]> {
	const { baseImage, collectionFolder, remoteUser, cliHost, skipAutogenerated, skipScenarios, skipDuplicateTest } = args;
	let { features } = args;

	const testsDir = `${collectionFolder}/test`;

	log(`baseImage:         ${baseImage}`);
	log(`Target Folder:     ${collectionFolder}`);

	// Parse comma separated list of features
	// If a set of '--features' isn't specified, run all features with a 'test' subfolder in random order.
	if (!features) {
		// Auto-detect
		features =
			(await cliHost.readDir(testsDir))
				.filter(f => f !== '_global'); // Exclude any folder named '_global'

		if (features.length === 0) {
			fail(`No features specified and no test folders found in '${testsDir}'`);
		}
	}

	log(`features:          ${features.join(', ')}`);

	let workspaceFolder: string | undefined = undefined;
	let params: DockerResolverParameters | undefined = undefined;
	if (!skipAutogenerated) {
		// Generate temporary project with 'baseImage' and all the 'features..'
		workspaceFolder = await generateDefaultProjectFromFeatures(
			cliHost,
			baseImage,
			collectionFolder,
			features,
			remoteUser
		);

		params = await generateDockerParams(workspaceFolder, args);
		await createContainerFromWorkingDirectory(params, workspaceFolder, args);
	}

	log('Starting test(s)...\n', { prefix: '\n🏃', info: true });

	// Exec default 'test.sh' script for each feature, in the provided order.
	// Also exec a test's test scenarios, if a scenarios.json is present in the feature's test folder.
	for (const feature of features) {
		log(`Starting '${feature}' tests...`, { prefix: '🧪' });
		const featureTestFolder = path.join(collectionFolder, 'test', feature);

		if (!skipAutogenerated) {
			if (!workspaceFolder || !params) {
				fail('Uninitialized workspaceFolder or params');
				return [];
			}
			await doRunAutoTest(feature, workspaceFolder, featureTestFolder, args, testResults);
		}

		// If there is a feature-scoped 'scenarios.json' with additional tests, also exec those.
		// Pass  'testResults' array reference in to capture results.
		if (!skipScenarios) {
			log(`Executing scenarios for feature '${feature}'...`, { prefix: '🧪' });
			await doScenario(featureTestFolder, feature, args, testResults);
		}

		if (!skipDuplicateTest) {
			log(`Executing duplicate test for feature '${feature}'...`, { prefix: '🧪' });
			await runDuplicateTest(args, feature, testResults);
		}

		if (!testResults) {
			fail(`Failed to run tests`);
			return []; // We never reach here, we exit via fail().
		}
	}
	return testResults;
}

async function doRunAutoTest(feature: string, workspaceFolder: string, featureTestFolder: string, args: FeaturesTestCommandInput, testResults: TestResult[] = []): Promise<TestResult[]> {
	const { cliHost } = args;
	const testScriptPath = path.join(featureTestFolder, 'test.sh');
	if (!(await cliHost.isFile(testScriptPath))) {
		fail(`Could not find test.sh script at ${testScriptPath}`);
	}

	// Move the entire test directory for the given Feature into the workspaceFolder
	await cpDirectoryLocal(featureTestFolder, workspaceFolder);

	// Move the test library script into the workspaceFolder test scripts folder.
	await cliHost.writeFile(path.join(workspaceFolder, TEST_LIBRARY_SCRIPT_NAME), Buffer.from(testLibraryScript));

	// Execute Test
	const result = await execTest('test.sh', workspaceFolder, cliHost);
	testResults.push({
		testName: feature,
		result,
	});

	return testResults;
}

async function doScenario(pathToTestDir: string, targetFeatureOrGlobal: string, args: FeaturesTestCommandInput, testResults: TestResult[] = []): Promise<TestResult[]> {
	const { collectionFolder, cliHost, filter } = args;
	const scenariosPath = path.join(pathToTestDir, 'scenarios.json');

	if (!(await cliHost.isFile(scenariosPath))) {
		log(`No scenario file found at '${scenariosPath}'. Skipping...`, { prefix: '⚠️', });
		return testResults;
	}

	// Read in scenarios.json
	const scenariosBuffer = await cliHost.readFile(scenariosPath);
	// Parse to json
	let scenarios: Scenarios = {};
	let errors: jsonc.ParseError[] = [];
	scenarios = jsonc.parse(scenariosBuffer.toString(), errors);
	if (errors.length > 0) {
		// Print each jsonc error
		errors.forEach(error => {
			log(`${jsonc.printParseErrorCode(error.error)}`, { prefix: '⚠️' });
		});
		fail(`Failed to parse scenarios.json at ${scenariosPath}`);
		return []; // We never reach here, we exit via fail()
	}

	// For EACH scenario: Spin up a container and exec the scenario test script
	for (const [scenarioName, scenarioConfig] of Object.entries(scenarios)) {

		if (filter && !scenarioName.includes(filter)) {
			continue;
		}

		log(`Running scenario:  ${scenarioName}`);

		// Check if we have a scenario test script, otherwise skip.
		if (!(await cliHost.isFile(path.join(pathToTestDir, `${scenarioName}.sh`)))) {
			fail(`No scenario test script found at path '${path.join(pathToTestDir, `${scenarioName}.sh`)}'.  Either add a script to the test folder, or remove from scenarios.json.`);
		}

		// Create Container
		const workspaceFolder = await generateProjectFromScenario(cliHost, collectionFolder, scenarioName, scenarioConfig, targetFeatureOrGlobal);
		const params = await generateDockerParams(workspaceFolder, args);
		await createContainerFromWorkingDirectory(params, workspaceFolder, args);

		// Move the entire test directory for the given Feature into the workspaceFolder
		await cpDirectoryLocal(pathToTestDir, workspaceFolder);

		// Move the test library script into the workspaceFolder
		await cliHost.writeFile(path.join(workspaceFolder, TEST_LIBRARY_SCRIPT_NAME), Buffer.from(testLibraryScript));

		// Execute Test
		testResults.push({
			testName: scenarioName,
			result: await execTest(`${scenarioName}.sh`, workspaceFolder, cliHost)
		});
	}
	return testResults;
}

function analyzeTestResults(testResults: { testName: string; result: boolean }[]): number {
	if (!testResults) {
		fail('No test results found!');
	}
	// 4. Print results
	// NOTE: 0 tests means allPassed == true.
	const allPassed = testResults.every((x) => x.result);
	process.stdout.write('\n\n\n');
	log('================== TEST REPORT ==================', { 'info': true, 'prefix': ' ' });
	testResults.forEach(t => {
		if (t.result) {
			log(`Passed:      '${t.testName}'`, { 'prefix': '✅', 'info': true });
		} else {
			log(`Failed:      '${t.testName}'`, { 'prefix': '❌', 'info': true });
		}
	});
	process.stdout.write('\n');
	return allPassed ? 0 : 1;
}

const devcontainerTemplate = `
{
	#{REMOTE_USER}
	"image": "#{IMAGE}",
	"features": {
		#{FEATURES}
	}
}`;

async function createContainerFromWorkingDirectory(params: DockerResolverParameters, workspaceFolder: string, args: FeaturesTestCommandInput): Promise<LaunchResult | undefined> {
	const { quiet, disposables } = args;
	log(`workspaceFolder:   ${workspaceFolder}`);

	// 2. Use  'devcontainer-cli up'  to build and start a container
	log('Building test container...\n', { prefix: '\n⏳', info: true });
	const launchResult: LaunchResult | undefined = await launchProject(params, workspaceFolder, quiet, disposables);
	if (!launchResult || !launchResult.containerId) {
		fail('Failed to launch container');
		return;
	}

	const { containerId } = launchResult;

	log(`Launched container.`, { prefix: '\n🚀', info: true });
	log(`containerId:          ${containerId}`);

	return launchResult;
}

async function createTempDevcontainerFolder(cliHost: CLIHost): Promise<string> {
	const systemTmpDir = tmpdir();
	const tmpFolder = path.join(systemTmpDir, 'devcontainercli', 'container-features-test', Date.now().toString());
	await cliHost.mkdirp(`${tmpFolder}/.devcontainer`);
	return tmpFolder;
}

async function generateDefaultProjectFromFeatures(
	cliHost: CLIHost,
	baseImage: string,
	collectionsDirectory: string,
	featuresToTest: string[],
	remoteUser: string | undefined
): Promise<string> {
	const tmpFolder = await createTempDevcontainerFolder(cliHost);

	const features = featuresToTest
		.map((x) => `"./${x}": {}`)
		.join(',\n');

	for (const featureId of featuresToTest) {
		// Copy the feature source code to the temp folder
		const pathToFeatureSource = `${collectionsDirectory}/src/${featureId}`;

		if (! await cliHost.isFolder(pathToFeatureSource)) {
			await rmLocal(tmpFolder, { recursive: true, force: true });
			fail(`Folder '${pathToFeatureSource}' does not exist for the '${featureId}' Feature.`);
		}

		await cpDirectoryLocal(pathToFeatureSource, `${tmpFolder}/.devcontainer/${featureId}`);
	}

	let template = devcontainerTemplate
		.replace('#{IMAGE}', baseImage)
		.replace('#{FEATURES}', features);

	if (remoteUser) {
		template = template.replace('#{REMOTE_USER}', `"remoteUser": "${remoteUser}",`);
	} else {
		template = template.replace('#{REMOTE_USER}', '');
	}

	await cliHost.writeFile(`${tmpFolder}/.devcontainer/devcontainer.json`, Buffer.from(template));

	return tmpFolder;
}

async function generateProjectFromScenario(
	cliHost: CLIHost,
	collectionsDirectory: string,
	scenarioId: string,
	scenarioObject: DevContainerConfig,
	targetFeatureOrGlobal: string | undefined,
	additionalFeatures: { featureId: string; featureValue: {} }[] = []
): Promise<string> {
	const tmpFolder = await createTempDevcontainerFolder(cliHost);

	let features = scenarioObject.features;
	if (!scenarioObject || !features) {
		fail(`Scenario '${scenarioId}' is missing Features!`);
		return ''; // Exits in the 'fail()' before this line is reached.
	}

	// Prefix the local path to the collections directory
	let updatedFeatures: Record<string, string | boolean | Record<string, string | boolean>> = {};
	for (const [featureId, featureValue] of Object.entries(features)) {
		// Do not overwrite Features that are not part of the target collection
		// The '/' is only valid in a fully qualified Feature ID (eg: '[ghcr].io/devcontainers/features/go')
		// This lets you use external Features as a part of the test scenario.
		if (featureId.indexOf('/') !== -1) {
			updatedFeatures[featureId] = featureValue;
			continue;
		}

		// Copy the feature source code to the temp folder
		const pathToFeatureSource = `${collectionsDirectory}/src/${featureId}`;
		await cpDirectoryLocal(pathToFeatureSource, `${tmpFolder}/.devcontainer/${featureId}`);

		// Reference Feature in the devcontainer.json
		updatedFeatures[`./${featureId}`] = featureValue;
	}

	let counter = 0;
	for (const { featureId, featureValue } of additionalFeatures) {
		const pathToFeatureSource = `${collectionsDirectory}/src/${featureId}`;

		const orderedFeatureId = `${featureId}-${counter++}`;
		const destPath = `${tmpFolder}/.devcontainer/${orderedFeatureId}`;
		await cpDirectoryLocal(pathToFeatureSource, destPath);

		// Reference Feature in the devcontainer.json
		updatedFeatures[`./${orderedFeatureId}`] = featureValue;
	}

	scenarioObject.features = updatedFeatures;

	log(`Scenario generated: ${JSON.stringify(scenarioObject, null, 2)}`, { prefix: '\n📝', info: true });

	await cliHost.writeFile(`${tmpFolder}/.devcontainer/devcontainer.json`, Buffer.from(JSON.stringify(scenarioObject)));

	// If the current scenario has a corresponding additional config folder, copy it into the $TMP/.devcontainer directory
	// This lets the scenario use things like Dockerfiles, shell scripts, etc. in the build.
	if (targetFeatureOrGlobal) {
		const localPathToAdditionalConfigFolder = `${collectionsDirectory}/test/${targetFeatureOrGlobal}/${scenarioId}`;
		if (await cliHost.isFolder(localPathToAdditionalConfigFolder)) {
			await cpDirectoryLocal(localPathToAdditionalConfigFolder, `${tmpFolder}/.devcontainer`);
		}
	}

	// Update permissions on the copied files to make them readable/writable/executable by everyone
	await cliHost.exec({ cmd: 'chmod', args: ['-R', '777', tmpFolder], output: nullLog });

	// tmpFolder will serve as our auto-generated 'workingFolder'
	return tmpFolder;
}

async function launchProject(params: DockerResolverParameters, workspaceFolder: string, quiet: boolean, disposables: (() => Promise<unknown> | undefined)[]): Promise<LaunchResult> {
	const { common } = params;
	let response = {} as LaunchResult;

	const idLabels = [`devcontainer.local_folder=${workspaceFolder}`, `devcontainer.is_test_run=true`];
	const options: ProvisionOptions = {
		...staticProvisionParams,
		workspaceFolder,
		additionalLabels: [],
		logLevel: common.getLogLevel(),
		mountWorkspaceGitRoot: true,
		remoteEnv: common.remoteEnv,
		skipFeatureAutoMapping: common.skipFeatureAutoMapping,
		skipPersistingCustomizationsFromFeatures: common.skipPersistingCustomizationsFromFeatures,
		omitConfigRemotEnvFromMetadata: common.omitConfigRemotEnvFromMetadata,
		log: text => quiet ? null : process.stderr.write(text),
		dotfiles: {}
	};

	try {
		if (quiet) {
			// Launch container but don't await it to reduce output noise
			let isResolved = false;
			const p = launch(options, idLabels, disposables);
			p.then(function (res) {
				process.stdout.write('\n');
				response = res;
				isResolved = true;
			});
			while (!isResolved) {
				// Just so visual progress with dots
				process.stdout.write('.');
				await new Promise((resolve) => setTimeout(resolve, 500));
			}
		} else {
			// Stream all the container setup logs.
			response = await launch(options, idLabels, disposables);
		}

		return {
			...response,
			disposables,
		};
	} catch (e: any) {
		fail(`Failed to launch container:\n\n${e?.message ?? 'Unknown error'}`);
		return response; // `fail` exits before we return this.
	}
}

async function execTest(testFileName: string, workspaceFolder: string, cliHost: CLIHost, injectedEnv: { [varName: string]: string | boolean } = {}) {
	// Ensure all the tests scripts in the workspace folder are executable
	// Update permissions on the copied files to make them readable/writable/executable by everyone
	await cliHost.exec({ cmd: 'chmod', args: ['-R', '777', workspaceFolder], output: nullLog });

	const cmd = `./${testFileName}`;
	const args: string[] = [];
	return await exec(cmd, args, workspaceFolder, injectedEnv);
}

async function exec(cmd: string, args: string[], workspaceFolder: string, injectedEnv: { [name: string]: string | boolean } = {}) {
	const injectedEnvArray = Object.keys(injectedEnv).length > 0
		? Object.entries(injectedEnv).map(([key, value]) => `${getSafeId(key)}=${value}`)
		: undefined;

	const execArgs = {
		...staticExecParams,
		'remote-env': injectedEnvArray as any,
		'workspace-folder': workspaceFolder,
		'skip-feature-auto-mapping': false,
		cmd,
		args,
		_: [
			cmd,
			...args
		]
	};
	const result = await doExec(execArgs);
	return (!result.code && !result.signal);
}

async function generateDockerParams(workspaceFolder: string, args: FeaturesTestCommandInput): Promise<DockerResolverParameters> {
	const { logLevel, quiet, disposables } = args;
	return await createDockerParams({
		workspaceFolder,
		additionalLabels: [],
		dockerPath: undefined,
		dockerComposePath: undefined,
		containerDataFolder: undefined,
		containerSystemDataFolder: undefined,
		mountWorkspaceGitRoot: false,
		configFile: undefined,
		overrideConfigFile: undefined,
		logLevel,
		logFormat: 'text',
		log: text => quiet ? null : process.stderr.write(text),
		terminalDimensions: undefined,
		defaultUserEnvProbe: 'loginInteractiveShell',
		removeExistingContainer: false,
		buildNoCache: false,
		expectExistingContainer: false,
		postCreateEnabled: false,
		skipNonBlocking: false,
		prebuild: false,
		persistedFolder: undefined,
		additionalMounts: [],
		updateRemoteUserUIDDefault: 'never',
		remoteEnv: {},
		additionalCacheFroms: [],
		omitLoggerHeader: true,
		useBuildKit: 'auto',
		buildxPlatform: undefined,
		buildxPush: false,
		buildxOutput: undefined,
		buildxCacheTo: undefined,
		skipFeatureAutoMapping: false,
		skipPostAttach: false,
		skipPersistingCustomizationsFromFeatures: false,
		dotfiles: {}
	}, disposables);
}
</file>

<file path="src/spec-node/featuresCLI/utils.ts">
export const staticProvisionParams = {
    workspaceMountConsistency: 'cached' as 'cached',
    defaultUserEnvProbe: 'loginInteractiveShell' as 'loginInteractiveShell',
    logFormat: 'text' as 'text',
    removeExistingContainer: false,
    buildNoCache: false,
    expectExistingContainer: false,
    postCreateEnabled: true,
    skipNonBlocking: false,
    prebuild: false,
    additionalMounts: [],
    updateRemoteUserUIDDefault: 'on' as 'on',
    additionalCacheFroms: [],
    dockerPath: undefined,
    dockerComposePath: undefined,
    containerDataFolder: undefined,
    containerSystemDataFolder: undefined,
    configFile: undefined,
    overrideConfigFile: undefined,
    persistedFolder: undefined,
    terminalDimensions: undefined,
    useBuildKit: 'auto' as 'auto',
    buildxPlatform: undefined,
    buildxPush: false,
    buildxOutput: undefined,
    buildxCacheTo: undefined,
    skipPostAttach: false,
};

export const staticExecParams = {
    'user-data-folder': undefined,
    'docker-path': undefined,
    'docker-compose-path': undefined,
    'container-data-folder': undefined,
    'container-system-data-folder': undefined,
    'id-label': undefined,
    'config': undefined,
    'override-config': undefined,
    'terminal-rows': undefined,
    'terminal-columns': undefined,
    'container-id': undefined,
    'mount-workspace-git-root': true,
    'log-level': 'info' as 'info',
    'log-format': 'text' as 'text',
    'default-user-env-probe': 'loginInteractiveShell' as 'loginInteractiveShell',
};

export interface LaunchResult {
    disposables?: (() => Promise<unknown> | undefined)[];
    containerId: string;
    remoteUser?: string;
    remoteWorkspaceFolder?: string | undefined;
    finishBackgroundTasks?: () => Promise<void>;
    containerHost?: string;
    containerPort?: any;
}

// dev-container-features-test-lib
export const testLibraryScript = `
#!/bin/bash
SCRIPT_FOLDER="$(cd "$(dirname $0)" && pwd)"
USERNAME=\${1:-root}

if [ -z $HOME ]; then
    HOME="/root"
fi

FAILED=()

echoStderr()
{
    echo "$@" 1>&2
}

check() {
    LABEL=$1
    shift
    echo -e "\n"
    echo -e "🔄 Testing '$LABEL'"
    echo -e '\\033[37m'
    if "$@"; then
        echo -e "\n" 
        echo "✅  Passed '$LABEL'!"
        return 0
    else
        echo -e "\n"
        echoStderr "❌ $LABEL check failed."
        FAILED+=("$LABEL")
        return 1
    fi
}

checkMultiple() {
    PASSED=0
    LABEL="$1"
    echo -e "\n"
    echo -e "🔄 Testing '$LABEL'."
    shift; MINIMUMPASSED=$1
    shift; EXPRESSION="$1"
    while [ "$EXPRESSION" != "" ]; do
        if $EXPRESSION; then ((PASSED+=1)); fi
        shift; EXPRESSION=$1
    done
    if [ $PASSED -ge $MINIMUMPASSED ]; then
        echo -e "\n"
        echo "✅ Passed!"
        return 0
    else
        echo -e "\n"
        echoStderr "❌ '$LABEL' check failed."
        FAILED+=("$LABEL")
        return 1
    fi
}

reportResults() {
    if [ \${#FAILED[@]} -ne 0 ]; then
        echo -e "\n"
        echoStderr -e "💥  Failed tests: \${FAILED[@]}"
        exit 1
    else
        echo -e "\n"
        echo -e "Test Passed!"
        exit 0
    fi
}`;
</file>

<file path="src/spec-node/templatesCLI/apply.ts">
import { Argv } from 'yargs';
import { Log, LogLevel, mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import * as jsonc from 'jsonc-parser';
import { UnpackArgv } from '../devContainersSpecCLI';
import { fetchTemplate, SelectedTemplate, TemplateFeatureOption, TemplateOptions } from '../../spec-configuration/containerTemplatesOCI';
import { runAsyncHandler } from '../utils';

export function templateApplyOptions(y: Argv) {
	return y
		.options({
			'workspace-folder': { type: 'string', alias: 'w', demandOption: true, default: '.', description: 'Target workspace folder to apply Template' },
			'template-id': { type: 'string', alias: 't', demandOption: true, description: 'Reference to a Template in a supported OCI registry' },
			'template-args': { type: 'string', alias: 'a', default: '{}', description: 'Arguments to replace within the provided Template, provided as JSON' },
			'features': { type: 'string', alias: 'f', default: '[]', description: 'Features to add to the provided Template, provided as JSON.' },
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
			'tmp-dir': { type: 'string', description: 'Directory to use for temporary files. If not provided, the system default will be inferred.' },
			'omit-paths': { type: 'string', default: '[]', description: 'List of paths within the Template to omit applying, provided as JSON.  To ignore a directory append \'/*\'. Eg: \'[".github/*", "dir/a/*", "file.ts"]\'' },
		})
		.check(_argv => {
			return true;
		});
}

export type TemplateApplyArgs = UnpackArgv<ReturnType<typeof templateApplyOptions>>;

export function templateApplyHandler(args: TemplateApplyArgs) {
	runAsyncHandler(templateApply.bind(null, args));
}

async function templateApply({
	'workspace-folder': workspaceFolder,
	'template-id': templateId,
	'template-args': templateArgs,
	'features': featuresArgs,
	'log-level': inputLogLevel,
	'tmp-dir': userProvidedTmpDir,
	'omit-paths': omitPathsArg,
}: TemplateApplyArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables);

	const id = templateId;

	let templateArgsErrors: jsonc.ParseError[] = [];
	const options = jsonc.parse(templateArgs, templateArgsErrors);

	if (!options || !validateTemplateOptions(output, options, templateArgsErrors)) {
		output.write('Invalid template arguments provided.', LogLevel.Error);
		process.exit(1);
	}
	const features = jsonc.parse(featuresArgs);
	let featuresArgsErrors: jsonc.ParseError[] = [];
	if (!features || !validateTemplateFeatureOption(output, features, featuresArgsErrors)) {
		output.write('Invalid template arguments provided.', LogLevel.Error);
		process.exit(1);
	}

	let omitPaths: string[] = [];
	if (omitPathsArg) {
		let omitPathsErrors: jsonc.ParseError[] = [];
		omitPaths = jsonc.parse(omitPathsArg, omitPathsErrors);
		if (!Array.isArray(omitPaths)) {
			output.write('Invalid \'--omitPaths\' argument provided. Provide as a JSON array, eg: \'[".github/*", "dir/a/*", "file.ts"]\'', LogLevel.Error);
			process.exit(1);
		}
	}

	const selectedTemplate: SelectedTemplate = {
		id: templateId,
		options,
		features,
		omitPaths,
	};

	const files = await fetchTemplate({ output, env: process.env }, selectedTemplate, workspaceFolder, userProvidedTmpDir);
	if (!files) {
		output.write(`Failed to fetch template '${id}'.`, LogLevel.Error);
		process.exit(1);
	}

	console.log(JSON.stringify({ files }));
	await dispose();
	process.exit();
}

// '{ "installZsh": "false", "upgradePackages": "true", "dockerVersion": "20.10", "moby": "true", "enableNonRootDocker": "true" }'
function validateTemplateOptions(output: Log, target: unknown, errors: jsonc.ParseError[]): target is TemplateOptions {
	if (hasJsonParseError(output, errors)) {
		return false;
	}

	if (Array.isArray(target) || typeof target !== 'object' || target === null) {
		output.write(`Invalid template options provided. Expected an object.`, LogLevel.Error);
		return false;
	}

	for (const [_, [key, value]] of Object.entries(target).entries()) {
		if (typeof key !== 'string') {
			output.write(`Invalid template options provided. Expected a string key, but got ${typeof key}`, LogLevel.Error);
			return false;
		}

		if (typeof value !== 'string') {
			output.write(`Invalid template options provided. Expected a string value, but got ${typeof value}`, LogLevel.Error);
			return false;
		}
	}

	return true;
}

// '[{ "id": "ghcr.io/devcontainers/features/azure-cli:1", "options": { "version" : "1" } }]'
function validateTemplateFeatureOption(output: Log, target: unknown, errors: jsonc.ParseError[]): target is TemplateFeatureOption[] {
	if (hasJsonParseError(output, errors)) {
		return false;
	}

	if (!Array.isArray(target)) {
		output.write(`Invalid template options provided. Expected an array.`, LogLevel.Error);
		return false;
	}

	for (const [_, value] of Object.entries(target)) {
		const feature = value as TemplateFeatureOption;
		if (!feature?.id) {
			output.write(`Feature entry requires an Id.`, LogLevel.Error);
			return false;
		}
	}

	return true;
}

function hasJsonParseError(output: Log, errors: jsonc.ParseError[]) {
	for (const error of errors) {
		output.write(`JSON parse error: ${jsonc.printParseErrorCode(error.error)}`, LogLevel.Error);
	}
	return errors.length > 0;
}
</file>

<file path="src/spec-node/templatesCLI/generateDocs.ts">
import { Argv } from 'yargs';
import { UnpackArgv } from '../devContainersSpecCLI';
import { generateTemplatesDocumentation } from '../collectionCommonUtils/generateDocsCommandImpl';
import { createLog } from '../devContainers';
import { mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { runAsyncHandler } from '../utils';

// -- 'templates generate-docs' command
export function templatesGenerateDocsOptions(y: Argv) {
	return y
		.options({
			'project-folder': { type: 'string', alias: 'p', default: '.', description: 'Path to folder containing \'src\' and \'test\' sub-folders. This is likely the git root of the project.' },
			'github-owner': { type: 'string', default: '', description: `GitHub owner for docs.` },
			'github-repo': { type: 'string', default: '', description: `GitHub repo for docs.` },
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' }
		})
		.check(_argv => {
			return true;
		});
}

export type TemplatesGenerateDocsArgs = UnpackArgv<ReturnType<typeof templatesGenerateDocsOptions>>;

export function templatesGenerateDocsHandler(args: TemplatesGenerateDocsArgs) {
	runAsyncHandler(templatesGenerateDocs.bind(null, args));
}

export async function templatesGenerateDocs({
	'project-folder': collectionFolder,
	'github-owner': gitHubOwner,
	'github-repo': gitHubRepo,
	'log-level': inputLogLevel,
}: TemplatesGenerateDocsArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables);

	await generateTemplatesDocumentation(collectionFolder, gitHubOwner, gitHubRepo, output);

	// Cleanup
	await dispose();
	process.exit();
}
</file>

<file path="src/spec-node/templatesCLI/metadata.ts">
import { Argv } from 'yargs';
import { LogLevel, mapLogLevel } from '../../spec-utils/log';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import { fetchOCIManifestIfExists, getRef } from '../../spec-configuration/containerCollectionsOCI';

import { UnpackArgv } from '../devContainersSpecCLI';
import { runAsyncHandler } from '../utils';

export function templateMetadataOptions(y: Argv) {
	return y
		.options({
			'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
		})
		.positional('templateId', { type: 'string', demandOption: true, description: 'Template Identifier' });
}

export type TemplateMetadataArgs = UnpackArgv<ReturnType<typeof templateMetadataOptions>>;

export function templateMetadataHandler(args: TemplateMetadataArgs) {
	runAsyncHandler(templateMetadata.bind(null, args));
}

async function templateMetadata({
	'log-level': inputLogLevel,
	'templateId': templateId,
}: TemplateMetadataArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};

	const pkg = getPackageConfig();

	const output = createLog({
		logLevel: mapLogLevel(inputLogLevel),
		logFormat: 'text',
		log: (str) => process.stderr.write(str),
		terminalDimensions: undefined,
	}, pkg, new Date(), disposables);

	const params = { output, env: process.env };
	output.write(`Fetching metadata for ${templateId}`, LogLevel.Trace);

	const templateRef = getRef(output, templateId);
	if (!templateRef) {
		console.log(JSON.stringify({}));
		process.exit(1);
	}

	const manifestContainer = await fetchOCIManifestIfExists(params, templateRef, undefined);
	if (!manifestContainer) {
		console.log(JSON.stringify({}));
		process.exit(1);
	}

	const { manifestObj, canonicalId } = manifestContainer;
	output.write(`Template '${templateId}' resolved to '${canonicalId}'`, LogLevel.Trace);

	// Templates must have been published with a CLI post commit
	// https://github.com/devcontainers/cli/commit/6c6aebfa7b74aea9d67760fd1e74b09573d31536
	// in order to contain attached metadata.
	const metadata = manifestObj.annotations?.['dev.containers.metadata'];
	if (!metadata) {
		output.write(`Template resolved to '${canonicalId}' but does not contain metadata on its manifest.`, LogLevel.Warning);
		output.write(`Ask the Template owner to republish this Template to populate the manifest.`, LogLevel.Warning);
		console.log(JSON.stringify({}));
		process.exit(1);
	}

	const unescaped = JSON.parse(metadata);
	console.log(JSON.stringify(unescaped));
	await dispose();
	process.exit();
}
</file>

<file path="src/spec-node/templatesCLI/packageImpl.ts">
import path from 'path';
import { OCICollectionFileName, packageCollection, packageSingleFeatureOrTemplate, prepPackageCommand, SourceInformation } from '../collectionCommonUtils/packageCommandImpl';
import { Template } from '../../spec-configuration/containerTemplatesConfiguration';
import { PackageCommandInput } from '../collectionCommonUtils/package';
import { LogLevel } from '../../spec-utils/log';
import { writeLocalFile } from '../../spec-utils/pfs';

export interface DevContainerCollectionMetadata {
	sourceInformation: SourceInformation;
	templates: Template[];
}

const collectionType = 'template';

export async function packageTemplates(args: PackageCommandInput): Promise<DevContainerCollectionMetadata | undefined> {
	args = await prepPackageCommand(args, collectionType);
	const { output, outputDir } = args;
	const isSingleTemplate = args.isSingle;

	// For each template, package each template and write to 'outputDir/{f}.tgz'
	// Returns an array of template metadata from each processed template

	let metadataOutput: Template[] | undefined = [];
	if (isSingleTemplate) {
		// Package individual templates
		output.write('Packaging single template...', LogLevel.Info);
		metadataOutput = await packageSingleTemplate(args);
	} else {
		output.write('Packaging template collection...', LogLevel.Info);
		metadataOutput = await packageTemplateCollection(args);
	}

	if (!metadataOutput) {
		output.write('Failed to package templates', LogLevel.Error);
		return undefined;
	}

	const collection: DevContainerCollectionMetadata = {
		sourceInformation: {
			source: 'devcontainer-cli',
		},
		templates: metadataOutput,
	};

	// Write the metadata to a file
	const metadataOutputPath = path.join(outputDir, OCICollectionFileName);
	await writeLocalFile(metadataOutputPath, JSON.stringify(collection, null, 4));
	return collection;
}

export async function packageSingleTemplate(args: PackageCommandInput): Promise<Template[] | undefined> {
	return await packageSingleFeatureOrTemplate(args, collectionType);
}

export async function packageTemplateCollection(args: PackageCommandInput): Promise<Template[] | undefined> {
	return await packageCollection(args, collectionType);
}
</file>

<file path="src/spec-node/templatesCLI/publish.ts">
import path from 'path';
import * as os from 'os';
import { Argv } from 'yargs';
import { LogLevel, mapLogLevel } from '../../spec-utils/log';
import { rmLocal } from '../../spec-utils/pfs';
import { getPackageConfig } from '../../spec-utils/product';
import { createLog } from '../devContainers';
import { UnpackArgv } from '../devContainersSpecCLI';
import { publishOptions } from '../collectionCommonUtils/publish';
import { getCLIHost } from '../../spec-common/cliHost';
import { loadNativeModule } from '../../spec-common/commonUtils';
import { PackageCommandInput } from '../collectionCommonUtils/package';
import { getArchiveName } from '../collectionCommonUtils/packageCommandImpl';
import { packageTemplates } from './packageImpl';
import { getCollectionRef, getRef, OCICollectionRef } from '../../spec-configuration/containerCollectionsOCI';
import { doPublishCommand, doPublishMetadata } from '../collectionCommonUtils/publishCommandImpl';
import { runAsyncHandler } from '../utils';

const collectionType = 'template';

export function templatesPublishOptions(y: Argv) {
    return publishOptions(y, 'template');
}

export type TemplatesPublishArgs = UnpackArgv<ReturnType<typeof templatesPublishOptions>>;

export function templatesPublishHandler(args: TemplatesPublishArgs) {
	runAsyncHandler(templatesPublish.bind(null, args));
}

async function templatesPublish({
    'target': targetFolder,
    'log-level': inputLogLevel,
    'registry': registry,
    'namespace': namespace
}: TemplatesPublishArgs) {
    const disposables: (() => Promise<unknown> | undefined)[] = [];
    const dispose = async () => {
        await Promise.all(disposables.map(d => d()));
    };

    const pkg = getPackageConfig();

    const cwd = process.cwd();
    const cliHost = await getCLIHost(cwd, loadNativeModule, true);
    const output = createLog({
        logLevel: mapLogLevel(inputLogLevel),
        logFormat: 'text',
        log: (str) => process.stderr.write(str),
        terminalDimensions: undefined,
    }, pkg, new Date(), disposables);

    const params = { output, env: process.env };

    // Package templates
    const outputDir = path.join(os.tmpdir(), `/templates-output-${Date.now()}`);

    const packageArgs: PackageCommandInput = {
        cliHost,
        targetFolder,
        outputDir,
        output,
        disposables,
        forceCleanOutputDir: true,
    };

    const metadata = await packageTemplates(packageArgs);

    if (!metadata) {
        process.exit(1);
    }

    let result = {};

    for (const t of metadata.templates) {
        output.write(`Processing template: ${t.id}...`, LogLevel.Info);

        if (!t.version) {
            output.write(`(!) WARNING: Version does not exist, skipping ${t.id}...`, LogLevel.Warning);
            continue;
        }

        const resource = `${registry}/${namespace}/${t.id}`;
        const templateRef = getRef(output, resource);
        if (!templateRef) {
            output.write(`(!) Could not parse provided Template identifier: '${resource}'`, LogLevel.Error);
            process.exit(1);
        }

        const archiveName = getArchiveName(t.id, collectionType);

        // Properties here are available on the manifest without needing to download the full Template archive.
        const templateAnnotations = {
            'dev.containers.metadata': JSON.stringify(t),
        };
        output.write(`Template Annotations: ${JSON.stringify(templateAnnotations)}`, LogLevel.Debug);

        const publishResult = await doPublishCommand(params, t.version, templateRef, outputDir, collectionType, archiveName, templateAnnotations);
        if (!publishResult) {
            output.write(`(!) ERR: Failed to publish '${resource}'`, LogLevel.Error);
            process.exit(1);
        }

        const thisResult = (publishResult?.digest && publishResult?.publishedTags?.length > 0) ? {
            ...publishResult,
            version: t.version,
        } : {};

        result = {
            ...result,
            [t.id]: thisResult,
        };
    }

    const templateCollectionRef: OCICollectionRef | undefined = getCollectionRef(output, registry, namespace);
    if (!templateCollectionRef) {
        output.write(`(!) Could not parse provided collection identifier with registry '${registry}' and namespace '${namespace}'`, LogLevel.Error);
        process.exit(1);
    }

    if (! await doPublishMetadata(params, templateCollectionRef, outputDir, collectionType)) {
        output.write(`(!) ERR: Failed to publish '${templateCollectionRef.registry}/${templateCollectionRef.path}'`, LogLevel.Error);
        process.exit(1);
    }

    console.log(JSON.stringify(result));

    // Cleanup
    await rmLocal(outputDir, { recursive: true, force: true });
    await dispose();
    process.exit();
}
</file>

<file path="src/spec-node/typings/node-pty.d.ts">
/**
 * Copyright (c) 2017, Daniel Imms (MIT License).
 * Copyright (c) 2018, Microsoft Corporation (MIT License).
 */

declare module 'node-pty' {
  /**
   * Forks a process as a pseudoterminal.
   * @param file The file to launch.
   * @param args The file's arguments as argv (string[]) or in a pre-escaped CommandLine format
   * (string). Note that the CommandLine option is only available on Windows and is expected to be
   * escaped properly.
   * @param options The options of the terminal.
   * @see CommandLineToArgvW https://msdn.microsoft.com/en-us/library/windows/desktop/bb776391(v=vs.85).aspx
   * @see Parsing C++ Comamnd-Line Arguments https://msdn.microsoft.com/en-us/library/17w5ykft.aspx
   * @see GetCommandLine https://msdn.microsoft.com/en-us/library/windows/desktop/ms683156.aspx
   */
  export function spawn(file: string, args: string[] | string, options: IPtyForkOptions | IWindowsPtyForkOptions): IPty;

  export interface IBasePtyForkOptions {

    /**
     * Name of the terminal to be set in environment ($TERM variable).
     */
    name?: string;

    /**
     * Number of intial cols of the pty.
     */
    cols?: number;

    /**
     * Number of initial rows of the pty.
     */
    rows?: number;

    /**
     * Working directory to be set for the slave program.
     */
    cwd?: string;

    /**
     * Environment to be set for the slave program.
     */
    env?: { [key: string]: string };

    /**
     * String encoding of the underlying pty.
     * If set, incoming data will be decoded to strings and outgoing strings to bytes applying this encoding.
     * If unset, incoming data will be delivered as raw bytes (Buffer type).
     * By default 'utf8' is assumed, to unset it explicitly set it to `null`.
     */
    encoding?: string | null;

    /**
     * (EXPERIMENTAL)
     * Whether to enable flow control handling (false by default). If enabled a message of `flowControlPause`
     * will pause the socket and thus blocking the slave program execution due to buffer back pressure.
     * A message of `flowControlResume` will resume the socket into flow mode.
     * For performance reasons only a single message as a whole will match (no message part matching).
     * If flow control is enabled the `flowControlPause` and `flowControlResume` messages are not forwarded to
     * the underlying pseudoterminal.
     */
    handleFlowControl?: boolean;

    /**
     * (EXPERIMENTAL)
     * The string that should pause the pty when `handleFlowControl` is true. Default is XOFF ('\x13').
     */
    flowControlPause?: string;

    /**
     * (EXPERIMENTAL)
     * The string that should resume the pty when `handleFlowControl` is true. Default is XON ('\x11').
     */
    flowControlResume?: string;
  }

  export interface IPtyForkOptions extends IBasePtyForkOptions {
    /**
     * Security warning: use this option with great caution, as opened file descriptors
     * with higher privileges might leak to the slave program.
     */
    uid?: number;
    gid?: number;
  }

  export interface IWindowsPtyForkOptions extends IBasePtyForkOptions {
    /**
     * Whether to use the ConPTY system on Windows. When this is not set, ConPTY will be used when
     * the Windows build number is >= 18309 (instead of winpty). Note that ConPTY is available from
     * build 17134 but is too unstable to enable by default.
     *
     * This setting does nothing on non-Windows.
     */
    useConpty?: boolean;

    /**
     * Whether to use PSEUDOCONSOLE_INHERIT_CURSOR in conpty.
     * @see https://docs.microsoft.com/en-us/windows/console/createpseudoconsole
     */
    conptyInheritCursor?: boolean;
  }

  /**
   * An interface representing a pseudoterminal, on Windows this is emulated via the winpty library.
   */
  export interface IPty {
    /**
     * The process ID of the outer process.
     */
    readonly pid: number;

    /**
     * The column size in characters.
     */
    readonly cols: number;

    /**
     * The row size in characters.
     */
    readonly rows: number;

    /**
     * The title of the active process.
     */
    readonly process: string;

    /**
     * (EXPERIMENTAL)
     * Whether to handle flow control. Useful to disable/re-enable flow control during runtime.
     * Use this for binary data that is likely to contain the `flowControlPause` string by accident.
     */
    handleFlowControl: boolean;

    /**
     * Adds an event listener for when a data event fires. This happens when data is returned from
     * the pty.
     * @returns an `IDisposable` to stop listening.
     */
    readonly onData: IEvent<string>;

    /**
     * Adds an event listener for when an exit event fires. This happens when the pty exits.
     * @returns an `IDisposable` to stop listening.
     */
    readonly onExit: IEvent<{ exitCode: number; signal?: number }>;

    /**
     * Adds a listener to the data event, fired when data is returned from the pty.
     * @param event The name of the event.
     * @param listener The callback function.
     * @deprecated Use IPty.onData
     */
    on(event: 'data', listener: (data: string) => void): void;

    /**
     * Adds a listener to the exit event, fired when the pty exits.
     * @param event The name of the event.
     * @param listener The callback function, exitCode is the exit code of the process and signal is
     * the signal that triggered the exit. signal is not supported on Windows.
     * @deprecated Use IPty.onExit
     */
    on(event: 'exit', listener: (exitCode: number, signal?: number) => void): void;

    /**
     * Resizes the dimensions of the pty.
     * @param columns THe number of columns to use.
     * @param rows The number of rows to use.
     */
    resize(columns: number, rows: number): void;

    /**
     * Writes data to the pty.
     * @param data The data to write.
     */
    write(data: string): void;

    /**
     * Kills the pty.
     * @param signal The signal to use, defaults to SIGHUP. This parameter is not supported on
     * Windows.
     * @throws Will throw when signal is used on Windows.
     */
    kill(signal?: string): void;
  }

  /**
   * An object that can be disposed via a dispose function.
   */
  export interface IDisposable {
    dispose(): void;
  }

  /**
   * An event that can be listened to.
   * @returns an `IDisposable` to stop listening.
   */
  export interface IEvent<T> {
    (listener: (e: T) => any): IDisposable;
  }
}
</file>

<file path="src/spec-node/configContainer.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';

import * as jsonc from 'jsonc-parser';

import { openDockerfileDevContainer } from './singleContainer';
import { openDockerComposeDevContainer } from './dockerCompose';
import { ResolverResult, DockerResolverParameters, isDockerFileConfig, runInitializeCommand, getWorkspaceConfiguration, BindMountConsistency, uriToFsPath, DevContainerAuthority, isDevContainerAuthority, SubstituteConfig, SubstitutedConfig, addSubstitution, envListToObj, findContainerAndIdLabels } from './utils';
import { beforeContainerSubstitute, substitute } from '../spec-common/variableSubstitution';
import { ContainerError } from '../spec-common/errors';
import { Workspace, workspaceFromPath, isWorkspacePath } from '../spec-utils/workspaces';
import { URI } from 'vscode-uri';
import { CLIHost } from '../spec-common/commonUtils';
import { Log } from '../spec-utils/log';
import { getDefaultDevContainerConfigPath, getDevContainerConfigPathIn } from '../spec-configuration/configurationCommonUtils';
import { DevContainerConfig, DevContainerFromDockerComposeConfig, DevContainerFromDockerfileConfig, DevContainerFromImageConfig, updateFromOldProperties } from '../spec-configuration/configuration';
import { ensureNoDisallowedFeatures } from './disallowedFeatures';
import { DockerCLIParameters } from '../spec-shutdown/dockerUtils';
import { createDocuments } from '../spec-configuration/editableFiles';


export async function resolve(params: DockerResolverParameters, configFile: URI | undefined, overrideConfigFile: URI | undefined, providedIdLabels: string[] | undefined, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>): Promise<ResolverResult> {
	if (configFile && !/\/\.?devcontainer\.json$/.test(configFile.path)) {
		throw new Error(`Filename must be devcontainer.json or .devcontainer.json (${uriToFsPath(configFile, params.common.cliHost.platform)}).`);
	}
	const parsedAuthority = params.parsedAuthority;
	if (!parsedAuthority || isDevContainerAuthority(parsedAuthority)) {
		return resolveWithLocalFolder(params, parsedAuthority, configFile, overrideConfigFile, providedIdLabels, additionalFeatures);
	} else {
		throw new Error(`Unexpected authority: ${JSON.stringify(parsedAuthority)}`);
	}
}

async function resolveWithLocalFolder(params: DockerResolverParameters, parsedAuthority: DevContainerAuthority | undefined, configFile: URI | undefined, overrideConfigFile: URI | undefined, providedIdLabels: string[] | undefined, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>): Promise<ResolverResult> {
	const { common, workspaceMountConsistencyDefault } = params;
	const { cliHost, output } = common;

	const cwd = cliHost.cwd; // Can be inside WSL.
	const workspace = parsedAuthority && workspaceFromPath(cliHost.path, isWorkspacePath(parsedAuthority.hostPath) ? cliHost.path.join(cwd, path.basename(parsedAuthority.hostPath)) : cwd);

	const configPath = configFile ? configFile : workspace
		? (await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath)
			|| (overrideConfigFile ? getDefaultDevContainerConfigPath(cliHost, workspace.configFolderPath) : undefined))
		: overrideConfigFile;
	const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, params.mountWorkspaceGitRoot, output, workspaceMountConsistencyDefault, overrideConfigFile) || undefined;
	if (!configs) {
		if (configPath || workspace) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configPath || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
		} else {
			throw new ContainerError({ description: `No dev container config and no workspace found.` });
		}
	}
	const idLabels = providedIdLabels || (await findContainerAndIdLabels(params, undefined, providedIdLabels, workspace?.rootFolderPath, configPath?.fsPath, params.removeOnStartup)).idLabels;
	const configWithRaw = addSubstitution(configs.config, config => beforeContainerSubstitute(envListToObj(idLabels), config));
	const { config } = configWithRaw;

	const { dockerCLI, dockerComposeCLI } = params;
	const { env } = common;
	const cliParams: DockerCLIParameters = { cliHost, dockerCLI, dockerComposeCLI, env, output, platformInfo: params.platformInfo };
	await ensureNoDisallowedFeatures(cliParams, config, additionalFeatures, idLabels);

	await runInitializeCommand({ ...params, common: { ...common, output: common.lifecycleHook.output } }, config.initializeCommand, common.lifecycleHook.onDidInput);

	let result: ResolverResult;
	if (isDockerFileConfig(config) || 'image' in config) {
		result = await openDockerfileDevContainer(params, configWithRaw as SubstitutedConfig<DevContainerFromDockerfileConfig | DevContainerFromImageConfig>, configs.workspaceConfig, idLabels, additionalFeatures);
	} else if ('dockerComposeFile' in config) {
		if (!workspace) {
			throw new ContainerError({ description: `A Dev Container using Docker Compose requires a workspace folder.` });
		}
		result = await openDockerComposeDevContainer(params, workspace, configWithRaw as SubstitutedConfig<DevContainerFromDockerComposeConfig>, idLabels, additionalFeatures);
	} else {
		throw new ContainerError({ description: `Dev container config (${(config as DevContainerConfig).configFilePath}) is missing one of "image", "dockerFile" or "dockerComposeFile" properties.` });
	}
	return result;
}

export async function readDevContainerConfigFile(cliHost: CLIHost, workspace: Workspace | undefined, configFile: URI, mountWorkspaceGitRoot: boolean, output: Log, consistency?: BindMountConsistency, overrideConfigFile?: URI) {
	const documents = createDocuments(cliHost);
	const content = await documents.readDocument(overrideConfigFile ?? configFile);
	if (!content) {
		return undefined;
	}
	const raw = jsonc.parse(content) as DevContainerConfig | undefined;
	const updated = raw && updateFromOldProperties(raw);
	if (!updated || typeof updated !== 'object' || Array.isArray(updated)) {
		throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile, cliHost.platform)}) must contain a JSON object literal.` });
	}
	const workspaceConfig = await getWorkspaceConfiguration(cliHost, workspace, updated, mountWorkspaceGitRoot, output, consistency);
	const substitute0: SubstituteConfig = value => substitute({
		platform: cliHost.platform,
		localWorkspaceFolder: workspace?.rootFolderPath,
		containerWorkspaceFolder: workspaceConfig.workspaceFolder,
		configFile,
		env: cliHost.env,
	}, value);
	const config: DevContainerConfig = substitute0(updated);
	if (typeof config.workspaceFolder === 'string') {
		workspaceConfig.workspaceFolder = config.workspaceFolder;
	}
	if ('workspaceMount' in config) {
		workspaceConfig.workspaceMount = config.workspaceMount;
	}
	config.configFilePath = configFile;
	return {
		config: {
			config,
			raw: updated,
			substitute: substitute0,
		},
		workspaceConfig,
	};
}
</file>

<file path="src/spec-node/containerFeatures.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';

import { DevContainerConfig } from '../spec-configuration/configuration';
import { dockerCLI, dockerPtyCLI, ImageDetails, toExecParameters, toPtyExecParameters } from '../spec-shutdown/dockerUtils';
import { LogLevel, makeLog } from '../spec-utils/log';
import { FeaturesConfig, getContainerFeaturesBaseDockerFile, getFeatureInstallWrapperScript, getFeatureLayers, getFeatureMainValue, getFeatureValueObject, generateFeaturesConfig, Feature, generateContainerEnvs } from '../spec-configuration/containerFeaturesConfiguration';
import { readLocalFile } from '../spec-utils/pfs';
import { includeAllConfiguredFeatures } from '../spec-utils/product';
import { createFeaturesTempFolder, DockerResolverParameters, getCacheFolder, getFolderImageName, getEmptyContextFolder, SubstitutedConfig } from './utils';
import { isEarlierVersion, parseVersion, runCommandNoPty } from '../spec-common/commonUtils';
import { getDevcontainerMetadata, getDevcontainerMetadataLabel, getImageBuildInfoFromImage, ImageBuildInfo, ImageMetadataEntry, imageMetadataLabel, MergedDevContainerConfig } from './imageMetadata';
import { supportsBuildContexts } from './dockerfileUtils';
import { ContainerError } from '../spec-common/errors';

// Escapes environment variable keys.
//
// Environment variables must contain:
//      - alpha-numeric values, or
//      - the '_' character, and
//      - a number cannot be the first character
export const getSafeId = (str: string) => str
	.replace(/[^\w_]/g, '_')
	.replace(/^[\d_]+/g, '_')
	.toUpperCase();

export async function extendImage(params: DockerResolverParameters, config: SubstitutedConfig<DevContainerConfig>, imageName: string, additionalImageNames: string[], additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>, canAddLabelsToContainer: boolean) {
	const { common } = params;
	const { cliHost, output } = common;

	const imageBuildInfo = await getImageBuildInfoFromImage(params, imageName, config.substitute);
	const extendImageDetails = await getExtendImageBuildInfo(params, config, imageName, imageBuildInfo, undefined, additionalFeatures, canAddLabelsToContainer);
	if (!extendImageDetails?.featureBuildInfo) {
		// no feature extensions - return
		if (additionalImageNames.length) {
			if (params.isTTY) {
				await Promise.all(additionalImageNames.map(name => dockerPtyCLI(params, 'tag', imageName, name)));
			} else {
				await Promise.all(additionalImageNames.map(name => dockerCLI(params, 'tag', imageName, name)));
			}
		}
		return {
			updatedImageName: [imageName],
			imageMetadata: getDevcontainerMetadata(imageBuildInfo.metadata, config, extendImageDetails?.featuresConfig),
			imageDetails: async () => imageBuildInfo.imageDetails,
			labels: extendImageDetails?.labels,
		};
	}
	const { featureBuildInfo, featuresConfig } = extendImageDetails;

	// Got feature extensions -> build the image
	const dockerfilePath = cliHost.path.join(featureBuildInfo.dstFolder, 'Dockerfile.extended');
	await cliHost.writeFile(dockerfilePath, Buffer.from(featureBuildInfo.dockerfilePrefixContent + featureBuildInfo.dockerfileContent));
	const folderImageName = getFolderImageName(common);
	const updatedImageName = `${imageName.startsWith(folderImageName) ? imageName : folderImageName}-features`;

	const args: string[] = [];
	if (!params.buildKitVersion &&
		(params.buildxPlatform || params.buildxPush)) {
		throw new ContainerError({ description: '--platform or --push require BuildKit enabled.', data: { fileWithError: dockerfilePath } });
	}
	if (params.buildKitVersion) {
		args.push('buildx', 'build');

		// --platform
		if (params.buildxPlatform) {
			output.write('Setting BuildKit platform(s): ' + params.buildxPlatform, LogLevel.Trace);
			args.push('--platform', params.buildxPlatform);
		}

		// --push/--output
		if (params.buildxPush) {
			args.push('--push');
		} else {
			if (params.buildxOutput) {
				args.push('--output', params.buildxOutput);
			} else {
				args.push('--load'); // (short for --output=docker, i.e. load into normal 'docker images' collection)
			}
		}
		if (params.buildxCacheTo) {
			args.push('--cache-to', params.buildxCacheTo);
		}
		if (!params.buildNoCache) {
			params.additionalCacheFroms.forEach(cacheFrom => args.push('--cache-from', cacheFrom));
		}

		for (const buildContext in featureBuildInfo.buildKitContexts) {
			args.push('--build-context', `${buildContext}=${featureBuildInfo.buildKitContexts[buildContext]}`);
		}

		for (const securityOpt of featureBuildInfo.securityOpts) {
			args.push('--security-opt', securityOpt);
		}
	} else {
		// Not using buildx
		args.push(
			'build',
		);
	}
	if (params.buildNoCache) {
		args.push('--no-cache');
	}
	for (const buildArg in featureBuildInfo.buildArgs) {
		args.push('--build-arg', `${buildArg}=${featureBuildInfo.buildArgs[buildArg]}`);
	}
	// Once this is step merged with the user Dockerfile (or working against the base image),
	// the path will be the dev container context
	// Set empty dir under temp path as the context for now to ensure we don't have dependencies on the features content
	const emptyTempDir = getEmptyContextFolder(common);
	cliHost.mkdirp(emptyTempDir);
	args.push(
		'--target', featureBuildInfo.overrideTarget,
		'-f', dockerfilePath,
		...additionalImageNames.length > 0 ? additionalImageNames.map(name => ['-t', name]).flat() : ['-t', updatedImageName],
		...params.additionalLabels.length > 0 ? params.additionalLabels.map(label => ['--label', label]).flat() : [],
		emptyTempDir
	);

	if (params.isTTY) {
		const infoParams = { ...toPtyExecParameters(params), output: makeLog(output, LogLevel.Info) };
		await dockerPtyCLI(infoParams, ...args);
	} else {
		const infoParams = { ...toExecParameters(params), output: makeLog(output, LogLevel.Info), print: 'continuous' as 'continuous' };
		await dockerCLI(infoParams, ...args);
	}
	return {
		updatedImageName: additionalImageNames.length > 0 ? additionalImageNames : [updatedImageName],
		imageMetadata: getDevcontainerMetadata(imageBuildInfo.metadata, config, featuresConfig),
		imageDetails: async () => imageBuildInfo.imageDetails,
	};
}

export async function getExtendImageBuildInfo(params: DockerResolverParameters, config: SubstitutedConfig<DevContainerConfig>, baseName: string, imageBuildInfo: ImageBuildInfo, composeServiceUser: string | undefined, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>, canAddLabelsToContainer: boolean): Promise<{ featureBuildInfo?: ImageBuildOptions; featuresConfig?: FeaturesConfig; labels?: Record<string, string> } | undefined> {

	// Creates the folder where the working files will be setup.
	const dstFolder = await createFeaturesTempFolder(params.common);

	// Processes the user's configuration.
	const platform = params.common.cliHost.platform;

	const cacheFolder = await getCacheFolder(params.common.cliHost);
	const { experimentalLockfile, experimentalFrozenLockfile } = params;
	const featuresConfig = await generateFeaturesConfig({ ...params.common, platform, cacheFolder, experimentalLockfile, experimentalFrozenLockfile }, dstFolder, config.config, additionalFeatures);
	if (!featuresConfig) {
		if (canAddLabelsToContainer && !imageBuildInfo.dockerfile) {
			return {
				labels: {
					[imageMetadataLabel]: JSON.stringify(getDevcontainerMetadata(imageBuildInfo.metadata, config, undefined, [], getOmitDevcontainerPropertyOverride(params.common)).raw),
				}
			};
		}
		return { featureBuildInfo: getImageBuildOptions(params, config, dstFolder, baseName, imageBuildInfo) };
	}

	// Generates the end configuration.
	const featureBuildInfo = await getFeaturesBuildOptions(params, config, featuresConfig, baseName, imageBuildInfo, composeServiceUser);
	if (!featureBuildInfo) {
		return undefined;
	}
	return { featureBuildInfo, featuresConfig };

}

// NOTE: only exported to enable testing. Not meant to be called outside file.
export function generateContainerEnvsV1(featuresConfig: FeaturesConfig) {
	let result = '';
	for (const fSet of featuresConfig.featureSets) {
		// We only need to generate this ENV references for the initial features specification.
		if (fSet.internalVersion !== '2')
		{
			result += '\n';
			result += fSet.features
				.filter(f => (includeAllConfiguredFeatures || f.included) && f.value)
				.reduce((envs, f) => envs.concat(generateContainerEnvs(f.containerEnv)), [] as string[])
				.join('\n');
		}
	}
	return result;
}

export interface ImageBuildOptions {
	dstFolder: string;
	dockerfileContent: string;
	overrideTarget: string;
	dockerfilePrefixContent: string;
	buildArgs: Record<string, string>;
	buildKitContexts: Record<string, string>;
	securityOpts: string[];
}

function getImageBuildOptions(params: DockerResolverParameters, config: SubstitutedConfig<DevContainerConfig>, dstFolder: string, baseName: string, imageBuildInfo: ImageBuildInfo): ImageBuildOptions {
	const syntax = imageBuildInfo.dockerfile?.preamble.directives.syntax;
	return {
		dstFolder,
		dockerfileContent: `
FROM $_DEV_CONTAINERS_BASE_IMAGE AS dev_containers_target_stage
${getDevcontainerMetadataLabel(getDevcontainerMetadata(imageBuildInfo.metadata, config, { featureSets: [] }, [], getOmitDevcontainerPropertyOverride(params.common)))}
`,
		overrideTarget: 'dev_containers_target_stage',
		dockerfilePrefixContent: `${syntax ? `# syntax=${syntax}` : ''}
	ARG _DEV_CONTAINERS_BASE_IMAGE=placeholder
`,
		buildArgs: {
			_DEV_CONTAINERS_BASE_IMAGE: baseName,
		} as Record<string, string>,
		buildKitContexts: {} as Record<string, string>,
		securityOpts: [],
	};
}

function getOmitDevcontainerPropertyOverride(resolverParams: { omitConfigRemotEnvFromMetadata?: boolean }): (keyof DevContainerConfig & keyof ImageMetadataEntry)[] {
	if (resolverParams.omitConfigRemotEnvFromMetadata) {
		return ['remoteEnv'];
	}

	return [];
}

async function getFeaturesBuildOptions(params: DockerResolverParameters, devContainerConfig: SubstitutedConfig<DevContainerConfig>, featuresConfig: FeaturesConfig, baseName: string, imageBuildInfo: ImageBuildInfo, composeServiceUser: string | undefined): Promise<ImageBuildOptions | undefined> {
	const { common } = params;
	const { cliHost, output } = common;
	const { dstFolder } = featuresConfig;

	if (!dstFolder || dstFolder === '') {
		output.write('dstFolder is undefined or empty in addContainerFeatures', LogLevel.Error);
		return undefined;
	}

	// With Buildkit (0.8.0 or later), we can supply an additional build context to provide access to
	// the container-features content.
	// For non-Buildkit, we build a temporary image to hold the container-features content in a way
	// that is accessible from the docker build for non-BuiltKit builds
	// TODO generate an image name that is specific to this dev container?
	const buildKitVersionParsed = params.buildKitVersion?.versionMatch ? parseVersion(params.buildKitVersion.versionMatch) : undefined;
	const minRequiredVersion = [0, 8, 0];
	const useBuildKitBuildContexts = buildKitVersionParsed ? !isEarlierVersion(buildKitVersionParsed, minRequiredVersion) : false;
	const buildContentImageName = 'dev_container_feature_content_temp';
	const disableSELinuxLabels = useBuildKitBuildContexts && await isUsingSELinuxLabels(params);

	const omitPropertyOverride = params.common.skipPersistingCustomizationsFromFeatures ? ['customizations'] : [];
	const imageMetadata = getDevcontainerMetadata(imageBuildInfo.metadata, devContainerConfig, featuresConfig, omitPropertyOverride, getOmitDevcontainerPropertyOverride(params.common));
	const { containerUser, remoteUser } = findContainerUsers(imageMetadata, composeServiceUser, imageBuildInfo.user);
	const builtinVariables = [
		`_CONTAINER_USER=${containerUser}`,
		`_REMOTE_USER=${remoteUser}`,
	];
	const envPath = cliHost.path.join(dstFolder, 'devcontainer-features.builtin.env');
	await cliHost.writeFile(envPath, Buffer.from(builtinVariables.join('\n') + '\n'));

	// When copying via buildkit, the content is accessed via '.' (i.e. in the context root)
	// When copying via temp image, the content is in '/tmp/build-features'
	const contentSourceRootPath = useBuildKitBuildContexts ? '.' : '/tmp/build-features/';
	const dockerfile = getContainerFeaturesBaseDockerFile(contentSourceRootPath)
		.replace('#{nonBuildKitFeatureContentFallback}', useBuildKitBuildContexts ? '' : `FROM ${buildContentImageName} as dev_containers_feature_content_source`)
		.replace('#{featureLayer}', getFeatureLayers(featuresConfig, containerUser, remoteUser, useBuildKitBuildContexts, contentSourceRootPath))
		.replace('#{containerEnv}', generateContainerEnvsV1(featuresConfig))
		.replace('#{devcontainerMetadata}', getDevcontainerMetadataLabel(imageMetadata))
		.replace('#{containerEnvMetadata}', generateContainerEnvs(devContainerConfig.config.containerEnv, true))
		;
	const syntax = imageBuildInfo.dockerfile?.preamble.directives.syntax;
	const omitSyntaxDirective = common.omitSyntaxDirective; // Can be removed when https://github.com/moby/buildkit/issues/4556 is fixed
	const dockerfilePrefixContent = `${omitSyntaxDirective ? '' :
		useBuildKitBuildContexts && !(imageBuildInfo.dockerfile && supportsBuildContexts(imageBuildInfo.dockerfile)) ? '# syntax=docker/dockerfile:1.4' :
		syntax ? `# syntax=${syntax}` : ''}
ARG _DEV_CONTAINERS_BASE_IMAGE=placeholder
`;

	// Build devcontainer-features.env and devcontainer-features-install.sh file(s) for each features source folder
	for await (const fSet of featuresConfig.featureSets) {
		if (fSet.internalVersion === '2')
		{
			for await (const fe of fSet.features) {
				if (fe.cachePath)
				{
					fe.internalVersion = '2';
					const envPath = cliHost.path.join(fe.cachePath, 'devcontainer-features.env');
					const variables = getFeatureEnvVariables(fe);
					await cliHost.writeFile(envPath, Buffer.from(variables.join('\n')));

					const installWrapperPath = cliHost.path.join(fe.cachePath, 'devcontainer-features-install.sh');
					const installWrapperContent = getFeatureInstallWrapperScript(fe, fSet, variables);
					await cliHost.writeFile(installWrapperPath, Buffer.from(installWrapperContent));
				}
			}
		} else {
			const featuresEnv = ([] as string[]).concat(
				...fSet.features
					.filter(f => (includeAllConfiguredFeatures || f.included) && f.value)
					.map(getFeatureEnvVariables)
			).join('\n');
			const envPath = cliHost.path.join(fSet.features[0].cachePath!, 'devcontainer-features.env');
			await Promise.all([
				cliHost.writeFile(envPath, Buffer.from(featuresEnv)),
				...fSet.features
					.filter(f => (includeAllConfiguredFeatures || f.included) && f.value)
				.map(f => {
					const consecutiveId = f.consecutiveId;
					if (!consecutiveId) {
						throw new Error('consecutiveId is undefined for Feature ' + f.id);
					}
					const featuresEnv = [
						...getFeatureEnvVariables(f),
						`_BUILD_ARG_${getSafeId(f.id)}_TARGETPATH=${path.posix.join('/usr/local/devcontainer-features', consecutiveId)}`
					]
						.join('\n');
					const envPath = cliHost.path.join(dstFolder, consecutiveId, 'devcontainer-features.env'); // next to bin/acquire
						return cliHost.writeFile(envPath, Buffer.from(featuresEnv));
					})
			]);
		}
	}

	// For non-BuildKit, build the temporary image for the container-features content
	if (!useBuildKitBuildContexts) {
		const buildContentDockerfile = `
	FROM scratch
	COPY . /tmp/build-features/
	`;
		const buildContentDockerfilePath = cliHost.path.join(dstFolder, 'Dockerfile.buildContent');
		await cliHost.writeFile(buildContentDockerfilePath, Buffer.from(buildContentDockerfile));
		const buildContentArgs = [
			'build',
			'-t', buildContentImageName,
			'-f', buildContentDockerfilePath,
		];
		buildContentArgs.push(dstFolder);

		if (params.isTTY) {
			const buildContentInfoParams = { ...toPtyExecParameters(params), output: makeLog(output, LogLevel.Info) };
			await dockerPtyCLI(buildContentInfoParams, ...buildContentArgs);
		} else {
			const buildContentInfoParams = { ...toExecParameters(params), output: makeLog(output, LogLevel.Info), print: 'continuous' as 'continuous' };
			await dockerCLI(buildContentInfoParams, ...buildContentArgs);
		}
	}
	return {
		dstFolder,
		dockerfileContent: dockerfile,
		overrideTarget: 'dev_containers_target_stage',
		dockerfilePrefixContent,
		buildArgs: {
			_DEV_CONTAINERS_BASE_IMAGE: baseName,
			_DEV_CONTAINERS_IMAGE_USER: imageBuildInfo.user,
			_DEV_CONTAINERS_FEATURE_CONTENT_SOURCE: buildContentImageName,
		},
		buildKitContexts: useBuildKitBuildContexts ? { dev_containers_feature_content_source: dstFolder } : {},
		securityOpts: disableSELinuxLabels ? ['label=disable'] : [],
	};
}

async function isUsingSELinuxLabels(params: DockerResolverParameters): Promise<boolean> {
	try {
		const { common } = params;
		const { cliHost, output } = common;
		return params.isPodman && cliHost.platform === 'linux'
			&& (await runCommandNoPty({
				exec: cliHost.exec,
				cmd: 'getenforce',
				output,
				print: true,
			})).stdout.toString().trim() !== 'Disabled'
			&& (await dockerCLI({
				...toExecParameters(params),
				print: true,
			}, 'info', '-f', '{{.Host.Security.SELinuxEnabled}}')).stdout.toString().trim() === 'true';
	} catch {
		// If we can't run the commands, assume SELinux is not enabled.
		return false;
		
	}
}

export function findContainerUsers(imageMetadata: SubstitutedConfig<ImageMetadataEntry[]>, composeServiceUser: string | undefined, imageUser: string) {
	const reversed = imageMetadata.config.slice().reverse();
	const containerUser = reversed.find(entry => entry.containerUser)?.containerUser || composeServiceUser || imageUser;
	const remoteUser = reversed.find(entry => entry.remoteUser)?.remoteUser || containerUser;
	return { containerUser, remoteUser };
}


function getFeatureEnvVariables(f: Feature) {
	const values = getFeatureValueObject(f);
	const idSafe = getSafeId(f.id);
	const variables = [];

	if(f.internalVersion !== '2')
	{
		if (values) {
			variables.push(...Object.keys(values)
				.map(name => `_BUILD_ARG_${idSafe}_${getSafeId(name)}="${values[name]}"`));
			variables.push(`_BUILD_ARG_${idSafe}=true`);
		}
		if (f.buildArg) {
			variables.push(`${f.buildArg}=${getFeatureMainValue(f)}`);
		}
		return variables;
	} else {
		if (values) {
			variables.push(...Object.keys(values)
				.map(name => `${getSafeId(name)}="${values[name]}"`));
		}
		if (f.buildArg) {
			variables.push(`${f.buildArg}=${getFeatureMainValue(f)}`);
		}
		return variables;
	}
}

export async function getRemoteUserUIDUpdateDetails(params: DockerResolverParameters, mergedConfig: MergedDevContainerConfig, imageName: string, imageDetails: () => Promise<ImageDetails>, runArgsUser: string | undefined) {
	const { common } = params;
	const { cliHost } = common;
	const { updateRemoteUserUID } = mergedConfig;
	if (params.updateRemoteUserUIDDefault === 'never' || !(typeof updateRemoteUserUID === 'boolean' ? updateRemoteUserUID : params.updateRemoteUserUIDDefault === 'on') || !(cliHost.platform === 'linux' || params.updateRemoteUserUIDOnMacOS && cliHost.platform === 'darwin')) {
		return null;
	}
	const details = await imageDetails();
	const imageUser = details.Config.User || 'root';
	const remoteUser = mergedConfig.remoteUser || runArgsUser || imageUser;
	if (remoteUser === 'root' || /^\d+$/.test(remoteUser)) {
		return null;
	}
	const folderImageName = getFolderImageName(common);
	const fixedImageName = `${imageName.startsWith(folderImageName) ? imageName : folderImageName}-uid`;

	return {
		imageName: fixedImageName,
		remoteUser,
		imageUser,
		platform: [details.Os, details.Architecture, details.Variant].filter(Boolean).join('/')
	};
}

export async function updateRemoteUserUID(params: DockerResolverParameters, mergedConfig: MergedDevContainerConfig, imageName: string, imageDetails: () => Promise<ImageDetails>, runArgsUser: string | undefined) {
	const { common } = params;
	const { cliHost } = common;

	const updateDetails = await getRemoteUserUIDUpdateDetails(params, mergedConfig, imageName, imageDetails, runArgsUser);
	if (!updateDetails) {
		return imageName;
	}
	const { imageName: fixedImageName, remoteUser, imageUser, platform } = updateDetails;

	const dockerfileName = 'updateUID.Dockerfile';
	const srcDockerfile = path.join(common.extensionPath, 'scripts', dockerfileName);
	const version = common.package.version;
	const destDockerfile = cliHost.path.join(await getCacheFolder(cliHost), `${dockerfileName}-${version}`);
	const tmpDockerfile = `${destDockerfile}-${Date.now()}`;
	await cliHost.mkdirp(cliHost.path.dirname(tmpDockerfile));
	await cliHost.writeFile(tmpDockerfile, await readLocalFile(srcDockerfile));
	await cliHost.rename(tmpDockerfile, destDockerfile);
	const emptyFolder = getEmptyContextFolder(common);
	await cliHost.mkdirp(emptyFolder);
	const args = [
		'build',
		'-f', destDockerfile,
		'-t', fixedImageName,
		...(platform ? ['--platform', platform] : []),
		'--build-arg', `BASE_IMAGE=${params.isPodman && !hasRegistryHostname(imageName) ? 'localhost/' : ''}${imageName}`, // Podman: https://github.com/microsoft/vscode-remote-release/issues/9748
		'--build-arg', `REMOTE_USER=${remoteUser}`,
		'--build-arg', `NEW_UID=${await cliHost.getuid!()}`,
		'--build-arg', `NEW_GID=${await cliHost.getgid!()}`,
		'--build-arg', `IMAGE_USER=${imageUser}`,
		emptyFolder,
	];
	if (params.isTTY) {
		await dockerPtyCLI(params, ...args);
	} else {
		await dockerCLI(params, ...args);
	}
	return fixedImageName;
}

function hasRegistryHostname(imageName: string) {
	if (imageName.startsWith('localhost/')) {
		return true;
	}
	const dot = imageName.indexOf('.');
	const slash = imageName.indexOf('/');
	return dot !== -1 && slash !== -1 && dot < slash;
}
</file>

<file path="src/spec-node/devContainers.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as crypto from 'crypto';
import * as os from 'os';

import { mapNodeOSToGOOS, mapNodeArchitectureToGOARCH } from '../spec-configuration/containerCollectionsOCI';
import { DockerResolverParameters, DevContainerAuthority, UpdateRemoteUserUIDDefault, BindMountConsistency, getCacheFolder, GPUAvailability } from './utils';
import { createNullLifecycleHook, finishBackgroundTasks, ResolverParameters, UserEnvProbe } from '../spec-common/injectHeadless';
import { GoARCH, GoOS, getCLIHost, loadNativeModule } from '../spec-common/commonUtils';
import { resolve } from './configContainer';
import { URI } from 'vscode-uri';
import { LogLevel, LogDimensions, toErrorText, createCombinedLog, createTerminalLog, Log, makeLog, LogFormat, createJSONLog, createPlainLog, LogHandler, replaceAllLog } from '../spec-utils/log';
import { dockerComposeCLIConfig } from './dockerCompose';
import { Mount } from '../spec-configuration/containerFeaturesConfiguration';
import { getPackageConfig, PackageConfiguration } from '../spec-utils/product';
import { dockerBuildKitVersion, isPodman } from '../spec-shutdown/dockerUtils';
import { Event } from '../spec-utils/event';


export interface ProvisionOptions {
	dockerPath: string | undefined;
	dockerComposePath: string | undefined;
	containerDataFolder: string | undefined;
	containerSystemDataFolder: string | undefined;
	workspaceFolder: string | undefined;
	workspaceMountConsistency?: BindMountConsistency;
	gpuAvailability?: GPUAvailability;
	mountWorkspaceGitRoot: boolean;
	configFile: URI | undefined;
	overrideConfigFile: URI | undefined;
	logLevel: LogLevel;
	logFormat: LogFormat;
	log: (text: string) => void;
	terminalDimensions: LogDimensions | undefined;
	onDidChangeTerminalDimensions?: Event<LogDimensions>;
	defaultUserEnvProbe: UserEnvProbe;
	removeExistingContainer: boolean;
	buildNoCache: boolean;
	expectExistingContainer: boolean;
	postCreateEnabled: boolean;
	skipNonBlocking: boolean;
	prebuild: boolean;
	persistedFolder: string | undefined;
	additionalMounts: Mount[];
	updateRemoteUserUIDDefault: UpdateRemoteUserUIDDefault;
	remoteEnv: Record<string, string>;
	additionalCacheFroms: string[];
	useBuildKit: 'auto' | 'never';
	omitLoggerHeader?: boolean | undefined;
	buildxPlatform: string | undefined;
	buildxPush: boolean;
	additionalLabels: string[];
	buildxOutput: string | undefined;
	buildxCacheTo: string | undefined;
	additionalFeatures?: Record<string, string | boolean | Record<string, string | boolean>>;
	skipFeatureAutoMapping: boolean;
	skipPostAttach: boolean;
	containerSessionDataFolder?: string;
	skipPersistingCustomizationsFromFeatures: boolean;
	omitConfigRemotEnvFromMetadata?: boolean;
	dotfiles: {
		repository?: string;
		installCommand?: string;
		targetPath?: string;
	};
	experimentalLockfile?: boolean;
	experimentalFrozenLockfile?: boolean;
	secretsP?: Promise<Record<string, string>>;
	omitSyntaxDirective?: boolean;
	includeConfig?: boolean;
	includeMergedConfig?: boolean;
}

export async function launch(options: ProvisionOptions, providedIdLabels: string[] | undefined, disposables: (() => Promise<unknown> | undefined)[]) {
	const params = await createDockerParams(options, disposables);
	const output = params.common.output;
	const text = 'Resolving Remote';
	const start = output.start(text);

	const result = await resolve(params, options.configFile, options.overrideConfigFile, providedIdLabels, options.additionalFeatures ?? {});
	output.stop(text, start);
	const { dockerContainerId, composeProjectName } = result;
	return {
		containerId: dockerContainerId,
		composeProjectName,
		remoteUser: result.properties.user,
		remoteWorkspaceFolder: result.properties.remoteWorkspaceFolder,
		configuration: options.includeConfig ? result.config : undefined,
		mergedConfiguration: options.includeMergedConfig ? result.mergedConfig : undefined,
		finishBackgroundTasks: async () => {
			try {
				await finishBackgroundTasks(result.params.backgroundTasks);
			} catch (err) {
				output.write(toErrorText(String(err && (err.stack || err.message) || err)));
			}
		},
	};
}

export async function createDockerParams(options: ProvisionOptions, disposables: (() => Promise<unknown> | undefined)[]): Promise<DockerResolverParameters> {
	const { persistedFolder, additionalMounts, updateRemoteUserUIDDefault, containerDataFolder, containerSystemDataFolder, workspaceMountConsistency, gpuAvailability, mountWorkspaceGitRoot, remoteEnv, experimentalLockfile, experimentalFrozenLockfile, omitLoggerHeader, secretsP } = options;
	let parsedAuthority: DevContainerAuthority | undefined;
	if (options.workspaceFolder) {
		parsedAuthority = { hostPath: options.workspaceFolder } as DevContainerAuthority;
	}
	const extensionPath = path.join(__dirname, '..', '..');
	const sessionStart = new Date();
	const pkg = getPackageConfig();
	const output = createLog(options, pkg, sessionStart, disposables, omitLoggerHeader, secretsP ? await secretsP : undefined);

	const appRoot = undefined;
	const cwd = options.workspaceFolder || process.cwd();
	const allowInheritTTY = options.logFormat === 'text';
	const cliHost = await getCLIHost(cwd, loadNativeModule, allowInheritTTY);
	const sessionId = crypto.randomUUID();

	const common: ResolverParameters = {
		prebuild: options.prebuild,
		computeExtensionHostEnv: false,
		package: pkg,
		containerDataFolder,
		containerSystemDataFolder,
		appRoot,
		extensionPath, // TODO: rename to packagePath
		sessionId,
		sessionStart,
		cliHost,
		env: cliHost.env,
		cwd,
		isLocalContainer: false,
		progress: () => { },
		output,
		allowSystemConfigChange: true,
		defaultUserEnvProbe: options.defaultUserEnvProbe,
		lifecycleHook: createNullLifecycleHook(options.postCreateEnabled, options.skipNonBlocking, output),
		getLogLevel: () => options.logLevel,
		onDidChangeLogLevel: () => ({ dispose() { } }),
		loadNativeModule,
		allowInheritTTY,
		shutdowns: [],
		backgroundTasks: [],
		persistedFolder: persistedFolder || await getCacheFolder(cliHost), // Fallback to tmp folder, even though that isn't 'persistent'
		remoteEnv,
		secretsP,
		buildxPlatform: options.buildxPlatform,
		buildxPush: options.buildxPush,
		buildxOutput: options.buildxOutput,
		buildxCacheTo: options.buildxCacheTo,
		skipFeatureAutoMapping: options.skipFeatureAutoMapping,
		skipPostAttach: options.skipPostAttach,
		containerSessionDataFolder: options.containerSessionDataFolder,
		skipPersistingCustomizationsFromFeatures: options.skipPersistingCustomizationsFromFeatures,
		omitConfigRemotEnvFromMetadata: options.omitConfigRemotEnvFromMetadata,
		dotfilesConfiguration: {
			repository: options.dotfiles.repository,
			installCommand: options.dotfiles.installCommand,
			targetPath: options.dotfiles.targetPath || '~/dotfiles',
		},
		omitSyntaxDirective: options.omitSyntaxDirective,
	};

	const dockerPath = options.dockerPath || 'docker';
	const dockerComposePath = options.dockerComposePath || 'docker-compose';
	const dockerComposeCLI = dockerComposeCLIConfig({
		exec: cliHost.exec,
		env: cliHost.env,
		output: common.output,
	}, dockerPath, dockerComposePath);

	const platformInfo = (() => {
		if (common.buildxPlatform) {
			const slash1 = common.buildxPlatform.indexOf('/');
			const slash2 = common.buildxPlatform.indexOf('/', slash1 + 1);
			// `--platform linux/amd64/v3` `--platform linux/arm64/v8`
			if (slash2 !== -1) {
				return {
					os: <GoOS> common.buildxPlatform.slice(0, slash1),
					arch: <GoARCH> common.buildxPlatform.slice(slash1 + 1, slash2),
					variant: common.buildxPlatform.slice(slash2 + 1),
				};
			}
			// `--platform linux/amd64` and `--platform linux/arm64`
			return {
				os: <GoOS> common.buildxPlatform.slice(0, slash1),
				arch: <GoARCH> common.buildxPlatform.slice(slash1 + 1),
			};
		} else {
			// `--platform` omitted
			return {
				os: mapNodeOSToGOOS(cliHost.platform),
				arch: mapNodeArchitectureToGOARCH(cliHost.arch),
			};
		}
	})();

	const buildKitVersion = options.useBuildKit === 'never' ? undefined : (await dockerBuildKitVersion({
		cliHost,
		dockerCLI: dockerPath,
		dockerComposeCLI,
		env: cliHost.env,
		output,
		platformInfo
	}));
	return {
		common,
		parsedAuthority,
		dockerCLI: dockerPath,
		isPodman: await isPodman({ exec: cliHost.exec, cmd: dockerPath, env: cliHost.env, output }),
		dockerComposeCLI: dockerComposeCLI,
		dockerEnv: cliHost.env,
		workspaceMountConsistencyDefault: workspaceMountConsistency,
		gpuAvailability: gpuAvailability || 'detect',
		mountWorkspaceGitRoot,
		updateRemoteUserUIDOnMacOS: false,
		cacheMount: 'bind',
		removeOnStartup: options.removeExistingContainer,
		buildNoCache: options.buildNoCache,
		expectExistingContainer: options.expectExistingContainer,
		additionalMounts,
		userRepositoryConfigurationPaths: [],
		updateRemoteUserUIDDefault,
		additionalCacheFroms: options.additionalCacheFroms,
		buildKitVersion,
		isTTY: process.stdout.isTTY || options.logFormat === 'json',
		experimentalLockfile,
		experimentalFrozenLockfile,
		buildxPlatform: common.buildxPlatform,
		buildxPush: common.buildxPush,
		additionalLabels: options.additionalLabels,
		buildxOutput: common.buildxOutput,
		buildxCacheTo: common.buildxCacheTo,
		platformInfo
	};
}

export interface LogOptions {
	logLevel: LogLevel;
	logFormat: LogFormat;
	log: (text: string) => void;
	terminalDimensions: LogDimensions | undefined;
	onDidChangeTerminalDimensions?: Event<LogDimensions>;
}

export function createLog(options: LogOptions, pkg: PackageConfiguration, sessionStart: Date, disposables: (() => Promise<unknown> | undefined)[], omitHeader?: boolean, secrets?: Record<string, string>) {
	const header = omitHeader ? undefined : `${pkg.name} ${pkg.version}. Node.js ${process.version}. ${os.platform()} ${os.release()} ${os.arch()}.`;
	const output = createLogFrom(options, sessionStart, header, secrets);
	output.dimensions = options.terminalDimensions;
	output.onDidChangeDimensions = options.onDidChangeTerminalDimensions;
	disposables.push(() => output.join());
	return output;
}

function createLogFrom({ log: write, logLevel, logFormat }: LogOptions, sessionStart: Date, header: string | undefined = undefined, secrets?: Record<string, string>): Log & { join(): Promise<void> } {
	const handler = logFormat === 'json' ? createJSONLog(write, () => logLevel, sessionStart) :
		process.stdout.isTTY ? createTerminalLog(write, () => logLevel, sessionStart) :
			createPlainLog(write, () => logLevel);
	const log = {
		...makeLog(createCombinedLog([maskSecrets(handler, secrets)], header)),
		join: async () => {
			// TODO: wait for write() to finish.
		},
	};
	return log;
}

function maskSecrets(handler: LogHandler, secrets?: Record<string, string>): LogHandler {
	if (secrets) {
		const mask = '********';
		const secretValues = Object.values(secrets);
		return replaceAllLog(handler, secretValues, mask);
	}

	return handler;
}
</file>

<file path="src/spec-node/devContainersSpecCLI.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import yargs, { Argv } from 'yargs';
import textTable from 'text-table';

import * as jsonc from 'jsonc-parser';

import { createDockerParams, createLog, launch, ProvisionOptions } from './devContainers';
import { SubstitutedConfig, createContainerProperties, envListToObj, inspectDockerImage, isDockerFileConfig, SubstituteConfig, addSubstitution, findContainerAndIdLabels, getCacheFolder, runAsyncHandler } from './utils';
import { URI } from 'vscode-uri';
import { ContainerError } from '../spec-common/errors';
import { Log, LogDimensions, LogLevel, makeLog, mapLogLevel } from '../spec-utils/log';
import { probeRemoteEnv, runLifecycleHooks, runRemoteCommand, UserEnvProbe, setupInContainer } from '../spec-common/injectHeadless';
import { extendImage } from './containerFeatures';
import { dockerCLI, DockerCLIParameters, dockerPtyCLI, inspectContainer } from '../spec-shutdown/dockerUtils';
import { buildAndExtendDockerCompose, dockerComposeCLIConfig, getDefaultImageName, getProjectName, readDockerComposeConfig, readVersionPrefix } from './dockerCompose';
import { DevContainerFromDockerComposeConfig, DevContainerFromDockerfileConfig, getDockerComposeFilePaths } from '../spec-configuration/configuration';
import { workspaceFromPath } from '../spec-utils/workspaces';
import { readDevContainerConfigFile } from './configContainer';
import { getDefaultDevContainerConfigPath, getDevContainerConfigPathIn, uriToFsPath } from '../spec-configuration/configurationCommonUtils';
import { CLIHost, getCLIHost } from '../spec-common/cliHost';
import { loadNativeModule, processSignals } from '../spec-common/commonUtils';
import { loadVersionInfo } from '../spec-configuration/containerFeaturesConfiguration';
import { featuresTestOptions, featuresTestHandler } from './featuresCLI/test';
import { featuresPackageHandler, featuresPackageOptions } from './featuresCLI/package';
import { featuresPublishHandler, featuresPublishOptions } from './featuresCLI/publish';
import { beforeContainerSubstitute, containerSubstitute, substitute } from '../spec-common/variableSubstitution';
import { getPackageConfig, } from '../spec-utils/product';
import { getDevcontainerMetadata, getImageBuildInfo, getImageMetadataFromContainer, ImageMetadataEntry, lifecycleCommandOriginMapFromMetadata, mergeConfiguration, MergedDevContainerConfig } from './imageMetadata';
import { templatesPublishHandler, templatesPublishOptions } from './templatesCLI/publish';
import { templateApplyHandler, templateApplyOptions } from './templatesCLI/apply';
import { featuresInfoHandler as featuresInfoHandler, featuresInfoOptions } from './featuresCLI/info';
import { bailOut, buildNamedImageAndExtend } from './singleContainer';
import { Event, NodeEventEmitter } from '../spec-utils/event';
import { ensureNoDisallowedFeatures } from './disallowedFeatures';
import { featuresResolveDependenciesHandler, featuresResolveDependenciesOptions } from './featuresCLI/resolveDependencies';
import { getFeatureIdWithoutVersion } from '../spec-configuration/containerFeaturesOCI';
import { featuresUpgradeHandler, featuresUpgradeOptions } from './upgradeCommand';
import { readFeaturesConfig } from './featureUtils';
import { featuresGenerateDocsHandler, featuresGenerateDocsOptions } from './featuresCLI/generateDocs';
import { templatesGenerateDocsHandler, templatesGenerateDocsOptions } from './templatesCLI/generateDocs';
import { mapNodeOSToGOOS, mapNodeArchitectureToGOARCH } from '../spec-configuration/containerCollectionsOCI';
import { templateMetadataHandler, templateMetadataOptions } from './templatesCLI/metadata';

const defaultDefaultUserEnvProbe: UserEnvProbe = 'loginInteractiveShell';

const mountRegex = /^type=(bind|volume),source=([^,]+),target=([^,]+)(?:,external=(true|false))?$/;

(async () => {

	const packageFolder = path.join(__dirname, '..', '..');
	const version = getPackageConfig().version;
	const argv = process.argv.slice(2);
	const restArgs = argv[0] === 'exec' && argv[1] !== '--help'; // halt-at-non-option doesn't work in subcommands: https://github.com/yargs/yargs/issues/1417
	const y = yargs([])
		.parserConfiguration({
			// By default, yargs allows `--no-myoption` to set a boolean `--myoption` to false
			// Disable this to allow `--no-cache` on the `build` command to align with `docker build` syntax
			'boolean-negation': false,
			'halt-at-non-option': restArgs,
		})
		.scriptName('devcontainer')
		.version(version)
		.demandCommand()
		.strict();
	y.wrap(Math.min(120, y.terminalWidth()));
	y.command('up', 'Create and run dev container', provisionOptions, provisionHandler);
	y.command('set-up', 'Set up an existing container as a dev container', setUpOptions, setUpHandler);
	y.command('build [path]', 'Build a dev container image', buildOptions, buildHandler);
	y.command('run-user-commands', 'Run user commands', runUserCommandsOptions, runUserCommandsHandler);
	y.command('read-configuration', 'Read configuration', readConfigurationOptions, readConfigurationHandler);
	y.command('outdated', 'Show current and available versions', outdatedOptions, outdatedHandler);
	y.command('upgrade', 'Upgrade lockfile', featuresUpgradeOptions, featuresUpgradeHandler);
	y.command('features', 'Features commands', (y: Argv) => {
		y.command('test [target]', 'Test Features', featuresTestOptions, featuresTestHandler);
		y.command('package <target>', 'Package Features', featuresPackageOptions, featuresPackageHandler);
		y.command('publish <target>', 'Package and publish Features', featuresPublishOptions, featuresPublishHandler);
		y.command('info <mode> <feature>', 'Fetch metadata for a published Feature', featuresInfoOptions, featuresInfoHandler);
		y.command('resolve-dependencies', 'Read and resolve dependency graph from a configuration', featuresResolveDependenciesOptions, featuresResolveDependenciesHandler);
		y.command('generate-docs', 'Generate documentation', featuresGenerateDocsOptions, featuresGenerateDocsHandler);
	});
	y.command('templates', 'Templates commands', (y: Argv) => {
		y.command('apply', 'Apply a template to the project', templateApplyOptions, templateApplyHandler);
		y.command('publish <target>', 'Package and publish templates', templatesPublishOptions, templatesPublishHandler);
		y.command('metadata <templateId>', 'Fetch a published Template\'s metadata', templateMetadataOptions, templateMetadataHandler);
		y.command('generate-docs', 'Generate documentation', templatesGenerateDocsOptions, templatesGenerateDocsHandler);
	});
	y.command(restArgs ? ['exec', '*'] : ['exec <cmd> [args..]'], 'Execute a command on a running dev container', execOptions, execHandler);
	y.epilog(`devcontainer@${version} ${packageFolder}`);
	y.parse(restArgs ? argv.slice(1) : argv);

})().catch(console.error);

export type UnpackArgv<T> = T extends Argv<infer U> ? U : T;

function provisionOptions(y: Argv) {
	return y.options({
		'docker-path': { type: 'string', description: 'Docker CLI path.' },
		'docker-compose-path': { type: 'string', description: 'Docker Compose CLI path.' },
		'container-data-folder': { type: 'string', description: 'Container data folder where user data inside the container will be stored.' },
		'container-system-data-folder': { type: 'string', description: 'Container system data folder where system data inside the container will be stored.' },
		'workspace-folder': { type: 'string', description: 'Workspace folder path. The devcontainer.json will be looked up relative to this path.' },
		'workspace-mount-consistency': { choices: ['consistent' as 'consistent', 'cached' as 'cached', 'delegated' as 'delegated'], default: 'cached' as 'cached', description: 'Workspace mount consistency.' },
		'gpu-availability': { choices: ['all' as 'all', 'detect' as 'detect', 'none' as 'none'], default: 'detect' as 'detect', description: 'Availability of GPUs in case the dev container requires any. `all` expects a GPU to be available.' },
		'mount-workspace-git-root': { type: 'boolean', default: true, description: 'Mount the workspace using its Git root.' },
		'id-label': { type: 'string', description: 'Id label(s) of the format name=value. These will be set on the container and used to query for an existing container. If no --id-label is given, one will be inferred from the --workspace-folder path.' },
		'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
		'override-config': { type: 'string', description: 'devcontainer.json path to override any devcontainer.json in the workspace folder (or built-in configuration). This is required when there is no devcontainer.json otherwise.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level for the --terminal-log-file. When set to trace, the log level for --log-file will also be set to trace.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'terminal-columns': { type: 'number', implies: ['terminal-rows'], description: 'Number of columns to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'terminal-rows': { type: 'number', implies: ['terminal-columns'], description: 'Number of rows to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'default-user-env-probe': { choices: ['none' as 'none', 'loginInteractiveShell' as 'loginInteractiveShell', 'interactiveShell' as 'interactiveShell', 'loginShell' as 'loginShell'], default: defaultDefaultUserEnvProbe, description: 'Default value for the devcontainer.json\'s "userEnvProbe".' },
		'update-remote-user-uid-default': { choices: ['never' as 'never', 'on' as 'on', 'off' as 'off'], default: 'on' as 'on', description: 'Default for updating the remote user\'s UID and GID to the local user\'s one.' },
		'remove-existing-container': { type: 'boolean', default: false, description: 'Removes the dev container if it already exists.' },
		'build-no-cache': { type: 'boolean', default: false, description: 'Builds the image with `--no-cache` if the container does not exist.' },
		'expect-existing-container': { type: 'boolean', default: false, description: 'Fail if the container does not exist.' },
		'skip-post-create': { type: 'boolean', default: false, description: 'Do not run onCreateCommand, updateContentCommand, postCreateCommand, postStartCommand or postAttachCommand and do not install dotfiles.' },
		'skip-non-blocking-commands': { type: 'boolean', default: false, description: 'Stop running user commands after running the command configured with waitFor or the updateContentCommand by default.' },
		prebuild: { type: 'boolean', default: false, description: 'Stop after onCreateCommand and updateContentCommand, rerunning updateContentCommand if it has run before.' },
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'mount': { type: 'string', description: 'Additional mount point(s). Format: type=<bind|volume>,source=<source>,target=<target>[,external=<true|false>]' },
		'remote-env': { type: 'string', description: 'Remote environment variables of the format name=value. These will be added when executing the user commands.' },
		'cache-from': { type: 'string', description: 'Additional image to use as potential layer cache during image building' },
		'cache-to': { type: 'string', description: 'Additional image to use as potential layer cache during image building' },
		'buildkit': { choices: ['auto' as 'auto', 'never' as 'never'], default: 'auto' as 'auto', description: 'Control whether BuildKit should be used' },
		'additional-features': { type: 'string', description: 'Additional features to apply to the dev container (JSON as per "features" section in devcontainer.json)' },
		'skip-feature-auto-mapping': { type: 'boolean', default: false, hidden: true, description: 'Temporary option for testing.' },
		'skip-post-attach': { type: 'boolean', default: false, description: 'Do not run postAttachCommand.' },
		'dotfiles-repository': { type: 'string', description: 'URL of a dotfiles Git repository (e.g., https://github.com/owner/repository.git)' },
		'dotfiles-install-command': { type: 'string', description: 'The command to run after cloning the dotfiles repository. Defaults to run the first file of `install.sh`, `install`, `bootstrap.sh`, `bootstrap`, `setup.sh` and `setup` found in the dotfiles repository`s root folder.' },
		'dotfiles-target-path': { type: 'string', default: '~/dotfiles', description: 'The path to clone the dotfiles repository to. Defaults to `~/dotfiles`.' },
		'container-session-data-folder': { type: 'string', description: 'Folder to cache CLI data, for example userEnvProbe results' },
		'omit-config-remote-env-from-metadata': { type: 'boolean', default: false, hidden: true, description: 'Omit remoteEnv from devcontainer.json for container metadata label' },
		'secrets-file': { type: 'string', description: 'Path to a json file containing secret environment variables as key-value pairs.' },
		'experimental-lockfile': { type: 'boolean', default: false, hidden: true, description: 'Write lockfile' },
		'experimental-frozen-lockfile': { type: 'boolean', default: false, hidden: true, description: 'Ensure lockfile remains unchanged' },
		'omit-syntax-directive': { type: 'boolean', default: false, hidden: true, description: 'Omit Dockerfile syntax directives' },
		'include-configuration': { type: 'boolean', default: false, description: 'Include configuration in result.' },
		'include-merged-configuration': { type: 'boolean', default: false, description: 'Include merged configuration in result.' },
	})
		.check(argv => {
			const idLabels = (argv['id-label'] && (Array.isArray(argv['id-label']) ? argv['id-label'] : [argv['id-label']])) as string[] | undefined;
			if (idLabels?.some(idLabel => !/.+=.+/.test(idLabel))) {
				throw new Error('Unmatched argument format: id-label must match <name>=<value>');
			}
			if (!(argv['workspace-folder'] || argv['id-label'])) {
				throw new Error('Missing required argument: workspace-folder or id-label');
			}
			if (!(argv['workspace-folder'] || argv['override-config'])) {
				throw new Error('Missing required argument: workspace-folder or override-config');
			}
			const mounts = (argv.mount && (Array.isArray(argv.mount) ? argv.mount : [argv.mount])) as string[] | undefined;
			if (mounts?.some(mount => !mountRegex.test(mount))) {
				throw new Error('Unmatched argument format: mount must match type=<bind|volume>,source=<source>,target=<target>[,external=<true|false>]');
			}
			const remoteEnvs = (argv['remote-env'] && (Array.isArray(argv['remote-env']) ? argv['remote-env'] : [argv['remote-env']])) as string[] | undefined;
			if (remoteEnvs?.some(remoteEnv => !/.+=.*/.test(remoteEnv))) {
				throw new Error('Unmatched argument format: remote-env must match <name>=<value>');
			}
			return true;
		});
}

type ProvisionArgs = UnpackArgv<ReturnType<typeof provisionOptions>>;

function provisionHandler(args: ProvisionArgs) {
	runAsyncHandler(provision.bind(null, args));
}

async function provision({
	'user-data-folder': persistedFolder,
	'docker-path': dockerPath,
	'docker-compose-path': dockerComposePath,
	'container-data-folder': containerDataFolder,
	'container-system-data-folder': containerSystemDataFolder,
	'workspace-folder': workspaceFolderArg,
	'workspace-mount-consistency': workspaceMountConsistency,
	'gpu-availability': gpuAvailability,
	'mount-workspace-git-root': mountWorkspaceGitRoot,
	'id-label': idLabel,
	config,
	'override-config': overrideConfig,
	'log-level': logLevel,
	'log-format': logFormat,
	'terminal-rows': terminalRows,
	'terminal-columns': terminalColumns,
	'default-user-env-probe': defaultUserEnvProbe,
	'update-remote-user-uid-default': updateRemoteUserUIDDefault,
	'remove-existing-container': removeExistingContainer,
	'build-no-cache': buildNoCache,
	'expect-existing-container': expectExistingContainer,
	'skip-post-create': skipPostCreate,
	'skip-non-blocking-commands': skipNonBlocking,
	prebuild,
	mount,
	'remote-env': addRemoteEnv,
	'cache-from': addCacheFrom,
	'cache-to': addCacheTo,
	'buildkit': buildkit,
	'additional-features': additionalFeaturesJson,
	'skip-feature-auto-mapping': skipFeatureAutoMapping,
	'skip-post-attach': skipPostAttach,
	'dotfiles-repository': dotfilesRepository,
	'dotfiles-install-command': dotfilesInstallCommand,
	'dotfiles-target-path': dotfilesTargetPath,
	'container-session-data-folder': containerSessionDataFolder,
	'omit-config-remote-env-from-metadata': omitConfigRemotEnvFromMetadata,
	'secrets-file': secretsFile,
	'experimental-lockfile': experimentalLockfile,
	'experimental-frozen-lockfile': experimentalFrozenLockfile,
	'omit-syntax-directive': omitSyntaxDirective,
	'include-configuration': includeConfig,
	'include-merged-configuration': includeMergedConfig,
}: ProvisionArgs) {

	const workspaceFolder = workspaceFolderArg ? path.resolve(process.cwd(), workspaceFolderArg) : undefined;
	const addRemoteEnvs = addRemoteEnv ? (Array.isArray(addRemoteEnv) ? addRemoteEnv as string[] : [addRemoteEnv]) : [];
	const addCacheFroms = addCacheFrom ? (Array.isArray(addCacheFrom) ? addCacheFrom as string[] : [addCacheFrom]) : [];
	const additionalFeatures = additionalFeaturesJson ? jsonc.parse(additionalFeaturesJson) as Record<string, string | boolean | Record<string, string | boolean>> : {};
	const providedIdLabels = idLabel ? Array.isArray(idLabel) ? idLabel as string[] : [idLabel] : undefined;

	const cwd = workspaceFolder || process.cwd();
	const cliHost = await getCLIHost(cwd, loadNativeModule, logFormat === 'text');
	const secretsP = readSecretsFromFile({ secretsFile, cliHost });

	const options: ProvisionOptions = {
		dockerPath,
		dockerComposePath,
		containerDataFolder,
		containerSystemDataFolder,
		workspaceFolder,
		workspaceMountConsistency,
		gpuAvailability,
		mountWorkspaceGitRoot,
		configFile: config ? URI.file(path.resolve(process.cwd(), config)) : undefined,
		overrideConfigFile: overrideConfig ? URI.file(path.resolve(process.cwd(), overrideConfig)) : undefined,
		logLevel: mapLogLevel(logLevel),
		logFormat,
		log: text => process.stderr.write(text),
		terminalDimensions: terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : undefined,
		defaultUserEnvProbe,
		removeExistingContainer,
		buildNoCache,
		expectExistingContainer,
		postCreateEnabled: !skipPostCreate,
		skipNonBlocking,
		prebuild,
		persistedFolder,
		additionalMounts: mount ? (Array.isArray(mount) ? mount : [mount]).map(mount => {
			const [, type, source, target, external] = mountRegex.exec(mount)!;
			return {
				type: type as 'bind' | 'volume',
				source,
				target,
				external: external === 'true'
			};
		}) : [],
		dotfiles: {
			repository: dotfilesRepository,
			installCommand: dotfilesInstallCommand,
			targetPath: dotfilesTargetPath,
		},
		updateRemoteUserUIDDefault,
		remoteEnv: envListToObj(addRemoteEnvs),
		secretsP,
		additionalCacheFroms: addCacheFroms,
		useBuildKit: buildkit,
		buildxPlatform: undefined,
		buildxPush: false,
		additionalLabels: [],
		buildxOutput: undefined,
		buildxCacheTo: addCacheTo,
		additionalFeatures,
		skipFeatureAutoMapping,
		skipPostAttach,
		containerSessionDataFolder,
		skipPersistingCustomizationsFromFeatures: false,
		omitConfigRemotEnvFromMetadata,
		experimentalLockfile,
		experimentalFrozenLockfile,
		omitSyntaxDirective,
		includeConfig,
		includeMergedConfig,
	};

	const result = await doProvision(options, providedIdLabels);
	const exitCode = result.outcome === 'error' ? 1 : 0;
	await new Promise<void>((resolve, reject) => {
		process.stdout.write(JSON.stringify(result) + '\n', err => err ? reject(err) : resolve());
	});
	if (result.outcome === 'success') {
		await result.finishBackgroundTasks();
	}
	await result.dispose();
	process.exit(exitCode);
}

async function doProvision(options: ProvisionOptions, providedIdLabels: string[] | undefined) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	try {
		const result = await launch(options, providedIdLabels, disposables);
		return {
			outcome: 'success' as 'success',
			dispose,
			...result,
		};
	} catch (originalError) {
		const originalStack = originalError?.stack;
		const err = originalError instanceof ContainerError ? originalError : new ContainerError({
			description: 'An error occurred setting up the container.',
			originalError
		});
		if (originalStack) {
			console.error(originalStack);
		}
		return {
			outcome: 'error' as 'error',
			message: err.message,
			description: err.description,
			containerId: err.containerId,
			disallowedFeatureId: err.data.disallowedFeatureId,
			didStopContainer: err.data.didStopContainer,
			learnMoreUrl: err.data.learnMoreUrl,
			dispose,
		};
	}
}

function setUpOptions(y: Argv) {
	return y.options({
		'docker-path': { type: 'string', description: 'Docker CLI path.' },
		'container-data-folder': { type: 'string', description: 'Container data folder where user data inside the container will be stored.' },
		'container-system-data-folder': { type: 'string', description: 'Container system data folder where system data inside the container will be stored.' },
		'container-id': { type: 'string', required: true, description: 'Id of the container.' },
		'config': { type: 'string', description: 'devcontainer.json path.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level for the --terminal-log-file. When set to trace, the log level for --log-file will also be set to trace.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'terminal-columns': { type: 'number', implies: ['terminal-rows'], description: 'Number of columns to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'terminal-rows': { type: 'number', implies: ['terminal-columns'], description: 'Number of rows to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'default-user-env-probe': { choices: ['none' as 'none', 'loginInteractiveShell' as 'loginInteractiveShell', 'interactiveShell' as 'interactiveShell', 'loginShell' as 'loginShell'], default: defaultDefaultUserEnvProbe, description: 'Default value for the devcontainer.json\'s "userEnvProbe".' },
		'skip-post-create': { type: 'boolean', default: false, description: 'Do not run onCreateCommand, updateContentCommand, postCreateCommand, postStartCommand or postAttachCommand and do not install dotfiles.' },
		'skip-non-blocking-commands': { type: 'boolean', default: false, description: 'Stop running user commands after running the command configured with waitFor or the updateContentCommand by default.' },
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'remote-env': { type: 'string', description: 'Remote environment variables of the format name=value. These will be added when executing the user commands.' },
		'dotfiles-repository': { type: 'string', description: 'URL of a dotfiles Git repository (e.g., https://github.com/owner/repository.git)' },
		'dotfiles-install-command': { type: 'string', description: 'The command to run after cloning the dotfiles repository. Defaults to run the first file of `install.sh`, `install`, `bootstrap.sh`, `bootstrap`, `setup.sh` and `setup` found in the dotfiles repository`s root folder.' },
		'dotfiles-target-path': { type: 'string', default: '~/dotfiles', description: 'The path to clone the dotfiles repository to. Defaults to `~/dotfiles`.' },
		'container-session-data-folder': { type: 'string', description: 'Folder to cache CLI data, for example userEnvProbe results' },
		'include-configuration': { type: 'boolean', default: false, description: 'Include configuration in result.' },
		'include-merged-configuration': { type: 'boolean', default: false, description: 'Include merged configuration in result.' },
	})
		.check(argv => {
			const remoteEnvs = (argv['remote-env'] && (Array.isArray(argv['remote-env']) ? argv['remote-env'] : [argv['remote-env']])) as string[] | undefined;
			if (remoteEnvs?.some(remoteEnv => !/.+=.*/.test(remoteEnv))) {
				throw new Error('Unmatched argument format: remote-env must match <name>=<value>');
			}
			return true;
		});
}

type SetUpArgs = UnpackArgv<ReturnType<typeof setUpOptions>>;

function setUpHandler(args: SetUpArgs) {
	runAsyncHandler(setUp.bind(null, args));
}

async function setUp(args: SetUpArgs) {
	const result = await doSetUp(args);
	const exitCode = result.outcome === 'error' ? 1 : 0;
	await new Promise<void>((resolve, reject) => {
		process.stdout.write(JSON.stringify(result) + '\n', err => err ? reject(err) : resolve());
	});
	await result.dispose();
	process.exit(exitCode);
}

async function doSetUp({
	'user-data-folder': persistedFolder,
	'docker-path': dockerPath,
	'container-data-folder': containerDataFolder,
	'container-system-data-folder': containerSystemDataFolder,
	'container-id': containerId,
	config: configParam,
	'log-level': logLevel,
	'log-format': logFormat,
	'terminal-rows': terminalRows,
	'terminal-columns': terminalColumns,
	'default-user-env-probe': defaultUserEnvProbe,
	'skip-post-create': skipPostCreate,
	'skip-non-blocking-commands': skipNonBlocking,
	'remote-env': addRemoteEnv,
	'dotfiles-repository': dotfilesRepository,
	'dotfiles-install-command': dotfilesInstallCommand,
	'dotfiles-target-path': dotfilesTargetPath,
	'container-session-data-folder': containerSessionDataFolder,
	'include-configuration': includeConfig,
	'include-merged-configuration': includeMergedConfig,
}: SetUpArgs) {

	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	try {
		const addRemoteEnvs = addRemoteEnv ? (Array.isArray(addRemoteEnv) ? addRemoteEnv as string[] : [addRemoteEnv]) : [];
		const configFile = configParam ? URI.file(path.resolve(process.cwd(), configParam)) : undefined;
		const params = await createDockerParams({
			dockerPath,
			dockerComposePath: undefined,
			containerSessionDataFolder,
			containerDataFolder,
			containerSystemDataFolder,
			workspaceFolder: undefined,
			mountWorkspaceGitRoot: false,
			configFile,
			overrideConfigFile: undefined,
			logLevel: mapLogLevel(logLevel),
			logFormat,
			log: text => process.stderr.write(text),
			terminalDimensions: terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : undefined,
			defaultUserEnvProbe,
			removeExistingContainer: false,
			buildNoCache: false,
			expectExistingContainer: false,
			postCreateEnabled: !skipPostCreate,
			skipNonBlocking,
			prebuild: false,
			persistedFolder,
			additionalMounts: [],
			updateRemoteUserUIDDefault: 'never',
			remoteEnv: envListToObj(addRemoteEnvs),
			additionalCacheFroms: [],
			useBuildKit: 'auto',
			buildxPlatform: undefined,
			buildxPush: false,
			additionalLabels: [],
			buildxOutput: undefined,
			buildxCacheTo: undefined,
			skipFeatureAutoMapping: false,
			skipPostAttach: false,
			skipPersistingCustomizationsFromFeatures: false,
			dotfiles: {
				repository: dotfilesRepository,
				installCommand: dotfilesInstallCommand,
				targetPath: dotfilesTargetPath,
			},
		}, disposables);

		const { common } = params;
		const { cliHost, output } = common;
		const configs = configFile && await readDevContainerConfigFile(cliHost, undefined, configFile, params.mountWorkspaceGitRoot, output, undefined, undefined);
		if (configFile && !configs) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile, cliHost.platform)}) not found.` });
		}

		const config0 = configs?.config || {
			raw: {},
			config: {},
			substitute: value => substitute({ platform: cliHost.platform, env: cliHost.env }, value)
		};

		const container = await inspectContainer(params, containerId);
		if (!container) {
			bailOut(common.output, 'Dev container not found.');
		}

		const config = addSubstitution(config0, config => beforeContainerSubstitute(undefined, config));

		const imageMetadata = getImageMetadataFromContainer(container, config, undefined, undefined, output).config;
		const mergedConfig = mergeConfiguration(config.config, imageMetadata);
		const containerProperties = await createContainerProperties(params, container.Id, configs?.workspaceConfig.workspaceFolder, mergedConfig.remoteUser);
		const res = await setupInContainer(common, containerProperties, config.config, mergedConfig, lifecycleCommandOriginMapFromMetadata(imageMetadata));
		return {
			outcome: 'success' as 'success',
			configuration: includeConfig ? res.updatedConfig : undefined,
			mergedConfiguration: includeMergedConfig ? res.updatedMergedConfig : undefined,
			dispose,
		};
	} catch (originalError) {
		const originalStack = originalError?.stack;
		const err = originalError instanceof ContainerError ? originalError : new ContainerError({
			description: 'An error occurred running user commands in the container.',
			originalError
		});
		if (originalStack) {
			console.error(originalStack);
		}
		return {
			outcome: 'error' as 'error',
			message: err.message,
			description: err.description,
			dispose,
		};
	}
}

function buildOptions(y: Argv) {
	return y.options({
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'docker-path': { type: 'string', description: 'Docker CLI path.' },
		'docker-compose-path': { type: 'string', description: 'Docker Compose CLI path.' },
		'workspace-folder': { type: 'string', required: true, description: 'Workspace folder path. The devcontainer.json will be looked up relative to this path.' },
		'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'no-cache': { type: 'boolean', default: false, description: 'Builds the image with `--no-cache`.' },
		'image-name': { type: 'string', description: 'Image name.' },
		'cache-from': { type: 'string', description: 'Additional image to use as potential layer cache' },
		'cache-to': { type: 'string', description: 'A destination of buildx cache' },
		'buildkit': { choices: ['auto' as 'auto', 'never' as 'never'], default: 'auto' as 'auto', description: 'Control whether BuildKit should be used' },
		'platform': { type: 'string', description: 'Set target platforms.' },
		'push': { type: 'boolean', default: false, description: 'Push to a container registry.' },
		'label': { type: 'string', description: 'Provide key and value configuration that adds metadata to an image' },
		'output': { type: 'string', description: 'Overrides the default behavior to load built images into the local docker registry. Valid options are the same ones provided to the --output option of docker buildx build.' },
		'additional-features': { type: 'string', description: 'Additional features to apply to the dev container (JSON as per "features" section in devcontainer.json)' },
		'skip-feature-auto-mapping': { type: 'boolean', default: false, hidden: true, description: 'Temporary option for testing.' },
		'skip-persisting-customizations-from-features': { type: 'boolean', default: false, hidden: true, description: 'Do not save customizations from referenced Features as image metadata' },
		'experimental-lockfile': { type: 'boolean', default: false, hidden: true, description: 'Write lockfile' },
		'experimental-frozen-lockfile': { type: 'boolean', default: false, hidden: true, description: 'Ensure lockfile remains unchanged' },
		'omit-syntax-directive': { type: 'boolean', default: false, hidden: true, description: 'Omit Dockerfile syntax directives' },
	});
}

type BuildArgs = UnpackArgv<ReturnType<typeof buildOptions>>;

function buildHandler(args: BuildArgs) {
	runAsyncHandler(build.bind(null, args));
}

async function build(args: BuildArgs) {
	const result = await doBuild(args);
	const exitCode = result.outcome === 'error' ? 1 : 0;
	await new Promise<void>((resolve, reject) => {
		process.stdout.write(JSON.stringify(result) + '\n', err => err ? reject(err) : resolve());
	});
	await result.dispose();
	process.exit(exitCode);
}

async function doBuild({
	'user-data-folder': persistedFolder,
	'docker-path': dockerPath,
	'docker-compose-path': dockerComposePath,
	'workspace-folder': workspaceFolderArg,
	config: configParam,
	'log-level': logLevel,
	'log-format': logFormat,
	'no-cache': buildNoCache,
	'image-name': argImageName,
	'cache-from': addCacheFrom,
	'buildkit': buildkit,
	'platform': buildxPlatform,
	'push': buildxPush,
	'label': buildxLabel,
	'output': buildxOutput,
	'cache-to': buildxCacheTo,
	'additional-features': additionalFeaturesJson,
	'skip-feature-auto-mapping': skipFeatureAutoMapping,
	'skip-persisting-customizations-from-features': skipPersistingCustomizationsFromFeatures,
	'experimental-lockfile': experimentalLockfile,
	'experimental-frozen-lockfile': experimentalFrozenLockfile,
	'omit-syntax-directive': omitSyntaxDirective,
}: BuildArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	try {
		const workspaceFolder = path.resolve(process.cwd(), workspaceFolderArg);
		const configFile: URI | undefined = configParam ? URI.file(path.resolve(process.cwd(), configParam)) : undefined;
		const overrideConfigFile: URI | undefined = /* overrideConfig ? URI.file(path.resolve(process.cwd(), overrideConfig)) : */ undefined;
		const addCacheFroms = addCacheFrom ? (Array.isArray(addCacheFrom) ? addCacheFrom as string[] : [addCacheFrom]) : [];
		const additionalFeatures = additionalFeaturesJson ? jsonc.parse(additionalFeaturesJson) as Record<string, string | boolean | Record<string, string | boolean>> : {};
		const params = await createDockerParams({
			dockerPath,
			dockerComposePath,
			containerDataFolder: undefined,
			containerSystemDataFolder: undefined,
			workspaceFolder,
			mountWorkspaceGitRoot: false,
			configFile,
			overrideConfigFile,
			logLevel: mapLogLevel(logLevel),
			logFormat,
			log: text => process.stderr.write(text),
			terminalDimensions: /* terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : */ undefined, // TODO
			defaultUserEnvProbe: 'loginInteractiveShell',
			removeExistingContainer: false,
			buildNoCache,
			expectExistingContainer: false,
			postCreateEnabled: false,
			skipNonBlocking: false,
			prebuild: false,
			persistedFolder,
			additionalMounts: [],
			updateRemoteUserUIDDefault: 'never',
			remoteEnv: {},
			additionalCacheFroms: addCacheFroms,
			useBuildKit: buildkit,
			buildxPlatform,
			buildxPush,
			additionalLabels: [],
			buildxOutput,
			buildxCacheTo,
			skipFeatureAutoMapping,
			skipPostAttach: true,
			skipPersistingCustomizationsFromFeatures: skipPersistingCustomizationsFromFeatures,
			dotfiles: {},
			experimentalLockfile,
			experimentalFrozenLockfile,
			omitSyntaxDirective,
		}, disposables);

		const { common, dockerComposeCLI } = params;
		const { cliHost, env, output } = common;
		const workspace = workspaceFromPath(cliHost.path, workspaceFolder);
		const configPath = configFile ? configFile : workspace
			? (await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath)
				|| (overrideConfigFile ? getDefaultDevContainerConfigPath(cliHost, workspace.configFolderPath) : undefined))
			: overrideConfigFile;
		const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, params.mountWorkspaceGitRoot, output, undefined, overrideConfigFile) || undefined;
		if (!configs) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
		}
		const configWithRaw = configs.config;
		const { config } = configWithRaw;
		let imageNameResult: string[] = [''];

		if (buildxOutput && buildxPush) {
			throw new ContainerError({ description: '--push true cannot be used with --output.' });
		}

		const buildParams: DockerCLIParameters = { cliHost, dockerCLI: params.dockerCLI, dockerComposeCLI, env, output, platformInfo: params.platformInfo };
		await ensureNoDisallowedFeatures(buildParams, config, additionalFeatures, undefined);

		// Support multiple use of `--image-name`
		const imageNames = (argImageName && (Array.isArray(argImageName) ? argImageName : [argImageName]) as string[]) || undefined;

		// Support multiple use of `--label`
		params.additionalLabels = (buildxLabel && (Array.isArray(buildxLabel) ? buildxLabel : [buildxLabel]) as string[]) || [];

		if (isDockerFileConfig(config)) {

			// Build the base image and extend with features etc.
			let { updatedImageName } = await buildNamedImageAndExtend(params, configWithRaw as SubstitutedConfig<DevContainerFromDockerfileConfig>, additionalFeatures, false, imageNames);

			if (imageNames) {
				imageNameResult = imageNames;
			} else {
				imageNameResult = updatedImageName;
			}
		} else if ('dockerComposeFile' in config) {

			if (buildxPlatform || buildxPush) {
				throw new ContainerError({ description: '--platform or --push not supported.' });
			}

			if (buildxOutput) {
				throw new ContainerError({ description: '--output not supported.' });
			}

			if (buildxCacheTo) {
				throw new ContainerError({ description: '--cache-to not supported.' });
			}

			const cwdEnvFile = cliHost.path.join(cliHost.cwd, '.env');
			const envFile = Array.isArray(config.dockerComposeFile) && config.dockerComposeFile.length === 0 && await cliHost.isFile(cwdEnvFile) ? cwdEnvFile : undefined;
			const composeFiles = await getDockerComposeFilePaths(cliHost, config, cliHost.env, workspaceFolder);

			// If dockerComposeFile is an array, add -f <file> in order. https://docs.docker.com/compose/extends/#multiple-compose-files
			const composeGlobalArgs = ([] as string[]).concat(...composeFiles.map(composeFile => ['-f', composeFile]));
			if (envFile) {
				composeGlobalArgs.push('--env-file', envFile);
			}
			
			const composeConfig = await readDockerComposeConfig(buildParams, composeFiles, envFile);
			const projectName = await getProjectName(params, workspace, composeFiles, composeConfig);
			const services = Object.keys(composeConfig.services || {});
			if (services.indexOf(config.service) === -1) {
				throw new Error(`Service '${config.service}' configured in devcontainer.json not found in Docker Compose configuration.`);
			}

			const versionPrefix = await readVersionPrefix(cliHost, composeFiles);
			const infoParams = { ...params, common: { ...params.common, output: makeLog(buildParams.output, LogLevel.Info) } };
			const { overrideImageName } = await buildAndExtendDockerCompose(configWithRaw as SubstitutedConfig<DevContainerFromDockerComposeConfig>, projectName, infoParams, composeFiles, envFile, composeGlobalArgs, [config.service], params.buildNoCache || false, params.common.persistedFolder, 'docker-compose.devcontainer.build', versionPrefix, additionalFeatures, false, addCacheFroms);

			const service = composeConfig.services[config.service];
			const originalImageName = overrideImageName || service.image || getDefaultImageName(await buildParams.dockerComposeCLI(), projectName, config.service);

			if (imageNames) {
				// Future improvement: Compose 2.6.0 (released 2022-05-30) added `tags` to the compose file.
				if (params.isTTY) {
					await Promise.all(imageNames.map(imageName => dockerPtyCLI(params, 'tag', originalImageName, imageName)));
				} else {
					await Promise.all(imageNames.map(imageName => dockerCLI(params, 'tag', originalImageName, imageName)));
				}
				imageNameResult = imageNames;
			} else {
				imageNameResult = originalImageName;
			}
		} else {

			if (!config.image) {
				throw new ContainerError({ description: 'No image information specified in devcontainer.json.' });
			}

			await inspectDockerImage(params, config.image, true);
			const { updatedImageName } = await extendImage(params, configWithRaw, config.image, imageNames || [], additionalFeatures, false);

			if (imageNames) {
				imageNameResult = imageNames;
			} else {
				imageNameResult = updatedImageName;
			}
		}

		return {
			outcome: 'success' as 'success',
			imageName: imageNameResult,
			dispose,
		};
	} catch (originalError) {
		const originalStack = originalError?.stack;
		const err = originalError instanceof ContainerError ? originalError : new ContainerError({
			description: 'An error occurred building the container.',
			originalError
		});
		if (originalStack) {
			console.error(originalStack);
		}
		return {
			outcome: 'error' as 'error',
			message: err.message,
			description: err.description,
			dispose,
		};
	}
}

function runUserCommandsOptions(y: Argv) {
	return y.options({
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'docker-path': { type: 'string', description: 'Docker CLI path.' },
		'docker-compose-path': { type: 'string', description: 'Docker Compose CLI path.' },
		'container-data-folder': { type: 'string', description: 'Container data folder where user data inside the container will be stored.' },
		'container-system-data-folder': { type: 'string', description: 'Container system data folder where system data inside the container will be stored.' },
		'workspace-folder': { type: 'string', description: 'Workspace folder path. The devcontainer.json will be looked up relative to this path.' },
		'mount-workspace-git-root': { type: 'boolean', default: true, description: 'Mount the workspace using its Git root.' },
		'container-id': { type: 'string', description: 'Id of the container to run the user commands for.' },
		'id-label': { type: 'string', description: 'Id label(s) of the format name=value. If no --container-id is given the id labels will be used to look up the container. If no --id-label is given, one will be inferred from the --workspace-folder path.' },
		'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
		'override-config': { type: 'string', description: 'devcontainer.json path to override any devcontainer.json in the workspace folder (or built-in configuration). This is required when there is no devcontainer.json otherwise.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level for the --terminal-log-file. When set to trace, the log level for --log-file will also be set to trace.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'terminal-columns': { type: 'number', implies: ['terminal-rows'], description: 'Number of columns to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'terminal-rows': { type: 'number', implies: ['terminal-columns'], description: 'Number of rows to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'default-user-env-probe': { choices: ['none' as 'none', 'loginInteractiveShell' as 'loginInteractiveShell', 'interactiveShell' as 'interactiveShell', 'loginShell' as 'loginShell'], default: defaultDefaultUserEnvProbe, description: 'Default value for the devcontainer.json\'s "userEnvProbe".' },
		'skip-non-blocking-commands': { type: 'boolean', default: false, description: 'Stop running user commands after running the command configured with waitFor or the updateContentCommand by default.' },
		prebuild: { type: 'boolean', default: false, description: 'Stop after onCreateCommand and updateContentCommand, rerunning updateContentCommand if it has run before.' },
		'stop-for-personalization': { type: 'boolean', default: false, description: 'Stop for personalization.' },
		'remote-env': { type: 'string', description: 'Remote environment variables of the format name=value. These will be added when executing the user commands.' },
		'skip-feature-auto-mapping': { type: 'boolean', default: false, hidden: true, description: 'Temporary option for testing.' },
		'skip-post-attach': { type: 'boolean', default: false, description: 'Do not run postAttachCommand.' },
		'dotfiles-repository': { type: 'string', description: 'URL of a dotfiles Git repository (e.g., https://github.com/owner/repository.git)' },
		'dotfiles-install-command': { type: 'string', description: 'The command to run after cloning the dotfiles repository. Defaults to run the first file of `install.sh`, `install`, `bootstrap.sh`, `bootstrap`, `setup.sh` and `setup` found in the dotfiles repository`s root folder.' },
		'dotfiles-target-path': { type: 'string', default: '~/dotfiles', description: 'The path to clone the dotfiles repository to. Defaults to `~/dotfiles`.' },
		'container-session-data-folder': { type: 'string', description: 'Folder to cache CLI data, for example userEnvProbe results' },
		'secrets-file': { type: 'string', description: 'Path to a json file containing secret environment variables as key-value pairs.' },
	})
		.check(argv => {
			const idLabels = (argv['id-label'] && (Array.isArray(argv['id-label']) ? argv['id-label'] : [argv['id-label']])) as string[] | undefined;
			if (idLabels?.some(idLabel => !/.+=.+/.test(idLabel))) {
				throw new Error('Unmatched argument format: id-label must match <name>=<value>');
			}
			const remoteEnvs = (argv['remote-env'] && (Array.isArray(argv['remote-env']) ? argv['remote-env'] : [argv['remote-env']])) as string[] | undefined;
			if (remoteEnvs?.some(remoteEnv => !/.+=.*/.test(remoteEnv))) {
				throw new Error('Unmatched argument format: remote-env must match <name>=<value>');
			}
			if (!argv['container-id'] && !idLabels?.length && !argv['workspace-folder']) {
				throw new Error('Missing required argument: One of --container-id, --id-label or --workspace-folder is required.');
			}
			return true;
		});
}

type RunUserCommandsArgs = UnpackArgv<ReturnType<typeof runUserCommandsOptions>>;

function runUserCommandsHandler(args: RunUserCommandsArgs) {
	runAsyncHandler(runUserCommands.bind(null, args));
}
async function runUserCommands(args: RunUserCommandsArgs) {
	const result = await doRunUserCommands(args);
	const exitCode = result.outcome === 'error' ? 1 : 0;
	await new Promise<void>((resolve, reject) => {
		process.stdout.write(JSON.stringify(result) + '\n', err => err ? reject(err) : resolve());
	});
	await result.dispose();
	process.exit(exitCode);
}

async function doRunUserCommands({
	'user-data-folder': persistedFolder,
	'docker-path': dockerPath,
	'docker-compose-path': dockerComposePath,
	'container-data-folder': containerDataFolder,
	'container-system-data-folder': containerSystemDataFolder,
	'workspace-folder': workspaceFolderArg,
	'mount-workspace-git-root': mountWorkspaceGitRoot,
	'container-id': containerId,
	'id-label': idLabel,
	config: configParam,
	'override-config': overrideConfig,
	'log-level': logLevel,
	'log-format': logFormat,
	'terminal-rows': terminalRows,
	'terminal-columns': terminalColumns,
	'default-user-env-probe': defaultUserEnvProbe,
	'skip-non-blocking-commands': skipNonBlocking,
	prebuild,
	'stop-for-personalization': stopForPersonalization,
	'remote-env': addRemoteEnv,
	'skip-feature-auto-mapping': skipFeatureAutoMapping,
	'skip-post-attach': skipPostAttach,
	'dotfiles-repository': dotfilesRepository,
	'dotfiles-install-command': dotfilesInstallCommand,
	'dotfiles-target-path': dotfilesTargetPath,
	'container-session-data-folder': containerSessionDataFolder,
	'secrets-file': secretsFile,
}: RunUserCommandsArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	try {
		const workspaceFolder = workspaceFolderArg ? path.resolve(process.cwd(), workspaceFolderArg) : undefined;
		const providedIdLabels = idLabel ? Array.isArray(idLabel) ? idLabel as string[] : [idLabel] : undefined;
		const addRemoteEnvs = addRemoteEnv ? (Array.isArray(addRemoteEnv) ? addRemoteEnv as string[] : [addRemoteEnv]) : [];
		const configFile = configParam ? URI.file(path.resolve(process.cwd(), configParam)) : undefined;
		const overrideConfigFile = overrideConfig ? URI.file(path.resolve(process.cwd(), overrideConfig)) : undefined;

		const cwd = workspaceFolder || process.cwd();
		const cliHost = await getCLIHost(cwd, loadNativeModule, logFormat === 'text');
		const secretsP = readSecretsFromFile({ secretsFile, cliHost });

		const params = await createDockerParams({
			dockerPath,
			dockerComposePath,
			containerDataFolder,
			containerSystemDataFolder,
			workspaceFolder,
			mountWorkspaceGitRoot,
			configFile,
			overrideConfigFile,
			logLevel: mapLogLevel(logLevel),
			logFormat,
			log: text => process.stderr.write(text),
			terminalDimensions: terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : undefined,
			defaultUserEnvProbe,
			removeExistingContainer: false,
			buildNoCache: false,
			expectExistingContainer: false,
			postCreateEnabled: true,
			skipNonBlocking,
			prebuild,
			persistedFolder,
			additionalMounts: [],
			updateRemoteUserUIDDefault: 'never',
			remoteEnv: envListToObj(addRemoteEnvs),
			additionalCacheFroms: [],
			useBuildKit: 'auto',
			buildxPlatform: undefined,
			buildxPush: false,
			additionalLabels: [],
			buildxOutput: undefined,
			buildxCacheTo: undefined,
			skipFeatureAutoMapping,
			skipPostAttach,
			skipPersistingCustomizationsFromFeatures: false,
			dotfiles: {
				repository: dotfilesRepository,
				installCommand: dotfilesInstallCommand,
				targetPath: dotfilesTargetPath,
			},
			containerSessionDataFolder,
			secretsP,
		}, disposables);

		const { common } = params;
		const { output } = common;
		const workspace = workspaceFolder ? workspaceFromPath(cliHost.path, workspaceFolder) : undefined;
		const configPath = configFile ? configFile : workspace
			? (await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath)
				|| (overrideConfigFile ? getDefaultDevContainerConfigPath(cliHost, workspace.configFolderPath) : undefined))
			: overrideConfigFile;
		const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, params.mountWorkspaceGitRoot, output, undefined, overrideConfigFile) || undefined;
		if ((configFile || workspaceFolder || overrideConfigFile) && !configs) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
		}

		const config0 = configs?.config || {
			raw: {},
			config: {},
			substitute: value => substitute({ platform: cliHost.platform, env: cliHost.env }, value)
		};

		const { container, idLabels } = await findContainerAndIdLabels(params, containerId, providedIdLabels, workspaceFolder, configPath?.fsPath);
		if (!container) {
			bailOut(common.output, 'Dev container not found.');
		}

		const config1 = addSubstitution(config0, config => beforeContainerSubstitute(envListToObj(idLabels), config));
		const config = addSubstitution(config1, config => containerSubstitute(cliHost.platform, config1.config.configFilePath, envListToObj(container.Config.Env), config));

		const imageMetadata = getImageMetadataFromContainer(container, config, undefined, idLabels, output).config;
		const mergedConfig = mergeConfiguration(config.config, imageMetadata);
		const containerProperties = await createContainerProperties(params, container.Id, configs?.workspaceConfig.workspaceFolder, mergedConfig.remoteUser);
		const updatedConfig = containerSubstitute(cliHost.platform, config.config.configFilePath, containerProperties.env, mergedConfig);
		const remoteEnvP = probeRemoteEnv(common, containerProperties, updatedConfig);
		const result = await runLifecycleHooks(common, lifecycleCommandOriginMapFromMetadata(imageMetadata), containerProperties, updatedConfig, remoteEnvP, secretsP, stopForPersonalization);
		return {
			outcome: 'success' as 'success',
			result,
			dispose,
		};
	} catch (originalError) {
		const originalStack = originalError?.stack;
		const err = originalError instanceof ContainerError ? originalError : new ContainerError({
			description: 'An error occurred running user commands in the container.',
			originalError
		});
		if (originalStack) {
			console.error(originalStack);
		}
		return {
			outcome: 'error' as 'error',
			message: err.message,
			description: err.description,
			dispose,
		};
	}
}


function readConfigurationOptions(y: Argv) {
	return y.options({
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'docker-path': { type: 'string', description: 'Docker CLI path.' },
		'docker-compose-path': { type: 'string', description: 'Docker Compose CLI path.' },
		'workspace-folder': { type: 'string', description: 'Workspace folder path. The devcontainer.json will be looked up relative to this path.' },
		'mount-workspace-git-root': { type: 'boolean', default: true, description: 'Mount the workspace using its Git root.' },
		'container-id': { type: 'string', description: 'Id of the container to run the user commands for.' },
		'id-label': { type: 'string', description: 'Id label(s) of the format name=value. If no --container-id is given the id labels will be used to look up the container. If no --id-label is given, one will be inferred from the --workspace-folder path.' },
		'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
		'override-config': { type: 'string', description: 'devcontainer.json path to override any devcontainer.json in the workspace folder (or built-in configuration). This is required when there is no devcontainer.json otherwise.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level for the --terminal-log-file. When set to trace, the log level for --log-file will also be set to trace.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'terminal-columns': { type: 'number', implies: ['terminal-rows'], description: 'Number of columns to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'terminal-rows': { type: 'number', implies: ['terminal-columns'], description: 'Number of rows to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'include-features-configuration': { type: 'boolean', default: false, description: 'Include features configuration.' },
		'include-merged-configuration': { type: 'boolean', default: false, description: 'Include merged configuration.' },
		'additional-features': { type: 'string', description: 'Additional features to apply to the dev container (JSON as per "features" section in devcontainer.json)' },
		'skip-feature-auto-mapping': { type: 'boolean', default: false, hidden: true, description: 'Temporary option for testing.' },
	})
		.check(argv => {
			const idLabels = (argv['id-label'] && (Array.isArray(argv['id-label']) ? argv['id-label'] : [argv['id-label']])) as string[] | undefined;
			if (idLabels?.some(idLabel => !/.+=.+/.test(idLabel))) {
				throw new Error('Unmatched argument format: id-label must match <name>=<value>');
			}
			if (!argv['container-id'] && !idLabels?.length && !argv['workspace-folder']) {
				throw new Error('Missing required argument: One of --container-id, --id-label or --workspace-folder is required.');
			}
			return true;
		});
}

type ReadConfigurationArgs = UnpackArgv<ReturnType<typeof readConfigurationOptions>>;

function readConfigurationHandler(args: ReadConfigurationArgs) {
	runAsyncHandler(readConfiguration.bind(null, args));
}

async function readConfiguration({
	// 'user-data-folder': persistedFolder,
	'docker-path': dockerPath,
	'docker-compose-path': dockerComposePath,
	'workspace-folder': workspaceFolderArg,
	'mount-workspace-git-root': mountWorkspaceGitRoot,
	config: configParam,
	'override-config': overrideConfig,
	'container-id': containerId,
	'id-label': idLabel,
	'log-level': logLevel,
	'log-format': logFormat,
	'terminal-rows': terminalRows,
	'terminal-columns': terminalColumns,
	'include-features-configuration': includeFeaturesConfig,
	'include-merged-configuration': includeMergedConfig,
	'additional-features': additionalFeaturesJson,
	'skip-feature-auto-mapping': skipFeatureAutoMapping,
}: ReadConfigurationArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	let output: Log | undefined;
	try {
		const workspaceFolder = workspaceFolderArg ? path.resolve(process.cwd(), workspaceFolderArg) : undefined;
		const providedIdLabels = idLabel ? Array.isArray(idLabel) ? idLabel as string[] : [idLabel] : undefined;
		const configFile = configParam ? URI.file(path.resolve(process.cwd(), configParam)) : undefined;
		const overrideConfigFile = overrideConfig ? URI.file(path.resolve(process.cwd(), overrideConfig)) : undefined;
		const cwd = workspaceFolder || process.cwd();
		const cliHost = await getCLIHost(cwd, loadNativeModule, logFormat === 'text');
		const extensionPath = path.join(__dirname, '..', '..');
		const sessionStart = new Date();
		const pkg = getPackageConfig();
		output = createLog({
			logLevel: mapLogLevel(logLevel),
			logFormat,
			log: text => process.stderr.write(text),
			terminalDimensions: terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : undefined,
		}, pkg, sessionStart, disposables);

		const workspace = workspaceFolder ? workspaceFromPath(cliHost.path, workspaceFolder) : undefined;
		const configPath = configFile ? configFile : workspace
			? (await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath)
				|| (overrideConfigFile ? getDefaultDevContainerConfigPath(cliHost, workspace.configFolderPath) : undefined))
			: overrideConfigFile;
		const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, mountWorkspaceGitRoot, output, undefined, overrideConfigFile) || undefined;
		if ((configFile || workspaceFolder || overrideConfigFile) && !configs) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
		}

		let configuration = configs?.config || {
			raw: {},
			config: {},
			substitute: value => substitute({ platform: cliHost.platform, env: cliHost.env }, value)
		};

		const dockerCLI = dockerPath || 'docker';
		const dockerComposeCLI = dockerComposeCLIConfig({
			exec: cliHost.exec,
			env: cliHost.env,
			output,
		}, dockerCLI, dockerComposePath || 'docker-compose');
		const params: DockerCLIParameters = {
			cliHost,
			dockerCLI,
			dockerComposeCLI,
			env: cliHost.env,
			output,
			platformInfo: {
				os: mapNodeOSToGOOS(cliHost.platform),
				arch: mapNodeArchitectureToGOARCH(cliHost.arch),
			}
		};
		const { container, idLabels } = await findContainerAndIdLabels(params, containerId, providedIdLabels, workspaceFolder, configPath?.fsPath);
		if (container) {
			configuration = addSubstitution(configuration, config => beforeContainerSubstitute(envListToObj(idLabels), config));
			configuration = addSubstitution(configuration, config => containerSubstitute(cliHost.platform, configuration.config.configFilePath, envListToObj(container.Config.Env), config));
		}

		const additionalFeatures = additionalFeaturesJson ? jsonc.parse(additionalFeaturesJson) as Record<string, string | boolean | Record<string, string | boolean>> : {};
		const needsFeaturesConfig = includeFeaturesConfig || (includeMergedConfig && !container);
		const featuresConfiguration = needsFeaturesConfig ? await readFeaturesConfig(params, pkg, configuration.config, extensionPath, skipFeatureAutoMapping, additionalFeatures) : undefined;
		let mergedConfig: MergedDevContainerConfig | undefined;
		if (includeMergedConfig) {
			let imageMetadata: ImageMetadataEntry[];
			if (container) {
				imageMetadata = getImageMetadataFromContainer(container, configuration, featuresConfiguration, idLabels, output).config;
				const substitute2: SubstituteConfig = config => containerSubstitute(cliHost.platform, configuration.config.configFilePath, envListToObj(container.Config.Env), config);
				imageMetadata = imageMetadata.map(substitute2);
			} else {
				const imageBuildInfo = await getImageBuildInfo(params, configuration);
				imageMetadata = getDevcontainerMetadata(imageBuildInfo.metadata, configuration, featuresConfiguration).config;
			}
			mergedConfig = mergeConfiguration(configuration.config, imageMetadata);
		}
		await new Promise<void>((resolve, reject) => {
			process.stdout.write(JSON.stringify({
				configuration: configuration.config,
				workspace: configs?.workspaceConfig,
				featuresConfiguration,
				mergedConfiguration: mergedConfig,
			}) + '\n', err => err ? reject(err) : resolve());
		});
	} catch (err) {
		if (output) {
			output.write(err && (err.stack || err.message) || String(err));
		} else {
			console.error(err);
		}
		await dispose();
		process.exit(1);
	}
	await dispose();
	process.exit(0);
}

function outdatedOptions(y: Argv) {
	return y.options({
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'workspace-folder': { type: 'string', required: true, description: 'Workspace folder path. The devcontainer.json will be looked up relative to this path.' },
		'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
		'output-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text', description: 'Output format.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level for the --terminal-log-file. When set to trace, the log level for --log-file will also be set to trace.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'terminal-columns': { type: 'number', implies: ['terminal-rows'], description: 'Number of columns to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'terminal-rows': { type: 'number', implies: ['terminal-columns'], description: 'Number of rows to render the output for. This is required for some of the subprocesses to correctly render their output.' },
	});
}

type OutdatedArgs = UnpackArgv<ReturnType<typeof outdatedOptions>>;

function outdatedHandler(args: OutdatedArgs) {
	runAsyncHandler(outdated.bind(null, args));
}

async function outdated({
	// 'user-data-folder': persistedFolder,
	'workspace-folder': workspaceFolderArg,
	config: configParam,
	'output-format': outputFormat,
	'log-level': logLevel,
	'log-format': logFormat,
	'terminal-rows': terminalRows,
	'terminal-columns': terminalColumns,
}: OutdatedArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	let output: Log | undefined;
	try {
		const workspaceFolder = path.resolve(process.cwd(), workspaceFolderArg);
		const configFile = configParam ? URI.file(path.resolve(process.cwd(), configParam)) : undefined;
		const cliHost = await getCLIHost(workspaceFolder, loadNativeModule, logFormat === 'text');
		const extensionPath = path.join(__dirname, '..', '..');
		const sessionStart = new Date();
		const pkg = getPackageConfig();
		output = createLog({
			logLevel: mapLogLevel(logLevel),
			logFormat,
			log: text => process.stderr.write(text),
			terminalDimensions: terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : undefined,
		}, pkg, sessionStart, disposables);

		const workspace = workspaceFromPath(cliHost.path, workspaceFolder);
		const configPath = configFile ? configFile : await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath);
		const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, true, output) || undefined;
		if (!configs) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
		}

		const cacheFolder = await getCacheFolder(cliHost);
		const params = {
			extensionPath,
			cacheFolder,
			cwd: cliHost.cwd,
			output,
			env: cliHost.env,
			skipFeatureAutoMapping: false,
			platform: cliHost.platform,
		};

		const outdated = await loadVersionInfo(params, configs.config.config);
		await new Promise<void>((resolve, reject) => {
			let text;
			if (outputFormat === 'text') {
				const rows = Object.keys(outdated.features).map(key => {
					const value = outdated.features[key];
					return [ getFeatureIdWithoutVersion(key), value.current, value.wanted, value.latest ]
						.map(v => v === undefined ? '-' : v);
				});
				const header = ['Feature', 'Current', 'Wanted', 'Latest'];
				text = textTable([
					header,
					...rows,
				]);
			} else {
				text = JSON.stringify(outdated, undefined, process.stdout.isTTY ? '  ' : undefined);
			}
			process.stdout.write(text + '\n', err => err ? reject(err) : resolve());
		});
	} catch (err) {
		if (output) {
			output.write(err && (err.stack || err.message) || String(err));
		} else {
			console.error(err);
		}
		await dispose();
		process.exit(1);
	}
	await dispose();
	process.exit(0);
}

function execOptions(y: Argv) {
	return y.options({
		'user-data-folder': { type: 'string', description: 'Host path to a directory that is intended to be persisted and share state between sessions.' },
		'docker-path': { type: 'string', description: 'Docker CLI path.' },
		'docker-compose-path': { type: 'string', description: 'Docker Compose CLI path.' },
		'container-data-folder': { type: 'string', description: 'Container data folder where user data inside the container will be stored.' },
		'container-system-data-folder': { type: 'string', description: 'Container system data folder where system data inside the container will be stored.' },
		'workspace-folder': { type: 'string', description: 'Workspace folder path. The devcontainer.json will be looked up relative to this path.' },
		'mount-workspace-git-root': { type: 'boolean', default: true, description: 'Mount the workspace using its Git root.' },
		'container-id': { type: 'string', description: 'Id of the container to run the user commands for.' },
		'id-label': { type: 'string', description: 'Id label(s) of the format name=value. If no --container-id is given the id labels will be used to look up the container. If no --id-label is given, one will be inferred from the --workspace-folder path.' },
		'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
		'override-config': { type: 'string', description: 'devcontainer.json path to override any devcontainer.json in the workspace folder (or built-in configuration). This is required when there is no devcontainer.json otherwise.' },
		'log-level': { choices: ['info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level for the --terminal-log-file. When set to trace, the log level for --log-file will also be set to trace.' },
		'log-format': { choices: ['text' as 'text', 'json' as 'json'], default: 'text' as 'text', description: 'Log format.' },
		'terminal-columns': { type: 'number', implies: ['terminal-rows'], description: 'Number of columns to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'terminal-rows': { type: 'number', implies: ['terminal-columns'], description: 'Number of rows to render the output for. This is required for some of the subprocesses to correctly render their output.' },
		'default-user-env-probe': { choices: ['none' as 'none', 'loginInteractiveShell' as 'loginInteractiveShell', 'interactiveShell' as 'interactiveShell', 'loginShell' as 'loginShell'], default: defaultDefaultUserEnvProbe, description: 'Default value for the devcontainer.json\'s "userEnvProbe".' },
		'remote-env': { type: 'string', description: 'Remote environment variables of the format name=value. These will be added when executing the user commands.' },
		'skip-feature-auto-mapping': { type: 'boolean', default: false, hidden: true, description: 'Temporary option for testing.' },
	})
		.positional('cmd', {
			type: 'string',
			description: 'Command to execute.',
			demandOption: true,
		}).positional('args', {
			type: 'string',
			array: true,
			description: 'Arguments to the command.',
			demandOption: true,
		})
		.check(argv => {
			const idLabels = (argv['id-label'] && (Array.isArray(argv['id-label']) ? argv['id-label'] : [argv['id-label']])) as string[] | undefined;
			if (idLabels?.some(idLabel => !/.+=.+/.test(idLabel))) {
				throw new Error('Unmatched argument format: id-label must match <name>=<value>');
			}
			const remoteEnvs = (argv['remote-env'] && (Array.isArray(argv['remote-env']) ? argv['remote-env'] : [argv['remote-env']])) as string[] | undefined;
			if (remoteEnvs?.some(remoteEnv => !/.+=.*/.test(remoteEnv))) {
				throw new Error('Unmatched argument format: remote-env must match <name>=<value>');
			}
			if (!argv['container-id'] && !idLabels?.length && !argv['workspace-folder']) {
				throw new Error('Missing required argument: One of --container-id, --id-label or --workspace-folder is required.');
			}
			return true;
		});
}

export type ExecArgs = UnpackArgv<ReturnType<typeof execOptions>>;

function execHandler(args: ExecArgs) {
	runAsyncHandler(exec.bind(null, args));
}

async function exec(args: ExecArgs) {
	const result = await doExec(args);
	const exitCode = typeof result.code === 'number' && (result.code || !result.signal) ? result.code :
		typeof result.signal === 'number' && result.signal > 0 ? 128 + result.signal : // 128 + signal number convention: https://tldp.org/LDP/abs/html/exitcodes.html
		typeof result.signal === 'string' && processSignals[result.signal] ? 128 + processSignals[result.signal]! : 1;
	await result.dispose();
	process.exit(exitCode);
}

export async function doExec({
	'user-data-folder': persistedFolder,
	'docker-path': dockerPath,
	'docker-compose-path': dockerComposePath,
	'container-data-folder': containerDataFolder,
	'container-system-data-folder': containerSystemDataFolder,
	'workspace-folder': workspaceFolderArg,
	'mount-workspace-git-root': mountWorkspaceGitRoot,
	'container-id': containerId,
	'id-label': idLabel,
	config: configParam,
	'override-config': overrideConfig,
	'log-level': logLevel,
	'log-format': logFormat,
	'terminal-rows': terminalRows,
	'terminal-columns': terminalColumns,
	'default-user-env-probe': defaultUserEnvProbe,
	'remote-env': addRemoteEnv,
	'skip-feature-auto-mapping': skipFeatureAutoMapping,
	_: restArgs,
}: ExecArgs & { _?: string[] }) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	let output: Log | undefined;
	const isTTY = process.stdin.isTTY && process.stdout.isTTY || logFormat === 'json'; // If stdin or stdout is a pipe, we don't want to use a PTY.
	try {
		const workspaceFolder = workspaceFolderArg ? path.resolve(process.cwd(), workspaceFolderArg) : undefined;
		const providedIdLabels = idLabel ? Array.isArray(idLabel) ? idLabel as string[] : [idLabel] : undefined;
		const addRemoteEnvs = addRemoteEnv ? (Array.isArray(addRemoteEnv) ? addRemoteEnv as string[] : [addRemoteEnv]) : [];
		const configFile = configParam ? URI.file(path.resolve(process.cwd(), configParam)) : undefined;
		const overrideConfigFile = overrideConfig ? URI.file(path.resolve(process.cwd(), overrideConfig)) : undefined;
		const params = await createDockerParams({
			dockerPath,
			dockerComposePath,
			containerDataFolder,
			containerSystemDataFolder,
			workspaceFolder,
			mountWorkspaceGitRoot,
			configFile,
			overrideConfigFile,
			logLevel: mapLogLevel(logLevel),
			logFormat,
			log: text => process.stderr.write(text),
			terminalDimensions: terminalColumns && terminalRows ? { columns: terminalColumns, rows: terminalRows } : isTTY ? { columns: process.stdout.columns, rows: process.stdout.rows } : undefined,
			onDidChangeTerminalDimensions: terminalColumns && terminalRows ? undefined : isTTY ? createStdoutResizeEmitter(disposables) : undefined,
			defaultUserEnvProbe,
			removeExistingContainer: false,
			buildNoCache: false,
			expectExistingContainer: false,
			postCreateEnabled: true,
			skipNonBlocking: false,
			prebuild: false,
			persistedFolder,
			additionalMounts: [],
			updateRemoteUserUIDDefault: 'never',
			remoteEnv: envListToObj(addRemoteEnvs),
			additionalCacheFroms: [],
			useBuildKit: 'auto',
			omitLoggerHeader: true,
			buildxPlatform: undefined,
			buildxPush: false,
			additionalLabels: [],
			buildxCacheTo: undefined,
			skipFeatureAutoMapping,
			buildxOutput: undefined,
			skipPostAttach: false,
			skipPersistingCustomizationsFromFeatures: false,
			dotfiles: {}
		}, disposables);

		const { common } = params;
		const { cliHost } = common;
		output = common.output;
		const workspace = workspaceFolder ? workspaceFromPath(cliHost.path, workspaceFolder) : undefined;
		const configPath = configFile ? configFile : workspace
			? (await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath)
				|| (overrideConfigFile ? getDefaultDevContainerConfigPath(cliHost, workspace.configFolderPath) : undefined))
			: overrideConfigFile;
		const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, params.mountWorkspaceGitRoot, output, undefined, overrideConfigFile) || undefined;
		if ((configFile || workspaceFolder || overrideConfigFile) && !configs) {
			throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
		}

		const config = configs?.config || {
			raw: {},
			config: {},
			substitute: value => substitute({ platform: cliHost.platform, env: cliHost.env }, value)
		};

		const { container, idLabels } = await findContainerAndIdLabels(params, containerId, providedIdLabels, workspaceFolder, configPath?.fsPath);
		if (!container) {
			bailOut(common.output, 'Dev container not found.');
		}
		const imageMetadata = getImageMetadataFromContainer(container, config, undefined, idLabels, output).config;
		const mergedConfig = mergeConfiguration(config.config, imageMetadata);
		const containerProperties = await createContainerProperties(params, container.Id, configs?.workspaceConfig.workspaceFolder, mergedConfig.remoteUser);
		const updatedConfig = containerSubstitute(cliHost.platform, config.config.configFilePath, containerProperties.env, mergedConfig);
		const remoteEnv = probeRemoteEnv(common, containerProperties, updatedConfig);
		const remoteCwd = containerProperties.remoteWorkspaceFolder || containerProperties.homeFolder;
		await runRemoteCommand({ ...common, output, stdin: process.stdin, ...(logFormat !== 'json' ? { stdout: process.stdout, stderr: process.stderr } : {}) }, containerProperties, restArgs || [], remoteCwd, { remoteEnv: await remoteEnv, pty: isTTY, print: 'continuous' });
		return {
			code: 0,
			dispose,
		};

	} catch (err) {
		if (!err?.code && !err?.signal) {
			if (output) {
				output.write(err?.stack || err?.message || String(err), LogLevel.Error);
			} else {
				console.error(err?.stack || err?.message || String(err));
			}
		}
		return {
			code: err?.code as number | undefined,
			signal: err?.signal as string | number | undefined,
			dispose,
		};
	}
}

function createStdoutResizeEmitter(disposables: (() => Promise<unknown> | void)[]): Event<LogDimensions> {
	const resizeListener = () => {
		emitter.fire({
			rows: process.stdout.rows,
			columns: process.stdout.columns
		});
	};
	const emitter = new NodeEventEmitter<LogDimensions>({
		on: () => process.stdout.on('resize', resizeListener),
		off: () => process.stdout.off('resize', resizeListener),
	});
	disposables.push(() => emitter.dispose());
	return emitter.event;
}

async function readSecretsFromFile(params: { output?: Log; secretsFile?: string; cliHost: CLIHost }) {
	const { secretsFile, cliHost, output } = params;
	if (!secretsFile) {
		return {};
	}

	try {
		const fileBuff = await cliHost.readFile(secretsFile);
		const parseErrors: jsonc.ParseError[] = [];
		const secrets = jsonc.parse(fileBuff.toString(), parseErrors) as Record<string, string>;
		if (parseErrors.length) {
			throw new Error('Invalid json data');
		}

		return secrets;
	}
	catch (e) {
		if (output) {
			output.write(`Failed to read/parse secrets from file '${secretsFile}'`, LogLevel.Error);
		}

		throw new ContainerError({
			description: 'Failed to read/parse secrets',
			originalError: e
		});
	}
}
</file>

<file path="src/spec-node/disallowedFeatures.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *--------------------------------------------------------------------------------------------*/

import { DevContainerConfig } from '../spec-configuration/configuration';
import { ContainerError } from '../spec-common/errors';
import { DockerCLIParameters, dockerCLI } from '../spec-shutdown/dockerUtils';
import { findDevContainer } from './singleContainer';
import { DevContainerControlManifest, DisallowedFeature, getControlManifest } from '../spec-configuration/controlManifest';
import { getCacheFolder } from './utils';


export async function ensureNoDisallowedFeatures(params: DockerCLIParameters, config: DevContainerConfig, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>, idLabels: string[] | undefined) {
	const controlManifest = await getControlManifest(await getCacheFolder(params.cliHost), params.output);
	const disallowed = Object.keys({
		...config.features,
		...additionalFeatures,
	}).map(configFeatureId => {
		const disallowedFeatureEntry = findDisallowedFeatureEntry(controlManifest, configFeatureId);
		return disallowedFeatureEntry ? { configFeatureId, disallowedFeatureEntry } : undefined;
	}).filter(Boolean) as {
		configFeatureId: string;
		disallowedFeatureEntry: DisallowedFeature;
	}[];

	if (!disallowed.length) {
		return;
	}

	let stopped = false;
	if (idLabels) {
		const container = await findDevContainer(params, idLabels);
		if (container?.State?.Status === 'running') {
			await dockerCLI(params, 'stop', '-t', '0', container.Id);
			stopped = true;
		}
	}

	const d = disallowed[0]!;
	const documentationURL = d.disallowedFeatureEntry.documentationURL;
	throw new ContainerError({
		description: `Cannot use the '${d.configFeatureId}' Feature since it was reported to be problematic. Please remove this Feature from your configuration and rebuild any dev container using it before continuing.${stopped ? ' The existing dev container was stopped.' : ''}${documentationURL ? ` See ${documentationURL} to learn more.` : ''}`,
		data: {
			disallowedFeatureId: d.configFeatureId,
			didStopContainer: stopped,
			learnMoreUrl: documentationURL,
		},
	});
}

export function findDisallowedFeatureEntry(controlManifest: DevContainerControlManifest, featureId: string): DisallowedFeature | undefined {
	return controlManifest.disallowedFeatures.find(
		disallowedFeature =>
			featureId.startsWith(disallowedFeature.featureIdPrefix) &&
			(featureId.length === disallowedFeature.featureIdPrefix.length || // Feature id equal to prefix.
				'/:@'.indexOf(featureId[disallowedFeature.featureIdPrefix.length]) !== -1) // Feature id with prefix and continued by separator.
	);
}
</file>

<file path="src/spec-node/dockerCompose.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as yaml from 'js-yaml';
import * as shellQuote from 'shell-quote';

import { createContainerProperties, startEventSeen, ResolverResult, getTunnelInformation, DockerResolverParameters, inspectDockerImage, getEmptyContextFolder, getFolderImageName, SubstitutedConfig, checkDockerSupportForGPU, isBuildKitImagePolicyError } from './utils';
import { ContainerProperties, setupInContainer, ResolverProgress } from '../spec-common/injectHeadless';
import { ContainerError } from '../spec-common/errors';
import { Workspace } from '../spec-utils/workspaces';
import { equalPaths, parseVersion, isEarlierVersion, CLIHost } from '../spec-common/commonUtils';
import { ContainerDetails, inspectContainer, listContainers, DockerCLIParameters, dockerComposeCLI, dockerComposePtyCLI, PartialExecParameters, DockerComposeCLI, ImageDetails, toExecParameters, toPtyExecParameters, removeContainer } from '../spec-shutdown/dockerUtils';
import { DevContainerFromDockerComposeConfig, getDockerComposeFilePaths } from '../spec-configuration/configuration';
import { Log, LogLevel, makeLog, terminalEscapeSequences } from '../spec-utils/log';
import { getExtendImageBuildInfo, updateRemoteUserUID } from './containerFeatures';
import { Mount, parseMount } from '../spec-configuration/containerFeaturesConfiguration';
import path from 'path';
import { getDevcontainerMetadata, getImageBuildInfoFromDockerfile, getImageBuildInfoFromImage, getImageMetadataFromContainer, ImageBuildInfo, lifecycleCommandOriginMapFromMetadata, mergeConfiguration, MergedDevContainerConfig } from './imageMetadata';
import { ensureDockerfileHasFinalStageName } from './dockerfileUtils';
import { randomUUID } from 'crypto';

const projectLabel = 'com.docker.compose.project';
const serviceLabel = 'com.docker.compose.service';

export async function openDockerComposeDevContainer(params: DockerResolverParameters, workspace: Workspace, config: SubstitutedConfig<DevContainerFromDockerComposeConfig>, idLabels: string[], additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>): Promise<ResolverResult> {
	const { common, dockerCLI, dockerComposeCLI } = params;
	const { cliHost, env, output } = common;
	const buildParams: DockerCLIParameters = { cliHost, dockerCLI, dockerComposeCLI, env, output, platformInfo: params.platformInfo };
	return _openDockerComposeDevContainer(params, buildParams, workspace, config, getRemoteWorkspaceFolder(config.config), idLabels, additionalFeatures);
}

async function _openDockerComposeDevContainer(params: DockerResolverParameters, buildParams: DockerCLIParameters, workspace: Workspace, configWithRaw: SubstitutedConfig<DevContainerFromDockerComposeConfig>, remoteWorkspaceFolder: string, idLabels: string[], additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>): Promise<ResolverResult> {
	const { common } = params;
	const { cliHost: buildCLIHost } = buildParams;
	const { config } = configWithRaw;

	let container: ContainerDetails | undefined;
	let containerProperties: ContainerProperties | undefined;
	try {

		const composeFiles = await getDockerComposeFilePaths(buildCLIHost, config, buildCLIHost.env, buildCLIHost.cwd);
		const cwdEnvFile = buildCLIHost.path.join(buildCLIHost.cwd, '.env');
		const envFile = Array.isArray(config.dockerComposeFile) && config.dockerComposeFile.length === 0 && await buildCLIHost.isFile(cwdEnvFile) ? cwdEnvFile : undefined;
		const composeConfig = await readDockerComposeConfig(buildParams, composeFiles, envFile);
		const projectName = await getProjectName(buildParams, workspace, composeFiles, composeConfig);
		const containerId = await findComposeContainer(params, projectName, config.service);
		if (params.expectExistingContainer && !containerId) {
			throw new ContainerError({ description: 'The expected container does not exist.' });
		}
		container = containerId ? await inspectContainer(params, containerId) : undefined;

		if (container && (params.removeOnStartup === true || params.removeOnStartup === container.Id)) {
			const text = 'Removing existing container.';
			const start = common.output.start(text);
			await removeContainer(params, container.Id);
			common.output.stop(text, start);
			container = undefined;
		}

		// let collapsedFeaturesConfig: CollapsedFeaturesConfig | undefined;
		if (!container || container.State.Status !== 'running') {
			const res = await startContainer(params, buildParams, configWithRaw, projectName, composeFiles, envFile, composeConfig, container, idLabels, additionalFeatures);
			container = await inspectContainer(params, res.containerId);
			// 	collapsedFeaturesConfig = res.collapsedFeaturesConfig;
			// } else {
			// 	const labels = container.Config.Labels || {};
			// 	const featuresConfig = await generateFeaturesConfig(params.common, (await createFeaturesTempFolder(params.common)), config, async () => labels, getContainerFeaturesFolder);
			// 	collapsedFeaturesConfig = collapseFeaturesConfig(featuresConfig);
		}

		const imageMetadata = getImageMetadataFromContainer(container, configWithRaw, undefined, idLabels, common.output).config;
		const mergedConfig = mergeConfiguration(configWithRaw.config, imageMetadata);
		containerProperties = await createContainerProperties(params, container.Id, remoteWorkspaceFolder, mergedConfig.remoteUser);

		const {
			remoteEnv: extensionHostEnv,
			updatedConfig,
			updatedMergedConfig,
		} = await setupInContainer(common, containerProperties, config, mergedConfig, lifecycleCommandOriginMapFromMetadata(imageMetadata));

		return {
			params: common,
			properties: containerProperties,
			config: updatedConfig,
			mergedConfig: updatedMergedConfig,
			resolvedAuthority: {
				extensionHostEnv,
			},
			tunnelInformation: common.isLocalContainer ? getTunnelInformation(container) : {},
			dockerParams: params,
			dockerContainerId: container.Id,
			composeProjectName: projectName,
		};

	} catch (originalError) {
		const err = originalError instanceof ContainerError ? originalError : new ContainerError({
			description: 'An error occurred setting up the container.',
			originalError
		});
		if (container) {
			err.manageContainer = true;
			err.params = params.common;
			err.containerId = container.Id;
			err.dockerParams = params;
		}
		if (containerProperties) {
			err.containerProperties = containerProperties;
		}
		err.config = config;
		throw err;
	}
}

export function getRemoteWorkspaceFolder(config: DevContainerFromDockerComposeConfig) {
	return config.workspaceFolder || '/';
}

// exported for testing
export function getBuildInfoForService(composeService: any, cliHostPath: typeof path, localComposeFiles: string[]) {
	// composeService should taken from readDockerComposeConfig
	// the 'build' property can be a string or an object (https://docs.docker.com/compose/compose-file/build/#build-definition)

	const image = composeService.image as string | undefined;
	const composeBuild = composeService.build;
	if (!composeBuild) {
		return {
			image
		};
	}
	if (typeof (composeBuild) === 'string') {
		return {
			image,
			build: {
				context: composeBuild,
				dockerfilePath: 'Dockerfile'
			}
		};
	}
	return {
		image,
		build: {
			dockerfilePath: (composeBuild.dockerfile as string | undefined) ?? 'Dockerfile',
			context: (composeBuild.context as string | undefined) ?? cliHostPath.dirname(localComposeFiles[0]),
			target: composeBuild.target as string | undefined,
			args: composeBuild.args as Record<string, string> | undefined,
		}
	};
}

export async function buildAndExtendDockerCompose(configWithRaw: SubstitutedConfig<DevContainerFromDockerComposeConfig>, projectName: string, params: DockerResolverParameters, localComposeFiles: string[], envFile: string | undefined, composeGlobalArgs: string[], runServices: string[], noCache: boolean, overrideFilePath: string, overrideFilePrefix: string, versionPrefix: string, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>, canAddLabelsToContainer: boolean, additionalCacheFroms?: string[], noBuild?: boolean) {

	const { common, dockerCLI, dockerComposeCLI: dockerComposeCLIFunc } = params;
	const { cliHost, env, output } = common;
	const { config } = configWithRaw;

	const cliParams: DockerCLIParameters = { cliHost, dockerCLI, dockerComposeCLI: dockerComposeCLIFunc, env, output, platformInfo: params.platformInfo };
	const composeConfig = await readDockerComposeConfig(cliParams, localComposeFiles, envFile);
	const composeService = composeConfig.services[config.service];

	// determine base imageName for generated features build stage(s)
	let baseName = 'dev_container_auto_added_stage_label';
	let dockerfile: string | undefined;
	let imageBuildInfo: ImageBuildInfo;
	const serviceInfo = getBuildInfoForService(composeService, cliHost.path, localComposeFiles);
	if (serviceInfo.build) {
		const { context, dockerfilePath, target } = serviceInfo.build;
		const resolvedDockerfilePath = cliHost.path.isAbsolute(dockerfilePath) ? dockerfilePath : path.resolve(context, dockerfilePath);
		const originalDockerfile = (await cliHost.readFile(resolvedDockerfilePath)).toString();
		dockerfile = originalDockerfile;
		if (target) {
			// Explictly set build target for the dev container build features on that
			baseName = target;
		} else {
			// Use the last stage in the Dockerfile
			// Find the last line that starts with "FROM" (possibly preceeded by white-space)
			const { lastStageName, modifiedDockerfile } = ensureDockerfileHasFinalStageName(originalDockerfile, baseName);
			baseName = lastStageName;
			if (modifiedDockerfile) {
				dockerfile = modifiedDockerfile;
			}
		}
		imageBuildInfo = await getImageBuildInfoFromDockerfile(params, originalDockerfile, serviceInfo.build?.args || {}, serviceInfo.build?.target, configWithRaw.substitute);
	} else {
		imageBuildInfo = await getImageBuildInfoFromImage(params, composeService.image, configWithRaw.substitute);
	}

	// determine whether we need to extend with features
	const version = parseVersion((await params.dockerComposeCLI()).version);
	const supportsAdditionalBuildContexts = !params.isPodman && version && !isEarlierVersion(version, [2, 17, 0]);
	const optionalBuildKitParams = supportsAdditionalBuildContexts ? params : { ...params, buildKitVersion: undefined };
	const extendImageBuildInfo = await getExtendImageBuildInfo(optionalBuildKitParams, configWithRaw, baseName, imageBuildInfo, composeService.user, additionalFeatures, canAddLabelsToContainer);

	let overrideImageName: string | undefined;
	let buildOverrideContent = '';
	if (extendImageBuildInfo?.featureBuildInfo) {
		// Avoid retagging a previously pulled image.
		if (!serviceInfo.build) {
			overrideImageName = getFolderImageName(common);
			buildOverrideContent += `    image: ${overrideImageName}\n`;
		}
		// Create overridden Dockerfile and generate docker-compose build override content
		buildOverrideContent += '    build:\n';
		if (!dockerfile) {
			dockerfile = `FROM ${composeService.image} AS ${baseName}\n`;
		}
		const { featureBuildInfo } = extendImageBuildInfo;
		// We add a '# syntax' line at the start, so strip out any existing line
		const syntaxMatch = dockerfile.match(/^\s*#\s*syntax\s*=.*[\r\n]/g);
		if (syntaxMatch) {
			dockerfile = dockerfile.slice(syntaxMatch[0].length);
		}
		let finalDockerfileContent = `${featureBuildInfo.dockerfilePrefixContent}${dockerfile}\n${featureBuildInfo.dockerfileContent}`;
		const finalDockerfilePath = cliHost.path.join(featureBuildInfo?.dstFolder, 'Dockerfile-with-features');
		await cliHost.writeFile(finalDockerfilePath, Buffer.from(finalDockerfileContent));
		buildOverrideContent += `      dockerfile: ${finalDockerfilePath}\n`;
		if (serviceInfo.build?.target) {
			// Replace target. (Only when set because it is only supported with Docker Compose file version 3.4 and later.)
			buildOverrideContent += `      target: ${featureBuildInfo.overrideTarget}\n`;
		}

		if (!serviceInfo.build?.context) {
			// need to supply a context as we don't have one inherited
			const emptyDir = getEmptyContextFolder(common);
			await cliHost.mkdirp(emptyDir);
			buildOverrideContent += `      context: ${emptyDir}\n`;
		}
		// track additional build args to include
		if (Object.keys(featureBuildInfo.buildArgs).length > 0 || params.buildKitVersion) {
			buildOverrideContent += '      args:\n';
			if (params.buildKitVersion) {
				buildOverrideContent += '        - BUILDKIT_INLINE_CACHE=1\n';
			}
			for (const buildArg in featureBuildInfo.buildArgs) {
				buildOverrideContent += `        - ${buildArg}=${featureBuildInfo.buildArgs[buildArg]}\n`;
			}
		}

		if (Object.keys(featureBuildInfo.buildKitContexts).length > 0) {
			buildOverrideContent += '      additional_contexts:\n';
			for (const buildKitContext in featureBuildInfo.buildKitContexts) {
				buildOverrideContent += `        - ${buildKitContext}=${featureBuildInfo.buildKitContexts[buildKitContext]}\n`;
			}
		}
	}

	// Generate the docker-compose override and build
	const args = ['--project-name', projectName, ...composeGlobalArgs];
	const additionalComposeOverrideFiles: string[] = [];
	if (additionalCacheFroms && additionalCacheFroms.length > 0 || buildOverrideContent) {
		const composeFolder = cliHost.path.join(overrideFilePath, 'docker-compose');
		await cliHost.mkdirp(composeFolder);
		const composeOverrideFile = cliHost.path.join(composeFolder, `${overrideFilePrefix}-${Date.now()}.yml`);
		const cacheFromOverrideContent = (additionalCacheFroms && additionalCacheFroms.length > 0) ? `      cache_from:\n${additionalCacheFroms.map(cacheFrom => `        - ${cacheFrom}\n`).join('\n')}` : '';
		const composeOverrideContent = `${versionPrefix}services:
  ${config.service}:
${buildOverrideContent?.trimEnd()}
${cacheFromOverrideContent}
`;
		output.write(`Docker Compose override file for building image:\n${composeOverrideContent}`);
		await cliHost.writeFile(composeOverrideFile, Buffer.from(composeOverrideContent));
		additionalComposeOverrideFiles.push(composeOverrideFile);
		args.push('-f', composeOverrideFile);
	}

	if (!noBuild) {
		args.push('build');
		if (noCache) {
			args.push('--no-cache');
			// `docker build --pull` pulls local image: https://github.com/devcontainers/cli/issues/60
			if (!extendImageBuildInfo) {
				args.push('--pull');
			}
		}
		if (runServices.length) {
			args.push(...runServices);
			if (runServices.indexOf(config.service) === -1) {
				args.push(config.service);
			}
		}
		try {
			if (params.isTTY) {
				const infoParams = { ...toPtyExecParameters(params, await dockerComposeCLIFunc()), output: makeLog(output, LogLevel.Info) };
				await dockerComposePtyCLI(infoParams, ...args);
			} else {
				const infoParams = { ...toExecParameters(params, await dockerComposeCLIFunc()), output: makeLog(output, LogLevel.Info), print: 'continuous' as 'continuous' };
				await dockerComposeCLI(infoParams, ...args);
			}
		} catch (err) {
			if (isBuildKitImagePolicyError(err)) {
				throw new ContainerError({ description: 'Could not resolve image due to policy.', originalError: err, data: { fileWithError: localComposeFiles[0] } });
			}

			throw err instanceof ContainerError ? err : new ContainerError({ description: 'An error occurred building the Docker Compose images.', originalError: err, data: { fileWithError: localComposeFiles[0] } });
		}
	}

	return {
		imageMetadata: getDevcontainerMetadata(imageBuildInfo.metadata, configWithRaw, extendImageBuildInfo?.featuresConfig),
		additionalComposeOverrideFiles,
		overrideImageName,
		labels: extendImageBuildInfo?.labels,
	};
}

async function checkForPersistedFile(cliHost: CLIHost, output: Log, files: string[], prefix: string) {
	const file = files.find((f) => f.indexOf(prefix) > -1);
	if (file) {
		const composeFileExists = await cliHost.isFile(file);

		if (composeFileExists) {
			output.write(`Restoring ${file} from persisted storage`);
			return {
				foundLabel: true,
				fileExists: true,
				file
			};
		} else {
			output.write(`Expected ${file} to exist, but it did not`, LogLevel.Error);
			return {
				foundLabel: true,
				fileExists: false,
				file
			};
		}
	} else {
		output.write(`Expected to find a docker-compose file prefixed with ${prefix}, but did not.`, LogLevel.Error);
	}
	return {
		foundLabel: false
	};
}

async function startContainer(params: DockerResolverParameters, buildParams: DockerCLIParameters, configWithRaw: SubstitutedConfig<DevContainerFromDockerComposeConfig>, projectName: string, composeFiles: string[], envFile: string | undefined, composeConfig: any, container: ContainerDetails | undefined, idLabels: string[], additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>) {
	const { common } = params;
	const { persistedFolder, output } = common;
	const { cliHost: buildCLIHost } = buildParams;
	const { config } = configWithRaw;
	const featuresBuildOverrideFilePrefix = 'docker-compose.devcontainer.build';
	const featuresStartOverrideFilePrefix = 'docker-compose.devcontainer.containerFeatures';

	common.progress(ResolverProgress.StartingContainer);

	// If dockerComposeFile is an array, add -f <file> in order. https://docs.docker.com/compose/extends/#multiple-compose-files
	const composeGlobalArgs = ([] as string[]).concat(...composeFiles.map(composeFile => ['-f', composeFile]));
	if (envFile) {
		composeGlobalArgs.push('--env-file', envFile);
	}

	const infoOutput = makeLog(buildParams.output, LogLevel.Info);
	const services = Object.keys(composeConfig.services || {});
	if (services.indexOf(config.service) === -1) {
		throw new ContainerError({ description: `Service '${config.service}' configured in devcontainer.json not found in Docker Compose configuration.`, data: { fileWithError: composeFiles[0] } });
	}

	let cancel: () => void;
	const canceled = new Promise<void>((_, reject) => cancel = reject);
	const { started } = await startEventSeen(params, { [projectLabel]: projectName, [serviceLabel]: config.service }, canceled, common.output, common.getLogLevel() === LogLevel.Trace); // await getEvents, but only assign started.

	const service = composeConfig.services[config.service];
	const originalImageName = service.image || getDefaultImageName(await buildParams.dockerComposeCLI(), projectName, config.service);

	// Try to restore the 'third' docker-compose file and featuresConfig from persisted storage.
	// This file may have been generated upon a Codespace creation.
	const labels = container?.Config?.Labels;
	output.write(`PersistedPath=${persistedFolder}, ContainerHasLabels=${!!labels}`);

	let didRestoreFromPersistedShare = false;
	if (container) {
		if (labels) {
			// update args for `docker-compose up` to use cached overrides
			const configFiles = labels['com.docker.compose.project.config_files'];
			output.write(`Container was created with these config files: ${configFiles}`);

			// Parse out the full name of the 'containerFeatures' configFile
			const files = configFiles?.split(',') ?? [];
			const persistedBuildFile = await checkForPersistedFile(buildCLIHost, output, files, featuresBuildOverrideFilePrefix);
			const persistedStartFile = await checkForPersistedFile(buildCLIHost, output, files, featuresStartOverrideFilePrefix);
			if ((persistedBuildFile.fileExists || !persistedBuildFile.foundLabel) // require build file if in label
				&& persistedStartFile.fileExists // always require start file
			) {
				didRestoreFromPersistedShare = true;
				if (persistedBuildFile.fileExists) {
					composeGlobalArgs.push('-f', persistedBuildFile.file);
				}
				if (persistedStartFile.fileExists) {
					composeGlobalArgs.push('-f', persistedStartFile.file);
				}
			}
		}
	}

	if (!container || !didRestoreFromPersistedShare) {
		const noBuild = !!container; //if we have an existing container, just recreate override files but skip the build

		const versionPrefix = await readVersionPrefix(buildCLIHost, composeFiles);
		const infoParams = { ...params, common: { ...params.common, output: infoOutput } };
		const { imageMetadata, additionalComposeOverrideFiles, overrideImageName, labels } = await buildAndExtendDockerCompose(configWithRaw, projectName, infoParams, composeFiles, envFile, composeGlobalArgs, config.runServices ?? [], params.buildNoCache ?? false, persistedFolder, featuresBuildOverrideFilePrefix, versionPrefix, additionalFeatures, true, params.additionalCacheFroms, noBuild);
		additionalComposeOverrideFiles.forEach(overrideFilePath => composeGlobalArgs.push('-f', overrideFilePath));

		const currentImageName = overrideImageName || originalImageName;
		let cache: Promise<ImageDetails> | undefined;
		const imageDetails = () => cache || (cache = inspectDockerImage(params, currentImageName, true));
		const mergedConfig = mergeConfiguration(config, imageMetadata.config);
		const updatedImageName = noBuild ? currentImageName : await updateRemoteUserUID(params, mergedConfig, currentImageName, imageDetails, service.user);

		// Save override docker-compose file to disk.
		// Persisted folder is a path that will be maintained between sessions
		// Note: As a fallback, persistedFolder is set to the build's tmpDir() directory
		const additionalLabels = labels ? idLabels.concat(Object.keys(labels).map(key => `${key}=${labels[key]}`)) : idLabels;
		const overrideFilePath = await writeFeaturesComposeOverrideFile(updatedImageName, currentImageName, mergedConfig, config, versionPrefix, imageDetails, service, additionalLabels, params.additionalMounts, persistedFolder, featuresStartOverrideFilePrefix, buildCLIHost, params, output);

		if (overrideFilePath) {
			// Add file path to override file as parameter
			composeGlobalArgs.push('-f', overrideFilePath);
		}
	}

	const args = ['--project-name', projectName, ...composeGlobalArgs];
	args.push('up', '-d');
	if (container || params.expectExistingContainer) {
		args.push('--no-recreate');
	}
	if (config.runServices && config.runServices.length) {
		args.push(...config.runServices);
		if (config.runServices.indexOf(config.service) === -1) {
			args.push(config.service);
		}
	}
	try {
		if (params.isTTY) {
			await dockerComposePtyCLI({ ...buildParams, output: infoOutput }, ...args);
		} else {
			await dockerComposeCLI({ ...buildParams, output: infoOutput }, ...args);
		}
	} catch (err) {
		cancel!();

		let description = 'An error occurred starting Docker Compose up.';
		if (err?.cmdOutput?.includes('Cannot create container for service app: authorization denied by plugin')) {
			description = err.cmdOutput;
		}

		throw new ContainerError({ description, originalError: err, data: { fileWithError: composeFiles[0] } });
	}

	await started;
	return {
		containerId: (await findComposeContainer(params, projectName, config.service))!,
	};
}

export async function readVersionPrefix(cliHost: CLIHost, composeFiles: string[]) {
	if (!composeFiles.length) {
		return '';
	}
	const firstComposeFile = (await cliHost.readFile(composeFiles[0])).toString();
	const version = (/^\s*(version:.*)$/m.exec(firstComposeFile) || [])[1];
	return version ? `${version}\n\n` : '';
}

export function getDefaultImageName(dockerComposeCLI: DockerComposeCLI, projectName: string, serviceName: string) {
	const version = parseVersion(dockerComposeCLI.version);
	const separator = version && isEarlierVersion(version, [2, 8, 0]) ? '_' : '-';
	return `${projectName}${separator}${serviceName}`;
}

async function writeFeaturesComposeOverrideFile(
	updatedImageName: string,
	originalImageName: string,
	mergedConfig: MergedDevContainerConfig,
	config: DevContainerFromDockerComposeConfig,
	versionPrefix: string,
	imageDetails: () => Promise<ImageDetails>,
	service: any,
	additionalLabels: string[],
	additionalMounts: Mount[],
	overrideFilePath: string,
	overrideFilePrefix: string,
	buildCLIHost: CLIHost,
	params: DockerResolverParameters,
	output: Log,
) {
	const composeOverrideContent = await generateFeaturesComposeOverrideContent(updatedImageName, originalImageName, mergedConfig, config, versionPrefix, imageDetails, service, additionalLabels, additionalMounts, params);
	const overrideFileHasContents = !!composeOverrideContent && composeOverrideContent.length > 0 && composeOverrideContent.trim() !== '';
	if (overrideFileHasContents) {
		output.write(`Docker Compose override file for creating container:\n${composeOverrideContent}`);

		const fileName = `${overrideFilePrefix}-${Date.now()}-${randomUUID()}.yml`;
		const composeFolder = buildCLIHost.path.join(overrideFilePath, 'docker-compose');
		const composeOverrideFile = buildCLIHost.path.join(composeFolder, fileName);
		output.write(`Writing ${fileName} to ${composeFolder}`);
		await buildCLIHost.mkdirp(composeFolder);
		await buildCLIHost.writeFile(composeOverrideFile, Buffer.from(composeOverrideContent));

		return composeOverrideFile;
	} else {
		output.write('Override file was generated, but was empty and thus not persisted or included in the docker-compose arguments.');
		return undefined;
	}
}

async function generateFeaturesComposeOverrideContent(
	updatedImageName: string,
	originalImageName: string,
	mergedConfig: MergedDevContainerConfig,
	config: DevContainerFromDockerComposeConfig,
	versionPrefix: string,
	imageDetails: () => Promise<ImageDetails>,
	service: any,
	additionalLabels: string[],
	additionalMounts: Mount[],
	params: DockerResolverParameters,
) {
	const overrideImage = updatedImageName !== originalImageName;

	const user = mergedConfig.containerUser;
	const env = mergedConfig.containerEnv || {};
	const capAdd = mergedConfig.capAdd || [];
	const securityOpts = mergedConfig.securityOpt || [];
	const mounts = [
		...mergedConfig.mounts || [],
		...additionalMounts,
	].map(m => typeof m === 'string' ? parseMount(m) : m);
	const namedVolumeMounts = mounts.filter(m => m.type === 'volume' && m.source);
	const customEntrypoints = mergedConfig.entrypoints || [];
	const composeEntrypoint: string[] | undefined = typeof service.entrypoint === 'string' ? shellQuote.parse(service.entrypoint) : service.entrypoint;
	const composeCommand: string[] | undefined = typeof service.command === 'string' ? shellQuote.parse(service.command) : service.command;
	const { overrideCommand } = mergedConfig;
	const userEntrypoint = overrideCommand ? [] : composeEntrypoint /* $ already escaped. */
		|| ((await imageDetails()).Config.Entrypoint || []).map(c => c.replace(/\$/g, '$$$$')); // $ > $$ to escape docker-compose.yml's interpolation.
	const userCommand = overrideCommand ? [] : composeCommand /* $ already escaped. */
		|| (composeEntrypoint ? [/* Ignore image CMD per docker-compose.yml spec. */] : ((await imageDetails()).Config.Cmd || []).map(c => c.replace(/\$/g, '$$$$'))); // $ > $$ to escape docker-compose.yml's interpolation.

	const hasGpuRequirement = config.hostRequirements?.gpu;
	const addGpuCapability = hasGpuRequirement && await checkDockerSupportForGPU(params);
	if (hasGpuRequirement && hasGpuRequirement !== 'optional' && !addGpuCapability) {
		params.common.output.write('No GPU support found yet a GPU was required - consider marking it as "optional"', LogLevel.Warning);
	}
	const gpuResources = addGpuCapability ? `
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]` : '';

	return `${versionPrefix}services:
  '${config.service}':${overrideImage ? `
    image: ${updatedImageName}` : ''}
    entrypoint: ["/bin/sh", "-c", "echo Container started\\n
trap \\"exit 0\\" 15\\n
${customEntrypoints.join('\\n\n')}\\n
exec \\"$$@\\"\\n
while sleep 1 & wait $$!; do :; done", "-"${userEntrypoint.map(a => `, ${JSON.stringify(a)}`).join('')}]${userCommand !== composeCommand ? `
    command: ${JSON.stringify(userCommand)}` : ''}${mergedConfig.init ? `
    init: true` : ''}${user ? `
    user: ${user}` : ''}${Object.keys(env).length ? `
    environment:${Object.keys(env).map(key => `
      - '${key}=${String(env[key]).replace(/\n/g, '\\n').replace(/\$/g, '$$$$').replace(/'/g, '\'\'')}'`).join('')}` : ''}${mergedConfig.privileged ? `
    privileged: true` : ''}${capAdd.length ? `
    cap_add:${capAdd.map(cap => `
      - ${cap}`).join('')}` : ''}${securityOpts.length ? `
    security_opt:${securityOpts.map(securityOpt => `
      - ${securityOpt}`).join('')}` : ''}${additionalLabels.length ? `
    labels:${additionalLabels.map(label => `
      - '${label.replace(/\$/g, '$$$$').replace(/'/g, '\'\'')}'`).join('')}` : ''}${mounts.length ? `
    volumes:${mounts.map(m => `
      - ${convertMountToVolume(m)}`).join('')}` : ''}${gpuResources}${namedVolumeMounts.length ? `
volumes:${namedVolumeMounts.map(m => `
  ${convertMountToVolumeTopLevelElement(m)}`).join('')}` : ''}
`;
}

export async function readDockerComposeConfig(params: DockerCLIParameters, composeFiles: string[], envFile: string | undefined) {
	try {
		const composeGlobalArgs = ([] as string[]).concat(...composeFiles.map(composeFile => ['-f', composeFile]));
		if (envFile) {
			composeGlobalArgs.push('--env-file', envFile);
		}
		const composeCLI = await params.dockerComposeCLI();
		if ((parseVersion(composeCLI.version) || [])[0] >= 2) {
			composeGlobalArgs.push('--profile', '*');
		}
		try {
			const partial = toExecParameters(params, 'dockerComposeCLI' in params ? await params.dockerComposeCLI() : undefined);
			const { stdout } = await dockerComposeCLI({
				...partial,
				output: makeLog(params.output, LogLevel.Info),
				print: 'onerror'
			}, ...composeGlobalArgs, 'config');
			const stdoutStr = stdout.toString();
			params.output.write(stdoutStr);
			return yaml.load(stdoutStr) || {} as any;
		} catch (err) {
			if (!Buffer.isBuffer(err?.stderr) || err?.stderr.toString().indexOf('UnicodeEncodeError') === -1) {
				throw err;
			}
			// Upstream issues. https://github.com/microsoft/vscode-remote-release/issues/5308
			if (params.cliHost.platform === 'win32') {
				const { cmdOutput } = await dockerComposePtyCLI({
					...params,
					output: makeLog({
						event: params.output.event,
						dimensions: {
							columns: 999999,
							rows: 1,
						},
					}, LogLevel.Info),
				}, ...composeGlobalArgs, 'config');
				return yaml.load(cmdOutput.replace(terminalEscapeSequences, '')) || {} as any;
			}
			const { stdout } = await dockerComposeCLI({
				...params,
				env: {
					...params.env,
					LANG: 'en_US.UTF-8',
					LC_CTYPE: 'en_US.UTF-8',
				}
			}, ...composeGlobalArgs, 'config');
			const stdoutStr = stdout.toString();
			params.output.write(stdoutStr);
			return yaml.load(stdoutStr) || {} as any;
		}
	} catch (err) {
		throw err instanceof ContainerError ? err : new ContainerError({ description: 'An error occurred retrieving the Docker Compose configuration.', originalError: err, data: { fileWithError: composeFiles[0] } });
	}
}

export async function findComposeContainer(params: DockerCLIParameters | DockerResolverParameters, projectName: string, serviceName: string): Promise<string | undefined> {
	const list = await listContainers(params, true, [
		`${projectLabel}=${projectName}`,
		`${serviceLabel}=${serviceName}`
	]);
	return list && list[0];
}

export async function getProjectName(params: DockerCLIParameters | DockerResolverParameters, workspace: Workspace, composeFiles: string[], composeConfig: any) {
	const { cliHost } = 'cliHost' in params ? params : params.common;
	const newProjectName = await useNewProjectName(params);
	const envName = toProjectName(cliHost.env.COMPOSE_PROJECT_NAME || '', newProjectName);
	if (envName) {
		return envName;
	}
	try {
		const envPath = cliHost.path.join(cliHost.cwd, '.env');
		const buffer = await cliHost.readFile(envPath);
		const match = /^COMPOSE_PROJECT_NAME=(.+)$/m.exec(buffer.toString());
		const value = match && match[1].trim();
		const envFileName = toProjectName(value || '', newProjectName);
		if (envFileName) {
			return envFileName;
		}
	} catch (err) {
		if (!(err && (err.code === 'ENOENT' || err.code === 'EISDIR'))) {
			throw err;
		}
	}
	if (composeConfig?.name) {
		if (composeConfig.name !== 'devcontainer') {
			return toProjectName(composeConfig.name, newProjectName);
		}
		// Check if 'devcontainer' is from a compose file or just the default.
		for (let i = composeFiles.length - 1; i >= 0; i--) {
			try {
				const fragment = yaml.load((await cliHost.readFile(composeFiles[i])).toString()) || {} as any;
				if (fragment.name) {
					// Use composeConfig.name ('devcontainer') because fragment.name could include environment variables.
					return toProjectName(composeConfig.name, newProjectName);
				}
			} catch (error) {
				// Ignore when parsing fails due to custom yaml tags (e.g., !reset)
			}
		}
	}
	const configDir = workspace.configFolderPath;
	const workingDir = composeFiles[0] ? cliHost.path.dirname(composeFiles[0]) : cliHost.cwd; // From https://github.com/docker/compose/blob/79557e3d3ab67c3697641d9af91866d7e400cfeb/compose/config/config.py#L290
	if (equalPaths(cliHost.platform, workingDir, cliHost.path.join(configDir, '.devcontainer'))) {
		return toProjectName(`${cliHost.path.basename(configDir)}_devcontainer`, newProjectName);
	}
	return toProjectName(cliHost.path.basename(workingDir), newProjectName);
}

function toProjectName(basename: string, newProjectName: boolean) {
	// From https://github.com/docker/compose/blob/79557e3d3ab67c3697641d9af91866d7e400cfeb/compose/cli/command.py#L152
	if (!newProjectName) {
		return basename.toLowerCase().replace(/[^a-z0-9]/g, '');
	}
	return basename.toLowerCase().replace(/[^-_a-z0-9]/g, '');
}

async function useNewProjectName(params: DockerCLIParameters | DockerResolverParameters) {
	try {
		const version = parseVersion((await params.dockerComposeCLI()).version);
		if (!version) {
			return true; // Optimistically continue.
		}
		return !isEarlierVersion(version, [1, 21, 0]); // 1.21.0 changed allowed characters in project names (added hyphen and underscore).
	} catch (err) {
		return true; // Optimistically continue.
	}
}

export function dockerComposeCLIConfig(params: Omit<PartialExecParameters, 'cmd'>, dockerCLICmd: string, dockerComposeCLICmd: string) {
	let result: Promise<DockerComposeCLI>;
	return () => {
		return result || (result = (async () => {
			let v2 = true;
			let stdout: Buffer;
			try {
				stdout = (await dockerComposeCLI({
					...params,
					cmd: dockerCLICmd,
				}, 'compose', 'version', '--short')).stdout;
			} catch (err) {
				stdout = (await dockerComposeCLI({
					...params,
					cmd: dockerComposeCLICmd,
				}, 'version', '--short')).stdout;
				v2 = false;
			}
			const version = stdout.toString().trim();
			params.output.write(`Docker Compose version: ${version}`);
			return {
				version,
				cmd: v2 ? dockerCLICmd : dockerComposeCLICmd,
				args: v2 ? ['compose'] : [],
			};
		})());
	};
}

/**
 * Convert mount command arguments to Docker Compose volume
 * @param mount
 * @returns mount command representation for Docker compose
 */
function convertMountToVolume(mount: Mount): string {
	let volume: string = '';

	if (mount.source) {
		volume = `${mount.source}:`;
	}

	volume += mount.target;

	return volume;
}

/**
 * Convert mount command arguments to volume top-level element
 * @param mount
 * @returns mount object representation as volumes top-level element
 */
function convertMountToVolumeTopLevelElement(mount: Mount): string {
	let volume: string = `
  ${mount.source}:`;

	if (mount.external) {
		volume += '\n    external: true';
	}

	return volume;
}
</file>

<file path="src/spec-node/dockerfileUtils.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as semver from 'semver';
import { Mount } from '../spec-configuration/containerFeaturesConfiguration';


const findFromLines = new RegExp(/^(?<line>\s*FROM.*)/, 'gmi');
const parseFromLine = /FROM\s+(?<platform>--platform=\S+\s+)?(?<image>"?[^\s]+"?)(\s+AS\s+(?<label>[^\s]+))?/i;

const fromStatement = /^\s*FROM\s+(?<platform>--platform=\S+\s+)?(?<image>"?[^\s]+"?)(\s+AS\s+(?<label>[^\s]+))?/mi;
const argEnvUserStatements = /^\s*(?<instruction>ARG|ENV|USER)\s+(?<name>[^\s=]+)([ =]+("(?<value1>\S+)"|(?<value2>\S+)))?/gmi;
const directives = /^\s*#\s*(?<name>\S+)\s*=\s*(?<value>.+)/;

const argumentExpression = /\$\{?(?<variable>[a-zA-Z0-9_]+)(?<isVarExp>:(?<option>-|\+)(?<word>[^\}]+))?\}?/g;

export interface Dockerfile {
	preamble: {
		version: string | undefined;
		directives: Record<string, string>;
		instructions: Instruction[];
	};
	stages: Stage[];
	stagesByLabel: Record<string, Stage>;
}

export interface Stage {
	from: From;
	instructions: Instruction[];
}

export interface From {
	platform?: string;
	image: string;
	label?: string;
}

export interface Instruction {
	instruction: string;
	name: string;
	value: string | undefined;
}

function parseFromStatement(line: string): From {
	const match = fromStatement.exec(line);
	if (!match) {
		return { image: 'unknown' };
	}
	let { platform, image, label } = match.groups as unknown as From;
	image = image.replace(/^['"]|['"]$/g, ''); // remove quotes
	return { platform, image, label };
}

export function extractDockerfile(dockerfile: string): Dockerfile {
	const fromStatementsAhead = /(?=^[\t ]*FROM)/gmi;
	const parts = dockerfile.split(fromStatementsAhead);
	const preambleStr = fromStatementsAhead.test(parts[0] || '') ? '' : parts.shift()!;
	const stageStrs = parts;
	const stages = stageStrs.map(stageStr => ({
		from: parseFromStatement(stageStr),
		instructions: extractInstructions(stageStr),
	}));
	const directives = extractDirectives(preambleStr);
	const versionMatch = directives.syntax && /^(?:docker.io\/)?docker\/dockerfile(?::(?<version>\S+))?/i.exec(directives.syntax) || undefined;
	const version = versionMatch && (versionMatch.groups?.version || 'latest');
	return {
		preamble: {
			version,
			directives,
			instructions: extractInstructions(preambleStr),
		},
		stages,
		stagesByLabel: stages.reduce((obj, stage) => {
			if (stage.from.label) {
				obj[stage.from.label] = stage;
			}
			return obj;
		}, {} as Record<string, Stage>),
	} as Dockerfile;
}

export function findUserStatement(dockerfile: Dockerfile, buildArgs: Record<string, string>, baseImageEnv: Record<string, string>, target: string | undefined) {
	let stage: Stage | undefined = target ? dockerfile.stagesByLabel[target] : dockerfile.stages[dockerfile.stages.length - 1];
	const seen = new Set<Stage>();
	while (stage) {
		if (seen.has(stage)) {
			return undefined;
		}
		seen.add(stage);

		const i = findLastIndex(stage.instructions, i => i.instruction === 'USER');
		if (i !== -1) {
			return replaceVariables(dockerfile, buildArgs, baseImageEnv, stage.instructions[i].name, stage, i) || undefined;
		}
		const image = replaceVariables(dockerfile, buildArgs, baseImageEnv, stage.from.image, dockerfile.preamble, dockerfile.preamble.instructions.length);
		stage = dockerfile.stagesByLabel[image];
	}
	return undefined;
}

export function findBaseImage(dockerfile: Dockerfile, buildArgs: Record<string, string>, target: string | undefined) {
	let stage: Stage | undefined = target ? dockerfile.stagesByLabel[target] : dockerfile.stages[dockerfile.stages.length - 1];
	const seen = new Set<Stage>();
	while (stage) {
		if (seen.has(stage)) {
			return undefined;
		}
		seen.add(stage);

		const image = replaceVariables(dockerfile, buildArgs, /* not available in FROM instruction */ {}, stage.from.image, dockerfile.preamble, dockerfile.preamble.instructions.length);
		const nextStage = dockerfile.stagesByLabel[image];
		if (!nextStage) {
			return image;
		}
		stage = nextStage;
	}
	return undefined;
}

function extractDirectives(preambleStr: string) {
	const map: Record<string, string> = {};
	for (const line of preambleStr.split(/\r?\n/)) {
		const groups = line.match(directives)?.groups;
		if (groups) {
			if (!map[groups.name]) {
				map[groups.name] = groups.value;
			}
		} else {
			break;
		}
	}
	return map;
}

function extractInstructions(stageStr: string) {
	return [...stageStr.matchAll(argEnvUserStatements)]
		.map(match => {
			const groups = match.groups!;
			return {
				instruction: groups.instruction.toUpperCase(),
				name: groups.name,
				value: groups.value1 || groups.value2,
			};
		});
}

function getExpressionValue(option: string, isSet: boolean, word: string, value: string) {
	const operations: Record<string, Function> = { 
		'-': (isSet: boolean, word: string, value: string) => isSet ? value : word,
		'+': (isSet: boolean, word: string, value: string) => isSet ? word : value,
	};

	return operations[option](isSet, word, value).replace(/^['"]|['"]$/g, ''); // remove quotes from start and end of the string
}

function replaceVariables(dockerfile: Dockerfile, buildArgs: Record<string, string>, baseImageEnv: Record<string, string>, str: string, stage: { from?: From; instructions: Instruction[] }, beforeInstructionIndex: number) {			
	return [...str.matchAll(argumentExpression)]
		.map(match => {
			const variable = match.groups!.variable;
			const isVarExp = match.groups!.isVarExp ? true : false;
			let value = findValue(dockerfile, buildArgs, baseImageEnv, variable, stage, beforeInstructionIndex) || '';
			if (isVarExp) {
				// Handle replacing variable expressions (${var:+word}) if they exist
				const option = match.groups!.option;
				const word = match.groups!.word;
				const isSet = value !== '';
				value = getExpressionValue(option, isSet, word, value);
			}

			return {
				begin: match.index!,
				end: match.index! + match[0].length,
				value,
			};
		}).reverse()
		.reduce((str, { begin, end, value }) => str.substring(0, begin) + value + str.substring(end), str);
}

function findValue(dockerfile: Dockerfile, buildArgs: Record<string, string>, baseImageEnv: Record<string, string>, variable: string, stage: { from?: From; instructions: Instruction[] }, beforeInstructionIndex: number): string | undefined {
	let considerArg = true;
	const seen = new Set<typeof stage>();
	while (true) {
		if (seen.has(stage)) {
			return undefined;
		}
		seen.add(stage);

		const i = findLastIndex(stage.instructions, i => i.name === variable && (i.instruction === 'ENV' || (considerArg && typeof (buildArgs[i.name] ?? i.value) === 'string')), beforeInstructionIndex - 1);
		if (i !== -1) {
			const instruction = stage.instructions[i];
			if (instruction.instruction === 'ENV') {
				return replaceVariables(dockerfile, buildArgs, baseImageEnv, instruction.value!, stage, i);
			}
			if (instruction.instruction === 'ARG') {
				return replaceVariables(dockerfile, buildArgs, baseImageEnv, buildArgs[instruction.name] ?? instruction.value, stage, i);
			}
		}

		if (!stage.from) {
			const value = baseImageEnv[variable];
			if (typeof value === 'string') {
				return value;
			}
			return undefined;
		}

		const image = replaceVariables(dockerfile, buildArgs, baseImageEnv, stage.from.image, dockerfile.preamble, dockerfile.preamble.instructions.length);
		stage = dockerfile.stagesByLabel[image] || dockerfile.preamble;
		beforeInstructionIndex = stage.instructions.length;
		considerArg = stage === dockerfile.preamble;
	}
}

function findLastIndex<T>(array: T[], predicate: (value: T, index: number, obj: T[]) => boolean, position = array.length - 1): number {
	for (let i = position; i >= 0; i--) {
		if (predicate(array[i], i, array)) {
			return i;
		}
	}
	return -1;
}

// not expected to be called externally (exposed for testing)
export function ensureDockerfileHasFinalStageName(dockerfile: string, defaultLastStageName: string): { lastStageName: string; modifiedDockerfile: string | undefined } {

	// Find the last line that starts with "FROM" (possibly preceeded by white-space)
	const fromLines = [...dockerfile.matchAll(findFromLines)];
	if (fromLines.length === 0) {
		throw new Error('Error parsing Dockerfile: Dockerfile contains no FROM instructions');
	}

	const lastFromLineMatch = fromLines[fromLines.length - 1];
	const lastFromLine = lastFromLineMatch.groups?.line as string;

	// Test for "FROM [--platform=someplat] base [as label]"
	// That is, match against optional platform and label
	const fromMatch = lastFromLine.match(parseFromLine);
	if (!fromMatch) {
		throw new Error('Error parsing Dockerfile: failed to parse final FROM line');
	}
	if (fromMatch.groups?.label) {
		return {
			lastStageName: fromMatch.groups.label,
			modifiedDockerfile: undefined,
		};
	}

	// Last stage doesn't have a name, so modify the Dockerfile to set the name to defaultLastStageName
	const lastLineStartIndex = (lastFromLineMatch.index as number) + (fromMatch.index as number);
	const lastLineEndIndex = lastLineStartIndex + lastFromLine.length;
	const matchedFromText = fromMatch[0];
	let modifiedDockerfile = dockerfile.slice(0, lastLineStartIndex + matchedFromText.length);

	modifiedDockerfile += ` AS ${defaultLastStageName}`;
	const remainingFromLineLength = lastFromLine.length - matchedFromText.length;
	modifiedDockerfile += dockerfile.slice(lastLineEndIndex - remainingFromLineLength);

	return { lastStageName: defaultLastStageName, modifiedDockerfile: modifiedDockerfile };
}

export function supportsBuildContexts(dockerfile: Dockerfile) {
	const version = dockerfile.preamble.version;
	if (!version) {
		return dockerfile.preamble.directives.syntax ? 'unknown' : false;
	}
	const numVersion = (/^\d+(\.\d+){0,2}/.exec(version) || [])[0];
	if (!numVersion) {
		return true; // latest, labs or no tag.
	}
	return semver.intersects(numVersion, '>=1.4');
}

/**
 * Convert mount command' arguments to string 
 * @param mount 
 * @returns mount command string 
 */
export function generateMountCommand(mount: Mount | string): string[] {
	const command: string = '--mount';

	if (typeof mount === 'string') {
		return [command, mount];
	}

	const type: string = `type=${mount.type},`;
	const source: string = mount.source ? `src=${mount.source},` : '';
	const destination: string = `dst=${mount.target}`;

	const args: string = `${type}${source}${destination}`;

	return [command, args];
}
</file>

<file path="src/spec-node/featureUtils.ts">
import { DevContainerConfig } from '../spec-configuration/configuration';
import { FeaturesConfig, generateFeaturesConfig } from '../spec-configuration/containerFeaturesConfiguration';
import { DockerCLIParameters } from '../spec-shutdown/dockerUtils';
import { PackageConfiguration } from '../spec-utils/product';
import { createFeaturesTempFolder, getCacheFolder } from './utils';

export async function readFeaturesConfig(params: DockerCLIParameters, pkg: PackageConfiguration, config: DevContainerConfig, extensionPath: string, skipFeatureAutoMapping: boolean, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>): Promise<FeaturesConfig | undefined> {
	const { cliHost, output } = params;
	const { cwd, env, platform } = cliHost;
	const featuresTmpFolder = await createFeaturesTempFolder({ cliHost, package: pkg });
	const cacheFolder = await getCacheFolder(cliHost);
	return generateFeaturesConfig({ extensionPath, cacheFolder, cwd, output, env, skipFeatureAutoMapping, platform }, featuresTmpFolder, config, additionalFeatures);
}
</file>

<file path="src/spec-node/imageMetadata.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { ContainerError } from '../spec-common/errors';
import { LifecycleCommand, LifecycleHooksInstallMap } from '../spec-common/injectHeadless';
import { DevContainerConfig, DevContainerConfigCommand, DevContainerFromDockerComposeConfig, DevContainerFromDockerfileConfig, DevContainerFromImageConfig, getDockerComposeFilePaths, getDockerfilePath, HostGPURequirements, HostRequirements, isDockerFileConfig, PortAttributes, UserEnvProbe } from '../spec-configuration/configuration';
import { Feature, FeaturesConfig, Mount, parseMount, SchemaFeatureLifecycleHooks } from '../spec-configuration/containerFeaturesConfiguration';
import { ContainerDetails, DockerCLIParameters, ImageDetails } from '../spec-shutdown/dockerUtils';
import { Log, LogLevel } from '../spec-utils/log';
import { getBuildInfoForService, readDockerComposeConfig } from './dockerCompose';
import { Dockerfile, extractDockerfile, findBaseImage, findUserStatement } from './dockerfileUtils';
import { SubstituteConfig, SubstitutedConfig, DockerResolverParameters, inspectDockerImage, uriToWSLFsPath, envListToObj } from './utils';

const pickConfigProperties: (keyof DevContainerConfig & keyof ImageMetadataEntry)[] = [
	'onCreateCommand',
	'updateContentCommand',
	'postCreateCommand',
	'postStartCommand',
	'postAttachCommand',
	'waitFor',
	'customizations',
	'mounts',
	'containerEnv',
	'containerUser',
	'init',
	'privileged',
	'capAdd',
	'securityOpt',
	'remoteUser',
	'userEnvProbe',
	'remoteEnv',
	'overrideCommand',
	'portsAttributes',
	'otherPortsAttributes',
	'forwardPorts',
	'shutdownAction',
	'updateRemoteUserUID',
	'hostRequirements',
];

const pickUpdateableConfigProperties: (keyof DevContainerConfig & keyof ImageMetadataEntry)[] = [
	'remoteUser',
	'userEnvProbe',
	'remoteEnv',
];

const pickFeatureLifecycleHookProperties: Exclude<keyof SchemaFeatureLifecycleHooks, 'id'>[] = [
	'onCreateCommand',
	'updateContentCommand',
	'postCreateCommand',
	'postStartCommand',
	'postAttachCommand',
];

const pickFeatureProperties: Exclude<keyof Feature & keyof ImageMetadataEntry, 'id'>[] = [
	...pickFeatureLifecycleHookProperties,
	'init',
	'privileged',
	'capAdd',
	'securityOpt',
	'entrypoint',
	'mounts',
	'customizations',
];

export interface ImageMetadataEntry {
	id?: string;
	init?: boolean;
	privileged?: boolean;
	capAdd?: string[];
	securityOpt?: string[];
	entrypoint?: string;
	mounts?: (Mount | string)[];
	customizations?: Record<string, any>;
	onCreateCommand?: LifecycleCommand;
	updateContentCommand?: LifecycleCommand;
	postCreateCommand?: LifecycleCommand;
	postStartCommand?: LifecycleCommand;
	postAttachCommand?: LifecycleCommand;
	waitFor?: DevContainerConfigCommand;
	remoteUser?: string;
	containerUser?: string;
	userEnvProbe?: UserEnvProbe;
	remoteEnv?: Record<string, string | null>;
	containerEnv?: Record<string, string>;
	overrideCommand?: boolean;
	portsAttributes?: Record<string, PortAttributes>;
	otherPortsAttributes?: PortAttributes;
	forwardPorts?: (number | string)[];
	shutdownAction?: 'none' | 'stopContainer' | 'stopCompose';
	updateRemoteUserUID?: boolean;
	hostRequirements?: HostRequirements;
}

export type MergedDevContainerConfig = MergedConfig<DevContainerFromImageConfig> | MergedConfig<DevContainerFromDockerfileConfig> | MergedConfig<DevContainerFromDockerComposeConfig>;

type MergedConfig<T extends DevContainerConfig> = Omit<T, typeof replaceProperties[number]> & UpdatedConfigProperties;

const replaceProperties = [
	'customizations',
	'entrypoint',
	'onCreateCommand',
	'updateContentCommand',
	'postCreateCommand',
	'postStartCommand',
	'postAttachCommand',
	'shutdownAction'
] as const;

interface UpdatedConfigProperties {
	customizations?: Record<string, any[]>;
	entrypoints?: string[];
	onCreateCommands?: LifecycleCommand[];
	updateContentCommands?: LifecycleCommand[];
	postCreateCommands?: LifecycleCommand[];
	postStartCommands?: LifecycleCommand[];
	postAttachCommands?: LifecycleCommand[];
	shutdownAction?: 'none' | 'stopContainer' | 'stopCompose';
}

export function lifecycleCommandOriginMapFromMetadata(metadata: ImageMetadataEntry[]): LifecycleHooksInstallMap {
	const map: LifecycleHooksInstallMap = {
		onCreateCommand: [],
		updateContentCommand: [],
		postCreateCommand: [],
		postStartCommand: [],
		postAttachCommand: [],
		initializeCommand: []
	};
	for (const entry of metadata) {
		const id = entry.id; // Only Features have IDs encoded in the metadata.
		const origin = id ?? 'devcontainer.json';
		for (const hook of pickFeatureLifecycleHookProperties) {
			const command = entry[hook];
			if (command) {
				map[hook].push({ origin, command });
			}
		}
	}
	return map;
}

function mergeLifecycleHooks(metadata: ImageMetadataEntry[], hook: (keyof SchemaFeatureLifecycleHooks)): LifecycleCommand[] | undefined {
	const collected: LifecycleCommand[] = [];
	for (const entry of metadata) {
		const command = entry[hook];
		if (command) {
			collected.push(command);
		}
	}
	return collected;
}

export function mergeConfiguration(config: DevContainerConfig, imageMetadata: ImageMetadataEntry[]): MergedDevContainerConfig {
	const customizations = imageMetadata.reduce((obj, entry) => {
		for (const key in entry.customizations) {
			if (key in obj) {
				obj[key].push(entry.customizations[key]);
			} else {
				obj[key] = [entry.customizations[key]];
			}
		}
		return obj;
	}, {} as Record<string, any[]>);
	const reversed = imageMetadata.slice().reverse();
	const copy = { ...config };
	replaceProperties.forEach(property => delete (copy as any)[property]);
	const merged: MergedDevContainerConfig = {
		...copy,
		init: imageMetadata.some(entry => entry.init),
		privileged: imageMetadata.some(entry => entry.privileged),
		capAdd: unionOrUndefined(imageMetadata.map(entry => entry.capAdd)),
		securityOpt: unionOrUndefined(imageMetadata.map(entry => entry.securityOpt)),
		entrypoints: collectOrUndefined(imageMetadata, 'entrypoint'),
		mounts: mergeMounts(imageMetadata),
		customizations: Object.keys(customizations).length ? customizations : undefined,
		onCreateCommands: mergeLifecycleHooks(imageMetadata, 'onCreateCommand'),
		updateContentCommands: mergeLifecycleHooks(imageMetadata, 'updateContentCommand'),
		postCreateCommands: mergeLifecycleHooks(imageMetadata, 'postCreateCommand'),
		postStartCommands: mergeLifecycleHooks(imageMetadata, 'postStartCommand'),
		postAttachCommands: mergeLifecycleHooks(imageMetadata, 'postAttachCommand'),
		waitFor: reversed.find(entry => entry.waitFor)?.waitFor,
		remoteUser: reversed.find(entry => entry.remoteUser)?.remoteUser,
		containerUser: reversed.find(entry => entry.containerUser)?.containerUser,
		userEnvProbe: reversed.find(entry => entry.userEnvProbe)?.userEnvProbe,
		remoteEnv: Object.assign({}, ...imageMetadata.map(entry => entry.remoteEnv)),
		containerEnv: Object.assign({}, ...imageMetadata.map(entry => entry.containerEnv)),
		overrideCommand: reversed.find(entry => typeof entry.overrideCommand === 'boolean')?.overrideCommand,
		portsAttributes: Object.assign({}, ...imageMetadata.map(entry => entry.portsAttributes)),
		otherPortsAttributes: reversed.find(entry => entry.otherPortsAttributes)?.otherPortsAttributes,
		forwardPorts: mergeForwardPorts(imageMetadata),
		shutdownAction: reversed.find(entry => entry.shutdownAction)?.shutdownAction,
		updateRemoteUserUID: reversed.find(entry => typeof entry.updateRemoteUserUID === 'boolean')?.updateRemoteUserUID,
		hostRequirements: mergeHostRequirements(imageMetadata),
	};
	return merged;
}

function mergeForwardPorts(imageMetadata: ImageMetadataEntry[]): (number | string)[] | undefined {
	const forwardPorts = [
		...new Set(
			([] as (number | string)[]).concat(...imageMetadata.map(entry => entry.forwardPorts || []))
				.map(port => typeof port === 'number' ? `localhost:${port}` : port)
		)
	].map(port => /localhost:\d+/.test(port) ? parseInt(port.substring('localhost:'.length)) : port);
	return forwardPorts.length ? forwardPorts : undefined;
}

function mergeHostRequirements(imageMetadata: ImageMetadataEntry[]) {
	const cpus = Math.max(...imageMetadata.map(m => m.hostRequirements?.cpus || 0));
	const memory = Math.max(...imageMetadata.map(m => parseBytes(m.hostRequirements?.memory || '0')));
	const storage = Math.max(...imageMetadata.map(m => parseBytes(m.hostRequirements?.storage || '0')));
	const gpu = imageMetadata.map(m => m.hostRequirements?.gpu).reduce(mergeGpuRequirements, undefined);
	return cpus || memory || storage || gpu ? {
		cpus,
		memory: memory ? `${memory}` : undefined,
		storage: storage ? `${storage}` : undefined,
		gpu: gpu,
	} : undefined;
}

function mergeGpuRequirements(a: undefined | boolean | 'optional' | HostGPURequirements, b: undefined | boolean | 'optional' | HostGPURequirements): undefined | boolean | 'optional' | HostGPURequirements {
	// simple cases if either are undefined/false we use the other one
	if (a === undefined || a === false) {
		return b;
	} else if (b === undefined || b === false) {
		return a;
	} else if (a === 'optional' && b === 'optional') {
		return 'optional';
	} else {
		const aObject = asHostGPURequirements(a);
		const bObject = asHostGPURequirements(b);
		const cores = Math.max(aObject.cores || 0, bObject.cores || 0);
		const memory = Math.max(parseBytes(aObject.memory || '0'), parseBytes(bObject.memory || '0'));
		return {
			cores: cores ? cores : undefined,
			memory: memory ? `${memory}` : undefined,
		};
	}
}

function asHostGPURequirements(a: undefined | boolean | 'optional' | HostGPURequirements): HostGPURequirements {
	if (typeof a !== 'object') {
		return {};
	} else {
		return a as HostGPURequirements;
	}
}

function parseBytes(str: string) {
	const m = /^(\d+)([tgmk]b)?$/.exec(str);
	if (m) {
		const [, strn, stru] = m;
		const n = parseInt(strn, 10);
		const u = stru && { t: 2 ** 40, g: 2 ** 30, m: 2 ** 20, k: 2 ** 10 }[stru[0]] || 1;
		return n * u;
	}
	return 0;
}

function mergeMounts(imageMetadata: ImageMetadataEntry[]): (Mount | string)[] | undefined {
	const seen = new Set<string>();
	const mounts = imageMetadata.map(entry => entry.mounts)
		.filter(Boolean)
		.flat()
		.map(mount => ({
			obj: typeof mount === 'string' ? parseMount(mount) : mount!,
			orig: mount!,
		}))
		.reverse()
		.filter(mount => !seen.has(mount.obj.target) && seen.add(mount.obj.target))
		.reverse()
		.map(mount => mount.orig);
	return mounts.length ? mounts : undefined;
}

function unionOrUndefined<T>(entries: (T[] | undefined)[]): T[] | undefined {
	const values = [...new Set(([] as T[]).concat(...entries.filter(entry => !!entry) as T[][]))];
	return values.length ? values : undefined;
}

function collectOrUndefined<T, K extends keyof T>(entries: T[], property: K): NonNullable<T[K]>[] | undefined {
	const values = entries.map(entry => entry[property])
		.filter(value => !!value) as NonNullable<T[K]>[];
	return values.length ? values : undefined;
}

export function getDevcontainerMetadata(baseImageMetadata: SubstitutedConfig<ImageMetadataEntry[]>, devContainerConfig: SubstitutedConfig<DevContainerConfig>, featuresConfig: FeaturesConfig | undefined, omitPropertyOverride: string[] = [], omitDevcontainerPropertyOverride: (keyof DevContainerConfig & keyof ImageMetadataEntry)[] = []): SubstitutedConfig<ImageMetadataEntry[]> {
	const effectivePickFeatureProperties = pickFeatureProperties.filter(property => !omitPropertyOverride.includes(property));
	const effectivePickDevcontainerProperties = pickConfigProperties.filter(property => !omitDevcontainerPropertyOverride.includes(property));

	const featureRaw = featuresConfig?.featureSets.map(featureSet =>
		featureSet.features.map(feature => ({
			id: featureSet.sourceInformation.userFeatureId,
			...pick(feature, effectivePickFeatureProperties),
		}))).flat() || [];

	const raw = [
		...baseImageMetadata.raw,
		...featureRaw,
		pick(devContainerConfig.raw, effectivePickDevcontainerProperties),
	].filter(config => Object.keys(config).length);

	return {
		config: [
			...baseImageMetadata.config,
			...featureRaw.map(devContainerConfig.substitute),
			pick(devContainerConfig.config, effectivePickDevcontainerProperties),
		].filter(config => Object.keys(config).length),
		raw,
		substitute: devContainerConfig.substitute,
	};
}

function pick<T extends object, K extends keyof T>(obj: T, keys: K[]) {
	return keys.reduce((res, key) => {
		if (key in obj) {
			res[key] = obj[key];
		}
		return res;
	}, {} as Pick<T, K>);
}

export interface ImageBuildInfo {
	user: string;
	metadata: SubstitutedConfig<ImageMetadataEntry[]>;
	dockerfile?: Dockerfile;
}

export async function getImageBuildInfo(params: DockerResolverParameters | DockerCLIParameters, configWithRaw: SubstitutedConfig<DevContainerConfig>): Promise<ImageBuildInfo> {
	const { dockerCLI, dockerComposeCLI } = params;
	const { cliHost, output } = 'cliHost' in params ? params : params.common;

	const { config } = configWithRaw;
	if (isDockerFileConfig(config)) {

		const dockerfileUri = getDockerfilePath(cliHost, config);
		const dockerfilePath = await uriToWSLFsPath(dockerfileUri, cliHost);
		if (!cliHost.isFile(dockerfilePath)) {
			throw new ContainerError({ description: `Dockerfile (${dockerfilePath}) not found.` });
		}
		const dockerfile = (await cliHost.readFile(dockerfilePath)).toString();
		return getImageBuildInfoFromDockerfile(params, dockerfile, config.build?.args || {}, config.build?.target, configWithRaw.substitute);

	} else if ('dockerComposeFile' in config) {

		const cwdEnvFile = cliHost.path.join(cliHost.cwd, '.env');
		const envFile = Array.isArray(config.dockerComposeFile) && config.dockerComposeFile.length === 0 && await cliHost.isFile(cwdEnvFile) ? cwdEnvFile : undefined;
		const composeFiles = await getDockerComposeFilePaths(cliHost, config, cliHost.env, cliHost.cwd);
		const buildParams: DockerCLIParameters = { cliHost, dockerCLI, dockerComposeCLI, env: cliHost.env, output, platformInfo: params.platformInfo };

		const composeConfig = await readDockerComposeConfig(buildParams, composeFiles, envFile);
		const services = Object.keys(composeConfig.services || {});
		if (services.indexOf(config.service) === -1) {
			throw new Error(`Service '${config.service}' configured in devcontainer.json not found in Docker Compose configuration.`);
		}

		const composeService = composeConfig.services[config.service];
		const serviceInfo = getBuildInfoForService(composeService, cliHost.path, composeFiles);
		if (serviceInfo.build) {
			const { context, dockerfilePath } = serviceInfo.build;
			const resolvedDockerfilePath = cliHost.path.isAbsolute(dockerfilePath) ? dockerfilePath : cliHost.path.resolve(context, dockerfilePath);
			const dockerfile = (await cliHost.readFile(resolvedDockerfilePath)).toString();
			return getImageBuildInfoFromDockerfile(params, dockerfile, serviceInfo.build.args || {}, serviceInfo.build.target, configWithRaw.substitute);
		} else {
			return getImageBuildInfoFromImage(params, composeService.image, configWithRaw.substitute);
		}

	} else {

		if (!config.image) {
			throw new ContainerError({ description: 'No image information specified in devcontainer.json.' });
		}

		return getImageBuildInfoFromImage(params, config.image, configWithRaw.substitute);

	}
}

export async function getImageBuildInfoFromImage(params: DockerResolverParameters | DockerCLIParameters, imageName: string, substitute: SubstituteConfig): Promise<ImageBuildInfo & { imageDetails: ImageDetails }> {
	const imageDetails = await inspectDockerImage(params, imageName, true);
	const user = imageDetails.Config.User || 'root';
	const { output } = 'output' in params ? params : params.common;
	const metadata = getImageMetadata(imageDetails, substitute, output);
	return {
		user,
		metadata,
		imageDetails,
	};
}

export async function getImageBuildInfoFromDockerfile(params: DockerResolverParameters | DockerCLIParameters, dockerfile: string, dockerBuildArgs: Record<string, string>, targetStage: string | undefined, substitute: SubstituteConfig) {
	const { output } = 'output' in params ? params : params.common;
	const omitSyntaxDirective = 'common' in params ? !!params.common.omitSyntaxDirective : false;
	return internalGetImageBuildInfoFromDockerfile(imageName => inspectDockerImage(params, imageName, true), dockerfile, dockerBuildArgs, targetStage, substitute, output, omitSyntaxDirective);
}

export async function internalGetImageBuildInfoFromDockerfile(inspectDockerImage: (imageName: string) => Promise<ImageDetails>, dockerfileText: string, dockerBuildArgs: Record<string, string>, targetStage: string | undefined, substitute: SubstituteConfig, output: Log, omitSyntaxDirective: boolean): Promise<ImageBuildInfo> {
	const dockerfile = extractDockerfile(dockerfileText);
	if (dockerfile.preamble.directives.syntax && omitSyntaxDirective) {
		output.write(`Omitting syntax directive '${dockerfile.preamble.directives.syntax}' from Dockerfile.`, LogLevel.Trace);
		delete dockerfile.preamble.directives.syntax;
	}
	const baseImage = findBaseImage(dockerfile, dockerBuildArgs, targetStage);
	const imageDetails = baseImage && await inspectDockerImage(baseImage) || undefined;
	const dockerfileUser = findUserStatement(dockerfile, dockerBuildArgs, envListToObj(imageDetails?.Config.Env), targetStage);
	const user = dockerfileUser || imageDetails?.Config.User || 'root';
	const metadata = imageDetails ? getImageMetadata(imageDetails, substitute, output) : { config: [], raw: [], substitute };
	return {
		user,
		metadata,
		dockerfile,
	};
}

export const imageMetadataLabel = 'devcontainer.metadata';

export function getImageMetadataFromContainer(containerDetails: ContainerDetails, devContainerConfig: SubstitutedConfig<DevContainerConfig>, featuresConfig: FeaturesConfig | undefined, idLabels: string[] | undefined, output: Log): SubstitutedConfig<ImageMetadataEntry[]> {
	if (!(containerDetails.Config.Labels || {})[imageMetadataLabel]) {
		return getDevcontainerMetadata({ config: [], raw: [], substitute: devContainerConfig.substitute }, devContainerConfig, featuresConfig);
	}
	const metadata = internalGetImageMetadata(containerDetails, devContainerConfig.substitute, output);
	const hasIdLabels = !!idLabels && Object.keys(envListToObj(idLabels))
		.every(label => (containerDetails.Config.Labels || {})[label]);
	if (hasIdLabels) {
		return {
			config: [
				...metadata.config,
				pick(devContainerConfig.config, pickUpdateableConfigProperties),
			].filter(config => Object.keys(config).length),
			raw: [
				...metadata.raw,
				pick(devContainerConfig.raw, pickUpdateableConfigProperties),
			].filter(config => Object.keys(config).length),
			substitute: metadata.substitute,
		};
	}
	return getDevcontainerMetadata(metadata, devContainerConfig, featuresConfig);
}

export function getImageMetadata(imageDetails: ImageDetails, substitute: SubstituteConfig, output: Log) {
	return internalGetImageMetadata(imageDetails, substitute, output);
}

function internalGetImageMetadata(imageDetails: ImageDetails | ContainerDetails, substitute: SubstituteConfig, output: Log): SubstitutedConfig<ImageMetadataEntry[]> {
	const raw = internalGetImageMetadata0(imageDetails, output);
	return {
		config: raw.map(substitute),
		raw,
		substitute,
	};
}

export function internalGetImageMetadata0(imageDetails: ImageDetails | ContainerDetails, output: Log) {
	const str = (imageDetails.Config.Labels || {})[imageMetadataLabel];
	if (str) {
		try {
			const obj = JSON.parse(str);
			if (Array.isArray(obj)) {
				return obj as ImageMetadataEntry[];
			}
			if (obj && typeof obj === 'object') {
				return [obj as ImageMetadataEntry];
			}
			output.write(`Invalid image metadata: ${str}`);
		} catch (err) {
			output.write(`Error parsing image metadata: ${err?.message || err}`);
		}
	}
	return [];
}

export function getDevcontainerMetadataLabel(devContainerMetadata: SubstitutedConfig<ImageMetadataEntry[]>) {
	const metadata = devContainerMetadata.raw;
	if (!metadata.length) {
		return '';
	}
	const imageMetadataLabelValue = metadata.length !== 1
		? `[${metadata
			.map(feature => ` \\\n${toLabelString(feature)}`)
			.join(',')} \\\n]`
		: toLabelString(metadata[0]);
	return `LABEL ${imageMetadataLabel}="${imageMetadataLabelValue}"`;
}

function toLabelString(obj: object) {
	return JSON.stringify(obj)
		.replace(/(?=["\\$])/g, '\\');
}
</file>

<file path="src/spec-node/singleContainer.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/


import { createContainerProperties, startEventSeen, ResolverResult, getTunnelInformation, getDockerfilePath, getDockerContextPath, DockerResolverParameters, isDockerFileConfig, uriToWSLFsPath, WorkspaceConfiguration, getFolderImageName, inspectDockerImage, logUMask, SubstitutedConfig, checkDockerSupportForGPU, isBuildKitImagePolicyError } from './utils';
import { ContainerProperties, setupInContainer, ResolverProgress, ResolverParameters } from '../spec-common/injectHeadless';
import { ContainerError, toErrorText } from '../spec-common/errors';
import { ContainerDetails, listContainers, DockerCLIParameters, inspectContainers, dockerCLI, dockerPtyCLI, toPtyExecParameters, ImageDetails, toExecParameters, removeContainer } from '../spec-shutdown/dockerUtils';
import { DevContainerConfig, DevContainerFromDockerfileConfig, DevContainerFromImageConfig } from '../spec-configuration/configuration';
import { LogLevel, Log, makeLog } from '../spec-utils/log';
import { extendImage, getExtendImageBuildInfo, updateRemoteUserUID } from './containerFeatures';
import { getDevcontainerMetadata, getImageBuildInfoFromDockerfile, getImageMetadataFromContainer, ImageMetadataEntry, lifecycleCommandOriginMapFromMetadata, mergeConfiguration, MergedDevContainerConfig } from './imageMetadata';
import { ensureDockerfileHasFinalStageName, generateMountCommand } from './dockerfileUtils';

export const hostFolderLabel = 'devcontainer.local_folder'; // used to label containers created from a workspace/folder
export const configFileLabel = 'devcontainer.config_file';

export async function openDockerfileDevContainer(params: DockerResolverParameters, configWithRaw: SubstitutedConfig<DevContainerFromDockerfileConfig | DevContainerFromImageConfig>, workspaceConfig: WorkspaceConfiguration, idLabels: string[], additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>): Promise<ResolverResult> {
	const { common } = params;
	const { config } = configWithRaw;
	// let collapsedFeaturesConfig: () => Promise<CollapsedFeaturesConfig | undefined>;

	let container: ContainerDetails | undefined;
	let containerProperties: ContainerProperties | undefined;

	try {
		container = await findExistingContainer(params, idLabels);
		let imageMetadata: ImageMetadataEntry[];
		let mergedConfig: MergedDevContainerConfig;
		if (container) {
			// let _collapsedFeatureConfig: Promise<CollapsedFeaturesConfig | undefined>;
			// collapsedFeaturesConfig = async () => {
			// 	return _collapsedFeatureConfig || (_collapsedFeatureConfig = (async () => {
			// 		const allLabels = container?.Config.Labels || {};
			// 		const featuresConfig = await generateFeaturesConfig(params.common, (await createFeaturesTempFolder(params.common)), config, async () => allLabels, getContainerFeaturesFolder);
			// 		return collapseFeaturesConfig(featuresConfig);
			// 	})());
			// };
			await startExistingContainer(params, idLabels, container);
			imageMetadata = getImageMetadataFromContainer(container, configWithRaw, undefined, idLabels, common.output).config;
			mergedConfig = mergeConfiguration(config, imageMetadata);
		} else {
			const res = await buildNamedImageAndExtend(params, configWithRaw, additionalFeatures, true);
			imageMetadata = res.imageMetadata.config;
			mergedConfig = mergeConfiguration(config, imageMetadata);
			const { containerUser } = mergedConfig;
			const updatedImageName = await updateRemoteUserUID(params, mergedConfig, res.updatedImageName[0], res.imageDetails, findUserArg(config.runArgs) || containerUser);

			// collapsedFeaturesConfig = async () => res.collapsedFeaturesConfig;

			try {
				await spawnDevContainer(params, config, mergedConfig, updatedImageName, idLabels, workspaceConfig.workspaceMount, res.imageDetails, containerUser, res.labels || {});
			} finally {
				// In 'finally' because 'docker run' can fail after creating the container.
				// Trying to get it here, so we can offer 'Rebuild Container' as an action later.
				container = await findDevContainer(params, idLabels);
			}
			if (!container) {
				return bailOut(common.output, 'Dev container not found.');
			}
		}

		containerProperties = await createContainerProperties(params, container.Id, workspaceConfig.workspaceFolder, mergedConfig.remoteUser);
		return await setupContainer(container, params, containerProperties, config, mergedConfig, imageMetadata);

	} catch (e) {
		throw createSetupError(e, container, params, containerProperties, config);
	}
}

function createSetupError(originalError: any, container: ContainerDetails | undefined, params: DockerResolverParameters, containerProperties: ContainerProperties | undefined, config: DevContainerConfig | undefined): ContainerError {
	let description = 'An error occurred setting up the container.';

	if (originalError?.cmdOutput?.includes('docker: Error response from daemon: authorization denied by plugin')) {
		description = originalError.cmdOutput;
	}

	const err = originalError instanceof ContainerError ? originalError : new ContainerError({
		description,
		originalError
	});
	if (container) {
		err.manageContainer = true;
		err.params = params.common;
		err.containerId = container.Id;
		err.dockerParams = params;
	}
	if (containerProperties) {
		err.containerProperties = containerProperties;
	}
	if (config) {
		err.config = config;
	}
	return err;
}

async function setupContainer(container: ContainerDetails, params: DockerResolverParameters, containerProperties: ContainerProperties, config: DevContainerFromDockerfileConfig | DevContainerFromImageConfig, mergedConfig: MergedDevContainerConfig, imageMetadata: ImageMetadataEntry[]): Promise<ResolverResult> {
	const { common } = params;
	const {
		remoteEnv: extensionHostEnv,
		updatedConfig,
		updatedMergedConfig,
	} = await setupInContainer(common, containerProperties, config, mergedConfig, lifecycleCommandOriginMapFromMetadata(imageMetadata));

	return {
		params: common,
		properties: containerProperties,
		config: updatedConfig,
		mergedConfig: updatedMergedConfig,
		resolvedAuthority: {
			extensionHostEnv,
		},
		tunnelInformation: common.isLocalContainer ? getTunnelInformation(container) : {},
		dockerParams: params,
		dockerContainerId: container.Id,
	};
}

function getDefaultName(config: DevContainerFromDockerfileConfig | DevContainerFromImageConfig, params: DockerResolverParameters) {
	return 'image' in config && config.image ? config.image : getFolderImageName(params.common);
}
export async function buildNamedImageAndExtend(params: DockerResolverParameters, configWithRaw: SubstitutedConfig<DevContainerFromDockerfileConfig | DevContainerFromImageConfig>, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>, canAddLabelsToContainer: boolean, argImageNames?: string[]): Promise<{ updatedImageName: string[]; imageMetadata: SubstitutedConfig<ImageMetadataEntry[]>; imageDetails: () => Promise<ImageDetails>; labels?: Record<string, string> }> {
	const { config } = configWithRaw;
	const imageNames = argImageNames ?? [getDefaultName(config, params)];
	params.common.progress(ResolverProgress.BuildingImage);
	if (isDockerFileConfig(config)) {
		return await buildAndExtendImage(params, configWithRaw as SubstitutedConfig<DevContainerFromDockerfileConfig>, imageNames, params.buildNoCache ?? false, additionalFeatures);
	}
	// image-based dev container - extend
	return await extendImage(params, configWithRaw, imageNames[0], argImageNames || [], additionalFeatures, canAddLabelsToContainer);
}

async function buildAndExtendImage(buildParams: DockerResolverParameters, configWithRaw: SubstitutedConfig<DevContainerFromDockerfileConfig>, baseImageNames: string[], noCache: boolean, additionalFeatures: Record<string, string | boolean | Record<string, string | boolean>>) {
	const { cliHost, output } = buildParams.common;
	const { config } = configWithRaw;
	const dockerfileUri = getDockerfilePath(cliHost, config);
	const dockerfilePath = await uriToWSLFsPath(dockerfileUri, cliHost);
	if (!cliHost.isFile(dockerfilePath)) {
		throw new ContainerError({ description: `Dockerfile (${dockerfilePath}) not found.` });
	}

	let dockerfile = (await cliHost.readFile(dockerfilePath)).toString();
	const originalDockerfile = dockerfile;
	let baseName = 'dev_container_auto_added_stage_label';
	if (config.build?.target) {
		// Explictly set build target for the dev container build features on that
		baseName = config.build.target;
	} else {
		// Use the last stage in the Dockerfile
		// Find the last line that starts with "FROM" (possibly preceeded by white-space)
		const { lastStageName, modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, baseName);
		baseName = lastStageName;
		if (modifiedDockerfile) {
			dockerfile = modifiedDockerfile;
		}
	}

	const imageBuildInfo = await getImageBuildInfoFromDockerfile(buildParams, originalDockerfile, config.build?.args || {}, config.build?.target, configWithRaw.substitute);
	const extendImageBuildInfo = await getExtendImageBuildInfo(buildParams, configWithRaw, baseName, imageBuildInfo, undefined, additionalFeatures, false);

	let finalDockerfilePath = dockerfilePath;
	const additionalBuildArgs: string[] = [];
	if (extendImageBuildInfo?.featureBuildInfo) {
		const { featureBuildInfo } = extendImageBuildInfo;
		// We add a '# syntax' line at the start, so strip out any existing line
		const syntaxMatch = dockerfile.match(/^\s*#\s*syntax\s*=.*[\r\n]/g);
		if (syntaxMatch) {
			dockerfile = dockerfile.slice(syntaxMatch[0].length);
		}
		let finalDockerfileContent = `${featureBuildInfo.dockerfilePrefixContent}${dockerfile}\n${featureBuildInfo.dockerfileContent}`;
		finalDockerfilePath = cliHost.path.join(featureBuildInfo?.dstFolder, 'Dockerfile-with-features');
		await cliHost.writeFile(finalDockerfilePath, Buffer.from(finalDockerfileContent));

		// track additional build args to include below
		for (const buildContext in featureBuildInfo.buildKitContexts) {
			additionalBuildArgs.push('--build-context', `${buildContext}=${featureBuildInfo.buildKitContexts[buildContext]}`);
		}
		for (const buildArg in featureBuildInfo.buildArgs) {
			additionalBuildArgs.push('--build-arg', `${buildArg}=${featureBuildInfo.buildArgs[buildArg]}`);
		}

		for (const securityOpt of featureBuildInfo.securityOpts) {
			additionalBuildArgs.push('--security-opt', securityOpt);
		}
	}

	const args: string[] = [];
	if (!buildParams.buildKitVersion &&
		(buildParams.buildxPlatform || buildParams.buildxPush)) {
		throw new ContainerError({ description: '--platform or --push require BuildKit enabled.', data: { fileWithError: dockerfilePath } });
	}
	if (buildParams.buildKitVersion) {
		args.push('buildx', 'build');
		if (buildParams.buildxPlatform) {
			output.write('Setting BuildKit platform(s): ' + buildParams.buildxPlatform, LogLevel.Trace);
			args.push('--platform', buildParams.buildxPlatform);
		}
		if (buildParams.buildxPush) {
			args.push('--push');
		} else {
			if (buildParams.buildxOutput) { 
				args.push('--output', buildParams.buildxOutput);
			} else {
				args.push('--load'); // (short for --output=docker, i.e. load into normal 'docker images' collection)
			}
		}
		if (buildParams.buildxCacheTo) {
			args.push('--cache-to', buildParams.buildxCacheTo);
		}
		args.push('--build-arg', 'BUILDKIT_INLINE_CACHE=1');
	} else {
		args.push('build');
	}
	args.push('-f', finalDockerfilePath);

	baseImageNames.map(imageName => args.push('-t', imageName));

	const target = extendImageBuildInfo?.featureBuildInfo ? extendImageBuildInfo.featureBuildInfo.overrideTarget : config.build?.target;
	if (target) {
		args.push('--target', target);
	}
	if (noCache) {
		args.push('--no-cache');
		// `docker build --pull` pulls local image: https://github.com/devcontainers/cli/issues/60
		if (buildParams.buildKitVersion || !extendImageBuildInfo) {
			args.push('--pull');
		}
	} else {
		const configCacheFrom = config.build?.cacheFrom;
		if (buildParams.additionalCacheFroms.length || (configCacheFrom && (configCacheFrom === 'string' || configCacheFrom.length))) {
			await logUMask(buildParams);
		}
		buildParams.additionalCacheFroms.forEach(cacheFrom => args.push('--cache-from', cacheFrom));
		if (config.build && config.build.cacheFrom) {
			if (typeof config.build.cacheFrom === 'string') {
				args.push('--cache-from', config.build.cacheFrom);
			} else {
				for (let index = 0; index < config.build.cacheFrom.length; index++) {
					const cacheFrom = config.build.cacheFrom[index];
					args.push('--cache-from', cacheFrom);
				}
			}
		}
	}
	const buildArgs = config.build?.args;
	if (buildArgs) {
		for (const key in buildArgs) {
			args.push('--build-arg', `${key}=${buildArgs[key]}`);
		}
	}
	const buildOptions = config.build?.options;
	if (buildOptions?.length) {
		args.push(...buildOptions);
	}
	args.push(...additionalBuildArgs);
	args.push(await uriToWSLFsPath(getDockerContextPath(cliHost, config), cliHost));
	try {
		if (buildParams.isTTY) {
			const infoParams = { ...toPtyExecParameters(buildParams), output: makeLog(output, LogLevel.Info) };
			await dockerPtyCLI(infoParams, ...args);
		} else {
			const infoParams = { ...toExecParameters(buildParams), output: makeLog(output, LogLevel.Info), print: 'continuous' as 'continuous' };
			await dockerCLI(infoParams, ...args);
		}
	} catch (err) {
		if (isBuildKitImagePolicyError(err)) {
			throw new ContainerError({ description: 'Could not resolve image due to policy.', originalError: err, data: { fileWithError: dockerfilePath } });
		}

		throw new ContainerError({ description: 'An error occurred building the image.', originalError: err, data: { fileWithError: dockerfilePath } });
	}

	const imageDetails = () => inspectDockerImage(buildParams, baseImageNames[0], false);

	return {
		updatedImageName: baseImageNames,
		imageMetadata: getDevcontainerMetadata(imageBuildInfo.metadata, configWithRaw, extendImageBuildInfo?.featuresConfig),
		imageDetails
	};
}

export function findUserArg(runArgs: string[] = []) {
	for (let i = runArgs.length - 1; i >= 0; i--) {
		const runArg = runArgs[i];
		if ((runArg === '-u' || runArg === '--user') && i + 1 < runArgs.length) {
			return runArgs[i + 1];
		}
		if (runArg.startsWith('-u=') || runArg.startsWith('--user=')) {
			return runArg.substr(runArg.indexOf('=') + 1);
		}
	}
	return undefined;
}

export async function findExistingContainer(params: DockerResolverParameters, labels: string[]) {
	const { common } = params;
	let container = await findDevContainer(params, labels);
	if (params.expectExistingContainer && !container) {
		throw new ContainerError({ description: 'The expected container does not exist.' });
	}
	if (container && (params.removeOnStartup === true || params.removeOnStartup === container.Id)) {
		const text = 'Removing Existing Container';
		const start = common.output.start(text);
		await removeContainer(params, container.Id);
		common.output.stop(text, start);
		container = undefined;
	}
	return container;
}

async function startExistingContainer(params: DockerResolverParameters, labels: string[], container: ContainerDetails) {
	const { common } = params;
	const start = container.State.Status !== 'running';
	if (start) {
		const starting = 'Starting container';
		const start = common.output.start(starting);
		const infoParams = { ...toExecParameters(params), output: makeLog(common.output, LogLevel.Info), print: 'continuous' as 'continuous' };
		await dockerCLI(infoParams, 'start', container.Id);
		common.output.stop(starting, start);
		let startedContainer = await findDevContainer(params, labels);
		if (!startedContainer) {
			bailOut(common.output, 'Dev container not found.');
		}
	}
	return start;
}

export async function findDevContainer(params: DockerCLIParameters | DockerResolverParameters, labels: string[]): Promise<ContainerDetails | undefined> {
	const ids = await listContainers(params, true, labels);
	const details = await inspectContainers(params, ids);
	return details.filter(container => container.State.Status !== 'removing')[0];
}

export async function extraRunArgs(common: ResolverParameters, params: DockerResolverParameters, config: DevContainerFromDockerfileConfig | DevContainerFromImageConfig) {
	const extraArguments: string[] = [];
	if (config.hostRequirements?.gpu) {
		if (await checkDockerSupportForGPU(params)) {
			common.output.write(`GPU support found, add GPU flags to docker call.`);
			extraArguments.push('--gpus', 'all');
		} else {
			if (config.hostRequirements?.gpu !== 'optional') {
				common.output.write('No GPU support found yet a GPU was required - consider marking it as "optional"', LogLevel.Warning);
			}
		}
	}
	return extraArguments;
}

export async function spawnDevContainer(params: DockerResolverParameters, config: DevContainerFromDockerfileConfig | DevContainerFromImageConfig, mergedConfig: MergedDevContainerConfig, imageName: string, labels: string[], workspaceMount: string | undefined, imageDetails: () => Promise<ImageDetails>, containerUser: string | undefined, extraLabels: Record<string, string>) {
	const { common } = params;
	common.progress(ResolverProgress.StartingContainer);

	const appPort = config.appPort;
	const exposedPorts = typeof appPort === 'number' || typeof appPort === 'string' ? [appPort] : appPort || [];
	const exposed = (<string[]>[]).concat(...exposedPorts.map(port => ['-p', typeof port === 'number' ? `127.0.0.1:${port}:${port}` : port]));

	const cwdMount = workspaceMount ? ['--mount', workspaceMount] : [];

	const envObj = mergedConfig.containerEnv || {};
	const containerEnv = Object.keys(envObj)
		.reduce((args, key) => {
			args.push('-e', `${key}=${envObj[key]}`);
			return args;
		}, [] as string[]);

	const containerUserArgs = containerUser ? ['-u', containerUser] : [];

	const featureArgs: string[] = [];
	if (mergedConfig.init) {
		featureArgs.push('--init');
	}
	if (mergedConfig.privileged) {
		featureArgs.push('--privileged');
	}
	for (const cap of mergedConfig.capAdd || []) {
		featureArgs.push('--cap-add', cap);
	}
	for (const securityOpt of mergedConfig.securityOpt || []) {
		featureArgs.push('--security-opt', securityOpt);
	}

	const featureMounts = ([] as string[]).concat(
		...[
			...mergedConfig.mounts || [],
			...params.additionalMounts,
		].map(m => generateMountCommand(m))
	);

	const customEntrypoints = mergedConfig.entrypoints || [];
	const entrypoint = ['--entrypoint', '/bin/sh'];
	const cmd = ['-c', `echo Container started
trap "exit 0" 15
${customEntrypoints.join('\n')}
exec "$@"
while sleep 1 & wait $!; do :; done`, '-']; // `wait $!` allows for the `trap` to run (synchronous `sleep` would not).
	const overrideCommand = mergedConfig.overrideCommand;
	if (overrideCommand === false) {
		const details = await imageDetails();
		cmd.push(...details.Config.Entrypoint || []);
		cmd.push(...details.Config.Cmd || []);
	}

	const args = [
		'run',
		'--sig-proxy=false',
		'-a', 'STDOUT',
		'-a', 'STDERR',
		...exposed,
		...cwdMount,
		...featureMounts,
		...getLabels(labels),
		...containerEnv,
		...containerUserArgs,
		...await getPodmanArgs(params, config, mergedConfig, imageDetails),
		...(config.runArgs || []),
		...(await extraRunArgs(common, params, config) || []),
		...featureArgs,
		...entrypoint,
		...Object.keys(extraLabels).map(key => ['-l', `${key}=${extraLabels[key]}`]).flat(),
		imageName,
		...cmd
	];

	let cancel: () => void;
	const canceled = new Promise<void>((_, reject) => cancel = reject);
	const { started } = await startEventSeen(params, getLabelsAsRecord(labels), canceled, common.output, common.getLogLevel() === LogLevel.Trace);

	const text = 'Starting container';
	const start = common.output.start(text);

	const infoParams = { ...toPtyExecParameters(params), output: makeLog(params.common.output, LogLevel.Info) };
	const result = dockerPtyCLI(infoParams, ...args);
	result.then(cancel!, cancel!);

	await started;
	common.output.stop(text, start);
}

async function getPodmanArgs(params: DockerResolverParameters, config: DevContainerFromDockerfileConfig | DevContainerFromImageConfig, mergedConfig: MergedDevContainerConfig, imageDetails: () => Promise<ImageDetails>): Promise<string[]> {
	if (params.isPodman && params.common.cliHost.platform === 'linux') {
		const args = ['--security-opt', 'label=disable'];
		const hasIdMapping = (config.runArgs || []).some(arg => /--[ug]idmap(=|$)/.test(arg));
		if (!hasIdMapping) {
			const remoteUser = mergedConfig.remoteUser || findUserArg(config.runArgs) || (await imageDetails()).Config.User || 'root';
			if (remoteUser !== 'root' && remoteUser !== '0') {
				args.push('--userns=keep-id');
			}
		}
		return args;
	}
	return [];
}

function getLabels(labels: string[]): string[] {
	let result: string[] = [];
	labels.forEach(each => result.push('-l', each));
	return result;
}

function getLabelsAsRecord(labels: string[]): Record<string, string> {
	let result: Record<string, string> = {};
	labels.forEach(each => {
		let pair = each.split('=');
		result[pair[0]] = pair[1];
	});
	return result;
}

export function bailOut(output: Log, message: string): never {
	output.write(toErrorText(message));
	throw new Error(message);
}
</file>

<file path="src/spec-node/tsconfig.json">
{
	"extends": "../../tsconfig.base.json",
	"references": [
		{
			"path": "../spec-utils"
		},
		{
			"path": "../spec-common"
		},
		{
			"path": "../spec-configuration"
		},
		{
			"path": "../spec-shutdown"
		}
	]
}
</file>

<file path="src/spec-node/upgradeCommand.ts">
import { Argv } from 'yargs';
import { UnpackArgv } from './devContainersSpecCLI';
import { dockerComposeCLIConfig } from './dockerCompose';
import { Log, LogLevel, mapLogLevel } from '../spec-utils/log';
import { createLog } from './devContainers';
import { getPackageConfig } from '../spec-utils/product';
import { DockerCLIParameters } from '../spec-shutdown/dockerUtils';
import path from 'path';
import { CLIHost, getCLIHost } from '../spec-common/cliHost';
import { loadNativeModule } from '../spec-common/commonUtils';
import { URI } from 'vscode-uri';
import { Workspace, workspaceFromPath } from '../spec-utils/workspaces';
import { getDefaultDevContainerConfigPath, getDevContainerConfigPathIn, uriToFsPath } from '../spec-configuration/configurationCommonUtils';
import { readDevContainerConfigFile } from './configContainer';
import { ContainerError } from '../spec-common/errors';
import { getCacheFolder, runAsyncHandler } from './utils';
import { Lockfile, generateLockfile, getLockfilePath, writeLockfile } from '../spec-configuration/lockfile';
import { isLocalFile, readLocalFile, writeLocalFile } from '../spec-utils/pfs';
import { readFeaturesConfig } from './featureUtils';
import { DevContainerConfig } from '../spec-configuration/configuration';
import { mapNodeArchitectureToGOARCH, mapNodeOSToGOOS } from '../spec-configuration/containerCollectionsOCI';

export function featuresUpgradeOptions(y: Argv) {
	return y
		.options({
			'workspace-folder': { type: 'string', description: 'Workspace folder.', demandOption: true },
			'docker-path': { type: 'string', description: 'Path to docker executable.', default: 'docker' },
			'docker-compose-path': { type: 'string', description: 'Path to docker-compose executable.', default: 'docker-compose' },
			'config': { type: 'string', description: 'devcontainer.json path. The default is to use .devcontainer/devcontainer.json or, if that does not exist, .devcontainer.json in the workspace folder.' },
			'log-level': { choices: ['error' as 'error', 'info' as 'info', 'debug' as 'debug', 'trace' as 'trace'], default: 'info' as 'info', description: 'Log level.' },
			'dry-run': { type: 'boolean', description: 'Write generated lockfile to standard out instead of to disk.' },
			// Added for dependabot
			'feature': { hidden: true, type: 'string', alias: 'f', description: 'Upgrade the version requirements of a given Feature (and its dependencies).  Then, upgrade the lockfile.   Must supply \'--target-version\'.' },
			'target-version': { hidden: true, type: 'string', alias: 'v', description: 'The major (x), minor (x.y), or patch version (x.y.z) of the Feature to pin in devcontainer.json.  Must supply a \'--feature\'.' },
		})
		.check(argv => {
			if (argv.feature && !argv['target-version'] || !argv.feature && argv['target-version']) {
				throw new Error('The \'--target-version\' and \'--feature\' flag must be used together.');
			}

			if (argv['target-version']) {
				const targetVersion = argv['target-version'];
				if (!targetVersion.match(/^\d+(\.\d+(\.\d+)?)?$/)) {
					throw new Error(`Invalid version '${targetVersion}'.  Must be in the form of 'x', 'x.y', or 'x.y.z'`);
				}
			}
			return true;
		});
}

export type FeaturesUpgradeArgs = UnpackArgv<ReturnType<typeof featuresUpgradeOptions>>;

export function featuresUpgradeHandler(args: FeaturesUpgradeArgs) {
	runAsyncHandler(featuresUpgrade.bind(null, args));
}

async function featuresUpgrade({
	'workspace-folder': workspaceFolderArg,
	'docker-path': dockerPath,
	config: configArg,
	'docker-compose-path': dockerComposePath,
	'log-level': inputLogLevel,
	'dry-run': dryRun,
	feature: feature,
	'target-version': targetVersion,
}: FeaturesUpgradeArgs) {
	const disposables: (() => Promise<unknown> | undefined)[] = [];
	const dispose = async () => {
		await Promise.all(disposables.map(d => d()));
	};
	let output: Log | undefined;
	try {
		const workspaceFolder = path.resolve(process.cwd(), workspaceFolderArg);
		const configFile = configArg ? URI.file(path.resolve(process.cwd(), configArg)) : undefined;
		const cliHost = await getCLIHost(workspaceFolder, loadNativeModule, true);
		const extensionPath = path.join(__dirname, '..', '..');
		const sessionStart = new Date();
		const pkg = getPackageConfig();
		const output = createLog({
			logLevel: mapLogLevel(inputLogLevel),
			logFormat: 'text',
			log: text => process.stderr.write(text),
			terminalDimensions: undefined,
		}, pkg, sessionStart, disposables);
		const dockerComposeCLI = dockerComposeCLIConfig({
			exec: cliHost.exec,
			env: cliHost.env,
			output,
		}, dockerPath, dockerComposePath);
		const dockerParams: DockerCLIParameters = {
			cliHost,
			dockerCLI: dockerPath,
			dockerComposeCLI,
			env: cliHost.env,
			output,
			platformInfo: {
				os: mapNodeOSToGOOS(cliHost.platform),
				arch: mapNodeArchitectureToGOARCH(cliHost.arch),
			}
		};

		const workspace = workspaceFromPath(cliHost.path, workspaceFolder);
		const configPath = configFile ? configFile : await getDevContainerConfigPathIn(cliHost, workspace.configFolderPath);
		let config = await getConfig(configPath, cliHost, workspace, output, configFile);
		const cacheFolder = await getCacheFolder(cliHost);
		const params = {
			extensionPath,
			cacheFolder,
			cwd: cliHost.cwd,
			output,
			env: cliHost.env,
			skipFeatureAutoMapping: false,
			platform: cliHost.platform,
		};

		if (feature && targetVersion) {
			output.write(`Updating '${feature}' to '${targetVersion}' in devcontainer.json`, LogLevel.Info);
			// Update Feature version tag in devcontainer.json
			await updateFeatureVersionInConfig(params, config, config.configFilePath!.fsPath, feature, targetVersion);
			// Re-read config for subsequent lockfile generation
			config = await getConfig(configPath, cliHost, workspace, output, configFile);
		}

		const featuresConfig = await readFeaturesConfig(dockerParams, pkg, config, extensionPath, false, {});
		if (!featuresConfig) {
			throw new ContainerError({ description: `Failed to update lockfile` });
		}

		const lockfile: Lockfile = await generateLockfile(featuresConfig);

		if (dryRun) {
			console.log(JSON.stringify(lockfile, null, 2));
			return;
		}

		// Truncate any existing lockfile
		const lockfilePath = getLockfilePath(config);
		await writeLocalFile(lockfilePath, '');
		// Update lockfile
		await writeLockfile(params, config, lockfile, true);
	} catch (err) {
		if (output) {
			output.write(err && (err.stack || err.message) || String(err));
		} else {
			console.error(err);
		}
		await dispose();
		process.exit(1);
	}
	await dispose();
	process.exit(0);
}

async function updateFeatureVersionInConfig(params: { output: Log }, config: DevContainerConfig, configPath: string, targetFeature: string, targetVersion: string) {
	const { output } = params;

	if (!config.features) {
		// No Features in config to upgrade
		output.write(`No Features found in '${configPath}'.`);
		return;
	}

	if (!configPath || !(await isLocalFile(configPath))) {
		throw new ContainerError({ description: `Error running upgrade command.  Config path '${configPath}' does not exist.` });
	}

	const configText = await readLocalFile(configPath);
	const previousConfigText: string = configText.toString();
	let updatedText: string = configText.toString();

	const targetFeatureNoVersion = getFeatureIdWithoutVersion(targetFeature);
	for (const [userFeatureId, _] of Object.entries(config.features)) {
		if (targetFeatureNoVersion !== getFeatureIdWithoutVersion(userFeatureId)) {
			continue;
		}
		updatedText = upgradeFeatureKeyInConfig(updatedText, userFeatureId, `${targetFeatureNoVersion}:${targetVersion}`);
		break;
	}

	output.write(updatedText, LogLevel.Trace);
	if (updatedText === previousConfigText) {
		output.write(`No changes to config file: ${configPath}\n`, LogLevel.Trace);
		return;
	}

	output.write(`Updating config file: '${configPath}'`, LogLevel.Info);
	await writeLocalFile(configPath, updatedText);
}

function upgradeFeatureKeyInConfig(configText: string, current: string, updated: string) {
	const featureIdRegex = new RegExp(current, 'g');
	return configText.replace(featureIdRegex, updated);
}

async function getConfig(configPath: URI | undefined, cliHost: CLIHost, workspace: Workspace, output: Log, configFile: URI | undefined): Promise<DevContainerConfig> {
	const configs = configPath && await readDevContainerConfigFile(cliHost, workspace, configPath, true, output) || undefined;
	if (!configs) {
		throw new ContainerError({ description: `Dev container config (${uriToFsPath(configFile || getDefaultDevContainerConfigPath(cliHost, workspace!.configFolderPath), cliHost.platform)}) not found.` });
	}
	return configs.config.config;
}

const lastDelimiter = /[:@][^/]*$/;
function getFeatureIdWithoutVersion(featureId: string) {
	const m = lastDelimiter.exec(featureId);
	return m ? featureId.substring(0, m.index) : featureId;
}
</file>

<file path="src/spec-node/utils.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as crypto from 'crypto';
import * as os from 'os';

import { ContainerError, toErrorText } from '../spec-common/errors';
import { CLIHost, runCommandNoPty, runCommand, getLocalUsername, PlatformInfo } from '../spec-common/commonUtils';
import { Log, LogLevel, makeLog, nullLog } from '../spec-utils/log';

import { CommonDevContainerConfig, ContainerProperties, getContainerProperties, LifecycleCommand, ResolverParameters } from '../spec-common/injectHeadless';
import { Workspace } from '../spec-utils/workspaces';
import { URI } from 'vscode-uri';
import { ShellServer } from '../spec-common/shellServer';
import { inspectContainer, inspectImage, getEvents, ContainerDetails, DockerCLIParameters, dockerExecFunction, dockerPtyCLI, dockerPtyExecFunction, toDockerImageName, DockerComposeCLI, ImageDetails, dockerCLI, removeContainer } from '../spec-shutdown/dockerUtils';
import { getRemoteWorkspaceFolder } from './dockerCompose';
import { findGitRootFolder } from '../spec-common/git';
import { parentURI, uriToFsPath } from '../spec-configuration/configurationCommonUtils';
import { DevContainerConfig, DevContainerFromDockerfileConfig, getConfigFilePath, getDockerfilePath } from '../spec-configuration/configuration';
import { StringDecoder } from 'string_decoder';
import { Event } from '../spec-utils/event';
import { Mount } from '../spec-configuration/containerFeaturesConfiguration';
import { PackageConfiguration } from '../spec-utils/product';
import { ImageMetadataEntry, MergedDevContainerConfig } from './imageMetadata';
import { getImageIndexEntryForPlatform, getManifest, getRef } from '../spec-configuration/containerCollectionsOCI';
import { requestEnsureAuthenticated } from '../spec-configuration/httpOCIRegistry';
import { configFileLabel, findDevContainer, hostFolderLabel } from './singleContainer';

export { getConfigFilePath, getDockerfilePath, isDockerFileConfig } from '../spec-configuration/configuration';
export { uriToFsPath, parentURI } from '../spec-configuration/configurationCommonUtils';


export type BindMountConsistency = 'consistent' | 'cached' | 'delegated' | undefined;

export type GPUAvailability = 'all' | 'detect' | 'none';

// Generic retry function
export async function retry<T>(fn: () => Promise<T>, options: { retryIntervalMilliseconds: number; maxRetries: number; output: Log }): Promise<T> {
	const { retryIntervalMilliseconds, maxRetries, output } = options;
	let lastError: Error | undefined;
	for (let i = 0; i < maxRetries; i++) {
		try {
			return await fn();
		} catch (err) {
			lastError = err;
			output.write(`Retrying (Attempt ${i}) with error '${toErrorText(err)}'`, LogLevel.Warning);
			await new Promise(resolve => setTimeout(resolve, retryIntervalMilliseconds));
		}
	}
	throw lastError;
}

export async function uriToWSLFsPath(uri: URI, cliHost: CLIHost): Promise<string> {
	if (uri.scheme === 'file' && cliHost.type === 'wsl') {
		// convert local path (e.g. repository-container Dockerfile) to WSL path
		const { stdout } = await runCommandNoPty({
			exec: cliHost.exec,
			cmd: 'wslpath',
			args: ['-u', uri.fsPath],
			output: nullLog,
		});
		const cliHostPath = stdout.toString().trim();
		return cliHostPath;
	}
	return uriToFsPath(uri, cliHost.platform);
}

export async function logUMask(params: DockerResolverParameters): Promise<string | undefined> {
	// process.umask() is deprecated: https://nodejs.org/api/process.html#processumask
	const { common } = params;
	const { cliHost, output } = common;
	if (cliHost.platform === 'win32') {
		return undefined;
	}
	try {
		const { stdout } = await runCommandNoPty({
			exec: cliHost.exec,
			cmd: 'umask',
			cwd: cliHost.cwd,
			env: cliHost.env,
			output,
			print: true,
		});
		return stdout.toString().trim();
	} catch {
		return undefined;
	}
}

export type ParsedAuthority = DevContainerAuthority;

export type UpdateRemoteUserUIDDefault = 'never' | 'on' | 'off';

export interface DockerResolverParameters {
	common: ResolverParameters;
	parsedAuthority: ParsedAuthority | undefined;
	dockerCLI: string;
	isPodman: boolean;
	dockerComposeCLI: () => Promise<DockerComposeCLI>;
	dockerEnv: NodeJS.ProcessEnv;
	workspaceMountConsistencyDefault: BindMountConsistency;
	gpuAvailability: GPUAvailability;
	mountWorkspaceGitRoot: boolean;
	updateRemoteUserUIDOnMacOS: boolean;
	cacheMount: 'volume' | 'bind' | 'none';
	removeOnStartup?: boolean | string;
	buildNoCache?: boolean;
	expectExistingContainer?: boolean;
	userRepositoryConfigurationPaths: string[];
	additionalMounts: Mount[];
	updateRemoteUserUIDDefault: UpdateRemoteUserUIDDefault;
	additionalCacheFroms: string[];
	buildKitVersion: { versionString: string; versionMatch?: string } | undefined;
	isTTY: boolean;
	experimentalLockfile?: boolean;
	experimentalFrozenLockfile?: boolean;
	buildxPlatform: string | undefined;
	buildxPush: boolean;
	additionalLabels: string[];
	buildxOutput: string | undefined;
	buildxCacheTo: string | undefined;
	platformInfo: PlatformInfo;
}

export interface ResolverResult {
	params: ResolverParameters;
	properties: ContainerProperties;
	config: CommonDevContainerConfig;
	mergedConfig: MergedDevContainerConfig;
	resolvedAuthority: { extensionHostEnv?: { [key: string]: string | null } };
	tunnelInformation: { environmentTunnels?: { remoteAddress: { port: number; host: string }; localAddress: string }[] };
	isTrusted?: boolean;
	dockerParams: DockerResolverParameters;
	dockerContainerId: string;
	composeProjectName?: string;
}

export interface SubstitutedConfig<T extends DevContainerConfig | ImageMetadataEntry[]> {
	config: T;
	raw: T;
	substitute: SubstituteConfig;
}

export type SubstituteConfig = <U extends DevContainerConfig | ImageMetadataEntry>(value: U) => U;

export function addSubstitution<T extends DevContainerConfig | ImageMetadataEntry[]>(config: SubstitutedConfig<T>, substitute: SubstituteConfig): SubstitutedConfig<T> {
	const substitute0 = config.substitute;
	const subsConfig = config.config;
	return {
		config: (Array.isArray(subsConfig) ? subsConfig.map(substitute) : substitute(subsConfig)) as T,
		raw: config.raw,
		substitute: value => substitute(substitute0(value)),
	};
}

export async function startEventSeen(params: DockerResolverParameters, labels: Record<string, string>, canceled: Promise<void>, output: Log, trace: boolean) {
	const eventsProcess = await getEvents(params, { event: ['start'] });
	return {
		started: new Promise<void>((resolve, reject) => {
			canceled.catch(err => {
				eventsProcess.terminate();
				reject(err);
			});
			const decoder = new StringDecoder('utf8');
			let startPart = '';
			eventsProcess.stdout.on('data', async chunk => {
				if (chunk) {
					const part = decoder.write(chunk);
					if (trace) {
						output.write(`Log: startEventSeen#data ${part.trim().replace(/\r?\n/g, '\r\n')}\r\n`);
					}
					const lines = (startPart + part).split('\n');
					startPart = lines.pop()!;
					for (const line of lines) {
						if (line.trim()) {
							try {
								const info = JSON.parse(line);
								// Docker uses 'status', Podman 'Status'.
								if ((info.status || info.Status) === 'start' && await hasLabels(params, info, labels)) {
									eventsProcess.terminate();
									resolve();
								}
							} catch (e) {
								// Ignore invalid JSON.
								console.error(e);
								console.error(line);
							}
						}
					}
				}
			});
		})
	};
}

async function hasLabels(params: DockerResolverParameters, info: any, expectedLabels: Record<string, string>) {
	const actualLabels = info.Actor?.Attributes
		// Docker uses 'id', Podman 'ID'.
		|| (await inspectContainer(params, info.id || info.ID)).Config.Labels
		|| {};
	return Object.keys(expectedLabels)
		.every(name => actualLabels[name] === expectedLabels[name]);
}

export async function checkDockerSupportForGPU(params: DockerResolverParameters): Promise<Boolean> {
	if (params.gpuAvailability === 'all') {
		return true;
	}
	if (params.gpuAvailability === 'none') {
		return false;
	}
	const result = await dockerCLI(params, 'info', '-f', '{{.Runtimes.nvidia}}');
	const runtimeFound = result.stdout.includes('nvidia-container-runtime');
	return runtimeFound;
}

export function isBuildKitImagePolicyError(err: any): boolean {
	const imagePolicyErrorString = 'could not resolve image due to policy'; // Seen in Buildkit 0.11.0
	const sourceDeniedString = 'source denied by policy'; // Seen in Buildkit 0.12.0

	const errCmdOutput = err?.cmdOutput;
	const errStderr = err?.stderr;

	return (errCmdOutput && typeof errCmdOutput === 'string' && (errCmdOutput.includes(imagePolicyErrorString) || errCmdOutput.includes(sourceDeniedString)))
		|| (errStderr && typeof errStderr === 'string' && (errStderr.includes(imagePolicyErrorString) || errStderr.includes(sourceDeniedString)));
}

export async function inspectDockerImage(params: DockerResolverParameters | DockerCLIParameters, imageName: string, pullImageOnError: boolean) {
	try {
		return await inspectImage(params, imageName);
	} catch (err) {
		if (!pullImageOnError) {
			throw err;
		}
		const output = 'cliHost' in params ? params.output : params.common.output;
		try {
			return await inspectImageInRegistry(output, params.platformInfo, imageName);
		} catch (err2) {
			output.write(`Error fetching image details: ${err2?.message}`);
		}
		try {
			await retry(async () => dockerPtyCLI(params, 'pull', imageName), { maxRetries: 5, retryIntervalMilliseconds: 1000, output });
		} catch (_err) {
			if (err.stdout) {
				output.write(err.stdout.toString());
			}
			if (err.stderr) {
				output.write(toErrorText(err.stderr.toString()));
			}
			throw err;
		}
		return inspectImage(params, imageName);
	}
}

export async function inspectImageInRegistry(output: Log, platformInfo: PlatformInfo, name: string): Promise<ImageDetails> {
	const resourceAndVersion = qualifyImageName(name);
	const params = { output, env: process.env };
	const ref = getRef(output, resourceAndVersion);
	if (!ref) {
		throw new Error(`Could not parse image name '${name}'`);
	}

	const registryServer = ref.registry === 'docker.io' ? 'registry-1.docker.io' : ref.registry;
	const manifestUrl = `https://${registryServer}/v2/${ref.path}/manifests/${ref.version}`;
	output.write(`manifest url: ${manifestUrl}`, LogLevel.Trace);

	let targetDigest: string | undefined = undefined;
	const manifest = await getManifest(params, manifestUrl, ref, 'application/vnd.docker.distribution.manifest.v2+json');
	if (manifest?.manifestObj.config) { // Checking for config because the above mime type sometimes returns an image index.
		targetDigest = manifest.manifestObj.config.digest;
	} else {
		// If we couldn't fetch the manifest, perhaps the registry supports querying for the 'Image Index'
		// Spec: https://github.com/opencontainers/image-spec/blob/main/image-index.md
		const imageIndexEntry = await getImageIndexEntryForPlatform(params, manifestUrl, ref, platformInfo);
		if (imageIndexEntry) {
			const manifestUrl = `https://${registryServer}/v2/${ref.path}/manifests/${imageIndexEntry.digest}`;
			const a = await getManifest(params, manifestUrl, ref);
			if (a) {
				targetDigest = a.manifestObj.config.digest;
			}
		}
	}

	if (!targetDigest) {
		throw new Error(`No manifest found for ${resourceAndVersion}.`);
	}

	const blobUrl = `https://${registryServer}/v2/${ref.path}/blobs/${targetDigest}`;
	output.write(`blob url: ${blobUrl}`, LogLevel.Trace);

	const httpOptions = {
		type: 'GET',
		url: blobUrl,
		headers: {}
	};

	const res = await requestEnsureAuthenticated(params, httpOptions, ref);
	if (!res) {
		throw new Error(`Failed to fetch blob for ${resourceAndVersion}.`);
	}
	const blob = res.resBody.toString();
	const obj = JSON.parse(blob);
	return {
		Id: targetDigest,
		Config: obj.config,
		Os: platformInfo.os,
		Variant: platformInfo.variant,
		Architecture: platformInfo.arch,
	};
}

export function qualifyImageName(name: string) {
	const segments = name.split('/');
	if (segments.length === 1) {
		return `docker.io/library/${name}`;
	} else if (segments.length === 2) {
		if (name.startsWith('docker.io/')) {
			return `docker.io/library/${segments[1]}`;
		} else {
			return `docker.io/${name}`;
		}
	} else {
		return name;
	}
}

export interface DevContainerAuthority {
	hostPath: string; // local path of the folder or workspace file
}

export function isDevContainerAuthority(authority: ParsedAuthority): authority is DevContainerAuthority {
	return (authority as DevContainerAuthority).hostPath !== undefined;
}

export async function getHostMountFolder(cliHost: CLIHost, folderPath: string, mountWorkspaceGitRoot: boolean, output: Log): Promise<string> {
	return mountWorkspaceGitRoot && await findGitRootFolder(cliHost, folderPath, output) || folderPath;
}

export interface WorkspaceConfiguration {
	workspaceMount: string | undefined;
	workspaceFolder: string | undefined;
}

export async function getWorkspaceConfiguration(cliHost: CLIHost, workspace: Workspace | undefined, config: DevContainerConfig, mountWorkspaceGitRoot: boolean, output: Log, consistency?: BindMountConsistency): Promise<WorkspaceConfiguration> {
	if ('dockerComposeFile' in config) {
		return {
			workspaceFolder: getRemoteWorkspaceFolder(config),
			workspaceMount: undefined,
		};
	}
	let { workspaceFolder, workspaceMount } = config;
	if (workspace && (!workspaceFolder || !('workspaceMount' in config))) {
		const hostMountFolder = await getHostMountFolder(cliHost, workspace.rootFolderPath, mountWorkspaceGitRoot, output);
		if (!workspaceFolder) {
			const rel = cliHost.path.relative(cliHost.path.dirname(hostMountFolder), workspace.rootFolderPath);
			workspaceFolder = `/workspaces/${cliHost.platform === 'win32' ? rel.replace(/\\/g, '/') : rel}`;
		}
		if (!('workspaceMount' in config)) {
			const containerMountFolder = `/workspaces/${cliHost.path.basename(hostMountFolder)}`;
			const cons = cliHost.platform !== 'linux' ? `,consistency=${consistency || 'consistent'}` : ''; // Podman does not tolerate consistency=
			const srcQuote = hostMountFolder.indexOf(',') !== -1 ? '"' : '';
			const tgtQuote = containerMountFolder.indexOf(',') !== -1 ? '"' : '';
			workspaceMount = `type=bind,${srcQuote}source=${hostMountFolder}${srcQuote},${tgtQuote}target=${containerMountFolder}${tgtQuote}${cons}`;
		}
	}
	return {
		workspaceFolder,
		workspaceMount,
	};
}

export function getTunnelInformation(container: ContainerDetails) /*: vscode.TunnelInformation */ {
	return {
		environmentTunnels: container.Ports.filter(staticPort => !!staticPort.PublicPort)
			.map((port) => {
				return {
					remoteAddress: {
						port: port.PrivatePort,
						host: port.IP
					},
					localAddress: port.IP + ':' + port.PublicPort
				};
			})
	};
}

export function getDockerContextPath(cliHost: { platform: NodeJS.Platform }, config: DevContainerFromDockerfileConfig) {
	const context = 'dockerFile' in config ? config.context : config.build.context;
	if (context) {
		return getConfigFilePath(cliHost, config, context);
	}
	return parentURI(getDockerfilePath(cliHost, config));
}

export async function createContainerProperties(params: DockerResolverParameters, containerId: string, remoteWorkspaceFolder: string | undefined, remoteUser: string | undefined, rootShellServer?: ShellServer) {
	const { common } = params;
	const inspecting = 'Inspecting container';
	const start = common.output.start(inspecting);
	const containerInfo = await inspectContainer(params, containerId);
	common.output.stop(inspecting, start);
	const containerUser = remoteUser || containerInfo.Config.User || 'root';
	const [, user, , group] = /([^:]*)(:(.*))?/.exec(containerUser) as (string | undefined)[];
	const containerEnv = envListToObj(containerInfo.Config.Env);
	const remoteExec = dockerExecFunction(params, containerId, containerUser);
	const remotePtyExec = await dockerPtyExecFunction(params, containerId, containerUser, common.loadNativeModule, common.allowInheritTTY);
	const remoteExecAsRoot = dockerExecFunction(params, containerId, 'root');
	return getContainerProperties({
		params: common,
		createdAt: containerInfo.Created,
		startedAt: containerInfo.State.StartedAt,
		remoteWorkspaceFolder,
		containerUser: user === '0' ? 'root' : user,
		containerGroup: group,
		containerEnv,
		remoteExec,
		remotePtyExec,
		remoteExecAsRoot,
		rootShellServer,
	});
}

export function envListToObj(list: string[] | null | undefined) {
	// Handle Env is null (https://github.com/microsoft/vscode-remote-release/issues/2058).
	return (list || []).reduce((obj, pair) => {
		const i = pair.indexOf('=');
		if (i !== -1) {
			obj[pair.substring(0, i)] = pair.substring(i + 1);
		}
		return obj;
	}, {} as Record<string, string>);
}

export async function runInitializeCommand(params: DockerResolverParameters, userCommand: LifecycleCommand | undefined, onDidInput?: Event<string>) {
	if (!userCommand) {
		return;
	}

	let hasCommand = false;
	if (typeof userCommand === 'string') {
		hasCommand = userCommand.trim().length > 0;
	} else if (Array.isArray(userCommand)) {
		hasCommand = userCommand.length > 0;
	} else if (typeof userCommand === 'object') {
		hasCommand = Object.keys(userCommand).length > 0;
	}

	if (!hasCommand) {
		return;
	}

	const { common, dockerEnv } = params;
	const { cliHost, output } = common;
	const hookName = 'initializeCommand';
	const isWindows = cliHost.platform === 'win32';
	const shell = isWindows ? [cliHost.env.ComSpec || 'cmd.exe', '/c'] : ['/bin/sh', '-c'];

	const infoOutput = makeLog(output, LogLevel.Info);

	try {
		// Runs a command.
		// Useful for the object syntax, where >1 command can be specified to run in parallel.
		async function runSingleCommand(command: string | string[], name?: string) {
			const updatedCommand = isWindows && Array.isArray(command) && command.length ?
				[(command[0] || '').replace(/\//g, '\\'), ...command.slice(1)] :
				command;
			const args = typeof updatedCommand === 'string' ? [...shell, updatedCommand] : updatedCommand;
			if (!args.length) {
				return;
			}

			// 'name' is set when parallel execution syntax is used.
			if (name) {
				infoOutput.raw(`\x1b[1mRunning '${name}' from ${hookName}...\x1b[0m\r\n\r\n`);
			} else {
				infoOutput.raw(`\x1b[1mRunning the ${hookName} from devcontainer.json...\x1b[0m\r\n\r\n`);
			}

			// If we have a command name then the command is running in parallel and
			// we need to hold output until the command is done so that the output
			// doesn't get interleaved with the output of other commands.
			const print = name ? 'end' : 'continuous';

		await runCommand({
			ptyExec: cliHost.ptyExec,
			cmd: args[0],
			args: args.slice(1),
			env: dockerEnv,
			output: infoOutput,
			onDidInput,
			print,
		});
		infoOutput.raw('\r\n');
		}

		let commands;
		if (typeof userCommand === 'string' || Array.isArray(userCommand)) {
			commands = [runSingleCommand(userCommand)];
		} else {
			commands = Object.keys(userCommand).map(name => {
				const command = userCommand[name];
				return runSingleCommand(command, name);
			});
		}
		await Promise.all(commands);

	} catch (err) {
		if (err && (err.code === 130 || err.signal === 2)) { // SIGINT seen on darwin as code === 130, would also make sense as signal === 2.
			infoOutput.raw(`\r\n\x1b[1m${hookName} interrupted.\x1b[0m\r\n\r\n`);
		} else {
			throw new ContainerError({
				description: `The ${hookName} in the devcontainer.json failed.`,
				originalError: err,
			});
		}
	}

}

export function getFolderImageName(params: ResolverParameters | DockerCLIParameters) {
	const { cwd } = 'cwd' in params ? params : params.cliHost;
	const folderHash = getFolderHash(cwd);
	const baseName = path.basename(cwd);
	return toDockerImageName(`vsc-${baseName}-${folderHash}`);
}

export function getFolderHash(fsPath: string): string {
	return crypto.createHash('sha256').update(fsPath).digest('hex');
}

export async function createFeaturesTempFolder(params: { cliHost: CLIHost; package: PackageConfiguration }): Promise<string> {
	const { cliHost } = params;
	const { version } = params.package;
	// Create temp folder
	const tmpFolder: string = cliHost.path.join(await getCacheFolder(cliHost), 'container-features', `${version}-${Date.now()}`);
	await cliHost.mkdirp(tmpFolder);
	return tmpFolder;
}

export async function getCacheFolder(cliHost: CLIHost): Promise<string> {
	return cliHost.path.join(await cliHost.tmpdir(), cliHost.platform === 'linux' ? `devcontainercli-${await cliHost.getUsername()}` : 'devcontainercli');
}

export async function getLocalCacheFolder() {
	return path.join(os.tmpdir(), process.platform === 'linux' ? `devcontainercli-${await getLocalUsername()}` : 'devcontainercli');
}

export function getEmptyContextFolder(common: ResolverParameters) {
	return common.cliHost.path.join(common.persistedFolder, 'empty-folder');
}

export async function findContainerAndIdLabels(params: DockerResolverParameters | DockerCLIParameters, containerId: string | undefined, providedIdLabels: string[] | undefined, workspaceFolder: string | undefined, configFile: string | undefined, removeContainerWithOldLabels?: boolean | string) {
	if (providedIdLabels) {
		return {
			container: containerId ? await inspectContainer(params, containerId) : await findDevContainer(params, providedIdLabels),
			idLabels: providedIdLabels,
		};
	}
	let container: ContainerDetails | undefined;
	if (containerId) {
		container = await inspectContainer(params, containerId);
	} else if (workspaceFolder && configFile) {
		container = await findDevContainer(params, [`${hostFolderLabel}=${workspaceFolder}`, `${configFileLabel}=${configFile}`]);
		if (!container) {
			// Fall back to old labels.
			container = await findDevContainer(params, [`${hostFolderLabel}=${workspaceFolder}`]);
			if (container) {
				if (container.Config.Labels?.[configFileLabel]) {
					// But ignore containers with new labels.
					container = undefined;
				} else if (removeContainerWithOldLabels === true || removeContainerWithOldLabels === container.Id) {
					// Remove container, so it will be rebuilt with new labels.
					await removeContainer(params, container.Id);
					container = undefined;
				}
			}
		}
	} else {
		throw new Error(`Either containerId or workspaceFolder and configFile must be provided.`);
	}
	return {
		container,
		idLabels: !container || container.Config.Labels?.[configFileLabel] ?
			[`${hostFolderLabel}=${workspaceFolder}`, `${configFileLabel}=${configFile}`] :
			[`${hostFolderLabel}=${workspaceFolder}`],
	};
}

export function runAsyncHandler(handler: () => Promise<void>) {
	(async () => {
		try {
			await handler();
		} catch (err) {
			console.error(err);
			process.exit(1);
		}
	})();
}
</file>

<file path="src/spec-shutdown/dockerUtils.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { CLIHost, runCommand, runCommandNoPty, ExecFunction, ExecParameters, Exec, PtyExecFunction, PtyExec, PtyExecParameters, plainExecAsPtyExec, PlatformInfo } from '../spec-common/commonUtils';
import { toErrorText } from '../spec-common/errors';
import * as ptyType from 'node-pty';
import { Log, makeLog } from '../spec-utils/log';
import { Event } from '../spec-utils/event';
import { escapeRegExCharacters } from '../spec-utils/strings';
import { delay } from '../spec-common/async';

export interface ContainerDetails {
	Id: string;
	Created: string;
	Name: string;
	State: {
		Status: string;
		StartedAt: string;
		FinishedAt: string;
	};
	Config: {
		Image: string;
		User: string;
		Env: string[] | null;
		Labels: Record<string, string | undefined> | null;
	};
	Mounts: {
		Type: string;
		Name?: string;
		Source: string;
		Destination: string;
	}[];
	NetworkSettings: {
		Ports: Record<string, {
			HostIp: string;
			HostPort: string;
		}[] | null>;
	};
	Ports: {
		IP: string;
		PrivatePort: number;
		PublicPort: number;
		Type: string;
	}[];
}

export interface DockerCLIParameters {
	cliHost: CLIHost;
	dockerCLI: string;
	dockerComposeCLI: () => Promise<DockerComposeCLI>;
	env: NodeJS.ProcessEnv;
	output: Log;
	platformInfo: PlatformInfo;
}

export interface PartialExecParameters {
	exec: ExecFunction;
	cmd: string;
	args?: string[];
	env: NodeJS.ProcessEnv;
	output: Log;
	print?: boolean | 'continuous' | 'onerror';
}

export interface PartialPtyExecParameters {
	ptyExec: PtyExecFunction;
	exec: ExecFunction; // for fallback operation
	cmd: string;
	args?: string[];
	env: NodeJS.ProcessEnv;
	output: Log;
	onDidInput?: Event<string>;
}

interface DockerResolverParameters {
	dockerCLI: string;
	isPodman: boolean;
	dockerComposeCLI: () => Promise<DockerComposeCLI>;
	dockerEnv: NodeJS.ProcessEnv;
	common: {
		cliHost: CLIHost;
		output: Log;
	};
}

export interface DockerComposeCLI {
	version: string;
	cmd: string;
	args: string[];
}

export async function inspectContainer(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, id: string): Promise<ContainerDetails> {
	return (await inspectContainers(params, [id]))[0];
}

export async function inspectContainers(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, ids: string[]): Promise<ContainerDetails[]> {
	const results = await inspect<ContainerDetails>(params, 'container', ids);
	for (const result of results) {
		result.Ports = [];
		const rawPorts = result.NetworkSettings.Ports;
		for (const privatePortAndType in rawPorts) {
			const [PrivatePort, Type] = privatePortAndType.split('/');
			for (const targetPort of rawPorts[privatePortAndType] || []) {
				const { HostIp: IP, HostPort: PublicPort } = targetPort;
				result.Ports.push({
					IP,
					PrivatePort: parseInt(PrivatePort),
					PublicPort: parseInt(PublicPort),
					Type
				});
			}
		}
	}
	return results;
}

export interface ImageDetails {
	Id: string;
	Architecture: string;
	Variant?: string;
	Os: string;
	Config: {
		User: string;
		Env: string[] | null;
		Labels: Record<string, string | undefined> | null;
		Entrypoint: string[] | null;
		Cmd: string[] | null;
	};
}

export async function inspectImage(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, id: string): Promise<ImageDetails> {
	return (await inspect<ImageDetails>(params, 'image', [id]))[0];
}

async function inspect<T>(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, type: 'container' | 'image' | 'volume', ids: string[]): Promise<T[]> {
	if (!ids.length) {
		return [];
	}
	const partial = toExecParameters(params);
	const result = await runCommandNoPty({
		...partial,
		args: (partial.args || []).concat(['inspect', '--type', type, ...ids]),
	});
	try {
		return JSON.parse(result.stdout.toString());
	} catch (err) {
		console.error({
			stdout: result.stdout.toString(),
			stderr: result.stderr.toString(),
		});
		throw err;
	}
}

export async function listContainers(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, all = false, labels: string[] = []) {
	const filterArgs = [];
	if (all) {
		filterArgs.push('-a');
	}
	for (const label of labels) {
		filterArgs.push('--filter', `label=${label}`);
	}
	const result = await dockerCLI(params, 'ps', '-q', ...filterArgs);
	return result.stdout
		.toString()
		.split(/\r?\n/)
		.filter(s => !!s);
}

export async function removeContainer(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, nameOrId: string) {
	let eventsProcess: Exec | undefined;
	let removedSeenP: Promise<void> | undefined;
	try {
		for (let i = 0, n = 7; i < n; i++) {
			try {
				await dockerCLI(params, 'rm', '-f', nameOrId);
				return;
			} catch (err) {
				// https://github.com/microsoft/vscode-remote-release/issues/6509
				const stderr: string = err?.stderr?.toString().toLowerCase() || '';
				if (i === n - 1 || !stderr.includes('already in progress')) {
					throw err;
				}
				if (!removedSeenP) {
					eventsProcess = await getEvents(params, {
						container: [nameOrId],
						event: ['destroy'],
					});
					removedSeenP = new Promise<void>(resolve => {
						eventsProcess!.stdout.on('data', () => {
							resolve();
							eventsProcess!.terminate();
							removedSeenP = new Promise(() => {}); // safeguard in case we see the 'removal already in progress' error again
						});
					});
				}
				await Promise.race([removedSeenP, delay(1000)]);
			}
		}
	} finally {
		if (eventsProcess) {
			eventsProcess.terminate();
		}
	}
}

export async function getEvents(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, filters?: Record<string, string[]>) {
	const { exec, cmd, args, env, output } = toExecParameters(params);
	const filterArgs = [];
	for (const filter in filters) {
		for (const value of filters[filter]) {
			filterArgs.push('--filter', `${filter}=${value}`);
		}
	}
	const format = 'isPodman' in params && params.isPodman ? 'json' : '{{json .}}'; // https://github.com/containers/libpod/issues/5981
	const combinedArgs = (args || []).concat(['events', '--format', format, ...filterArgs]);

	const p = await exec({
		cmd,
		args: combinedArgs,
		env,
		output,
	});

	const stderr: Buffer[] = [];
	p.stderr.on('data', data => stderr.push(data));

	p.exit.then(({ code, signal }) => {
		if (stderr.length) {
			output.write(toErrorText(Buffer.concat(stderr).toString()));
		}
		if (code || (signal && signal !== 'SIGKILL')) {
			output.write(toErrorText(`Docker events terminated (code: ${code}, signal: ${signal}).`));
		}
	}, err => {
		output.write(toErrorText(err && (err.stack || err.message)));
	});

	return p;
}

export async function dockerBuildKitVersion(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters): Promise<{ versionString: string; versionMatch?: string } | undefined> {
	try {
		const execParams = {
			...toExecParameters(params),
			print: true,
		};
		const result = await dockerCLI(execParams, 'buildx', 'version');
		const versionString = result.stdout.toString();
		const versionMatch = versionString.match(/(?<major>[0-9]+)\.(?<minor>[0-9]+)\.(?<patch>[0-9]+)/);
		if (!versionMatch) {
			return { versionString };
		}
		return { versionString, versionMatch: versionMatch[0] };
	} catch {
		return undefined;
	}
}

export async function dockerCLI(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, ...args: string[]) {
	const partial = toExecParameters(params);
	return runCommandNoPty({
		...partial,
		args: (partial.args || []).concat(args),
	});
}

export async function isPodman(params: PartialExecParameters) {
	try {
		const { stdout } = await dockerCLI(params, '-v');
		return stdout.toString().toLowerCase().indexOf('podman') !== -1;
	} catch (err) {
		return false;
	}
}

export async function dockerPtyCLI(params: PartialPtyExecParameters | DockerResolverParameters | DockerCLIParameters, ...args: string[]) {
	const partial = toPtyExecParameters(params);
	return runCommand({
		...partial,
		args: (partial.args || []).concat(args),
	});
}

export async function dockerComposeCLI(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, ...args: string[]) {
	const partial = toExecParameters(params, 'dockerComposeCLI' in params ? await params.dockerComposeCLI() : undefined);
	return runCommandNoPty({
		...partial,
		args: (partial.args || []).concat(args),
	});
}

export async function dockerComposePtyCLI(params: DockerCLIParameters | PartialPtyExecParameters | DockerResolverParameters, ...args: string[]) {
	const partial = toPtyExecParameters(params, 'dockerComposeCLI' in params ? await params.dockerComposeCLI() : undefined);
	return runCommand({
		...partial,
		args: (partial.args || []).concat(args),
	});
}

export function dockerExecFunction(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, containerName: string, user: string | undefined, allocatePtyIfPossible = false): ExecFunction {
	return async function (execParams: ExecParameters): Promise<Exec> {
		const { exec, cmd, args, env } = toExecParameters(params);
		// Spawning without node-pty: `docker exec` only accepts -t if stdin is a TTY. (https://github.com/devcontainers/cli/issues/606)
		const canAllocatePty = allocatePtyIfPossible && process.stdin.isTTY && execParams.stdio?.[0] === 'inherit';
		const { argsPrefix, args: execArgs } = toDockerExecArgs(containerName, user, execParams, canAllocatePty);
		return exec({
			cmd,
			args: (args || []).concat(execArgs),
			env,
			stdio: execParams.stdio,
			output: replacingDockerExecLog(execParams.output, cmd, argsPrefix),
		});
	};
}

export async function dockerPtyExecFunction(params: PartialPtyExecParameters | DockerResolverParameters, containerName: string, user: string | undefined, loadNativeModule: <T>(moduleName: string) => Promise<T | undefined>, allowInheritTTY: boolean): Promise<PtyExecFunction> {
	const pty = await loadNativeModule<typeof ptyType>('node-pty');
	if (!pty) {
		const plain = dockerExecFunction(params, containerName, user, true);
		return plainExecAsPtyExec(plain, allowInheritTTY);
	}

	return async function (execParams: PtyExecParameters): Promise<PtyExec> {
		const { ptyExec, cmd, args, env } = toPtyExecParameters(params);
		const { argsPrefix, args: execArgs } = toDockerExecArgs(containerName, user, execParams, true);
		return ptyExec({
			cmd,
			args: (args || []).concat(execArgs),
			env,
			output: replacingDockerExecLog(execParams.output, cmd, argsPrefix),
		});
	};
}

function replacingDockerExecLog(original: Log, cmd: string, args: string[]) {
	return replacingLog(original, `Run: ${cmd} ${(args || []).join(' ').replace(/\n.*/g, '')}`, 'Run in container:');
}

function replacingLog(original: Log, search: string, replace: string) {
	const searchR = new RegExp(escapeRegExCharacters(search), 'g');
	const wrapped = makeLog({
		...original,
		get dimensions() {
			return original.dimensions;
		},
		event: e => original.event('text' in e ? {
			...e,
			text: e.text.replace(searchR, replace),
		} : e),
	});
	return wrapped;
}

function toDockerExecArgs(containerName: string, user: string | undefined, params: ExecParameters | PtyExecParameters, pty: boolean) {
	const { env, cwd, cmd, args } = params;
	const execArgs = ['exec', '-i'];
	if (pty) {
		execArgs.push('-t');
	}
	if (user) {
		execArgs.push('-u', user);
	}
	if (env) {
		Object.keys(env)
			.forEach(key => execArgs.push('-e', `${key}=${env[key]}`));
	}
	if (cwd) {
		execArgs.push('-w', cwd);
	}
	execArgs.push(containerName);
	const argsPrefix = execArgs.slice();
	execArgs.push(cmd);
	if (args) {
		execArgs.push(...args);
	}
	return { argsPrefix, args: execArgs };
}

export function toExecParameters(params: DockerCLIParameters | PartialExecParameters | DockerResolverParameters, compose?: DockerComposeCLI): PartialExecParameters {
	return 'dockerEnv' in params ? {
		exec: params.common.cliHost.exec,
		cmd: compose ? compose.cmd : params.dockerCLI,
		args: compose ? compose.args : [],
		env: params.dockerEnv,
		output: params.common.output,
	} : 'cliHost' in params ? {
		exec: params.cliHost.exec,
		cmd: compose ? compose.cmd : params.dockerCLI,
		args: compose ? compose.args : [],
		env: params.env,
		output: params.output,
	} : {
		...params,
		env: params.env,
	};
}

export function toPtyExecParameters(params: DockerCLIParameters | PartialPtyExecParameters | DockerResolverParameters, compose?: DockerComposeCLI): PartialPtyExecParameters {
	return 'dockerEnv' in params ? {
		ptyExec: params.common.cliHost.ptyExec,
		exec: params.common.cliHost.exec,
		cmd: compose ? compose.cmd : params.dockerCLI,
		args: compose ? compose.args : [],
		env: params.dockerEnv,
		output: params.common.output,
	} : 'cliHost' in params ? {
		ptyExec: params.cliHost.ptyExec,
		exec: params.cliHost.exec,
		cmd: compose ? compose.cmd : params.dockerCLI,
		args: compose ? compose.args : [],
		env: params.env,
		output: params.output,
	} : {
		...params,
		env: params.env,
	};
}

export function toDockerImageName(name: string) {
	// https://docs.docker.com/engine/reference/commandline/tag/#extended-description
	return name
		.toLowerCase()
		.replace(/[^a-z0-9\._-]+/g, '')
		.replace(/(\.[\._-]|_[\.-]|__[\._-]|-+[\._])[\._-]*/g, (_, a) => a.substr(0, a.length - 1));
}
</file>

<file path="src/spec-shutdown/tsconfig.json">
{
	"extends": "../../tsconfig.base.json",
	"references": [
		{
			"path": "../spec-common"
		},
		{
			"path": "../spec-utils"
		}
	]
}
</file>

<file path="src/spec-utils/event.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { EventEmitter } from 'events';

export interface Event<T> {
	(listener: (e: T) => void): Disposable;
}

export class NodeEventEmitter<T> {

	private nodeEmitter = new EventEmitter();

	constructor(private register?: { on: () => void; off: () => void }) { }
	event: Event<T> = (listener: (e: T) => void): Disposable => {
		this.nodeEmitter.on('event', listener);
		if (this.register && this.nodeEmitter.listenerCount('event') === 1) {
			this.register.on();
		}
		return {
			dispose: () => {
				if (this.register && this.nodeEmitter.listenerCount('event') === 1) {
					this.register.off();
				}
				this.nodeEmitter.off('event', listener);
			}
		};
	};

	fire(data: T) {
		this.nodeEmitter.emit('event', data);
	}
	dispose() {
		this.nodeEmitter.removeAllListeners();
	}
}

export interface Disposable {
	dispose(): void;
}
</file>

<file path="src/spec-utils/httpRequest.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import type { RequestOptions } from 'https';
import { https, http, FollowOptions } from 'follow-redirects';
import { ProxyAgent } from 'proxy-agent';
import * as url from 'url';
import * as tls from 'tls';
import { Log, LogLevel } from './log';
import { readLocalFile } from './pfs';

export async function request(options: { type: string; url: string; headers: Record<string, string>; data?: Buffer }, output: Log) {
	const secureContext = await secureContextWithExtraCerts(output);
	return new Promise<Buffer>((resolve, reject) => {
		const parsed = new url.URL(options.url);
		const reqOptions: RequestOptions & tls.CommonConnectionOptions = {
			hostname: parsed.hostname,
			port: parsed.port,
			path: parsed.pathname + parsed.search,
			method: options.type,
			headers: options.headers,
			agent: new ProxyAgent(),
			secureContext,
		};

		const plainHTTP = parsed.protocol === 'http:' || parsed.hostname === 'localhost';
		if (plainHTTP) {
			output.write('Sending as plain HTTP request', LogLevel.Warning);
		}

		const req = (plainHTTP ? http : https).request(reqOptions, res => {
			if (res.statusCode! < 200 || res.statusCode! > 299) {
				reject(new Error(`HTTP ${res.statusCode}: ${res.statusMessage}`));
				output.write(`[-] HTTP request failed with status code ${res.statusCode}: : ${res.statusMessage}`, LogLevel.Trace);
			} else {
				res.on('error', reject);
				const chunks: Buffer[] = [];
				res.on('data', chunk => chunks.push(chunk as Buffer));
				res.on('end', () => resolve(Buffer.concat(chunks)));
			}
		});
		req.on('error', reject);
		if (options.data) {
			req.write(options.data);
		}
		req.end();
	});
}

// HTTP HEAD request that returns status code.
export async function headRequest(options: { url: string; headers: Record<string, string> }, output: Log) {
	const secureContext = await secureContextWithExtraCerts(output);
	return new Promise<number>((resolve, reject) => {
		const parsed = new url.URL(options.url);
		const reqOptions: RequestOptions & tls.CommonConnectionOptions = {
			hostname: parsed.hostname,
			port: parsed.port,
			path: parsed.pathname + parsed.search,
			method: 'HEAD',
			headers: options.headers,
			agent: new ProxyAgent(),
			secureContext,
		};

		const plainHTTP = parsed.protocol === 'http:' || parsed.hostname === 'localhost';
		if (plainHTTP) {
			output.write('Sending as plain HTTP request', LogLevel.Warning);
		}

		const req = (plainHTTP ? http : https).request(reqOptions, res => {
			res.on('error', reject);
			output.write(`HEAD ${options.url} -> ${res.statusCode}`, LogLevel.Trace);
			resolve(res.statusCode!);
		});
		req.on('error', reject);
		req.end();
	});
}

// Send HTTP Request.
// Does not throw on status code, but rather always returns 'statusCode', 'resHeaders', and 'resBody'.
export async function requestResolveHeaders(options: { type: string; url: string; headers: Record<string, string>; data?: Buffer }, output: Log) {
	const secureContext = await secureContextWithExtraCerts(output);
	return new Promise<{ statusCode: number; resHeaders: Record<string, string>; resBody: Buffer }>((resolve, reject) => {
		const parsed = new url.URL(options.url);
		const reqOptions: RequestOptions & tls.CommonConnectionOptions & FollowOptions<any> = {
			hostname: parsed.hostname,
			maxBodyLength: 100 * 1024 * 1024,
			port: parsed.port,
			path: parsed.pathname + parsed.search,
			method: options.type,
			headers: options.headers,
			agent: new ProxyAgent(),
			secureContext,
		};

		const plainHTTP = parsed.protocol === 'http:' || parsed.hostname === 'localhost';
		if (plainHTTP) {
			output.write('Sending as plain HTTP request', LogLevel.Warning);
		}

		const req = (plainHTTP ? http : https).request(reqOptions, res => {
			res.on('error', reject);

			// Resolve response body
			const chunks: Buffer[] = [];
			res.on('data', chunk => chunks.push(chunk as Buffer));
			res.on('end', () => {
				resolve({
					statusCode: res.statusCode!,
					resHeaders: res.headers! as Record<string, string>,
					resBody: Buffer.concat(chunks)
				});
			});
		});

		if (options.data) {
			req.write(options.data);
		}

		req.on('error', reject);
		req.end();
	});
}

let _secureContextWithExtraCerts: Promise<tls.SecureContext | undefined> | undefined;

async function secureContextWithExtraCerts(output: Log, options?: tls.SecureContextOptions) {
	// Work around https://github.com/electron/electron/issues/10257.

	if (_secureContextWithExtraCerts) {
		return _secureContextWithExtraCerts;
	}

	return _secureContextWithExtraCerts = (async () => {
		if (!process.versions.electron || !process.env.NODE_EXTRA_CA_CERTS) {
			return undefined;
		}
	
		try {
			const content = await readLocalFile(process.env.NODE_EXTRA_CA_CERTS, { encoding: 'utf8' });
			const certs = (content.split(/(?=-----BEGIN CERTIFICATE-----)/g)
				.filter(pem => !!pem.length));
			output.write(`Loading ${certs.length} extra certificates from ${process.env.NODE_EXTRA_CA_CERTS}.`);
			if (!certs.length) {
				return undefined;
			}
	
			const secureContext = tls.createSecureContext(options);
			for (const cert of certs) {
				secureContext.context.addCACert(cert);
			}
			return secureContext;
		} catch (err) {
			output.write(`Error loading extra certificates from ${process.env.NODE_EXTRA_CA_CERTS}: ${err.message}`, LogLevel.Error);
			return undefined;
		}
	})();
}
</file>

<file path="src/spec-utils/pfs.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as fs from 'fs';
import { promisify } from 'util';
import * as path from 'path';
import * as ncp from 'ncp';

import { URI } from 'vscode-uri';

export function isLocalFile(filepath: string): Promise<boolean> {
	return new Promise(r => fs.stat(filepath, (err, stat) => r(!err && stat.isFile())));
}

export function isLocalFolder(filepath: string): Promise<boolean> {
	return new Promise(r => fs.stat(filepath, (err, stat) => r(!err && stat.isDirectory())));
}

export const readLocalFile = promisify(fs.readFile);
export const writeLocalFile = promisify(fs.writeFile);
export const appendLocalFile = promisify(fs.appendFile);
export const renameLocal = promisify(fs.rename);
export const readLocalDir = promisify(fs.readdir);
export const unlinkLocal = promisify(fs.unlink);
export const mkdirpLocal = (path: string) => new Promise<void>((res, rej) => fs.mkdir(path, { recursive: true }, err => err ? rej(err) : res()));
export const rmdirLocal = promisify(fs.rmdir);
export const rmLocal = promisify(fs.rm);
export const cpLocal = promisify(fs.copyFile);
export const cpDirectoryLocal = promisify(ncp.ncp);

export interface FileHost {
	platform: NodeJS.Platform;
	path: typeof path.posix | typeof path.win32;
	isFile(filepath: string): Promise<boolean>;
	readFile(filepath: string): Promise<Buffer>;
	writeFile(filepath: string, content: Buffer): Promise<void>;
	readDir(dirpath: string): Promise<string[]>;
	readDirWithTypes?(dirpath: string): Promise<[string, FileTypeBitmask][]>;
	mkdirp(dirpath: string): Promise<void>;
	toCommonURI(filePath: string): Promise<URI | undefined>;
}

export enum FileTypeBitmask {
	Unknown = 0,
	File = 1,
	Directory = 2,
	SymbolicLink = 64
}
</file>

<file path="src/spec-utils/product.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/


export interface PackageConfiguration {
	name: string;
	version: string;
}

export function getPackageConfig(): PackageConfiguration {
	return require('../../package.json');
}
export const includeAllConfiguredFeatures = true;
</file>

<file path="src/spec-utils/strings.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/


export function escapeRegExCharacters(str: string) {
	return str.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
}
</file>

<file path="src/spec-utils/tsconfig.json">
{
	"extends": "../../tsconfig.base.json"
}
</file>

<file path="src/spec-utils/workspaces.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';

export interface Workspace {
	readonly isWorkspaceFile: boolean;
	readonly workspaceOrFolderPath: string;
	readonly rootFolderPath: string;
	readonly configFolderPath: string;
}

export function workspaceFromPath(path_: typeof path.posix | typeof path.win32, workspaceOrFolderPath: string): Workspace {
	if (isWorkspacePath(workspaceOrFolderPath)) {
		const workspaceFolder = path_.dirname(workspaceOrFolderPath);
		return {
			isWorkspaceFile: true,
			workspaceOrFolderPath,
			rootFolderPath: workspaceFolder, // use workspaceFolder as root folder
			configFolderPath: workspaceFolder, // have config file in workspaceFolder (to be discussed...)
		};
	}
	return {
		isWorkspaceFile: false,
		workspaceOrFolderPath,
		rootFolderPath: workspaceOrFolderPath,
		configFolderPath: workspaceOrFolderPath,
	};
}

export function isWorkspacePath(workspaceOrFolderPath: string) {
	return path.extname(workspaceOrFolderPath) === '.code-workspace'; // TODO: Remove VS Code specific code.
}
</file>

<file path="src/test/configs/compose-Dockerfile-alpine/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "test",
	"workspaceFolder": "/",
	"postCreateCommand": "touch /tmp/postCreateCommand.testmarker",
	"postStartCommand": "touch /tmp/postStartCommand.testmarker",
	"postAttachCommand": "touch /tmp/postAttachCommand.testmarker",
	"remoteUser": "bar",
	"remoteEnv": {
		"bar": "baz"
	},
	"settings": {
		"search.followSymlinks": false
	},
	"extensions": [
		"dbaeumer.vscode-eslint"
	],
	"userEnvProbe": "interactiveShell",
	"devPort": 1234
}
</file>

<file path="src/test/configs/compose-Dockerfile-alpine/.devcontainer/docker-compose.yml">
version: '3'

services:
  test:
    build: .
    command: sleep infinity
</file>

<file path="src/test/configs/compose-Dockerfile-alpine/.devcontainer/Dockerfile">
FROM alpine:latest

RUN adduser foo --disabled-password

RUN adduser bar --disabled-password

RUN echo export PROFILE_SEEN=true >>/home/bar/.profile
</file>

<file path="src/test/configs/compose-Dockerfile-with-features/.devcontainer/devcontainer.json">
{
	"name": "Node.js & Mongo DB",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace",
	"customizations": {
		"vscode": {
			// Set *default* container specific settings.json values on container create.
			"settings": {},
			// Add the IDs of extensions you want installed when the container is created.
			"extensions": [
				"dbaeumer.vscode-eslint",
				"mongodb.mongodb-vscode"
			]
		}
	},
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [3000, 27017],
	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "yarn install",
	// Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "node",
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"codspace/myfeatures/helloworld": {
			"greeting": "howdy"
		}
	},
	"postCreateCommand": "echo \"Val: $TEST\" | sudo tee /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/compose-Dockerfile-with-features/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Update 'VARIANT' to pick an LTS version of Node.js: 18, 16, 14.
        # Append -bullseye or -buster to pin to an OS version.
        # Use -bullseye variants on local arm64/Apple Silicon.
        VARIANT: 18-bookworm
    volumes:
      - ..:/workspace:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db
    # Uncomment the next line to use a non-root user for all processes.
    # user: node

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: mongo:latest
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    # Uncomment to change startup options
    # environment:
    #  MONGO_INITDB_ROOT_USERNAME: root
    #  MONGO_INITDB_ROOT_PASSWORD: example
    #  MONGO_INITDB_DATABASE: your-database-here

    # Add "forwardPorts": ["27017"] to **devcontainer.json** to forward MongoDB locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  mongodb-data: null
</file>

<file path="src/test/configs/compose-Dockerfile-with-features/.devcontainer/Dockerfile">
# [Choice] Node.js version (use -bullseye variants on local arm64/Apple Silicon): 18, 16, 14, 18-bullseye, 16-bullseye, 14-bullseye, 18-buster, 16-buster, 14-buster
ARG VARIANT=16-bullseye
FROM mcr.microsoft.com/devcontainers/javascript-node:1-${VARIANT}

# Install MongoDB command line tools if on buster and x86_64 (arm64 not supported)
ARG MONGO_TOOLS_VERSION=5.0
RUN . /etc/os-release \
    && if [ "${VERSION_CODENAME}" = "buster" ] && [ "$(dpkg --print-architecture)" = "amd64" ]; then \
        curl -sSL "https://www.mongodb.org/static/pgp/server-${MONGO_TOOLS_VERSION}.asc" | gpg --dearmor > /usr/share/keyrings/mongodb-archive-keyring.gpg \
        && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/mongodb-archive-keyring.gpg] http://repo.mongodb.org/apt/debian $(lsb_release -cs)/mongodb-org/${MONGO_TOOLS_VERSION} main" | tee /etc/apt/sources.list.d/mongodb-org-${MONGO_TOOLS_VERSION}.list \
        && apt-get update && export DEBIAN_FRONTEND=noninteractive \
        && apt-get install -y mongodb-database-tools mongodb-mongosh \
        && apt-get clean -y && rm -rf /var/lib/apt/lists/*; \
    fi

# [Optional] Uncomment this section to install additional OS packages.
# RUN apt-get update && export DEBIAN_FRONTEND=noninteractive \
#     && apt-get -y install --no-install-recommends <your-package-list-here>

# [Optional] Uncomment if you want to install an additional version of node using nvm
# ARG EXTRA_NODE_VERSION=10
# RUN su node -c "source /usr/local/share/nvm/nvm.sh && nvm install ${EXTRA_NODE_VERSION}"

# [Optional] Uncomment if you want to install more global node modules
# RUN su node -c "npm install -g <your-package-list-here>"
</file>

<file path="src/test/configs/compose-Dockerfile-with-target/.devcontainer/devcontainer.json">
{
	"name": "Node.js & Mongo DB",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace",
	"customizations": {
		"vscode": {
			// Set *default* container specific settings.json values on container create.
			"settings": {},
			// Add the IDs of extensions you want installed when the container is created.
			"extensions": [
				"dbaeumer.vscode-eslint",
				"mongodb.mongodb-vscode"
			]
		}
	},
	"postCreateCommand": "touch /tmp/postCreateCommand.testmarker",
	"postStartCommand": "touch /tmp/postStartCommand.testmarker",
	"postAttachCommand": "touch /tmp/postAttachCommand.testmarker",
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [3000, 27017],
	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "yarn install",
	// Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "node",
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"codspace/myfeatures/helloworld": {
			"greeting": "howdy"
		}
	}
}
</file>

<file path="src/test/configs/compose-Dockerfile-with-target/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: desired-image
      args:
        # Update 'VARIANT' to pick an LTS version of Node.js: 18, 16, 14.
        # Append -bullseye or -buster to pin to an OS version.
        # Use -bullseye variants on local arm64/Apple Silicon.
        VARIANT: 18-bookworm
    volumes:
      - ..:/workspace:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db
    # Uncomment the next line to use a non-root user for all processes.
    # user: node

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: mongo:latest
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    # Uncomment to change startup options
    # environment:
    #  MONGO_INITDB_ROOT_USERNAME: root
    #  MONGO_INITDB_ROOT_PASSWORD: example
    #  MONGO_INITDB_DATABASE: your-database-here

    # Add "forwardPorts": ["27017"] to **devcontainer.json** to forward MongoDB locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  mongodb-data: null
</file>

<file path="src/test/configs/compose-Dockerfile-with-target/.devcontainer/Dockerfile">
# [Choice] Node.js version (use -bullseye variants on local arm64/Apple Silicon): 18, 16, 14, 18-bullseye, 16-bullseye, 14-bullseye, 18-buster, 16-buster, 14-buster
ARG VARIANT=16-bullseye
# Target should skip this layer
FROM alpine as false-start 


FROM mcr.microsoft.com/devcontainers/javascript-node:1-${VARIANT} as desired-image

# Install MongoDB command line tools if on buster and x86_64 (arm64 not supported)
ARG MONGO_TOOLS_VERSION=5.0
RUN . /etc/os-release \
    && if [ "${VERSION_CODENAME}" = "buster" ] && [ "$(dpkg --print-architecture)" = "amd64" ]; then \
    curl -sSL "https://www.mongodb.org/static/pgp/server-${MONGO_TOOLS_VERSION}.asc" | gpg --dearmor > /usr/share/keyrings/mongodb-archive-keyring.gpg \
    && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/mongodb-archive-keyring.gpg] http://repo.mongodb.org/apt/debian $(lsb_release -cs)/mongodb-org/${MONGO_TOOLS_VERSION} main" | tee /etc/apt/sources.list.d/mongodb-org-${MONGO_TOOLS_VERSION}.list \
    && apt-get update && export DEBIAN_FRONTEND=noninteractive \
    && apt-get install -y mongodb-database-tools mongodb-mongosh \
    && apt-get clean -y && rm -rf /var/lib/apt/lists/*; \
    fi

# [Optional] Uncomment this section to install additional OS packages.
# RUN apt-get update && export DEBIAN_FRONTEND=noninteractive \
#     && apt-get -y install --no-install-recommends <your-package-list-here>

# [Optional] Uncomment if you want to install an additional version of node using nvm
# ARG EXTRA_NODE_VERSION=10
# RUN su node -c "source /usr/local/share/nvm/nvm.sh && nvm install ${EXTRA_NODE_VERSION}"

# [Optional] Uncomment if you want to install more global node modules
# RUN su node -c "npm install -g <your-package-list-here>"

RUN echo "||test-content||" | sudo tee /var/test-marker

# Target should skip this layer
FROM alpine as false-finish
</file>

<file path="src/test/configs/compose-Dockerfile-without-features/.devcontainer/devcontainer.json">
{
	"name": "Node.js & Mongo DB",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace",
	// Set *default* container specific settings.json values on container create.
	"settings": {},
	// Add the IDs of extensions you want installed when the container is created.
	"extensions": [
		"dbaeumer.vscode-eslint",
		"mongodb.mongodb-vscode"
	],
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [3000, 27017],
	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "yarn install",
	// Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "node",
	"postCreateCommand": "echo \"Val: $TEST\" | sudo tee /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/compose-Dockerfile-without-features/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Update 'VARIANT' to pick an LTS version of Node.js: 18, 16, 14.
        # Append -bullseye or -buster to pin to an OS version.
        # Use -bullseye variants on local arm64/Apple Silicon.
        VARIANT: 16-bullseye
    volumes:
      - ..:/workspace:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db
    # Uncomment the next line to use a non-root user for all processes.
    # user: node

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: mongo:latest
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    # Uncomment to change startup options
    # environment:
    #  MONGO_INITDB_ROOT_USERNAME: root
    #  MONGO_INITDB_ROOT_PASSWORD: example
    #  MONGO_INITDB_DATABASE: your-database-here

    # Add "forwardPorts": ["27017"] to **devcontainer.json** to forward MongoDB locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  mongodb-data: null
</file>

<file path="src/test/configs/compose-Dockerfile-without-features/.devcontainer/Dockerfile">
# [Choice] Node.js version (use -bullseye variants on local arm64/Apple Silicon): 18, 16, 14, 18-bullseye, 16-bullseye, 14-bullseye, 18-buster, 16-buster, 14-buster
ARG VARIANT=16-bullseye
FROM mcr.microsoft.com/vscode/devcontainers/javascript-node:0-${VARIANT}

# Install MongoDB command line tools if on buster and x86_64 (arm64 not supported)
ARG MONGO_TOOLS_VERSION=5.0
RUN . /etc/os-release \
    && if [ "${VERSION_CODENAME}" = "buster" ] && [ "$(dpkg --print-architecture)" = "amd64" ]; then \
        curl -sSL "https://www.mongodb.org/static/pgp/server-${MONGO_TOOLS_VERSION}.asc" | gpg --dearmor > /usr/share/keyrings/mongodb-archive-keyring.gpg \
        && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/mongodb-archive-keyring.gpg] http://repo.mongodb.org/apt/debian $(lsb_release -cs)/mongodb-org/${MONGO_TOOLS_VERSION} main" | tee /etc/apt/sources.list.d/mongodb-org-${MONGO_TOOLS_VERSION}.list \
        && apt-get update && export DEBIAN_FRONTEND=noninteractive \
        && apt-get install -y mongodb-database-tools mongodb-mongosh \
        && apt-get clean -y && rm -rf /var/lib/apt/lists/*; \
    fi

# [Optional] Uncomment this section to install additional OS packages.
# RUN apt-get update && export DEBIAN_FRONTEND=noninteractive \
#     && apt-get -y install --no-install-recommends <your-package-list-here>

# [Optional] Uncomment if you want to install an additional version of node using nvm
# ARG EXTRA_NODE_VERSION=10
# RUN su node -c "source /usr/local/share/nvm/nvm.sh && nvm install ${EXTRA_NODE_VERSION}"

# [Optional] Uncomment if you want to install more global node modules
# RUN su node -c "npm install -g <your-package-list-here>"
</file>

<file path="src/test/configs/compose-image-with-features/.devcontainer/devcontainer.json">
{
	"name": "Node.js & Mongo DB",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace",
	"customizations": {
		"vscode": {
			// Set *default* container specific settings.json values on container create.
			"settings": {},
			// Add the IDs of extensions you want installed when the container is created.
			"extensions": [
				"dbaeumer.vscode-eslint",
				"mongodb.mongodb-vscode"
			]
		}
	},
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [3000, 27017],
	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "yarn install",
	// Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "node",
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"codspace/myfeatures/helloworld": {
			"greeting": "howdy"
		}
	},
	"postCreateCommand": "echo \"Val: $TEST\" | sudo tee /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/compose-image-with-features/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    image: mcr.microsoft.com/devcontainers/javascript-node:1-18-bookworm
    volumes:
      - ..:/workspace:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db
    # Uncomment the next line to use a non-root user for all processes.
    # user: node

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: mongo:latest
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    # Uncomment to change startup options
    # environment:
    #  MONGO_INITDB_ROOT_USERNAME: root
    #  MONGO_INITDB_ROOT_PASSWORD: example
    #  MONGO_INITDB_DATABASE: your-database-here

    # Add "forwardPorts": ["27017"] to **devcontainer.json** to forward MongoDB locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  mongodb-data: null
</file>

<file path="src/test/configs/compose-image-with-mounts/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "test",
	"workspaceFolder": "/",
	"mounts": [
        {
            "target": "/home/test_devcontainer_config",
            "type": "volume",
        }
    ]
}
</file>

<file path="src/test/configs/compose-image-with-mounts/.devcontainer/docker-compose.yml">
version: '3'

services:
  test:
    image: mcr.microsoft.com/devcontainers/base:latest
    command: sleep infinity
    volumes:
      - /home/test_docker_compose
</file>

<file path="src/test/configs/compose-image-without-features/.devcontainer/devcontainer.json">
{
	"name": "Node.js & Mongo DB",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace",
	// Set *default* container specific settings.json values on container create.
	"settings": {},
	// Add the IDs of extensions you want installed when the container is created.
	"extensions": [
		"dbaeumer.vscode-eslint",
		"mongodb.mongodb-vscode"
	],
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [3000, 27017],
	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "yarn install",
	// Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "node",
}
</file>

<file path="src/test/configs/compose-image-without-features/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    image: mcr.microsoft.com/vscode/devcontainers/javascript-node:0-16-bullseye
    volumes:
      - ..:/workspace:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db
    # Uncomment the next line to use a non-root user for all processes.
    # user: node

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: mongo:latest
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    # Uncomment to change startup options
    # environment:
    #  MONGO_INITDB_ROOT_USERNAME: root
    #  MONGO_INITDB_ROOT_PASSWORD: example
    #  MONGO_INITDB_DATABASE: your-database-here

    # Add "forwardPorts": ["27017"] to **devcontainer.json** to forward MongoDB locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  mongodb-data: null
</file>

<file path="src/test/configs/compose-image-without-features-minimal/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace",
	"postCreateCommand": "echo \"Val: $TEST\" > /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/compose-image-without-features-minimal/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    image: ubuntu:latest
    volumes:
      - ..:/workspace:cached
    command: sleep infinity
</file>

<file path="src/test/configs/compose-with-name/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace"
}
</file>

<file path="src/test/configs/compose-with-name/.devcontainer/docker-compose.yml">
version: '3.8'

name: custom-project-name

services:
  app:
    image: ubuntu:latest
    volumes:
      - ..:/workspace:cached
    command: sleep infinity
</file>

<file path="src/test/configs/compose-with-name-and-custom-yaml/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace"
}
</file>

<file path="src/test/configs/compose-with-name-and-custom-yaml/.devcontainer/docker-compose.yml">
version: '3.8'

name: custom-project-name-custom-yaml

services:
  app:
    image: ubuntu:latest
    ports: !reset []
    volumes:
      - ..:/workspace:cached
    command: sleep infinity
</file>

<file path="src/test/configs/compose-with-name-using-env-var/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace"
}
</file>

<file path="src/test/configs/compose-with-name-using-env-var/.devcontainer/docker-compose.yml">
version: '3.8'

name: ${CUSTOM_NAME}

services:
  app:
    image: ubuntu:latest
    volumes:
      - ..:/workspace:cached
    command: sleep infinity
</file>

<file path="src/test/configs/compose-without-name/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspace"
}
</file>

<file path="src/test/configs/compose-without-name/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    image: ubuntu:latest
    volumes:
      - ..:/workspace:cached
    command: sleep infinity
</file>

<file path="src/test/configs/disallowed-features/.devcontainer/allowed/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:latest",
	"features": {
		"ghcr.io/devcontainers/features/github-cli:latest": "latest"
	}
}
</file>

<file path="src/test/configs/disallowed-features/.devcontainer/disallowed/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:latest",
	"features": {
		"ghcr.io/devcontainers/features/github-cli:latest": "latest",
		"ghcr.io/devcontainers/features/disallowed-feature:latest": "latest"
	}
}
</file>

<file path="src/test/configs/dockerfile-with-features/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"args": { 
			"VARIANT": "18-bookworm"
		}
	},
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"ghcr.io/devcontainers/feature-starter/hello:1": {
			"greeting": "howdy"
		}
	},
	"postCreateCommand": "echo \"Val: $TEST\" | sudo tee /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/dockerfile-with-features/Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"
FROM mcr.microsoft.com/devcontainers/typescript-node:1-${VARIANT}
</file>

<file path="src/test/configs/dockerfile-with-parallel-commands/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"args": { 
			"VARIANT": "16-bullseye"
		}
	},
	"postCreateCommand": {
		"post-create-command-1": "touch /tmp/postCreateCommand1.testmarker && echo post create command 1",
		"post-create-command-2": "touch /tmp/postCreateCommand2.testmarker && echo post create command 2"
	},
	"postStartCommand": {
		"post-start-command-1": "touch /tmp/postStartCommand1.testmarker && echo post start command 1",
		"post-start-command-2": "touch /tmp/postStartCommand2.testmarker && echo post start command 2"
	},
	"postAttachCommand": {
		"post-attach-command-1": "touch /tmp/postAttachCommand1.testmarker && echo post attach command 1",
		"post-attach-command-2": "touch /tmp/postAttachCommand2.testmarker && echo post attach command 2"
	},
}
</file>

<file path="src/test/configs/dockerfile-with-parallel-commands/Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"

# Target should skip this layer
FROM alpine as false-start 

FROM mcr.microsoft.com/devcontainers/typescript-node:0-${VARIANT} as desired-image

RUN echo "||test-content||" | sudo tee /var/test-marker

# Target should skip this layer
FROM alpine as false-finish
</file>

<file path="src/test/configs/dockerfile-with-syntax/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"args": { 
			"VARIANT": "18-bookworm"
		}
	},
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"codspace/myfeatures/helloworld": {
			"greeting": "howdy"
		}
	}
}
</file>

<file path="src/test/configs/dockerfile-with-syntax/Dockerfile">
# syntax=docker/dockerfile:1
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"
FROM mcr.microsoft.com/devcontainers/typescript-node:1-${VARIANT}
</file>

<file path="src/test/configs/dockerfile-with-target/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"target": "desired-image",
		"args": { 
			"VARIANT": "18-bookworm"
		},
		"options": [ "--label", "test_build_options=success" ]
	},
	"postCreateCommand": "touch /tmp/postCreateCommand.testmarker",
	"postStartCommand": "touch /tmp/postStartCommand.testmarker",
	"postAttachCommand": "touch /tmp/postAttachCommand.testmarker",
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"codspace/myfeatures/helloworld": {
			"greeting": "howdy"
		}
	}
}
</file>

<file path="src/test/configs/dockerfile-with-target/Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"

# Target should skip this layer
FROM alpine as false-start 

FROM mcr.microsoft.com/devcontainers/typescript-node:1-${VARIANT} as desired-image

RUN echo "||test-content||" | sudo tee /var/test-marker

# Target should skip this layer
FROM alpine as false-finish
</file>

<file path="src/test/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"remoteEnv": {
		"SUBFOLDER_CONFIG_REMOTE_ENV": "true"
	},
	"postCreateCommand": "touch /subfolderConfigPostCreateCommand.txt"
}
</file>

<file path="src/test/configs/dockerfile-without-features/.devcontainer/subfolder/Dockerfile">
FROM ubuntu:latest

ENV SUBFOLDER_CONFIG_IMAGE_ENV=true
</file>

<file path="src/test/configs/dockerfile-without-features/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"args": {
			"VARIANT": "16-bullseye"
		}
	},
	"postCreateCommand": "echo \"Val: $TEST\" | sudo tee /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/dockerfile-without-features/Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"
FROM mcr.microsoft.com/vscode/devcontainers/typescript-node:0-${VARIANT}
</file>

<file path="src/test/configs/example/.devcontainer.json">
// Example devcontainer.json configuration, 
// wired into the vscode launch task (.vscode/launch.json)
{
	"image": "mcr.microsoft.com/devcontainers/base:latest",
	"features": {
		"ghcr.io/devcontainers/features/go:1": {
			"version": "latest"
		}
	}
}
</file>

<file path="src/test/configs/image/.devcontainer.json">
{
	"image": "ubuntu:latest",
	"postCreateCommand": "echo \"Val: $TEST\" > /postCreateCommand.txt",
	"runArgs": ["-e", "TEST_CE=TEST_VALUE3"],
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}",
		"LOCAL_PATH": "${localEnv:PATH}",
		"CONTAINER_PATH": "${containerEnv:PATH}",
		"TEST_RE": "${containerEnv:TEST_CE}"
	}
}
</file>

<file path="src/test/configs/image-containerEnv-issue/.devcontainer/devcontainer.json">
{
	"dockerComposeFile": "docker-compose.yml",
	"service": "devcontainerissues",
	"workspaceFolder": "/workspaces/cli",		
	"containerEnv": {
		"SOME_PATH": "/tmp/path/doc-ver/loc",
		"Test_Message": "H\"\n\ne\"'''llo M:;a/t?h&^iKa%#@!``ni,sk_a-",
		"ROSCONSOLE_FORMAT": "[$${severity}] [$${walltime:%Y-%m-%d %H:%M:%S}] [$${node}]: $${message}",
        "VAR_WITH_SPACES": "value with spaces",
        "VAR_WITH_QUOTES_WE_WANT_TO_KEEP": "value with \"quotes\" we want to keep",
        "VAR_WITH_DOLLAR_SIGN": "value with $dollar sign",
        "VAR_WITH_BACK_SLASH": "value with \\back slash",
        "ENV_WITH_COMMAND": "bash -c 'echo -n \"Hello, World!\"'"		
	}
}
</file>

<file path="src/test/configs/image-containerEnv-issue/.devcontainer/docker-compose.yml">
services:
  devcontainerissues:
    # set this to the premade image generated by running the 'original_container' vsc-original-container-c521b00ea40fee92e585b105d9e4f1699ad8216f18220c1b914451f2eafef3b4
    image: mcr.microsoft.com/devcontainers/javascript-node:1-22-bookworm
    volumes:
      - ../..:/workspaces:cached
    environment:
      FOO: b"\n\ta"r
      Test_Message:  "Hello Max"
      ROSCONSOLE_FORMAT: "Ros from compose"
    command: sleep infinity
</file>

<file path="src/test/configs/image-metadata/.devcontainer/localFeatureA/devcontainer-feature.json">
{
    "id": "localFeatureA",
    "version": "1.0.0",
    "init": true,
    "customizations": {
        "vscode": {
            "extensions": [
                "extensionA",
                "extensionB"
            ]
        }
    },
    "updateContentCommand": [
        "one",
        "two"
    ],
    "onCreateCommand": {
        "command": "three",
        "commandWithArgs": [
            "four",
            "arg1",
            "arg2"
        ]
    },
    "postCreateCommand": "five",
    "postStartCommand": "six",
    "postAttachCommand": "seven"
}
</file>

<file path="src/test/configs/image-metadata/.devcontainer/localFeatureA/install.sh">
#!/bin/sh

touch /localFeatureA
</file>

<file path="src/test/configs/image-metadata/.devcontainer/localFeatureB/devcontainer-feature.json">
{
    "id": "localFeatureB",
    "version": "1.0.0",
    "privileged": true
}
</file>

<file path="src/test/configs/image-metadata/.devcontainer/localFeatureB/install.sh">
#!/bin/sh

touch /localFeatureB
</file>

<file path="src/test/configs/image-metadata/.devcontainer/devcontainer.json">
{
	"image": "image-metadata-test-base",
	"features": {
		"./localFeatureA": "latest",
		"./localFeatureB": "latest"
	}
}
</file>

<file path="src/test/configs/image-metadata/base-image/Dockerfile">
FROM ubuntu:latest

LABEL devcontainer.metadata="{\"id\":\"baseFeature\"}"
</file>

<file path="src/test/configs/image-metadata-containerEnv/.devcontainer/devcontainer.json">
{
    "image": "mcr.microsoft.com/devcontainers/base:ubuntu",
    "features": {
        "ghcr.io/devcontainers/features/java:1": {
            "version": "none"
        }
    },
    "containerEnv": {
        "JAVA_HOME": "/usr/lib/jvm/msopenjdk-current",
        "VAR_WITH_SPACES": "value with spaces",
        "VAR_WITH_LOTS_OF_SPACES": "    value with lots of spaces.   ",
        "VAR_WITH_QUOTES_WE_WANT_TO_KEEP": "value with \"quotes\" we want to keep",
        "VAR_WITH_DOLLAR_SIGN": "value with $dollar sign",
        "VAR_WITH_BACK_SLASH": "value with \\back slash",
        "ENV_WITH_COMMAND": "bash -c 'echo -n \"Hello, World!\"'"
    }
}
</file>

<file path="src/test/configs/image-with-features/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/typescript-node:1-18-bookworm",
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": {},
		"ghcr.io/devcontainers/feature-starter/hello:1": {
			"greeting": "howdy"
		}
	},
	"postCreateCommand": "echo \"Val: $TEST\" | sudo tee /postCreateCommand.txt",
	"remoteEnv": {
		"TEST": "ENV",
		"TEST_ESCAPING": "{\n  \"fo$o\": \"ba'r\"\n}"
	}
}
</file>

<file path="src/test/configs/image-with-git-feature/.devcontainer.json">
{
	"image": "mcr.microsoft.com/vscode/devcontainers/typescript-node:0-16-bullseye",
	"features": {
		"ghcr.io/devcontainers/features/git": {}
	},
	"remoteEnv": {
		"TEST_REMOTE_ENV": "Value 1"
	},
	"remoteUser": "node"
}
</file>

<file path="src/test/configs/image-with-local-feature/.devcontainer.json">
{
	"image": "ubuntu:latest",
	"features": {
		"myfeature": {}
	}
}
</file>

<file path="src/test/configs/image-with-mounts/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:latest",
	"mounts": [
        {
            "target": "/home/test_devcontainer_config",
            "type": "volume",
        }
    ]
}
</file>

<file path="src/test/configs/image-with-parallel-initialize-command/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:alpine",
	"initializeCommand": {
		"touch-test1": "touch ${localWorkspaceFolder}/initializeCommand.1.testMarker",
		"touch-test2": "touch ${localWorkspaceFolder}/initializeCommand.2.testMarker"
	}
}
</file>

<file path="src/test/configs/poetry-example/.devcontainer.json">
// Example devcontainer.json configuration, 
// wired into the vscode launch task (.vscode/launch.json)
{
	"image": "mcr.microsoft.com/devcontainers/base:latest",
	"features": {
		"ghcr.io/devcontainers/features/python:1": {
			"version": "latest"
		}
	},
	"postStartCommand": {
		"poetry setup": [
			"/bin/bash",
			"-i",
			"-c",
			"python3 -m venv $HOME/.local && source $HOME/.local/bin/activate && poetry install"
		]
	}
}
</file>

<file path="src/test/configs/set-up-with-config/devcontainer.json">
{
	"postAttachCommand": "touch /postAttachCommand.txt",
	"remoteEnv": {
		"TEST_RE": "${containerEnv:TEST_CE}"
	}
}
</file>

<file path="src/test/configs/set-up-with-metadata/Dockerfile">
FROM alpine:3.17

LABEL "devcontainer.metadata"="{ \"postCreateCommand\": \"touch /postCreateCommand.txt\", \"remoteEnv\": { \"TEST_RE\": \"\${containerEnv:TEST_CE}\" } }"
</file>

<file path="src/test/configs/updateUID/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"remoteUser": "foo"
}
</file>

<file path="src/test/configs/updateUID/Dockerfile">
FROM debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDamd64/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"remoteUser": "foo"
}
</file>

<file path="src/test/configs/updateUIDamd64/Dockerfile">
FROM --platform=linux/amd64 debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDamd64-platform-option/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"options": [
			"--platform",
			"linux/amd64"
		]
	},
	"remoteUser": "foo",
	"runArgs": [
		"--platform",
		"linux/amd64"
	]
}
</file>

<file path="src/test/configs/updateUIDamd64-platform-option/Dockerfile">
FROM debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDarm64/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"remoteUser": "foo"
}
</file>

<file path="src/test/configs/updateUIDarm64/Dockerfile">
FROM --platform=linux/arm64 debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDarm64-platform-option/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"options": [
			"--platform",
			"linux/arm64"
		]
	},
	"remoteUser": "foo",
	"runArgs": [
		"--platform",
		"linux/arm64"
	]
}
</file>

<file path="src/test/configs/updateUIDarm64-platform-option/Dockerfile">
FROM debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDarm64v8/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"remoteUser": "foo"
}
</file>

<file path="src/test/configs/updateUIDarm64v8/Dockerfile">
FROM --platform=linux/arm64/v8 debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDarm64v8-platform-option/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"options": [
			"--platform",
			"linux/arm64/v8"
		]
	},
	"remoteUser": "foo",
	"runArgs": [
		"--platform",
		"linux/arm64/v8"
	]
}
</file>

<file path="src/test/configs/updateUIDarm64v8-platform-option/Dockerfile">
FROM debian:latest

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/updateUIDOnly/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"args": {
			"LOCAL_GID": "${localEnv:LOCAL_GID}"
		}
	},
	"remoteUser": "foo"
}
</file>

<file path="src/test/configs/updateUIDOnly/Dockerfile">
FROM debian:latest

ARG LOCAL_GID
RUN groupadd -g $LOCAL_GID bar || true

RUN groupadd -g 4321 foo
RUN useradd -m -u 1234 -g 4321 foo
</file>

<file path="src/test/configs/test-secrets.json">
{
	"SECRET1": "SecretValue1",
	"MASK_IT": "container",
	"LARGE35K_SECRET": "cccccccccccccccNEWcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvNEWvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbNEWbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmNEWmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxcccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssddddddddddddddssddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss"
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder/.devcontainer/localFeatureA/devcontainer-feature.json">
{
    "id": "localFeatureA",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    },
    "customizations": {
        "vscode": {
            "extensions": [
                "dbaeumer.vscode-eslint"
            ],
            "settings": {
                "files.watcherExclude": {
                    "**/target/**": true
                }
            }
        }
    }
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder/.devcontainer/localFeatureA/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder/.devcontainer/localFeatureB/devcontainer-feature.json">
{
    "id": "localFeatureB",
    "version": "1.0.0",
    "name": "A feature to remind you of your favorite color",
    "options": {
        "favorite": {
            "type": "string",
            "enum": [
                "red",
                "gold",
                "green"
            ],
            "default": "red",
            "description": "Choose your favorite color."
        }
    },
    "extensions": [
        "ms-dotnettools.csharp"
    ],
    "settings": {
        "files.watcherExclude": {
            "**/test/**": true
        }
    }
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder/.devcontainer/localFeatureB/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureB'"
echo "The provided favorite color is: ${FAVORITE}"

cat > /usr/local/bin/color \
<< EOF
#!/bin/sh
echo "my favorite color is ${FAVORITE}"
EOF

chmod +x /usr/local/bin/color
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder/.devcontainer/devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"./localFeatureA": {
			"greeting": "Hello there",
			"punctuation": "!!!!"
		},
		"./localFeatureB": {
			"favorite": "gold"
		}
	}
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder/.devcontainer/Dockerfile">
FROM mcr.microsoft.com/vscode/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/.devcontainer/localFeatureA/devcontainer-feature.json">
{
    "id": "localFeatureA",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    },
    "customizations": {
        "vscode": {
            "extensions": [
                "dbaeumer.vscode-eslint"
            ],
            "settings": {
                "files.watcherExclude": {
                    "**/target/**": true
                }
            }
        }
    }
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/.devcontainer/localFeatureA/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/.devcontainer/localFeatureB/devcontainer-feature.json">
{
    "id": "localFeatureB",
    "version": "1.0.0",
    "name": "A feature to remind you of your favorite color",
    "options": {
        "favorite": {
            "type": "string",
            "enum": [
                "red",
                "gold",
                "green"
            ],
            "default": "red",
            "description": "Choose your favorite color."
        }
    },
    "extensions": [
        "ms-dotnettools.csharp"
    ],
    "settings": {
        "files.watcherExclude": {
            "**/test/**": true
        }
    }
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/.devcontainer/localFeatureB/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureB'"
echo "The provided favorite color is: ${FAVORITE}"

cat > /usr/local/bin/color \
<< EOF
#!/bin/sh
echo "my favorite color is ${FAVORITE}"
EOF

chmod +x /usr/local/bin/color
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"./.devcontainer/localFeatureA": {
			"greeting": "Hello there",
			"punctuation": "!!!!"
		},
		"./.devcontainer/localFeatureB": {
			"favorite": "gold"
		}
	}
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/Dockerfile">
FROM mcr.microsoft.com/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder/README.md">
This is a README in a project.
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-oci-features/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile",
		"args": {
			"VARIANT": "18-bookworm"
		}
	},
	"features": {
		"terraform": "latest",
		"ghcr.io/devcontainers/features/docker-in-docker@sha256:440bdb81cf8af43f3e922450d33db9775c1097340557a5b7b6fe705bc758c5ef": {},
		"node": "16"
	}
}
</file>

<file path="src/test/container-features/configs/dockerfile-with-v2-oci-features/Dockerfile">
#  Copyright (c) Microsoft Corporation. All rights reserved.
#  Licensed under the MIT License. See License.txt in the project root for license information.
ARG VARIANT="16-bullseye"
FROM mcr.microsoft.com/devcontainers/typescript-node:1-${VARIANT}
</file>

<file path="src/test/container-features/configs/example-installsAfter/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:jammy",
	"features": {
		"ghcr.io/codspace/features/fruit:1": {},
		"ghcr.io/codspace/features/hello:1.0.7": {}
	}
}
</file>

<file path="src/test/container-features/configs/example-legacyIds/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/features/hello:1": {},
		"ghcr.io/codspace/features/new-color:1": {}
	}
}
</file>

<file path="src/test/container-features/configs/example-legacyIds-2/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/features/flower:1": {},
		"ghcr.io/codspace/features/color:1": {}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"dependsOn": {
		"./c": {
			"magicNumber": "50"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "c",
	"version": "0.0.1",
	"dependsOn": {
		"./a": {
			"magicNumber": "50"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/c/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/invalid-circular/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-simple/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {
			"magicNumber": "50"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-simple/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-simple/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-simple/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-simple/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {
			"optA": "a",
			"optB": "a"
		},
		"./c": {}
	},
	"options": {
		"optA": {
			"type": "string",
			"default": "0",
			"description": ""
		},
		"optB": {
			"type": "string",
			"default": "0",
			"description": ""
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"options": {
		"optA": {
			"type": "string",
			"default": "0",
			"description": ""
		},
		"optB": {
			"type": "string",
			"default": "0",
			"description": ""
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {
			"optA": "b",
			"optB": "a"
		},
		"./d": {},
		"./e": {}
	},
	"options": {
		"optA": {
			"type": "string",
			"default": "0",
			"description": ""
		},
		"optB": {
			"type": "string",
			"default": "0",
			"description": ""
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/d/devcontainer-feature.json">
{
	"name": "FeatureD",
	"id": "d",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {
			"optA": "b",
			"optB": "b"
		}
	},
	"options": {
		"optA": {
			"type": "string",
			"default": "0",
			"description": ""
		},
		"optB": {
			"type": "string",
			"default": "0",
			"description": ""
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/d/install.sh">
#!/bin/sh

NAME="D"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/e/devcontainer-feature.json">
{
	"name": "FeatureE",
	"id": "e",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {}
	},
	"options": {
		"optA": {
			"type": "string",
			"default": "0",
			"description": ""
		},
		"optB": {
			"type": "string",
			"default": "0",
			"description": ""
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/e/install.sh">
#!/bin/sh

NAME="E"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/local-with-options/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {
			"optA": "a",
			"optB": "b"
		},
		"./b": {
			"optA": "a",
			"optB": "b"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/oci-ab/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/dependson/b": {
			"magicNumber": "400"
		},
		"ghcr.io/codspace/dependson/a": {
			"magicNumber": "10"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/oci-fgh/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/dependson/f": {
			"magicNumber": "10"
		},
		"ghcr.io/codspace/dependson/g": {
			"magicNumber": "20"
		},
		"ghcr.io/codspace/dependson/h": {
			"magicNumber": "30"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/oci-ij/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/dependson/i": {
			"magicNumber": "50"
		},
		"ghcr.io/codspace/dependson/j": {
			"magicNumber": "100"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn/tgz-ab/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-B.tgz": {
			"magicNumber": "400"
		},
		"https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-A.tgz": {
			"magicNumber": "10"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/a/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/dependsOnAndInstallsAfter/a": {}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"installsAfter": [
		"./b"
	],
	"dependsOn": {
		"./c": {
			"magicNumber": "321"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/dependsOn-and-installsAfter/local-simple/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"installsAfter": [
		"./b"
	],
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"installsAfter": [
		"./c"
	],
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "c",
	"version": "0.0.1",
	"installsAfter": [
		"./a"
	],
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/c/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/invalid-circular/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {},
		"./b": {},
		"./c": {}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"installsAfter": [
		"./b",
		"./c"
	],
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/installsAfter/local-simple/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {},
		"./c": {
			"magicNumber": "321"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/image-with-v1-features-with-overrideFeatureInstallOrder/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/vscode/devcontainers/typescript-node:0-16-bullseye",
	"features": {
		"terraform": "latest",
		"codspace/myfeatures/helloworld": {
			"greeting": "howdy"
		},
		"codspace/features/devcontainer-feature-go@tarball02": {}
	},
	"overrideFeatureInstallOrder": [
		"codspace/features/devcontainer-feature-go",
		"codspace/myfeatures/helloworld",
		"terraform"
	]
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/image-with-v2-features-with-overrideFeatureInstallOrder/.devcontainer/localFeatureA/devcontainer-feature.json">
{
    "id": "localFeatureA",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/image-with-v2-features-with-overrideFeatureInstallOrder/.devcontainer/localFeatureA/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/image-with-v2-features-with-overrideFeatureInstallOrder/.devcontainer/localFeatureB/devcontainer-feature.json">
{
    "id": "localFeatureB",
    "version": "1.0.0",
    "name": "Another hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/image-with-v2-features-with-overrideFeatureInstallOrder/.devcontainer/localFeatureB/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureB'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/image-with-v2-features-with-overrideFeatureInstallOrder/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/python",
	"features": {
		"ghcr.io/devcontainers/features/python@sha256:675f3c93e52fa4b205827e3aae744905ae67951f70e3ec2611f766304b31f4a2": {
			"version": "none"
		},
		"ghcr.io/codspace/features/python:1": {
			"version": "none"
		},
		"./localFeatureA": {
			"greeting": "buongiorno"
		},
		"./localFeatureB": {
			"greeting": "buongiorno"
		},
		"https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz": {
			"version": "latest"
		}
	},
	"overrideFeatureInstallOrder": [
		"./localFeatureA",
		"https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz",
		"ghcr.io/devcontainers/features/python"
	]
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {},
		"./d": {}
	},
	"installsAfter": [
		"./c"
	],
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"dependsOn": {
		"./c": {}
	},
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/d/devcontainer-feature.json">
{
	"name": "FeatureD",
	"id": "d",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/d/install.sh">
#!/bin/sh

NAME="D"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-intermediate/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {}
	},
	"overrideFeatureInstallOrder": [
		"./c",
		"./d"
	]
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"dependsOn": {
		"./a": {}
	},
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-roundPriority/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./b": {},
		"./c": {}
	},
	"overrideFeatureInstallOrder": [
		"./a",
		"./b",
		"./c"
	]
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {},
		"./c": {},
		"./d": {}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/d/devcontainer-feature.json">
{
	"name": "FeatureD",
	"id": "d",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/d/install.sh">
#!/bin/sh

NAME="D"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/local-simple/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {}
	},
	"overrideFeatureInstallOrder": [
		"./c"
	]
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/a/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "a",
	"version": "0.0.1",
	"dependsOn": {
		"./b": {},
		"./c": {},
		"./d": {},
		"ghcr.io/codspace/dependson/b": {
			"magicNumber": "400"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/a/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/b/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "b",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/b/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/c/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "c",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/c/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/d/devcontainer-feature.json">
{
	"name": "FeatureD",
	"id": "d",
	"version": "0.0.1",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/d/install.sh">
#!/bin/sh

NAME="D"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/configs/feature-dependencies/overrideFeatureInstallOrder/mixed/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"./a": {}
	},
	"overrideFeatureInstallOrder": [
		"ghcr.io/codspace/dependson/a",
		"./d"
	]
}
</file>

<file path="src/test/container-features/configs/image-with-v1-features-node-python-local-cache/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"node": "latest"
	}

}
</file>

<file path="src/test/container-features/configs/image-with-v2-tarball/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/typescript-node:1-18-bookworm",
	"features": {
		"https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz": {}
	}
}
</file>

<file path="src/test/container-features/configs/invalid-configs/dockerfile-with-v2-local-features-no-dev-container-folder/local-features/localFeatureA/devcontainer-feature.json">
{
    "id": "localFeatureA",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/configs/invalid-configs/dockerfile-with-v2-local-features-no-dev-container-folder/local-features/localFeatureA/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/configs/invalid-configs/dockerfile-with-v2-local-features-no-dev-container-folder/local-features/localFeatureB/devcontainer-feature.json">
{
    "id": "localFeatureB",
    "version": "1.0.0",
    "name": "A feature to remind you of your favorite color",
    "options": {
        "favorite": {
            "type": "string",
            "enum": [
                "red",
                "gold",
                "green"
            ],
            "default": "red",
            "description": "Choose your favorite color."
        }
    }
}
</file>

<file path="src/test/container-features/configs/invalid-configs/dockerfile-with-v2-local-features-no-dev-container-folder/local-features/localFeatureB/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'color'"
echo "The provided favorite color is: ${FAVORITE}"

cat > /usr/local/bin/color \
<< EOF
#!/bin/sh
echo "my favorite color is ${FAVORITE}"
EOF

chmod +x /usr/local/bin/color
</file>

<file path="src/test/container-features/configs/invalid-configs/dockerfile-with-v2-local-features-no-dev-container-folder/.devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"./local-features/localFeatureA": {
			"greeting": "Hello there",
			"punctuation": "!!!!"
		},
		"./local-features/localFeatureB": {
			"favorite": "gold"
		}
	}
}
</file>

<file path="src/test/container-features/configs/invalid-configs/dockerfile-with-v2-local-features-no-dev-container-folder/Dockerfile">
FROM mcr.microsoft.com/vscode/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/configs/invalid-configs/invalid-v1-features/.devcontainer.json">
{
    "image": "ubuntu",
    "features": {
        "devcontainers/features/myfakefeature": "latest"
    }
}
</file>

<file path="src/test/container-features/configs/invalid-configs/invalid-v2-features/.devcontainer.json">
{
    "image": "ubuntu",
    "features": {
        "ghcr.io/devcontainers/features/myfakefeature:1": "latest"
    }
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/otter/devcontainer-feature.json">
{
    "id": "otter",
    "version": "1.2.3",
    "options": {},
    "updateContentCommand": "/usr/features/otter/helper_script.sh updateContentCommand",
    "onCreateCommand": "/usr/features/otter/helper_script.sh onCreateCommand",
    "postCreateCommand": {
        "parallel1": "/usr/features/otter/helper_script.sh parallel_postCreateCommand_1",
        "parallel2": [
            "/usr/features/otter/helper_script.sh",
            "parallel_postCreateCommand_2"
        ]
    },
    "postStartCommand": [
        "/usr/features/otter/helper_script.sh",
        "postStartCommand"
    ],
    "postAttachCommand": [
        "/usr/features/otter/helper_script.sh",
        "postAttachCommand"
    ]
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/otter/helper_script.sh">
#!/bin/bash

MARKER_FILE_NAME="$1"
echo "Hello from otter helper_script.sh invoked by ${MARKER_FILE_NAME}"
touch "helperScript.otter.${MARKER_FILE_NAME}.testMarker"
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/otter/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'otter'"

cat > /usr/local/bin/otter \
<< EOF
#!/bin/sh
echo "i-am-an-otter"
EOF

# Copy helper script into somewhere that will persist
mkdir -p /usr/features/otter
chmod -R 0755 /usr/features/otter
cp ./helper_script.sh /usr/features/otter/helper_script.sh

chmod +x /usr/local/bin/otter
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/rabbit/devcontainer-feature.json">
{
    "id": "rabbit",
    "version": "100.200.300",
    "options": {},
    "updateContentCommand": "/usr/features/rabbit/helper_script.sh updateContentCommand",
    "onCreateCommand": "/usr/features/rabbit/helper_script.sh onCreateCommand",
    "postCreateCommand": {
        "parallel1": "/usr/features/rabbit/helper_script.sh parallel_postCreateCommand_1",
        "parallel2": [
            "/usr/features/rabbit/helper_script.sh",
            "parallel_postCreateCommand_2"
        ]
    },
    "postStartCommand": [
        "/usr/features/rabbit/helper_script.sh",
        "postStartCommand"
    ],
    "postAttachCommand": [
        "/usr/features/rabbit/helper_script.sh",
        "postAttachCommand"
    ]
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/rabbit/helper_script.sh">
#!/bin/bash

MARKER_FILE_NAME="$1"
echo "Hello from rabbit helper_script.sh invoked by ${MARKER_FILE_NAME}"
touch "helperScript.rabbit.${MARKER_FILE_NAME}.testMarker"
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/rabbit/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'rabbit'"

cat > /usr/local/bin/rabbit \
<< EOF
#!/bin/sh
echo "i-am-a-rabbit"
EOF

# Copy helper script into somewhere that will persist
mkdir -p /usr/features/rabbit
chmod -R 0755 /usr/features/rabbit
cp ./helper_script.sh /usr/features/rabbit/helper_script.sh


chmod +x /usr/local/bin/rabbit
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"./otter": {},
		"./rabbit": {}
	},
	"postCreateCommand": {
		"parallel1": ".devcontainer/helper_script.sh parallel_postCreateCommand_1",
		"parallel2": [
			".devcontainer/helper_script.sh",
			"parallel_postCreateCommand_2"
		]
	},
	"postStartCommand": "touch `rabbit`.postStartCommand.testMarker", // The 'rabbit' command is installed and added to the path by .devcontainer/rabbit/install.sh
	"postAttachCommand": "touch `otter`.postAttachCommand.testMarker" // The 'otter'  command is installed and added to the path by .devcontainer/otter/install.sh
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/Dockerfile">
FROM mcr.microsoft.com/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-advanced/.devcontainer/helper_script.sh">
#!/bin/bash

MARKER_FILE_NAME="$1"
echo "Hello from the .devcontainer helper_script.sh invoked by ${MARKER_FILE_NAME}"
touch "helperScript.devContainer.${MARKER_FILE_NAME}.testMarker"
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/panda/devcontainer-feature.json">
{
    "id": "panda",
    "version": "4.5.6",
    "name": "Echos the panda emoji. That is it!",
    "options": {},
    "updateContentCommand": [
        ".devcontainer/createMarker.sh",
        "panda.updateContentCommand.testMarker"
    ],
    "onCreateCommand": "./.devcontainer/createMarker.sh panda.onCreateCommand.testMarker",
    "postCreateCommand": "./.devcontainer/createMarker.sh panda.postCreateCommand.testMarker",
    "postStartCommand": "./.devcontainer/createMarker.sh panda.postStartCommand.testMarker",
    "postAttachCommand": "./.devcontainer/createMarker.sh panda.postAttachCommand.testMarker"
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/panda/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'panda'"

cat > /usr/local/bin/panda \
<< EOF
#!/bin/sh
echo 🐼
EOF

chmod +x /usr/local/bin/panda
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/tiger/devcontainer-feature.json">
{
    "id": "tiger",
    "version": "8.9.10",
    "name": "Echos the tiger emoji. That is it!",
    "options": {},
    "updateContentCommand": "./.devcontainer/createMarker.sh tiger.updateContentCommand.testMarker",
    "onCreateCommand": "./.devcontainer/createMarker.sh tiger.onCreateCommand.testMarker",
    "postCreateCommand": "./.devcontainer/createMarker.sh tiger.postCreateCommand.testMarker",
    "postStartCommand": "./.devcontainer/createMarker.sh tiger.postStartCommand.testMarker",
    "postAttachCommand": [
        ".devcontainer/createMarker.sh",
        "tiger.postAttachCommand.testMarker"
    ],
    "installsAfter": [
        "./panda"
    ]
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/tiger/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'tiger'"

cat > /usr/local/bin/tiger \
<< EOF
#!/bin/sh
echo 🐯
EOF

chmod +x /usr/local/bin/tiger
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/createMarker.sh">
#!/bin/bash

MARKER_FILE_NAME="$1"

echo "Starting '${MARKER_FILE_NAME}'...."
sleep 1s

[[ -f saved_value.testMarker ]] || echo 0 > saved_value.testMarker
n=$(< saved_value.testMarker)
echo "${n}.`date +%s%3N`" > "${n}.${MARKER_FILE_NAME}"
printenv >> "${n}.${MARKER_FILE_NAME}"
echo $(( n + 1 )) > saved_value.testMarker

echo "Ending '${MARKER_FILE_NAME}'...."
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"./tiger": {},
		"./panda": {}
	},
	"onCreateCommand": ".devcontainer/createMarker.sh devContainer.onCreateCommand.testMarker",
	"updateContentCommand": ".devcontainer/createMarker.sh devContainer.updateContentCommand.testMarker",
	"postCreateCommand": [
		".devcontainer/createMarker.sh",
		"devContainer.postCreateCommand.testMarker"
	],
	"postStartCommand": ".devcontainer/createMarker.sh devContainer.postStartCommand.testMarker",
	"postAttachCommand": ".devcontainer/createMarker.sh devContainer.postAttachCommand.testMarker"
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-inline-commands/.devcontainer/Dockerfile">
FROM mcr.microsoft.com/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-resume-existing-container/.devcontainer/hippo/createMarker.sh">
#!/bin/bash

MARKER_FILE_NAME="$1"

echo "Starting '${MARKER_FILE_NAME}'...."
sleep 1s

[[ -f saved_value.testMarker ]] || echo 0 > saved_value.testMarker
n=$(< saved_value.testMarker)
echo "${n}.`date +%s%3N`" > "${n}.${MARKER_FILE_NAME}"
echo $(( n + 1 )) > saved_value.testMarker

echo "Ending '${MARKER_FILE_NAME}'...."
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-resume-existing-container/.devcontainer/hippo/devcontainer-feature.json">
{
    "id": "hippo",
    "version": "1.0.1",
    "name": "Hippo",
    "options": {},
    "postStartCommand": "/usr/features/hippo/createMarker.sh hippo.postStartCommand.testMarker",
    "postAttachCommand": "/usr/features/hippo/createMarker.sh hippo.postAttachCommand.testMarker"
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-resume-existing-container/.devcontainer/hippo/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'hippo'"

cat > /usr/local/bin/hippo \
<< EOF
#!/bin/sh
echo 🦛
EOF

# Copy helper script into somewhere that will persist
mkdir -p /usr/features/hippo
cp ./createMarker.sh /usr/features/hippo
chmod -R 0755 /usr/features/hippo

chmod +x /usr/local/bin/hippo
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-resume-existing-container/.devcontainer/devcontainer.json">
{
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"./hippo": {}
	}
}
</file>

<file path="src/test/container-features/configs/lifecycle-hooks-resume-existing-container/.devcontainer/Dockerfile">
FROM mcr.microsoft.com/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/configs/lockfile/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/features/flower:1.0.0": {},
		"ghcr.io/codspace/features/color:1.0.4": {},
		"https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-D.tgz": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile/.gitignore">
.devcontainer-lock.json
</file>

<file path="src/test/container-features/configs/lockfile/expected.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/codspace/features/color:1.0.4": {
      "version": "1.0.4",
      "resolved": "ghcr.io/codspace/features/color@sha256:6e9d07c7f488fabc981e7508d8c25eea4b102ebe4b87f9fc6f233efa1d325908",
      "integrity": "sha256:6e9d07c7f488fabc981e7508d8c25eea4b102ebe4b87f9fc6f233efa1d325908"
    },
    "ghcr.io/codspace/features/flower:1.0.0": {
      "version": "1.0.0",
      "resolved": "ghcr.io/codspace/features/flower@sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43",
      "integrity": "sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43"
    },
    "https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-D.tgz": {
      "version": "2.0.0",
      "resolved": "https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-D.tgz",
      "integrity": "sha256:41607bd6aba3975adcd0641cc479e67b04abd21763ba8a41ea053bcc04a6a818"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-dependson/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/dependson/A:2": {},
		"ghcr.io/codspace/dependson/E:1": {},
		"https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-A.tgz": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-dependson/.gitignore">
.devcontainer-lock.json
</file>

<file path="src/test/container-features/configs/lockfile-dependson/expected.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/codspace/dependson/A:2": {
      "version": "2.0.1",
      "resolved": "ghcr.io/codspace/dependson/a@sha256:932027ef71da186210e6ceb3294c3459caaf6b548d2b547d5d26be3fc4b2264a",
      "integrity": "sha256:932027ef71da186210e6ceb3294c3459caaf6b548d2b547d5d26be3fc4b2264a",
      "dependsOn": [
        "ghcr.io/codspace/dependson/E"
      ]
    },
    "ghcr.io/codspace/dependson/E": {
      "version": "2.0.0",
      "resolved": "ghcr.io/codspace/dependson/e@sha256:9f36f159c70f8bebff57f341904b030733adb17ef12a5d58d4b3d89b2a6c7d5a",
      "integrity": "sha256:9f36f159c70f8bebff57f341904b030733adb17ef12a5d58d4b3d89b2a6c7d5a"
    },
    "ghcr.io/codspace/dependson/E:1": {
      "version": "1.0.0",
      "resolved": "ghcr.io/codspace/dependson/e@sha256:90b84127edab28ecb169cd6c6f2101ce0ea1d77589cee01951fec7f879f3a11c",
      "integrity": "sha256:90b84127edab28ecb169cd6c6f2101ce0ea1d77589cee01951fec7f879f3a11c"
    },
    "https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-A.tgz": {
      "version": "2.0.1",
      "resolved": "https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-A.tgz",
      "integrity": "sha256:f2dd5be682cceedb5497f9a734b5d5e7834424ade75b8cc700927242585ec671",
      "dependsOn": [
        "ghcr.io/codspace/dependson/E"
      ]
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-frozen/.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/codspace/features/color:1": {
      "version": "1.0.4",
      "resolved": "ghcr.io/codspace/features/color@sha256:6e9d07c7f488fabc981e7508d8c25eea4b102ebe4b87f9fc6f233efa1d325908",
      "integrity": "sha256:6e9d07c7f488fabc981e7508d8c25eea4b102ebe4b87f9fc6f233efa1d325908"
    },
    "ghcr.io/codspace/features/flower:1": {
      "version": "1.0.0",
      "resolved": "ghcr.io/codspace/features/flower@sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43",
      "integrity": "sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-frozen/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/features/flower:1": {},
		"ghcr.io/codspace/features/color:1": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-generate-from-empty-file/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base",
	"features": {
		"ghcr.io/devcontainers/features/dotnet:2": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-generate-from-empty-file-frozen/.devcontainer/devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base",
	"features": {
		"ghcr.io/devcontainers/features/dotnet:2": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-oci-integrity/.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/codspace/features/color:1.0.0": {
      "version": "1.0.0",
      "resolved": "ghcr.io/codspace/features/color@sha256:c22e8f1065e198289b86780f38a041ad32d827819677fbb1c4c9555797814a0b",
      "integrity": "sha256:c22e8f1065e198289b86780f38a041ad32d827819677fbb1c4c9555797814a00"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-oci-integrity/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/features/color:1.0.0": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-outdated/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/codspace/features/flower:1.0.0": {},
		"ghcr.io/codspace/features/color:1.0.5": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-outdated/.gitignore">
.devcontainer-lock.json
</file>

<file path="src/test/container-features/configs/lockfile-outdated/expected.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/codspace/features/color:1.0.5": {
      "version": "1.0.5",
      "resolved": "ghcr.io/codspace/features/color@sha256:a20e55d6a70ad4bfb9eca962693de0982c607f41d732c3ff57ed1d75e9b59f9c",
      "integrity": "sha256:a20e55d6a70ad4bfb9eca962693de0982c607f41d732c3ff57ed1d75e9b59f9c"
    },
    "ghcr.io/codspace/features/flower:1.0.0": {
      "version": "1.0.0",
      "resolved": "ghcr.io/codspace/features/flower@sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43",
      "integrity": "sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-outdated/original.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/codspace/features/color:1.0.4": {
      "version": "1.0.4",
      "resolved": "ghcr.io/codspace/features/color@sha256:6e9d07c7f488fabc981e7508d8c25eea4b102ebe4b87f9fc6f233efa1d325908",
      "integrity": "sha256:6e9d07c7f488fabc981e7508d8c25eea4b102ebe4b87f9fc6f233efa1d325908"
    },
    "ghcr.io/codspace/features/flower:1.0.0": {
      "version": "1.0.0",
      "resolved": "ghcr.io/codspace/features/flower@sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43",
      "integrity": "sha256:c9cc1ac636b9ef595512b5ca7ecb3a35b7d3499cb6f86372edec76ae0cd71d43"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-outdated-command/.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/devcontainers/features/git:1.0": {
      "version": "1.0.4",
      "resolved": "ghcr.io/devcontainers/features/git@sha256:0bb490abcc0a3fb23937d29e2c18a225b51c5584edc0d9eb4131569a980f60b6",
      "integrity": "sha256:0bb490abcc0a3fb23937d29e2c18a225b51c5584edc0d9eb4131569a980f60b6"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-outdated-command/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/devcontainers/features/git:1.0": "latest",
		"ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c": "latest",
		"./features/mylocalfeature2": "latest",
		"ghcr.io/devcontainers/features/github-cli": "latest",
		"ghcr.io/devcontainers/features/azure-cli:0": "latest",
		"ghcr.io/codspace/versioning/foo:0.3.1": "latest",
		"ghcr.io/codspace/doesnotexist:0.1.2": "latest",
		"./mylocalfeature": {},
		"terraform": "latest",
		"https://myfeatures.com/features.tgz": "latest"
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-tarball-integrity/.devcontainer-lock.json">
{
  "features": {
    "https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz": {
      "version": "1.0.0",
      "resolved": "https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz",
      "integrity": "sha256:9cf3f2a17c1bb2b599b6027cfa975d2fb28234df88ba33ff5e276fa052aac7a0"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-tarball-integrity/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz": {}
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-command/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/devcontainers/features/git:1.1.5": "latest",
		"ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c": "latest",
		"ghcr.io/devcontainers/features/github-cli:1.0.9": "latest",
		"ghcr.io/devcontainers/features/azure-cli:1.2.1": "latest"
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-command/.gitignore">
.devcontainer-lock.json
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-command/outdated.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/devcontainers/features/azure-cli:1.2.0": {
      "version": "1.2.0",
      "resolved": "ghcr.io/devcontainers/features/azure-cli@sha256:cb2832052c03202e321c84389116a3981b5b24b8c6d0532841c46b03500e1415",
      "integrity": "sha256:cb2832052c03202e321c84389116a3981b5b24b8c6d0532841c46b03500e1415"
    },
    "ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c": {
      "version": "1.0.6",
      "resolved": "ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c",
      "integrity": "sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c"
    },
    "ghcr.io/devcontainers/features/git:1.1.0": {
      "version": "1.1.0",
      "resolved": "ghcr.io/devcontainers/features/git@sha256:bc4b9ae3f843a35edfea7b9295a0e89958d2ddfe8b2bf327ec1a5f7cf3c5a2fa",
      "integrity": "sha256:bc4b9ae3f843a35edfea7b9295a0e89958d2ddfe8b2bf327ec1a5f7cf3c5a2fa"
    },
    "ghcr.io/devcontainers/features/github-cli:1.0.2": {
      "version": "1.0.2",
      "resolved": "ghcr.io/devcontainers/features/github-cli@sha256:0b52d28bcaf2054bf70fd932161f93aae34830031d29747680acdd500e02cc09",
      "integrity": "sha256:0b52d28bcaf2054bf70fd932161f93aae34830031d29747680acdd500e02cc09"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-command/upgraded.devcontainer-lock.json">
{
  "features": {
    "ghcr.io/devcontainers/features/azure-cli:1.2.1": {
      "version": "1.2.1",
      "resolved": "ghcr.io/devcontainers/features/azure-cli@sha256:a00aa292592a8df58a940d6f6dfcf2bfd3efab145f62a17ccb12656528793134",
      "integrity": "sha256:a00aa292592a8df58a940d6f6dfcf2bfd3efab145f62a17ccb12656528793134"
    },
    "ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c": {
      "version": "1.0.6",
      "resolved": "ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c",
      "integrity": "sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c"
    },
    "ghcr.io/devcontainers/features/git:1.1.5": {
      "version": "1.1.5",
      "resolved": "ghcr.io/devcontainers/features/git@sha256:2ab83ca71d55d5c00a1255b07f3a83a53cd2de77ce8b9637abad38095d672a5b",
      "integrity": "sha256:2ab83ca71d55d5c00a1255b07f3a83a53cd2de77ce8b9637abad38095d672a5b"
    },
    "ghcr.io/devcontainers/features/github-cli:1.0.9": {
      "version": "1.0.9",
      "resolved": "ghcr.io/devcontainers/features/github-cli@sha256:9024deeca80347dea7603a3bb5b4951988f0bf5894ba036a6ee3f29c025692c6",
      "integrity": "sha256:9024deeca80347dea7603a3bb5b4951988f0bf5894ba036a6ee3f29c025692c6"
    }
  }
}
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-feature/.gitignore">
.devcontainer-lock.json
.devcontainer.json
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-feature/expected.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base",
	// Comment
	"features": {
		"ghcr.io/codspace/versioning/bar:1.0.0": {},
		// Comment
		"ghcr.io/codspace/versioning/foo:2": { // Comment
			"hello": "world" // Comment
		}
		// Comment
	}
}
</file>

<file path="src/test/container-features/configs/lockfile-upgrade-feature/input.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base",
	// Comment
	"features": {
		"ghcr.io/codspace/versioning/bar:1.0.0": {},
		// Comment
		"ghcr.io/codspace/versioning/foo:1": { // Comment
			"hello": "world" // Comment
		}
		// Comment
	}
}
</file>

<file path="src/test/container-features/configs/registry-compatibility/azure-anonymous/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"devcontainercli.azurecr.io/features/color:1": {
			"favorite": "pink"
		}
	}
}
</file>

<file path="src/test/container-features/configs/registry-compatibility/azure-registry-scoped/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"privatedevcontainercli.azurecr.io/features/rabbit:1": {}
	}
}
</file>

<file path="src/test/container-features/configs/registry-compatibility/github-anonymous/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/devcontainers/feature-starter/color:1": {
			"favorite": "pink"
		}
	}
}
</file>

<file path="src/test/container-features/configs/registry-compatibility/github-private/.devcontainer.json">
{
	"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
	"features": {
		"ghcr.io/devcontainers/private-feature-set-for-tests/color:1": {
			"favorite": "pink"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/a-installs-after-b/src/a/devcontainer-feature.json">
{
    "id": "a",
    "version": "1.0.0",
    "installsAfter": [
        "./b"
    ]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/a-installs-after-b/src/a/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'a'"

touch /usr/local/bin/a

# InstallsAfter Feature B

if [ ! -f /usr/local/bin/b ]; then
	echo "Feature B not available!"
	exit 1
fi
</file>

<file path="src/test/container-features/example-v2-features-sets/a-installs-after-b/src/b/devcontainer-feature.json">
{
    "id": "b",
    "version": "1.0.0"
}
</file>

<file path="src/test/container-features/example-v2-features-sets/a-installs-after-b/src/b/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'b'"

touch /usr/local/bin/b
</file>

<file path="src/test/container-features/example-v2-features-sets/a-installs-after-b/test/a/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

test -f /usr/local/bin/a
</file>

<file path="src/test/container-features/example-v2-features-sets/a-installs-after-b/test/b/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

test -f /usr/local/bin/b
</file>

<file path="src/test/container-features/example-v2-features-sets/autogenerated-set-flags/src/hey/devcontainer-feature.json">
{
    "id": "hey",
    "version": "0.0.16",
    "name": "A hey world feature",
    "options": {
        "greeting": {
            "type": "string",
            "default": "Good day",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/autogenerated-set-flags/src/hey/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
echo "The provided greeting is: $GREETING"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/example-v2-features-sets/autogenerated-set-flags/test/hey/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "runHelloCmd" hello

# Passed in by --remote-user flag, that overrides the base image's user of 'vscode'
# The 'simple' feature set tests the opposite.
check "ensure i am user root"  bash -c "whoami | grep 'root'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/b-installs-after-a/src/a/devcontainer-feature.json">
{
    "id": "a",
    "version": "1.0.0"
}
</file>

<file path="src/test/container-features/example-v2-features-sets/b-installs-after-a/src/a/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'a'"

touch /usr/local/bin/a
</file>

<file path="src/test/container-features/example-v2-features-sets/b-installs-after-a/src/b/devcontainer-feature.json">
{
    "id": "b",
    "version": "1.0.0",
    "installsAfter": [
        "./a"
    ]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/b-installs-after-a/src/b/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'b'"

touch /usr/local/bin/b

# InstallsAfter Feature A
if [ ! -f /usr/local/bin/a ]; then
	echo "Feature A not available!"
	exit 1
fi
</file>

<file path="src/test/container-features/example-v2-features-sets/b-installs-after-a/test/a/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

test -f /usr/local/bin/a
</file>

<file path="src/test/container-features/example-v2-features-sets/b-installs-after-a/test/b/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

test -f /usr/local/bin/b
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/A/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "A",
	"version": "2.0.1",
	"dependsOn": {
		"ghcr.io/codspace/dependson/E": {
			"magicNumber": "50"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/A/install.sh">
#!/bin/sh

NAME="A"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/B/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "B",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependson/C": {
			"magicNumber": "20"
		},
		"ghcr.io/codspace/dependson/D": {
			"magicNumber": "30"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/B/install.sh">
#!/bin/sh

NAME="B"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/C/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "C",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependson/A": {
			"magicNumber": "40"
		},
		"ghcr.io/codspace/dependson/E": {
			"magicNumber": "50"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/C/install.sh">
#!/bin/sh

NAME="C"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/D/devcontainer-feature.json">
{
	"name": "FeatureD",
	"id": "D",
	"version": "2.0.0",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/D/install.sh">
#!/bin/sh

NAME="D"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/E/devcontainer-feature.json">
{
	"name": "FeatureE",
	"id": "E",
	"version": "2.0.0",
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/E/install.sh">
#!/bin/sh

NAME="E"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/F/devcontainer-feature.json">
{
	"name": "FeatureF",
	"id": "F",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependson/G": {
			"magicNumber": "10"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/F/install.sh">
#!/bin/sh

NAME="F"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/G/devcontainer-feature.json">
{
	"name": "FeatureG",
	"id": "G",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependson/H": {
			"magicNumber": "20"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/G/install.sh">
#!/bin/sh

NAME="G"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/H/devcontainer-feature.json">
{
	"name": "FeatureH",
	"id": "H",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependson/F": {
			"magicNumber": "30"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/H/install.sh">
#!/bin/sh

NAME="H"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/I/devcontainer-feature.json">
{
	"name": "FeatureI",
	"id": "I",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependson/E:2.0.0": {
			"magicNumber": "50"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/I/install.sh">
#!/bin/sh

NAME="I"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/J/devcontainer-feature.json">
{
	"name": "FeatureJ",
	"id": "J",
	"version": "2.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependsOn/A:2.0.0": {
			"magicNumber": "60"
		},
		"ghcr.io/codspace/dependsOn/A:2.0.1": {
			"magicNumber": "60"
		},
		"ghcr.io/codspace/dependsOn/C": {
			"magicNumber": "100"
		}
	},
	"options": {
		"magicNumber": {
			"type": "string",
			"default": "0",
			"description": "The magic number"
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn/src/J/install.sh">
#!/bin/sh

NAME="J"

echo "Installing ${NAME}"
MAGIC_NUMBER=${MAGICNUMBER}
echo "The magic number is ${MAGIC_NUMBER}"
touch /usr/local/magic-number-${NAME}-${MAGIC_NUMBER}-$(date +%s).testMarker
echo "Done installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/A/devcontainer-feature.json">
{
	"name": "FeatureA",
	"id": "A",
	"version": "1.0.1",
	"dependsOn": {
		"ghcr.io/codspace/dependsOnAndInstallsAfter/B:latest": {}
	},
	"installsAfter": [
		"ghcr.io/codspace/dependsOnAndInstallsAfter/C"
	]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/A/install.sh">
#!/bin/sh

NAME="A"
echo "Installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/B/devcontainer-feature.json">
{
	"name": "FeatureB",
	"id": "B",
	"version": "1.0.0",
	"dependsOn": {
		"ghcr.io/codspace/dependsOnAndInstallsAfter/C:latest": {},
		"ghcr.io/codspace/dependsOnAndInstallsAfter/D:latest": {}
	},
	"installsAfter": [
		"ghcr.io/codspace/dependsOnAndInstallsAfter/E"
	]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/B/install.sh">
#!/bin/sh

NAME="B"
echo "Installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/C/devcontainer-feature.json">
{
	"name": "FeatureC",
	"id": "C",
	"version": "1.0.0",
	"installsAfter": [
		"ghcr.io/codspace/dependsOnAndInstallsAfter/E"
	]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/C/install.sh">
#!/bin/sh

NAME="C"
echo "Installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/D/devcontainer-feature.json">
{
	"name": "FeatureD",
	"id": "D",
	"version": "1.0.0"
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/D/install.sh">
#!/bin/sh

NAME="D"
echo "Installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/E/devcontainer-feature.json">
{
	"name": "FeatureE",
	"id": "E",
	"version": "1.0.0"
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dependsOn-and-installsAfter/src/E/install.sh">
#!/bin/sh

NAME="E"
echo "Installing ${NAME}"
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/src/smile/devcontainer-feature.json">
{
    "id": "smile",
    "version": "0.0.1",
    "name": "Smile",
    "options": {
        "shouldFrown": {
            "type": "boolean",
            "default": false
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/src/smile/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'smile'"


action=":)"

if "$SHOULDFROWN" = "true"; then
	action=":("
fi

cat > /usr/local/bin/smile \
<< EOF
#!/bin/sh
echo "${action}"
EOF

chmod +x /usr/local/bin/smile
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/test/smile/frowning_with_a_dockerfile/Dockerfile">
FROM mcr.microsoft.com/devcontainers/base:ubuntu
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/test/smile/frowning_with_a_dockerfile.sh">
#!/bin/bash

set -e

./frowning.sh
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/test/smile/frowning.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "is frowning"  smile | grep ":("

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/test/smile/scenarios.json">
{
	"smiling": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"smile": {
				"shouldFrown": false
			}
		}
	},
	"frowning": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"smile": {
				"shouldFrown": true
			}
		}
	},
	"frowning_with_a_dockerfile": {
		"build": {
			"dockerfile": "Dockerfile"
		},
		"features": {
			"smile": {
				"shouldFrown": true
			}
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/test/smile/smiling.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "is smiling"  smile | grep ":)"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/dockerfile-scenario-test/test/smile/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "can run smile command"  smile

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/failing-test/src/hello/devcontainer-feature.json">
{
    "id": "hello",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/failing-test/src/hello/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/example-v2-features-sets/failing-test/test/hello/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "testThatShouldFail" fakeCommand

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/installs-after-advanced/src/zzz/devcontainer-feature.json">
{
    "name": "Zzz",
    "id": "zzz",
    "version": "1.0.0",
    "installsAfter": [
        "ghcr.io/devcontainers/features/node"
    ]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/installs-after-advanced/src/zzz/install.sh">
#!/usr/bin/env bash

set -e

# Check if npm and node are installed.
if ! command -v npm &> /dev/null
then
    echo "npm could not be found! I need npm!"
    exit 1
fi
if ! command -v node &> /dev/null
then
    echo "node could not be found! I need node!"
    exit 1
fi

cat > /usr/local/bin/zzz \
<< EOF
#!/bin/sh
echo "ZzzZzzZzz"
EOF

chmod +x /usr/local/bin/zzz
</file>

<file path="src/test/container-features/example-v2-features-sets/installs-after-advanced/test/zzz/scenarios.json">
{
    "with-node-un-versioned": {
        "image": "debian:latest",
        "features": {
            "ghcr.io/devcontainers/features/node": {},
            "zzz": {}
        }
    },
    "with-node-is-versioned": {
        "image": "debian:latest",
        "features": {
            "ghcr.io/devcontainers/features/node:1": {},
            "zzz": {}
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/installs-after-advanced/test/zzz/with-node-is-versioned.sh">
#!/bin/bash
set -e

# Optional: Import test library bundled with the devcontainer CLI
source dev-container-features-test-lib

# Feature-specific tests
# The 'check' command comes from the dev-container-features-test-lib.
check "node -v" node -v
check "zzz" zzz

# Report result
# If any of the checks above exited with a non-zero exit code, the test will fail.
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/installs-after-advanced/test/zzz/with-node-un-versioned.sh">
#!/bin/bash
set -e

# Optional: Import test library bundled with the devcontainer CLI
source dev-container-features-test-lib

# Feature-specific tests
# The 'check' command comes from the dev-container-features-test-lib.
check "node -v" node -v
check "zzz" zzz

# Report result
# If any of the checks above exited with a non-zero exit code, the test will fail.
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/lifecycle-hooks/src/a/devcontainer-feature.json">
{
    "id": "a",
    "version": "1.0.0",
    "installsAfter": [
        "./b"
    ],
    "onCreateCommand": "touch a.onCreateCommand.testMarker && echo 'A-ON-CREATE-COMMAND'"
}
</file>

<file path="src/test/container-features/example-v2-features-sets/lifecycle-hooks/src/a/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'a'"

touch /usr/local/bin/a

# InstallsAfter Feature B

if [ ! -f /usr/local/bin/b ]; then
	echo "Feature B not available!"
	exit 1
fi
</file>

<file path="src/test/container-features/example-v2-features-sets/lifecycle-hooks/src/b/devcontainer-feature.json">
{
    "id": "b",
    "version": "1.0.0",
    "onCreateCommand": "touch b.onCreateCommand.testMarker && echo 'B-ON-CREATE-COMMAND'"
}
</file>

<file path="src/test/container-features/example-v2-features-sets/lifecycle-hooks/src/b/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'b'"

touch /usr/local/bin/b
</file>

<file path="src/test/container-features/example-v2-features-sets/lifecycle-hooks/test/a/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

test -f /usr/local/bin/a
</file>

<file path="src/test/container-features/example-v2-features-sets/lifecycle-hooks/test/b/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

test -f /usr/local/bin/b
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/src/whoisremoteuser/devcontainer-feature.json">
{
    "id": "whoisremoteuser",
    "version": "0.0.0",
    "name": "Stores and echoes original value of _REMOTE_USER",
    "options": {},
    "installsAfter": [
        "ghcr.io/devcontainers/features/common-utils"
    ]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/src/whoisremoteuser/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'whoisremoteuser'..."

cat > /usr/local/bin/whoisremoteuser \
<< EOF
#!/bin/sh
echo -n "$_REMOTE_USER"
EOF

chmod +x /usr/local/bin/whoisremoteuser
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/test/whoisremoteuser/add_with_common_utils.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

check "ensure i am user codespace"  bash -c "whoami | grep 'codespace'"

check "_REMOTE_USER was equal to codespace" bash -c "whoisremoteuser | grep 'codespace'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/test/whoisremoteuser/from_image_metadata_label_flag_disabled.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

check "ensure i am user root"  bash -c "whoami | grep 'root'"

check "_REMOTE_USER was equal to root" bash -c "whoisremoteuser | grep 'root'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/test/whoisremoteuser/from_image_metadata_label_flag_enabled.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

check "ensure i am user node"  bash -c "whoami | grep 'node'"

check "_REMOTE_USER was equal to node" bash -c "whoisremoteuser | grep 'node'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/test/whoisremoteuser/scenarios.json">
{
	"add_with_common_utils": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"remoteUser": "codespace",
		"features": {
			"ghcr.io/devcontainers/features/common-utils:1": {
				"installZsh": false,
				"installOhMyZsh": false,
				"upgradePackages": false,
				"username": "codespace"
			},
			"whoisremoteuser": {}
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/remote-user/test/whoisremoteuser/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "ensure i am root" bash -c "whoami | grep 'root'"

check "_REMOTE_USER was equal to root" bash -c "whoisremoteuser | grep 'root'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/renaming-feature/src/hello/devcontainer-feature.json">
{
    "id": "hello",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/renaming-feature/src/hello/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/example-v2-features-sets/renaming-feature/src/new-color/devcontainer-feature.json">
{
    "id": "new-color",
    "version": "1.0.1",
    "name": "A feature to remind you of your favorite color",
    "options": {
        "favorite": {
            "type": "string",
            "enum": [
                "red",
                "gold",
                "green"
            ],
            "default": "red",
            "description": "Choose your favorite color."
        }
    },
    "legacyIds": [
        "color",
        "old-color"
    ]
}
</file>

<file path="src/test/container-features/example-v2-features-sets/renaming-feature/src/new-color/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'color'"
echo "The provided favorite color is: ${FAVORITE}"

cat > /usr/local/bin/color \
<< EOF
#!/bin/sh
echo "my favorite color is ${FAVORITE}"
EOF

chmod +x /usr/local/bin/color
</file>

<file path="src/test/container-features/example-v2-features-sets/renaming-feature/src/not-a-feature/not-a-feature.sh">
# Added for testing - should log warning when packaging collection of Features with missing `devcontainer-feature.json` and continue.
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/src/util/devcontainer-feature.json">
{
    "id": "util",
    "version": "1.0.0",
    "name": "A utility",
    "options": {}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/src/util/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'util'"

cat > /usr/local/bin/util \
<< EOF
#!/bin/sh
echo "you did it"
EOF

chmod +x /usr/local/bin/util
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/a_different_script.sh">
#!/bin/sh

echo "I AM A DIFFERENT SCRIPT"
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/a_helper_script_for_scenario.sh">
#!/bin/sh

echo "I AM A HELPER SCRIPT FOR A SCENARIO"
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/random_scenario.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "run a helper script for from random_scenario" ./a_helper_script_for_scenario.sh

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/scenarios.json">
{
	"some_scenario": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"util": {}
		}
	},
	"some_scenario_2": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"util": {}
		}
	},
	"random_scenario": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"util": {}
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/some_scenario_2.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "run a helper script for from some_scenario_2" ./a_helper_script_for_scenario.sh

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/some_scenario.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "run a helper script from some_scenario" ./a_helper_script_for_scenario.sh

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/sharing-test-scripts/test/util/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "run a different script" ./a_different_script.sh

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/src/color/devcontainer-feature.json">
{
    "id": "color",
    // I am a comment inside json
    "version": "1.0.0",
    "name": "A feature to remind you of your favorite color",
    "options": {
        "favorite": {
            "type": "string",
            "enum": [
                "red",
                "gold",
                "green"
            ],
            "default": "red",
            "description": "Choose your favorite color."
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/src/color/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'color'"
echo "The provided favorite color is: ${FAVORITE}"

cat > /usr/local/bin/color \
<< EOF
#!/bin/sh
echo "my favorite color is ${FAVORITE}"
EOF

chmod +x /usr/local/bin/color

cp /usr/local/bin/color /usr/local/bin/color-${FAVORITE}
chmod +x /usr/local/bin/color-${FAVORITE}
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/src/hello/devcontainer-feature.json">
{
    "id": "hello",
    "version": "1.0.0",
    "name": "A hello world feature",
    "options": {
        "greeting": {
            "type": "string",
            "proposals": [
                "hey",
                "hello",
                "hi",
                "howdy"
            ],
            "default": "hey",
            "description": "Select a pre-made greeting, or enter your own"
        }
    }
}
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/src/hello/install.sh">
#!/bin/sh
set -e

echo "Activating feature 'localFeatureA'"

GREETING=${GREETING:-undefined}
PUNCTUATION=${PUNCTUATION:-?????}
echo "The provided greeting is: $GREETING"
echo "The provided punctuation is: $PUNCTUATION"

cat > /usr/local/bin/hello \
<< EOF
#!/bin/sh
RED='\033[0;91m'
NC='\033[0m' # No Color
echo "\${RED}${GREETING}, \$(whoami)${PUNCTUATION}\${NC}"
EOF

chmod +x /usr/local/bin/hello
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/src/not-a-feature/not-a-feature.sh">
# Added for testing - should log warning when packaging collection of Features with missing `devcontainer-feature.json` and continue.
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/_global/custom_options.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "correct color" color | grep "Magenta"
check "correct greeting" hello | grep "Ciao"

check "ensure i am user vscode"  bash -c "whoami | grep 'vscode'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/_global/scenarios.json">
{
	"custom_options": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features" : {
			"hello": {
				"greeting": "Ciao"
			},
			"color": {
				"favorite": "Magenta"
			}
		}
	},
	"with_external_feature": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"hello": {
				"greeting": "How ya doing"
			},
			"ghcr.io/devcontainers/feature-starter/color:1": {
				"favorite": "Silver"
			}
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/_global/with_external_feature.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "correct color" color | grep "Silver"
check "correct greeting" hello | grep "How ya doing"

check "ensure i am user vscode"  bash -c "whoami | grep 'vscode'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/color/duplicate.sh">
#!/bin/bash

set -e

env

# Optional: Import test library
source dev-container-features-test-lib

# The values of the randomized options will be set as environment variables.
if [ -z "${FAVORITE}" ]; then
	echo "Favorite color from randomized Feature not set!"
	exit 1
fi

# The values of the default options will be set as environment variables.
if [ -z "${FAVORITE__DEFAULT}" ]; then
	echo "Favorite color from default Feature not set!"
	exit 1
fi

# Definition specific tests
check "runColorCmd" color

# Definition test specific to what option was set.
check "Feature with randomized options installed correctly" color-"${FAVORITE}"

# Definition test specific to what option was set.
check "Feature with default options installed correctly" color-"${FAVORITE__DEFAULT}"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/color/scenarios.json">
{
	"specific_color_scenario": {
		"image": "mcr.microsoft.com/devcontainers/base:ubuntu",
		"features": {
			"color": {
				"favorite": "green"
			}
		}
	}
}
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/color/specific_color_scenario.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "correct color" color | grep "green"

check "ensure i am user vscode"  bash -c "whoami | grep 'vscode'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/color/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "runColorCmd" color

check "ensure i am user vscode"  bash -c "whoami | grep 'vscode'"

# Report result
reportResults
</file>

<file path="src/test/container-features/example-v2-features-sets/simple/test/hello/test.sh">
#!/bin/bash

set -e

# Optional: Import test library
source dev-container-features-test-lib

# Definition specific tests
check "runHelloCmd" hello

check "ensure i am user vscode"  bash -c "whoami | grep 'vscode'"

# Report result
reportResults
</file>

<file path="src/test/container-features/containerFeaturesOCI.test.ts">
import { assert } from 'chai';
import { getRef, getManifest, getBlob, getCollectionRef } from '../../spec-configuration/containerCollectionsOCI';
import { createPlainLog, LogLevel, makeLog } from '../../spec-utils/log';

export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));

describe('getCollectionRef()', async function () {
    this.timeout('240s');

    it('valid getCollectionRef()', async () => {
        const collectionRef = getCollectionRef(output, 'ghcr.io', 'devcontainers/templates');
        if (!collectionRef) {
            assert.fail('collectionRef should not be undefined');
        }
        assert.ok(collectionRef);
        assert.equal(collectionRef.registry, 'ghcr.io');
        assert.equal(collectionRef.path, 'devcontainers/templates');
        assert.equal(collectionRef.resource, 'ghcr.io/devcontainers/templates');
        assert.equal(collectionRef.version, 'latest');
        assert.equal(collectionRef.tag, collectionRef.version);
    });

    it('valid getCollectionRef() that was originally uppercase', async () => {
        const collectionRef = getCollectionRef(output, 'GHCR.IO', 'DEVCONTAINERS/TEMPLATES');
        if (!collectionRef) {
            assert.fail('collectionRef should not be undefined');
        }
        assert.ok(collectionRef);
        assert.equal(collectionRef.registry, 'ghcr.io');
        assert.equal(collectionRef.path, 'devcontainers/templates');
        assert.equal(collectionRef.resource, 'ghcr.io/devcontainers/templates');
        assert.equal(collectionRef.version, 'latest');
        assert.equal(collectionRef.tag, collectionRef.version);
    });

    it('valid getCollectionRef() with port in registry', async () => {
        const collectionRef = getCollectionRef(output, 'ghcr.io:8001', 'devcontainers/templates');
        if (!collectionRef) {
            assert.fail('collectionRef should not be undefined');
        }
        assert.ok(collectionRef);
        assert.equal(collectionRef.registry, 'ghcr.io:8001');
        assert.equal(collectionRef.path, 'devcontainers/templates');
        assert.equal(collectionRef.resource, 'ghcr.io:8001/devcontainers/templates');
        assert.equal(collectionRef.version, 'latest');
        assert.equal(collectionRef.tag, collectionRef.version);
    });

    it('invalid getCollectionRef() with an invalid character in path', async () => {
        const collectionRef = getCollectionRef(output, 'ghcr.io', 'devcont%ainers/templates');
        assert.isUndefined(collectionRef);
    });

    it('invalid getCollectionRef() with too many slashes in path', async () => {
        const collectionRef = getCollectionRef(output, 'ghcr.io', 'devcontainers//templates');
        assert.isUndefined(collectionRef);
    });

});

describe('getRef()', async function () {
    this.timeout('120s');

    it('valid getRef() with a tag', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers/templates/docker-from-docker:latest');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'ghcr.io');
        assert.equal(feat.resource, 'ghcr.io/devcontainers/templates/docker-from-docker');
        assert.equal(feat.tag, 'latest');
        assert.equal(feat.tag, feat.version);
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
    });

    it('valid getRef() with a digest', async () => {
        const feat = getRef(output, 'ghcr.io/my-org/my-features/my-feat@sha256:1234567890123456789012345678901234567890123456789012345678901234');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'my-feat');
        assert.equal(feat.namespace, 'my-org/my-features');
        assert.equal(feat.owner, 'my-org');
        assert.equal(feat.registry, 'ghcr.io');
        assert.equal(feat.resource, 'ghcr.io/my-org/my-features/my-feat');
        assert.equal(feat.path, 'my-org/my-features/my-feat');
        assert.isUndefined(feat.tag);
        assert.equal(feat.digest, 'sha256:1234567890123456789012345678901234567890123456789012345678901234');
        assert.equal(feat.digest, feat.version);
    });

    it('valid getRef() without a version tag', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers/templates/docker-from-docker');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'ghcr.io');
        assert.equal(feat.resource, 'ghcr.io/devcontainers/templates/docker-from-docker');
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
        assert.equal(feat.tag, 'latest'); // Defaults to 'latest' if not version supplied.
        assert.isUndefined(feat.digest);
        assert.equal(feat.tag, feat.version);
    });

    it('valid getRef() automatically downcases', async () => {
        const feat = getRef(output, 'ghcr.io/DeVContainERS/templates/Docker-FROM-Docker');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'ghcr.io');
        assert.equal(feat.resource, 'ghcr.io/devcontainers/templates/docker-from-docker');
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
        assert.equal(feat.tag, 'latest'); // Defaults to 'latest' if not version supplied.
        assert.isUndefined(feat.digest);
        assert.equal(feat.tag, feat.version);
    });

    it('valid getRef() with a registry that contains a port and a version tag.', async () => {
        const feat = getRef(output, 'docker.io:8001/devcontainers/templates/docker-from-docker:1.3.4');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'docker.io:8001');
        assert.equal(feat.resource, 'docker.io:8001/devcontainers/templates/docker-from-docker');
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
        assert.equal(feat.tag, '1.3.4');
        assert.isUndefined(feat.digest);
        assert.equal(feat.tag, feat.version);
    });

    it('valid getRef() with a registry that contains a port and latest tag.', async () => {
        const feat = getRef(output, 'docker.io:8001/devcontainers/templates/docker-from-docker:latest');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'docker.io:8001');
        assert.equal(feat.resource, 'docker.io:8001/devcontainers/templates/docker-from-docker');
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
        assert.equal(feat.tag, 'latest');
        assert.isUndefined(feat.digest);
        assert.equal(feat.tag, feat.version);
    });

    it('valid getRef() with a registry that contains a port and no tag.', async () => {
        const feat = getRef(output, 'docker.io:8001/devcontainers/templates/docker-from-docker');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'docker.io:8001');
        assert.equal(feat.resource, 'docker.io:8001/devcontainers/templates/docker-from-docker');
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
        assert.equal(feat.tag, 'latest'); // Assumes latest since there is no tag
        assert.isUndefined(feat.digest);
        assert.equal(feat.tag, feat.version);
    });

    it('valid getRef() with a registry that contains a port and a digest.', async () => {
        const feat = getRef(output, 'docker.io:8001/devcontainers/templates/docker-from-docker@sha256:4ef08c9c3b708f3c2faecc5a898b39736423dd639f09f2a9f8bf9b0b9252ef0a');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'docker-from-docker');
        assert.equal(feat.namespace, 'devcontainers/templates');
        assert.equal(feat.owner, 'devcontainers');
        assert.equal(feat.registry, 'docker.io:8001');
        assert.equal(feat.resource, 'docker.io:8001/devcontainers/templates/docker-from-docker');
        assert.equal(feat.path, 'devcontainers/templates/docker-from-docker');
        assert.equal(feat.digest, 'sha256:4ef08c9c3b708f3c2faecc5a898b39736423dd639f09f2a9f8bf9b0b9252ef0a');
        assert.isUndefined(feat.tag);
        assert.equal(feat.digest, feat.version);
    });

    it('valid getRef() really short path and no version', async () => {
        const feat = getRef(output, 'docker.io:8001/a/b/c');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        assert.ok(feat);
        assert.equal(feat.id, 'c');
        assert.equal(feat.namespace, 'a/b');
        assert.equal(feat.owner, 'a');
        assert.equal(feat.registry, 'docker.io:8001');
        assert.equal(feat.resource, 'docker.io:8001/a/b/c');
        assert.equal(feat.path, 'a/b/c');
        assert.equal(feat.tag, 'latest'); // Defaults to 'latest' if not version supplied. 
        assert.equal(feat.tag, feat.version);
    });

    it('invalid getRef() with duplicate version tags', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers/templates/docker-from-docker:latest:latest');
        assert.isUndefined(feat);
    });

    it('invalid getRef() with invalid character in namespace', async () => {
        const feat = getRef(output, 'ghcr.io/devco%ntainers/templates/docker-from-docker:latest');
        assert.isUndefined(feat);
    });

    it('invalid getRef() with invalid character in feature name', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers/templates/docker-from@docker:latest');
        assert.isUndefined(feat);
    });

    it('invalid getRef() with missing path with version tag', async () => {
        const feat = getRef(output, 'ghcr.io/:latest');
        assert.isUndefined(feat);
    });

    it('invalid getRef() with missing path without version tag', async () => {
        const feat = getRef(output, 'ghcr.io');
        assert.isUndefined(feat);
    });

    it('invalid getRef() multiple slashes in sequence', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers//templates/docker-from-docker:latest');
        assert.isUndefined(feat);
    });

    it('invalid getRef() with unsupported digest hashing algorithm', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers//templates/docker-from-docker@sha100:1234567890123456789012345678901234567890123456789012345678901234');
        assert.isUndefined(feat);
    });

    it('invalid getRef() with mis-shaped digest', async () => {
        const feat = getRef(output, 'ghcr.io/devcontainers//templates/docker-from-docker@1234567890123456789012345678901234567890123456789012345678901234');
        assert.isUndefined(feat);
    });

});

describe('Test OCI Pull', async function () {
    this.timeout('10s');

    it('Parse OCI identifier', async function () {
        const feat = getRef(output, 'ghcr.io/codspace/features/ruby:1');
        if (!feat) {
            assert.fail('featureRef should not be undefined');
        }
        output.write(`feat: ${JSON.stringify(feat)}`);

        assert.equal(feat.id, 'ruby');
        assert.equal(feat.namespace, 'codspace/features');
        assert.equal(feat.owner, 'codspace');
        assert.equal(feat.registry, 'ghcr.io');
        assert.equal(feat.resource, 'ghcr.io/codspace/features/ruby');
        assert.equal(feat.tag, '1');
        assert.equal(feat.path, 'codspace/features/ruby');
    });

    it('Get a manifest by tag', async () => {
        const featureRef = getRef(output, 'ghcr.io/codspace/features/ruby:1.0.13');
        if (!featureRef) {
            assert.fail('featureRef should not be undefined');
        }
        const manifest = await getManifest({ output, env: process.env }, 'https://ghcr.io/v2/codspace/features/ruby/manifests/1.0.13', featureRef);
        assert.isNotNull(manifest);
        assert.exists(manifest);

        if (!manifest) {
            return;
        }

        output.write(`mediaType: ${manifest.manifestObj.mediaType}`);
        manifest.manifestObj.layers.forEach(layer => {
            output.write(`Layer mediaType: ${layer.mediaType}`);
            output.write(`Layer digest: ${layer.digest}`);
            output.write(`Layer size: ${layer.size}`);

            output.write(`Layer imageTitle: ${layer.annotations['org.opencontainers.image.title']}`);
        });

        assert.equal(manifest.manifestObj.layers[0].digest, 'sha256:8f59630bd1ba6d9e78b485233a0280530b3d0a44338f472206090412ffbd3efb');
        assert.equal(manifest.canonicalId, 'ghcr.io/codspace/features/ruby@sha256:4757b07cbfbfc09015d8a5b7fb1c44e83d85de4fae13e9f311f7b9ae9ae0c25c');
    });

    it('Download a feature', async () => {
        const featureRef = getRef(output, 'ghcr.io/codspace/features/ruby:1.0.13');
        if (!featureRef) {
            assert.fail('featureRef should not be undefined');
        }
        const blobResult = await getBlob({ output, env: process.env }, 'https://ghcr.io/v2/codspace/features/ruby/blobs/sha256:8f59630bd1ba6d9e78b485233a0280530b3d0a44338f472206090412ffbd3efb', '/tmp', '/tmp/featureTest', featureRef, 'sha256:8f59630bd1ba6d9e78b485233a0280530b3d0a44338f472206090412ffbd3efb');
        assert.isDefined(blobResult);
        assert.isArray(blobResult?.files);
    });
});
</file>

<file path="src/test/container-features/containerFeaturesOCIPush.test.ts">
import { assert } from 'chai';
import { DEVCONTAINER_TAR_LAYER_MEDIATYPE, getRef } from '../../spec-configuration/containerCollectionsOCI';
import { fetchOCIFeatureManifestIfExistsFromUserIdentifier } from '../../spec-configuration/containerFeaturesOCI';
import { calculateDataLayer, checkIfBlobExists, calculateManifestAndContentDigest } from '../../spec-configuration/containerCollectionsOCIPush';
import { createPlainLog, LogLevel, makeLog } from '../../spec-utils/log';
import { ExecResult, shellExec } from '../testUtils';
import * as path from 'path';
import * as fs from 'fs';
import { readLocalFile, writeLocalFile } from '../../spec-utils/pfs';
import { Feature } from '../../spec-configuration/containerFeaturesConfiguration';

const pkg = require('../../../package.json');

export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));
const testAssetsDir = `${__dirname}/assets`;

interface PublishResult {
	publishedTags: string[];
	digest: string;
	version: string;
	publishedLegacyIds?: string[];
}

describe('Test OCI Push against reference registry', async function () {
	this.timeout('240s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp', Date.now().toString()));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install CLI and Start reference implementation registry', async () => {
		// Clean up any potential previous runs
		await shellExec(`docker rm registry -f`, {}, false, true);

		// Install CLI
		await shellExec(`rm -rf ${tmp}`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);

		// Copy contents of simple example to tmp
		// Do this so we can make changes to the files on disk to simulate editing/updating Features.
		await shellExec(`cp -r ${__dirname}/example-v2-features-sets/simple ${tmp}/simple-feature-set`);

		// Write htpasswd file to simulate basic auth.
		// Generated from 'htpasswd -cB -b auth.htpasswd myuser mypass'
		writeLocalFile(path.join(tmp, 'auth.htpasswd'), 'myuser:$2y$05$xmGlPoyYqECe3AY8GhO2ve1XvpxbSqe3yvPT2agOClbIeDIRAVPLC');

		const resolvedTmpPath = path.resolve(tmp);
		const startRegistryCmd = `docker run -d -p 5000:5000 \
-v ${resolvedTmpPath}/auth.htpasswd:/etc/docker/registry/auth.htpasswd \
-e REGISTRY_AUTH="{htpasswd: {realm: localhost, path: /etc/docker/registry/auth.htpasswd}}" \
--name registry \
registry`;

		await shellExec(startRegistryCmd, { cwd: tmp });

		// Wait for registry to start
		await shellExec(`docker exec registry sh -c "while ! nc -z localhost 5000; do sleep 3; done"`, { cwd: tmp });
		// Login with basic auth creds
		await shellExec('docker login -u myuser -p mypass localhost:5000');
	});

	it('Publish Features to registry', async () => {
		const collectionFolder = `${tmp}/simple-feature-set`;
		let success = false;

		let publishResult: ExecResult | undefined = undefined;
		let infoTagsResult: ExecResult | undefined = undefined;
		let infoManifestResult: ExecResult | undefined = undefined;
		let secondPublishResult: ExecResult | undefined = undefined;

		try {
			publishResult = await shellExec(`${cli} features publish --log-level trace -r localhost:5000 -n octocat/features ${collectionFolder}/src`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features publish sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(publishResult);


		{
			const result: { [featureId: string]: PublishResult } = JSON.parse(publishResult.stdout);
			assert.equal(Object.keys(result).length, 2);

			const color = result['color'];
			assert.isDefined(color);
			assert.isDefined(color.digest);
			assert.deepEqual(color.publishedTags, [
				'1',
				'1.0',
				'1.0.0',
				'latest',
			]);
			assert.strictEqual(color.version, '1.0.0');
			assert.isUndefined(color.publishedLegacyIds);

			const hello = result['hello'];
			assert.isDefined(hello);
			assert.isDefined(hello.digest);
			assert.deepEqual(hello.publishedTags, [
				'1',
				'1.0',
				'1.0.0',
				'latest',
			]);
			assert.strictEqual(hello.version, '1.0.0');
			assert.isUndefined(hello.publishedLegacyIds);
		}

		// --- See that the Features can be queried from the Dev Container CLI.

		success = false; // Reset success flag.
		try {
			infoTagsResult = await shellExec(`${cli} features info tags localhost:5000/octocat/features/hello --output-format json --log-level trace`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features info tags sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(infoTagsResult);
		const tags = JSON.parse(infoTagsResult.stdout);
		const publishedTags: string[] = tags['publishedTags'];
		assert.equal(publishedTags.length, 4);

		success = false; // Reset success flag.
		try {
			infoManifestResult = await shellExec(`${cli} features info manifest localhost:5000/octocat/features/hello --log-level trace`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features info tags sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(infoManifestResult);
		const manifest = infoManifestResult.stdout;
		const regex = /application\/vnd\.devcontainers\.layer\.v1\+tar/;
		assert.match(manifest, regex);

		success = false; // Reset success flag.

		// -- Increment the version of a single Feature and run publish again

		const featureMetadataFilePath = `${collectionFolder}/src/hello/devcontainer-feature.json`;
		const featureMetadata: Feature = JSON.parse((await readLocalFile(featureMetadataFilePath)).toString());
		featureMetadata.version = '1.0.1';
		await writeLocalFile(featureMetadataFilePath, JSON.stringify(featureMetadata, null, 2));

		try {
			secondPublishResult = await shellExec(`${cli} features publish --log-level trace -r localhost:5000 -n octocat/features ${collectionFolder}/src`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features publish sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(secondPublishResult);

		{

			const result: { [featureId: string]: PublishResult } = JSON.parse(secondPublishResult.stdout);
			assert.equal(Object.keys(result).length, 2);

			// -- Color was not changed, so it should not have been published again.
			const color = result['color'];
			assert.isDefined(color);
			assert.isObject(color);
			// Check that the color object has no properties
			assert.isUndefined(color.digest);
			assert.isUndefined(color.publishedTags);
			assert.isUndefined(color.version);

			// -- The breakfix version of hello was updated, so major and minor should be published again, too.
			const hello = result['hello'];
			assert.isDefined(hello);
			assert.isDefined(hello.digest);
			assert.isArray(hello.publishedTags);
			assert.deepEqual(hello.publishedTags, [
				'1',
				'1.0',
				'1.0.1',
				'latest',
			]);
			assert.strictEqual(hello.version, '1.0.1');
		}
	});

	it('Publish Features to registry with legacyIds', async () => {
		const collectionFolder = `${__dirname}/example-v2-features-sets/renaming-feature`;
		let success = false;

		let publishResult: ExecResult | undefined = undefined;
		let infoTagsResult: ExecResult | undefined = undefined;
		let infoManifestResult: ExecResult | undefined = undefined;
		let infoLegacyManifestResult: ExecResult | undefined = undefined;
		let infoLegacyManifest2Result: ExecResult | undefined = undefined;


		try {
			publishResult = await shellExec(`${cli} features publish --log-level trace -r localhost:5000 -n octocat/features2 ${collectionFolder}/src`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features publish sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(publishResult);

		{
			const result: { [featureId: string]: PublishResult } = JSON.parse(publishResult.stdout);
			assert.equal(Object.keys(result).length, 2);

			const newColor = result['new-color'];
			assert.isDefined(newColor);
			assert.isDefined(newColor.digest);
			assert.deepEqual(newColor.publishedTags, [
				'1',
				'1.0',
				'1.0.1',
				'latest',
			]);
			assert.strictEqual(newColor.version, '1.0.1');
			assert.deepEqual(newColor.publishedLegacyIds, [
				'color',
				'old-color'
			]);

			const hello = result['hello'];
			assert.isDefined(hello);
			assert.isDefined(hello.digest);
			assert.deepEqual(hello.publishedTags, [
				'1',
				'1.0',
				'1.0.0',
				'latest',
			]);
			assert.strictEqual(hello.version, '1.0.0');
			assert.isUndefined(hello.publishedLegacyIds);
		}

		// --- See that the manifest of legacyIds and ID are equal
		success = false; // Reset success flag.
		try {
			infoManifestResult = await shellExec(`${cli} features info manifest localhost:5000/octocat/features2/new-color --log-level trace --output-format json`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features info tags sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(infoManifestResult);
		const manifest = JSON.parse(infoManifestResult.stdout).manifest;

		success = false; // Reset success flag.
		try {
			infoLegacyManifestResult = await shellExec(`${cli} features info manifest localhost:5000/octocat/features2/color --log-level trace --output-format json`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features info tags sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(infoManifestResult);
		const legacyManifest = JSON.parse(infoLegacyManifestResult.stdout).manifest;
		assert.deepEqual(JSON.stringify(manifest), JSON.stringify(legacyManifest));

		success = false; // Reset success flag.
		try {
			infoLegacyManifest2Result = await shellExec(`${cli} features info manifest localhost:5000/octocat/features2/old-color --log-level trace --output-format json`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features info tags sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(infoManifestResult);
		const legacyManifest2 = JSON.parse(infoLegacyManifest2Result.stdout).manifest;
		assert.deepEqual(JSON.stringify(manifest), JSON.stringify(legacyManifest2));

		// --- Simple Feature
		success = false; // Reset success flag.
		try {
			infoTagsResult = await shellExec(`${cli} features info tags localhost:5000/octocat/features2/hello --output-format json --log-level trace`, { env: { ...process.env, 'DEVCONTAINERS_OCI_AUTH': 'localhost:5000|myuser|mypass' } });
			success = true;

		} catch (error) {
			assert.fail('features info tags sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(infoTagsResult);
		const tags = JSON.parse(infoTagsResult.stdout);
		const publishedTags: string[] = tags['publishedTags'];
		assert.equal(publishedTags.length, 4);
	});
});

//  NOTE: 
//  Test depends on https://github.com/orgs/codspace/packages/container/non-empty-config-layer%2Fcolor/225254837?tag=1.0.0
describe('Test OCI Push Helper Functions', function () {
	this.timeout('10s');
	it('Generates the correct tgz manifest layer', async () => {

		const dataBytes = fs.readFileSync(`${testAssetsDir}/devcontainer-feature-color.tgz`);

		const featureRef = getRef(output, 'ghcr.io/codspace/non-empty-config-layer/color');
		if (!featureRef) {
			assert.fail();
		}

		// Calculate the tgz layer and digest
		const res = await calculateDataLayer(output, dataBytes, 'devcontainer-feature-color.tgz', DEVCONTAINER_TAR_LAYER_MEDIATYPE);
		const expected = {
			digest: 'sha256:0bb92d2da46d760c599d0a41ed88d52521209408b529761417090b62ee16dfd1',
			mediaType: 'application/vnd.devcontainers.layer.v1+tar',
			size: 3584,
			annotations: {
				'org.opencontainers.image.title': 'devcontainer-feature-color.tgz'
			}
		};

		if (!res) {
			assert.fail();
		}
		assert.deepEqual(res, expected);

		// Generate entire manifest to be able to calculate content digest
		const annotations = {
			'dev.containers.metadata': '{\"id\":\"color\",\"version\":\"1.0.0\",\"name\":\"A feature to remind you of your favorite color\",\"options\":{\"favorite\":{\"type\":\"string\",\"enum\":[\"red\",\"gold\",\"green\"],\"default\":\"red\",\"description\":\"Choose your favorite color.\"}}}',
			'com.github.package.type': 'devcontainer_feature'
		};
		const manifestContainer = await calculateManifestAndContentDigest(output, featureRef, res, annotations);
		if (!manifestContainer) {
			assert.fail();
		}
		const { contentDigest, manifestBuffer } = manifestContainer;

		// 'Expected' is taken from intermediate value in oras reference implementation, before hash calculation
		assert.strictEqual('{"schemaVersion":2,"mediaType":"application/vnd.oci.image.manifest.v1+json","config":{"mediaType":"application/vnd.devcontainers","digest":"sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","size":2},"layers":[{"mediaType":"application/vnd.devcontainers.layer.v1+tar","digest":"sha256:0bb92d2da46d760c599d0a41ed88d52521209408b529761417090b62ee16dfd1","size":3584,"annotations":{"org.opencontainers.image.title":"devcontainer-feature-color.tgz"}}],"annotations":{"dev.containers.metadata":"{\\"id\\":\\"color\\",\\"version\\":\\"1.0.0\\",\\"name\\":\\"A feature to remind you of your favorite color\\",\\"options\\":{\\"favorite\\":{\\"type\\":\\"string\\",\\"enum\\":[\\"red\\",\\"gold\\",\\"green\\"],\\"default\\":\\"red\\",\\"description\\":\\"Choose your favorite color.\\"}}}","com.github.package.type":"devcontainer_feature"}}', manifestBuffer.toString());

		// This is the canonical digest of the manifest
		assert.strictEqual('sha256:dd328c25cc7382aaf4e9ee10104425d9a2561b47fe238407f6c0f77b3f8409fc', contentDigest);
	});

	it('Can fetch an artifact from a digest reference', async () => {
		const manifest = await fetchOCIFeatureManifestIfExistsFromUserIdentifier({ output, env: process.env }, 'ghcr.io/codspace/non-empty-config-layer/color', 'sha256:dd328c25cc7382aaf4e9ee10104425d9a2561b47fe238407f6c0f77b3f8409fc');
		assert.strictEqual(manifest?.manifestObj.layers[0].annotations['org.opencontainers.image.title'], 'devcontainer-feature-color.tgz');
	});

	it('Can check whether a blob exists', async () => {
		const ociFeatureRef = getRef(output, 'ghcr.io/codspace/non-empty-config-layer/color:1.0.0');
		if (!ociFeatureRef) {
			assert.fail('getRef() for the Feature should not be undefined');
		}


		const tarLayerBlobExists = await checkIfBlobExists({ output, env: process.env }, ociFeatureRef, 'sha256:0bb92d2da46d760c599d0a41ed88d52521209408b529761417090b62ee16dfd1');
		assert.isTrue(tarLayerBlobExists);

		const configLayerBlobExists = await checkIfBlobExists({ output, env: process.env }, ociFeatureRef, 'sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a');
		assert.isTrue(configLayerBlobExists);

		const randomStringDoesNotExist = await checkIfBlobExists({ output, env: process.env }, ociFeatureRef, 'sha256:41af286dc0b172ed2f1ca934fd2278de4a1192302ffa07087cea2682e7d372e3');
		assert.isFalse(randomStringDoesNotExist);
	});
});
</file>

<file path="src/test/container-features/containerFeaturesOrder.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import { OCISourceInformation, processFeatureIdentifier, userFeaturesToArray } from '../../spec-configuration/containerFeaturesConfiguration';
import { computeDependsOnInstallationOrder } from '../../spec-configuration/containerFeaturesOrder';
import { DevContainerConfig, DevContainerFeature } from '../../spec-configuration/configuration';
import { CommonParams } from '../../spec-configuration/containerCollectionsOCI';
import { LogLevel, createPlainLog, makeLog } from '../../spec-utils/log';
import { isLocalFile, readLocalFile } from '../../spec-utils/pfs';

// const pkg = require('../../../package.json');
export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Info));

async function setupInstallOrderTest(testWorkspaceFolder: string) {
    const params: CommonParams = {
        env: process.env,
        output,
        cachedAuthHeader: {}
    };

    const configPath = `${testWorkspaceFolder}/.devcontainer/devcontainer.json`;
    if (!(await isLocalFile(configPath))) {
        assert.fail(`Test: Config is not at the expected location: ${configPath}`);
    }

    const buffer = await readLocalFile(configPath);
    const config = JSON.parse(buffer.toString()) as DevContainerConfig;
    const userFeatures = userFeaturesToArray(config);

    if (!userFeatures) {
        assert.fail(`Test: Could not extract userFeatures from config: ${configPath}`);
    }

    const processFeature = async (_userFeature: DevContainerFeature) => {
        return await processFeatureIdentifier(params, configPath, testWorkspaceFolder, _userFeature);
    };

    return {
        params,
        userFeatures,
        config,
        processFeature
    };
}

describe('Feature Dependencies', function () {
    this.timeout('10s');
    const baseTestConfigPath = `${__dirname}/configs/feature-dependencies`;

    describe('installsAfter', function () {

        // 'local Features', Features that are checked into the repo alongside the devcontainer.json
        it('valid installsAfter with file-path Features', async function () {
            const testFolder = `${baseTestConfigPath}/installsAfter/local-simple`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 2);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './c',
                        options: { magicNumber: '321' }
                    },
                    {
                        userFeatureId: './a',
                        options: {}
                    }
                ]);
        });

        it('invalid circular dependency', async function () {
            const testFolder = `${baseTestConfigPath}/installsAfter/invalid-circular`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            assert.ok(!installOrderNodes);
        });

    });

    describe('dependsOn', function () {

        // 'local Features', Features that are checked into the repo alongside the devcontainer.json
        it('valid dependsOn with file-path Features', async function () {
            const testFolder = `${baseTestConfigPath}/dependsOn/local-simple`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 2);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './b',
                        options: { magicNumber: '50' }
                    },
                    {
                        userFeatureId: './a',
                        options: {}
                    }
                ]);
        });

        it('valid dependsOn with round sorting based on options', async function () {
            const testFolder = `${baseTestConfigPath}/dependsOn/local-with-options`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 9);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './b',
                        options: {}
                    },
                    {
                        userFeatureId: './b',
                        options: {
                            optA: 'a',
                            optB: 'a'
                        }
                    },
                    {
                        userFeatureId: './b',
                        options: {
                            optA: 'a',
                            optB: 'b'
                        }
                    },
                    {
                        userFeatureId: './b',
                        options: {
                            optA: 'b',
                            optB: 'a'
                        }
                    },
                    {
                        userFeatureId: './b',
                        options: {
                            optA: 'b',
                            optB: 'b'
                        }
                    },
                    {
                        userFeatureId: './d',
                        options: {}
                    },
                    {
                        userFeatureId: './e',
                        options: {}
                    },
                    {
                        userFeatureId: './c',
                        options: {}
                    },
                    {
                        userFeatureId: './a',
                        options: {
                            optA: 'a',
                            optB: 'b'
                        }
                    }
                ]);
        });

        it('valid dependsOn with published oci Features', async function () {
            const testFolder = `${baseTestConfigPath}/dependsOn/oci-ab`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'oci'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'oci'));

            const actual = installOrderNodes.map(fs => {
                const srcInfo = fs.sourceInformation as OCISourceInformation;
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value,
                    canonicalId: `${srcInfo.featureRef.resource}@${srcInfo.manifestDigest}`
                };
            });

            assert.deepStrictEqual(actual.length, 6);

            // Despite having different options, these two Features should have the same canconical ID (same exact contents, just run with a different set of options)
            const firstA = actual[2];
            const secondA = actual[3];
            assert.strictEqual(firstA.canonicalId, secondA.canonicalId);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/D',
                        options: { magicNumber: '30' },
                        canonicalId: 'ghcr.io/codspace/dependson/d@sha256:3795caa1e32ba6b30a08260039804eed6f3cf40811f0c65c118437743fa15ce8',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/E',
                        options: { magicNumber: '50' },
                        canonicalId: 'ghcr.io/codspace/dependson/e@sha256:9f36f159c70f8bebff57f341904b030733adb17ef12a5d58d4b3d89b2a6c7d5a',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/a',
                        options: { magicNumber: '10' },
                        canonicalId: 'ghcr.io/codspace/dependson/a@sha256:932027ef71da186210e6ceb3294c3459caaf6b548d2b547d5d26be3fc4b2264a',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/A',
                        options: { magicNumber: '40' },
                        canonicalId: 'ghcr.io/codspace/dependson/a@sha256:932027ef71da186210e6ceb3294c3459caaf6b548d2b547d5d26be3fc4b2264a',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/C',
                        options: { magicNumber: '20' },
                        canonicalId: 'ghcr.io/codspace/dependson/c@sha256:db651708398b6d7af48f184c358728eaaf959606637133413cb4107b8454a868',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/b',
                        options: { magicNumber: '400' },
                        canonicalId: 'ghcr.io/codspace/dependson/b@sha256:e7e6b52884ae7f349baf207ac59f78857ab64529c890b646bb0282f962bb2941',
                    }
                ]);
        });

        it('valid dependsOn with published tgz and oci Features', async function () {
            const testFolder = `${baseTestConfigPath}/dependsOn/tgz-ab`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'oci' or 'direct-tarball'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'oci' || fs.sourceInformation.type === 'direct-tarball'));

            const actual = installOrderNodes.map(fs => {
                const srcInfo = fs.sourceInformation;
                switch (srcInfo.type) {
                    case 'oci':
                        return {
                            userFeatureId: fs.sourceInformation.userFeatureId,
                            options: fs.features[0].value,
                            canonicalId: `${srcInfo.featureRef.resource}@${srcInfo.manifestDigest}`
                        };
                    case 'direct-tarball':
                        return {
                            tarballUri: srcInfo.tarballUri,
                            options: fs.features[0].value,
                        };
                    default:
                        assert.fail();
                }
            });

            assert.deepStrictEqual(actual.length, 6);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/D',
                        options: { magicNumber: '30' },
                        canonicalId: 'ghcr.io/codspace/dependson/d@sha256:3795caa1e32ba6b30a08260039804eed6f3cf40811f0c65c118437743fa15ce8',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/E',
                        options: { magicNumber: '50' },
                        canonicalId: 'ghcr.io/codspace/dependson/e@sha256:9f36f159c70f8bebff57f341904b030733adb17ef12a5d58d4b3d89b2a6c7d5a',
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/A',
                        options: { magicNumber: '40' },
                        canonicalId: 'ghcr.io/codspace/dependson/a@sha256:932027ef71da186210e6ceb3294c3459caaf6b548d2b547d5d26be3fc4b2264a',
                    },
                    {
                        tarballUri: 'https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-A.tgz',
                        options: { magicNumber: '10' },
                    },
                    {
                        userFeatureId: 'ghcr.io/codspace/dependson/C',
                        options: { magicNumber: '20' },
                        canonicalId: 'ghcr.io/codspace/dependson/c@sha256:db651708398b6d7af48f184c358728eaaf959606637133413cb4107b8454a868',
                    },
                    {
                        tarballUri: 'https://github.com/codspace/tgz-features-with-dependson/releases/download/0.0.2/devcontainer-feature-B.tgz',
                        options: { magicNumber: '400' }
                    }
                ]);
        });

        it('invalid circular dependency', async function () {
            const testFolder = `${baseTestConfigPath}/dependsOn/invalid-circular`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            assert.ok(!installOrderNodes);
        });
    });

    describe('dependsOnAndInstallsAfter', function () {

        it('valid dependsOn/installsAfter with file-path Features', async function () {
            const testFolder = `${baseTestConfigPath}/dependsOn-and-installsAfter/local-simple`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 2);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './c',
                        options: { magicNumber: '321' }
                    },
                    {
                        userFeatureId: './a',
                        options: {}
                    }
                ]);
        });
    });

    describe('overrideFeatureInstallOrder', function () {

        it('valid 1 override with file-path Features', async function () {
            const testFolder = `${baseTestConfigPath}/overrideFeatureInstallOrder/local-simple`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 4);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './c',
                        options: {}
                    },
                    {
                        userFeatureId: './b',
                        options: {}
                    },
                    {
                        userFeatureId: './d',
                        options: {}
                    },
                    {
                        userFeatureId: './a',
                        options: {}
                    }
                ]);
        });

        it('valid 2 overrides with file-path Features', async function () {
            const testFolder = `${baseTestConfigPath}/overrideFeatureInstallOrder/local-intermediate`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 4);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './c',
                        options: {}
                    },
                    {
                        userFeatureId: './d',
                        options: {}
                    },
                    {
                        userFeatureId: './b',
                        options: {}
                    },
                    {
                        userFeatureId: './a',
                        options: {}
                    }
                ]);
        });

        it('valid 3 overrides with file-path Feature where round priority beats independent feature', async function () {
            const testFolder = `${baseTestConfigPath}/overrideFeatureInstallOrder/local-roundPriority`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            // Assert all sourceInformation is of type 'local'
            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path'));

            const actual = installOrderNodes.map(fs => {
                return {
                    userFeatureId: fs.sourceInformation.userFeatureId,
                    options: fs.features[0].value
                };
            });

            assert.deepStrictEqual(actual.length, 3);
            assert.deepStrictEqual(actual,
                [
                    {
                        userFeatureId: './a',
                        options: {}
                    },
                    {
                        userFeatureId: './b',
                        options: {}
                    },
                    {
                        userFeatureId: './c',
                        options: {}
                    }
                ]);
        });

        it('valid 2 overrides with mixed Feature types', async function () {
            const testFolder = `${baseTestConfigPath}/overrideFeatureInstallOrder/mixed`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path' || fs.sourceInformation.type === 'oci'));

            const actual = installOrderNodes.map(fs => {
                switch (fs.sourceInformation.type) {
                    case 'oci':
                        const srcInfo = fs.sourceInformation as OCISourceInformation;
                        const ref = srcInfo.featureRef;
                        return {
                            id: `${ref.resource}@${srcInfo.manifestDigest}`,
                            options: fs.features[0].value,
                        };
                    default:
                        return {
                            id: fs.sourceInformation.userFeatureId,
                            options: fs.features[0].value
                        };
                }
            });

            assert.deepStrictEqual(actual.length, 9);
            assert.deepStrictEqual(actual,
                [
                    {
                        'id': './d',
                        'options': {}
                    },
                    {
                        'id': './b',
                        'options': {}
                    },
                    {
                        'id': './c',
                        'options': {}
                    },
                    {
                        'id': 'ghcr.io/codspace/dependson/d@sha256:3795caa1e32ba6b30a08260039804eed6f3cf40811f0c65c118437743fa15ce8',
                        'options': {
                            'magicNumber': '30'
                        }
                    },
                    {
                        'id': 'ghcr.io/codspace/dependson/e@sha256:9f36f159c70f8bebff57f341904b030733adb17ef12a5d58d4b3d89b2a6c7d5a',
                        'options': {
                            'magicNumber': '50'
                        }
                    },
                    {
                        'id': 'ghcr.io/codspace/dependson/a@sha256:932027ef71da186210e6ceb3294c3459caaf6b548d2b547d5d26be3fc4b2264a',
                        'options': {
                            'magicNumber': '40'
                        }
                    },
                    {
                        'id': 'ghcr.io/codspace/dependson/c@sha256:db651708398b6d7af48f184c358728eaaf959606637133413cb4107b8454a868',
                        'options': {
                            'magicNumber': '20'
                        }
                    },
                    {
                        'id': 'ghcr.io/codspace/dependson/b@sha256:e7e6b52884ae7f349baf207ac59f78857ab64529c890b646bb0282f962bb2941',
                        'options': {
                            'magicNumber': '400'
                        }
                    },
                    {
                        'id': './a',
                        'options': {}
                    }
                ]);
        });

        it('valid 3 overrides with mixed v2 Feature types', async function () {
            const testFolder = `${baseTestConfigPath}/overrideFeatureInstallOrder/image-with-v2-features-with-overrideFeatureInstallOrder`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'file-path' || fs.sourceInformation.type === 'direct-tarball' || fs.sourceInformation.type === 'oci'));

            const actual = installOrderNodes.map(fs => {
                switch (fs.sourceInformation.type) {
                    case 'oci':
                        const srcInfo = fs.sourceInformation as OCISourceInformation;
                        const ref = srcInfo.featureRef;
                        return {
                            id: `${ref.resource}@${srcInfo.manifestDigest}`,
                            options: fs.features[0].value,
                        };
                    default:
                        return {
                            id: fs.sourceInformation.userFeatureId,
                            options: fs.features[0].value
                        };
                }
            });

            assert.deepStrictEqual(actual.length, 5);
            assert.deepStrictEqual(actual,
                [
                    {
                        id: './localFeatureA',
                        options: {
                            'greeting': 'buongiorno'
                        }
                    },
                    {
                        id: 'https://github.com/codspace/features/releases/download/tarball02/devcontainer-feature-docker-in-docker.tgz',
                        options: {
                            'version': 'latest'
                        }
                    },
                    {
                        id: 'ghcr.io/devcontainers/features/python@sha256:675f3c93e52fa4b205827e3aae744905ae67951f70e3ec2611f766304b31f4a2',
                        options: {
                            version: 'none'
                        }
                    },
                    {
                        id: './localFeatureB',
                        options: {
                            'greeting': 'buongiorno'
                        }
                    },
                    {
                        id: 'ghcr.io/codspace/features/python@sha256:e4034c2a24d6c5d1cc0f6cb03091fc72d4e89f5cc64fa692cb69b671c81633d2',
                        options: {
                            'version': 'none'
                        }
                    }
                ]
            );
        });

        it('valid 3 overrides with mixed v1 Feature types', async function () {
            const testFolder = `${baseTestConfigPath}/overrideFeatureInstallOrder/image-with-v1-features-with-overrideFeatureInstallOrder`;
            const { params, userFeatures, processFeature, config } = await setupInstallOrderTest(testFolder);

            const installOrderNodes = await computeDependsOnInstallationOrder(params, processFeature, userFeatures, config);
            if (!installOrderNodes) {
                assert.fail();
            }

            assert.ok(installOrderNodes.every(fs => fs.sourceInformation.type === 'github-repo' || fs.sourceInformation.type === 'direct-tarball' || fs.sourceInformation.type === 'oci'));

            const actual = installOrderNodes.map(fs => {
                switch (fs.sourceInformation.type) {
                    case 'oci':
                        const srcInfo = fs.sourceInformation as OCISourceInformation;
                        const ref = srcInfo.featureRef;
                        return {
                            id: ref.resource,
                            options: fs.features[0].value,
                        };
                    default:
                        return {
                            id: fs.sourceInformation.userFeatureId,
                            options: fs.features[0].value
                        };
                }
            });

            assert.deepStrictEqual(actual.length, 3);
            assert.deepStrictEqual(actual,
                [
                    {
                        id: 'codspace/features/devcontainer-feature-go@tarball02',
                        options: {}
                    },
                    {
                        id: 'codspace/myfeatures/helloworld',
                        options: {
                            greeting: 'howdy'
                        }
                    },
                    {
                        id: 'ghcr.io/devcontainers/features/terraform',
                        options: 'latest'
                    }
                ]
            );
        });


    });
});
</file>

<file path="src/test/container-features/e2e.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { assert } from 'chai';
import * as path from 'path';
import { FeatureSet } from '../../spec-configuration/containerFeaturesConfiguration';
import { devContainerDown, devContainerUp, shellExec } from '../testUtils';
import { delay } from '../../spec-common/async';

const pkg = require('../../../package.json');

describe('Dev Container Features E2E (remote)', function () {
    this.timeout('300s');

    const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
    const cli = `npx --prefix ${tmp} devcontainer`;

    before('Install', async () => {
        await shellExec(`rm -rf ${tmp}/node_modules`);
        await shellExec(`mkdir -p ${tmp}`);
        await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
    });

    describe('Configs with invalid features should fail', () => {
        it('should fail when a non-existent v1 feature is in the config', async () => {
            const testFolder = `${__dirname}/configs/invalid-configs/invalid-v1-features`;
            let success = false;
            try {
                await shellExec(`${cli} build --workspace-folder ${testFolder} --log-level trace`);
                success = true;
            } catch (error) {
                assert.equal(error.error.code, 1, 'Should fail with exit code 1');
                // "Failed to fetch tarball" happens if the test is executed without a $GITHUB_TOKEN
                // "HTTP 404: Not Found" happens if the test is executed with a $GITHUB_TOKEN
                assert.ok(error.stderr.indexOf('Failed to fetch tarball') > -1 || error.stderr.indexOf('HTTP 404: Not Found') > -1, `Actual error msg:  ${error.stderr}`);
            }
            assert.equal(success, false, 'expect non-successful call');
        });

        it('should fail when a non-existent v2 feature is in the config', async () => {
            const testFolder = `${__dirname}/configs/invalid-configs/invalid-v2-features`;
            let success = false;
            try {
                await shellExec(`${cli} build --workspace-folder ${testFolder} --log-level trace`);
                success = true;
            } catch (error) {
                assert.equal(error.error.code, 1, 'Should fail with exit code 1');
                assert.ok(error.stderr.indexOf('Could not resolve Feature') > -1, `Actual error msg:  ${error.stderr}`);
            }
            assert.equal(success, false, 'expect non-successful call');
        });
    });

    describe('v2 - Dockerfile feature Configs', () => {

        describe(`dockerfile-with-v2-oci-features`, () => {
            let containerId: string | null = null;
            const testFolder = `${__dirname}/configs/dockerfile-with-v2-oci-features`;
            beforeEach(async () => {
                const res = await shellExec(`${cli} up --workspace-folder ${testFolder} --skip-feature-auto-mapping`);
                const response = JSON.parse(res.stdout);
                containerId = response.containerId;
            });
            afterEach(async () => await devContainerDown({ containerId }));
            it('should detect docker installed (--privileged flag implicitly passed)', async () => {
                // NOTE: Doing a docker ps will ensure that the --privileged flag was set by the feature
                for (let i = 2; i >= 0; i--) {
                    try {
                        const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker ps`);
                        await shellExec(`${cli} exec --workspace-folder ${testFolder} ps ax`);
                        assert.isNull(res.error);
                        assert.match(res.stdout, /CONTAINER ID/);
                        break;
                    } catch (err) {
                        await shellExec(`${cli} exec --workspace-folder ${testFolder} ps ax`);
                        if (i === 0) {
                            throw err;
                        }
                        delay(2000);
                    }
                }
            });

            it('should read configuration with features', async () => {
                const res = await shellExec(`${cli} read-configuration --workspace-folder ${testFolder} --include-features-configuration  --skip-feature-auto-mapping`);
                const response = JSON.parse(res.stdout);
                console.log(res.stderr);

                assert.strictEqual(response.featuresConfiguration?.featureSets.length, 3);

                const dind = response?.featuresConfiguration.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'docker-in-docker');
                assert.exists(dind);
                assert.includeMembers(dind.features[0].customizations.vscode.extensions, ['ms-azuretools.vscode-docker']);

                const node = response?.featuresConfiguration.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'node');
                assert.exists(node);
                assert.includeMembers(node.features[0].customizations.vscode.extensions, ['dbaeumer.vscode-eslint']);
            });
        });
    });

    describe('v2 - Image property feature Configs', () => {

        describe(`image-with-v2-tarball`, () => {
            let containerId: string | null = null;
            const testFolder = `${__dirname}/configs/image-with-v2-tarball`;
            beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId);
            afterEach(async () => await devContainerDown({ containerId }));
            it('should detect docker installed (--privileged flag implicitly passed)', async () => {
                // NOTE: Doing a docker ps will ensure that the --privileged flag was set by the feature
                for (let i = 2; i >= 0; i--) {
                    try {
                        const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker ps`);
                        await shellExec(`${cli} exec --workspace-folder ${testFolder} ps ax`);
                        assert.isNull(res.error);
                        assert.match(res.stdout, /CONTAINER ID/);
                        break;
                    } catch (err) {
                        await shellExec(`${cli} exec --workspace-folder ${testFolder} ps ax`);
                        if (i === 0) {
                            throw err;
                        }
                        delay(2000);
                    }
                }
            });
        });
    });
});

describe('Dev Container Features E2E - local cache/short-hand notation', function () {
    this.timeout('300s');

    const tmp = path.resolve(process.cwd(), path.join(__dirname, 'tmp3'));
    const cli = `npx --prefix ${tmp} devcontainer`;

    before('Install', async () => {
        await shellExec(`rm -rf ${tmp}/node_modules`);
        await shellExec(`mkdir -p ${tmp}`);
        await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
    });

    describe(`image-with-v1-features-node-python-local-cache with --skipFeatureAutoMapping`, () => {
        let containerId: string | null = null;
        const testFolder = `${__dirname}/configs/image-with-v1-features-node-python-local-cache`;
        beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace', 'extraArgs': '--skipFeatureAutoMapping' })).containerId);
        afterEach(async () => await devContainerDown({ containerId }));

        it('should exec a PATH without the string \'ENV\'', async () => {
            const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} echo \${PATH}`);
            assert.isNull(res.error);
            assert.notMatch(res.stdout, /ENV/);
        });
    });
});


describe('Dev Container Features E2E (local-path)', function () {
    this.timeout('120s');

    const tmp = path.resolve(process.cwd(), path.join(__dirname, 'tmp1'));
    const cli = `npx --prefix ${tmp} devcontainer`;

    before('Install', async () => {
        await shellExec(`rm -rf ${tmp}/node_modules`);
        await shellExec(`mkdir -p ${tmp}`);
        await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
    });

    describe(`dockerfile-with-v2-local-features-config-inside-dev-container-folder `, () => {
        let containerId: string | null = null;
        const testFolder = `${__dirname}/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder`;
        beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId);
        afterEach(async () => await devContainerDown({ containerId }));

        it('should exec the color command', async () => {
            const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} color`);
            assert.isNull(res.error);
            assert.match(res.stdout, /my favorite color is gold/);
        });
        it('should read configuration with features', async () => {
            const res = await shellExec(`${cli} read-configuration --workspace-folder ${testFolder} --include-features-configuration`);
            const response = JSON.parse(res.stdout);
            console.log(res.stderr);
            assert.equal(response?.featuresConfiguration?.featureSets[0]?.features[0]?.id, 'localFeatureA', `localFeatureA not found: ${JSON.stringify(response, undefined, '  ')}`);
        });
    });

        describe(`dockerfile-with-v2-local-features-config-outside-dev-container-folder `, () => {
            let containerId: string | null = null;
            const testFolder = `${__dirname}/configs/dockerfile-with-v2-local-features-config-outside-dev-container-folder`;
            beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId);
            afterEach(async () => await devContainerDown({ containerId }));

            it('should exec the color command', async () => {
                const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} color`);
                assert.isNull(res.error);
                assert.match(res.stdout, /my favorite color is gold/);
            });

            it('should exec the helloworld command', async () => {
            const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
            assert.isNull(res.error);
            assert.match(res.stdout, /Hello there, vscode!!!!/);
        });

        it('should read configuration with features', async () => {
            const res = await shellExec(`${cli} read-configuration --workspace-folder ${testFolder} --include-features-configuration`);
            const response = JSON.parse(res.stdout);
            console.log(res.stderr);
            assert.equal(response?.featuresConfiguration?.featureSets[0]?.features[0]?.id, 'localFeatureA', `localFeatureA not found: ${JSON.stringify(response, undefined, '  ')}`);
        });
    });

    describe(`dockerfile-with-v2-local-features-config-inside-dev-container-folder `, () => {
        let containerId: string | null = null;
        const testFolder = `${__dirname}/configs/dockerfile-with-v2-local-features-config-inside-dev-container-folder`;
        beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId);
        afterEach(async () => await devContainerDown({ containerId }));

        it('should exec the color commmand', async () => {
            const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} color`);
            assert.isNull(res.error);
            assert.match(res.stdout, /my favorite color is gold/);
        });

        it('should exec the helloworld commmand', async () => {
            const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
            assert.isNull(res.error);
            assert.match(res.stdout, /Hello there, vscode!!!!/);
        });

        it('should read configuration with features with customizations', async () => {
            const res = await shellExec(`${cli} read-configuration --workspace-folder ${testFolder} --include-features-configuration`);
            const response = JSON.parse(res.stdout);
            console.log(res.stderr);
            assert.equal(response?.featuresConfiguration?.featureSets[0]?.features[0]?.id, 'localFeatureA', `localFeatureA not found: ${JSON.stringify(response, undefined, '  ')}`);

            const featureA = response?.featuresConfiguration.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'localFeatureA');
            assert.exists(featureA);
            assert.includeMembers(featureA.features[0].customizations.vscode.extensions, ['dbaeumer.vscode-eslint']);
            const featureASettings = featureA?.features[0]?.customizations?.vscode?.settings;
            assert.isObject(featureASettings);

            // With top level "extensions" and "settings"
            const featureB = response?.featuresConfiguration.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'localFeatureB');
            assert.exists(featureB);
            assert.includeMembers(featureB.features[0].customizations.vscode.extensions, ['ms-dotnettools.csharp']);
            const featureBSettings = featureB?.features[0]?.customizations?.vscode?.settings;
            assert.isObject(featureBSettings);
        });
    });
});
</file>

<file path="src/test/container-features/featureAdvisories.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as path from 'path';
import * as os from 'os';
import * as crypto from 'crypto';
import * as assert from 'assert';

import { fetchFeatureAdvisories } from '../../spec-configuration/featureAdvisories';
import { Feature, FeaturesConfig } from '../../spec-configuration/containerFeaturesConfiguration';
import { getRef } from '../../spec-configuration/containerCollectionsOCI';
import { output } from '../testUtils';
import { FeatureAdvisory } from '../../spec-configuration/controlManifest';


describe('Feature Advisories', function () {
	
	const cacheFolder = path.join(os.tmpdir(), `devcontainercli-test-${crypto.randomUUID()}`);
	const featureId = 'ghcr.io/devcontainers/features/feature-with-advisory';
	const otherFeatureId = 'ghcr.io/devcontainers/features/other-feature';

	it('match feature in version range', async () => {
		const advisories = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1', '1.0.9'));
		assertTestAdvisory(advisories, featureId, '1.0.9');
		
		const advisories2 = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1.1', '1.1.5'));
		assertTestAdvisory(advisories2, featureId, '1.1.5');
	});

	it('match feature at version range', async () => {
		const advisories = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1', '1.0.7'));
		assertTestAdvisory(advisories, featureId, '1.0.7');

		const advisories2 = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1.1', '1.1.9'));
		assertTestAdvisory(advisories2, featureId, '1.1.9');
	});

	it('miss feature outside version range', async () => {
		const advisories = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1', '1.0.2'));
		assert.strictEqual(advisories.length, 0);
		
		const advisories2 = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1.1', '1.2.1'));
		assert.strictEqual(advisories2.length, 0);
	});

	it('miss feature at version range', async () => {
		const advisories = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1', '1.0.6'));
		assert.strictEqual(advisories.length, 0);
		
		const advisories2 = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(featureId, '1.1', '1.1.10'));
		assert.strictEqual(advisories2.length, 0);
	});

	it('miss other feature', async () => {
		const advisories = await fetchFeatureAdvisories({ cacheFolder, output }, getFeaturesConfig(otherFeatureId, '1', '1.0.9'));
		assert.strictEqual(advisories.length, 0);
	});
});

function assertTestAdvisory(advisories: { feature: { id: string; version: string }; advisories: FeatureAdvisory[] }[], featureId: string, actualVersion: string) {
	assert.strictEqual(advisories.length, 1);
	assert.strictEqual(advisories[0].feature.id, featureId);
	assert.strictEqual(advisories[0].feature.version, actualVersion);
	assert.strictEqual(advisories[0].advisories.length, 1);
	assert.strictEqual(advisories[0].advisories[0].featureId, featureId);
	assert.strictEqual(advisories[0].advisories[0].introducedInVersion, '1.0.7');
	assert.strictEqual(advisories[0].advisories[0].fixedInVersion, '1.1.10');
}

function getFeaturesConfig(featureId: string, featureConfigVersion: string, featureResolvedVersion: string): FeaturesConfig {
	const feature: Feature = {
		id: `${featureId}:${featureConfigVersion}`,
		version: featureResolvedVersion,
		value: 'someValue',
		included: true,
		consecutiveId: 'someFeature_1',
	};
	return {
		featureSets: [
			{
				features: [feature],
				sourceInformation: {
					type: 'oci',
					userFeatureId: `${featureId}:${featureConfigVersion}`,
					userFeatureIdWithoutVersion: featureId,
					featureRef: getRef(output, `${featureId}:${featureConfigVersion}`)!,
					manifest: {
						schemaVersion: 1,
						mediaType: '',
						config: {
							digest: '',
							mediaType: '',
							size: 0,
						},
						layers: [],
					},
					manifestDigest: '',
				}
			}
		]
	};
}
</file>

<file path="src/test/container-features/featureHelpers.test.ts">
import { assert } from 'chai';
import * as path from 'path';
import { DevContainerConfig, DevContainerFeature } from '../../spec-configuration/configuration';
import { OCIRef } from '../../spec-configuration/containerCollectionsOCI';
import { Feature, FeatureSet, getBackwardCompatibleFeatureId, getFeatureInstallWrapperScript, processFeatureIdentifier, updateDeprecatedFeaturesIntoOptions } from '../../spec-configuration/containerFeaturesConfiguration';
import { getSafeId, findContainerUsers } from '../../spec-node/containerFeatures';
import { ImageMetadataEntry } from '../../spec-node/imageMetadata';
import { SubstitutedConfig } from '../../spec-node/utils';
import { createPlainLog, LogLevel, makeLog, nullLog } from '../../spec-utils/log';

export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));

const params = { output, env: process.env };

describe('getIdSafe should return safe environment variable name', function () {

	it('should replace a "-" with "_"', function () {
		const ex = 'option-name';
		assert.strictEqual(getSafeId(ex), 'OPTION_NAME');
	});

	it('should replace all "-" with "_"', function () {
		const ex = 'option1-name-with_dashes-';
		assert.strictEqual(getSafeId(ex), 'OPTION1_NAME_WITH_DASHES_');
	});

	it('should only be capitalized if no special characters', function () {
		const ex = 'myOptionName';
		assert.strictEqual(getSafeId(ex), 'MYOPTIONNAME');
	});

	it('should delete a leading numbers and add a _', function () {
		const ex = '1name';
		assert.strictEqual(getSafeId(ex), '_NAME');
	});

	it('should delete all leading numbers and add a _', function () {
		const ex = '12345_option-name';
		assert.strictEqual(getSafeId(ex), '_OPTION_NAME');
	});
});

// A 'Feature' object's id should always be parsed to
// the individual feature's name (without any other 'sourceInfo' information)
const assertFeatureIdInvariant = (id: string) => {
	const includesInvalidCharacter = id.includes('/') || id.includes(':') || id.includes('\\') || id.includes('.');
	assert.isFalse(includesInvalidCharacter, `Individual feature id '${id}' contains invalid characters`);
};

describe('validate processFeatureIdentifier', async function () {
	// const VALID_TYPES = ['github-repo', 'direct-tarball', 'file-path', 'oci'];

	// In the real implementation, the cwd is passed by the calling function with the value of `--workspace-folder`.
	// See: https://github.com/devcontainers/cli/blob/45541ba21437bf6c16826762f084ab502157789b/src/spec-node/devContainersSpecCLI.ts#L152-L153
	const workspaceRoot = '/workspace/myProject';
	const defaultConfigPath = path.join(workspaceRoot, '.devcontainer', 'devcontainer.json');
	console.log(`workspaceRoot = ${workspaceRoot}, defaultConfigPath = ${defaultConfigPath}`);

	describe('VALID processFeatureIdentifier examples', async function () {

		it('should process v1 local-cache', async function () {
			// Parsed out of a user's devcontainer.json
			let userFeature: DevContainerFeature = {
				userFeatureId: 'docker-in-docker',
				options: {}
			};
			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}

			assert.strictEqual(featureSet.features.length, 1);

			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);

			assert.strictEqual(featureId, 'docker-in-docker');

			// Automapping feature ids from old shorthand syntax to ghcr.io/devcontainers/features/*
			assert.strictEqual(featureSet?.sourceInformation.type, 'oci');
		});

		it('should process github-repo (without version)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures/helloworld',
				options: {},
			};
			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}

			assert.strictEqual(featureSet.features.length, 1);

			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);

			assert.strictEqual(featureSet?.features[0].id, 'helloworld');
			assert.deepEqual(featureSet?.sourceInformation, {
				type: 'github-repo',
				owner: 'octocat',
				repo: 'myfeatures',
				apiUri: 'https://api.github.com/repos/octocat/myfeatures/releases/latest',
				unauthenticatedUri: 'https://github.com/octocat/myfeatures/releases/latest/download',
				isLatest: true,
				userFeatureId: 'octocat/myfeatures/helloworld',
				userFeatureIdWithoutVersion: 'octocat/myfeatures/helloworld'
			});
		});

		it('should process github-repo (with version)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures/helloworld@v0.0.4',
				options: {},
			};
			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}

			assert.strictEqual(featureSet.features.length, 1);

			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);

			assert.strictEqual(featureSet?.features[0].id, 'helloworld');
			assert.deepEqual(featureSet?.sourceInformation, {
				type: 'github-repo',
				owner: 'octocat',
				repo: 'myfeatures',
				tag: 'v0.0.4',
				apiUri: 'https://api.github.com/repos/octocat/myfeatures/releases/tags/v0.0.4',
				unauthenticatedUri: 'https://github.com/octocat/myfeatures/releases/download/v0.0.4',
				isLatest: false,
				userFeatureId: 'octocat/myfeatures/helloworld@v0.0.4',
				userFeatureIdWithoutVersion: 'octocat/myfeatures/helloworld'
			});
		});

		it('should process direct-tarball (v2 with direct tar download)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'https://example.com/some/long/path/devcontainer-feature-ruby.tgz',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}
			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);

			assert.exists(featureSet);
			assert.strictEqual(featureSet?.features[0].id, 'ruby');
			assert.deepEqual(featureSet?.sourceInformation, { type: 'direct-tarball', tarballUri: 'https://example.com/some/long/path/devcontainer-feature-ruby.tgz', userFeatureId: 'https://example.com/some/long/path/devcontainer-feature-ruby.tgz' });
		});

		it('local-path should parse when provided a relative path with Config file in $WORKSPACE_ROOT/.devcontainer', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: './featureA',
				options: {},
			};

			const customConfigPath = path.join(workspaceRoot, '.devcontainer', 'devcontainer.json');

			const featureSet = await processFeatureIdentifier(params, customConfigPath, workspaceRoot, userFeature);
			assert.exists(featureSet);
			assert.strictEqual(featureSet?.features[0].id, 'featureA');
			assert.deepEqual(featureSet?.sourceInformation, { type: 'file-path', resolvedFilePath: path.join(workspaceRoot, '.devcontainer', 'featureA'), userFeatureId: './featureA' });
		});


		it('local-path should parse when provided relative path with config file in $WORKSPACE_ROOT', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: './.devcontainer/featureB',
				options: {},
			};

			const customConfigPath = path.join(workspaceRoot, 'devcontainer.json');

			const featureSet = await processFeatureIdentifier(params, customConfigPath, workspaceRoot, userFeature);

			assert.exists(featureSet);
			assert.strictEqual(featureSet?.features[0].id, 'featureB');
			assert.deepEqual(featureSet?.sourceInformation, { type: 'file-path', resolvedFilePath: path.join(workspaceRoot, '.devcontainer', 'featureB'), userFeatureId: './.devcontainer/featureB' });
		});

		it('should process oci registry (without tag)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'ghcr.io/codspace/features/ruby',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}
			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);
			assert.strictEqual(featureSet?.features[0].id, 'ruby');

			assert.exists(featureSet);

			const expectedFeatureRef: OCIRef = {
				id: 'ruby',
				owner: 'codspace',
				namespace: 'codspace/features',
				registry: 'ghcr.io',
				tag: 'latest',
				digest: undefined,
				version: 'latest',
				resource: 'ghcr.io/codspace/features/ruby',
				path: 'codspace/features/ruby',
			};

			if (featureSet.sourceInformation.type === 'oci') {
				assert.ok(featureSet.sourceInformation.type === 'oci');
				assert.deepEqual(featureSet.sourceInformation.featureRef, expectedFeatureRef);
			} else {
				assert.fail('sourceInformation.type is not oci');
			}
		});

		it('should process oci registry (with a digest)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'ghcr.io/devcontainers/features/ruby@sha256:4ef08c9c3b708f3c2faecc5a898b39736423dd639f09f2a9f8bf9b0b9252ef0a',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}
			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);
			assert.strictEqual(featureSet?.features[0].id, 'ruby');

			assert.exists(featureSet);

			const expectedFeatureRef: OCIRef = {
				id: 'ruby',
				owner: 'devcontainers',
				namespace: 'devcontainers/features',
				registry: 'ghcr.io',
				tag: undefined,
				digest: 'sha256:4ef08c9c3b708f3c2faecc5a898b39736423dd639f09f2a9f8bf9b0b9252ef0a',
				version: 'sha256:4ef08c9c3b708f3c2faecc5a898b39736423dd639f09f2a9f8bf9b0b9252ef0a',
				resource: 'ghcr.io/devcontainers/features/ruby',
				path: 'devcontainers/features/ruby',
			};

			if (featureSet.sourceInformation.type === 'oci') {
				assert.ok(featureSet.sourceInformation.type === 'oci');
				assert.deepEqual(featureSet.sourceInformation.featureRef, expectedFeatureRef);
			} else {
				assert.fail('sourceInformation.type is not oci');
			}
		});

		it('should process oci registry (with a tag)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'ghcr.io/codspace/features/ruby:1.0.13',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			if (!featureSet) {
				assert.fail('processFeatureIdentifier returned null');
			}
			const featureId = featureSet.features[0].id;
			assertFeatureIdInvariant(featureId);
			assert.strictEqual(featureSet?.features[0].id, 'ruby');

			assert.exists(featureSet);

			const expectedFeatureRef: OCIRef = {
				id: 'ruby',
				owner: 'codspace',
				namespace: 'codspace/features',
				registry: 'ghcr.io',
				tag: '1.0.13',
				digest: undefined,
				version: '1.0.13',
				resource: 'ghcr.io/codspace/features/ruby',
				path: 'codspace/features/ruby',
			};

			if (featureSet.sourceInformation.type === 'oci') {
				assert.ok(featureSet.sourceInformation.type === 'oci');
				assert.deepEqual(featureSet.sourceInformation.featureRef, expectedFeatureRef);
			} else {
				assert.fail('sourceInformation.type is not oci');
			}
		});
	});

	describe('INVALID processFeatureIdentifier examples', async function () {
		it('local-path should fail to parse when provided  absolute path and defaultConfigPath with a .devcontainer', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: '/some/long/path/to/helloworld',
				options: {},
			};

			const testSpecificConfigPath = path.join(workspaceRoot, '.devcontainer', 'devcontainer.json');

			const featureSet = await processFeatureIdentifier(params, testSpecificConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('local-path should fail to parse when provided an absolute path and defaultConfigPath without a .devcontainer', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: '/some/long/path/to/helloworld',
				options: {},
			};

			const testSpecificConfigPath = path.join(workspaceRoot, '.devcontainer.json');

			const featureSet = await processFeatureIdentifier(params, testSpecificConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('local-path should fail to parse when provided an a relative path breaking out of the .devcontainer folder', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: '../featureC',
				options: {},
			};

			const testSpecificConfigPath = path.join(workspaceRoot, '.devcontainer.json');

			const featureSet = await processFeatureIdentifier(params, testSpecificConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a generic tar with no feature and trailing slash', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'https://example.com/some/long/path/devcontainer-features.tgz/',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should not parse gitHub without triple slash', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures#helloworld',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a generic tar with no feature and no trailing slash', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'https://example.com/some/long/path/devcontainer-features.tgz',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a generic tar with a hash but no feature', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'https://example.com/some/long/path/devcontainer-features.tgz#',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a marketplace shorthand with only two segments and a hash with no feature', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures#',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a marketplace shorthand with only two segments (no feature)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a marketplace shorthand with an invalid feature name (1)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures/@mycoolfeature',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a marketplace shorthand with an invalid feature name (2)', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures/MY_$UPER_COOL_FEATURE',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});

		it('should fail parsing a marketplace shorthand with only two segments, no hash, and with a version', async function () {
			const userFeature: DevContainerFeature = {
				userFeatureId: 'octocat/myfeatures@v0.0.1',
				options: {},
			};

			const featureSet = await processFeatureIdentifier(params, defaultConfigPath, workspaceRoot, userFeature);
			assert.notExists(featureSet);
		});
	});
});

describe('validate function getBackwardCompatibleFeatureId', () => {
    it('should map the migrated (old shorthand syntax) features to ghcr.io/devcontainers/features/*', () => {
        let id = 'node';
        let expectedId = 'ghcr.io/devcontainers/features/node:1';
		let mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);

        id = 'python';
        expectedId = 'ghcr.io/devcontainers/features/python:1';
		mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);
    });

    it('should map the renamed (old shorthand syntax) features to ghcr.io/devcontainers/features/*', () => {
        let id = 'golang';
        let expectedId = 'ghcr.io/devcontainers/features/go:1';
		let mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);

        id = 'common';
        expectedId = 'ghcr.io/devcontainers/features/common-utils:1';
		mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);
    });

    it('should keep the deprecated (old shorthand syntax) features id intact', () => {
        let id = 'fish';
        let expectedId = 'fish';
		let mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);

        id = 'maven';
        expectedId = 'maven';
		mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);
    });

    it('should keep all other features id intact', () => {
        let id = 'ghcr.io/devcontainers/features/node:1';
        let expectedId = id;
		let mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);

        id = 'ghcr.io/user/repo/go:1';
        expectedId = id;
		mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);

        id = 'ghcr.io/user/repo/go';
        expectedId = id;
		mappedId = getBackwardCompatibleFeatureId(output, id);

        assert.strictEqual(mappedId, expectedId);
    });
});

describe('validate function updateDeprecatedFeaturesIntoOptions', () => {
	it('should add feature with option', () => {
		const updated = updateDeprecatedFeaturesIntoOptions([
			{
				userFeatureId: 'jupyterlab',
				options: {}
			}
		], nullLog);
		if (!updated) {
			assert.fail('updated is null');
		}

		assert.strictEqual(updated.length, 1);
		assert.strictEqual(updated[0].userFeatureId, 'ghcr.io/devcontainers/features/python:1');
		assert.ok(updated[0].options);
		assert.strictEqual(typeof updated[0].options, 'object');
		assert.strictEqual((updated[0].options as Record<string, string | boolean | undefined>)['installJupyterlab'], true);
	});
	
	it('should update feature with option', () => {
		const updated = updateDeprecatedFeaturesIntoOptions([
			{
				userFeatureId: 'ghcr.io/devcontainers/features/python:1',
				options: {}
			},
			{
				userFeatureId: 'jupyterlab',
				options: {}
			}
		], nullLog);
		if (!updated) {
			assert.fail('updated is null');
		}

		assert.strictEqual(updated.length, 1);
		assert.strictEqual(updated[0].userFeatureId, 'ghcr.io/devcontainers/features/python:1');
		assert.ok(updated[0].options);
		assert.strictEqual(typeof updated[0].options, 'object');
		assert.strictEqual((updated[0].options as Record<string, string | boolean | undefined>)['installJupyterlab'], true);
	});

	it('should update legacy feature with option', () => {
		const updated = updateDeprecatedFeaturesIntoOptions([
			{
				userFeatureId: 'python',
				options: {}
			},
			{
				userFeatureId: 'jupyterlab',
				options: {}
			}
		], nullLog);
		if (!updated) {
			assert.fail('updated is null');
		}
		assert.strictEqual(updated.length, 1);
		assert.strictEqual(updated[0].userFeatureId, 'python');
		assert.ok(updated[0].options);
		assert.strictEqual(typeof updated[0].options, 'object');
		assert.strictEqual((updated[0].options as Record<string, string | boolean | undefined>)['installJupyterlab'], true);
	});
});

describe('validate function getFeatureInstallWrapperScript', () => {
	it('returns a valid script when optional feature values do not exist', () => {
        const feature: Feature = {
			id: 'test',
			value: {},
			included: true,
			name: undefined,
			description: undefined,
			version: undefined,
			documentationURL: undefined,
		};
		const set: FeatureSet = {
			features: [feature],
			sourceInformation: {
				type: 'file-path',
				resolvedFilePath: '',
				userFeatureId: './test',
				userFeatureIdWithoutVersion: './test'
			}
		};
		const options: string[] = [];

		const expected =
`#!/bin/sh
set -e

on_exit () {
	[ $? -eq 0 ] && exit
	echo 'ERROR: Feature "Unknown" (./test) failed to install!'
}

trap on_exit EXIT

echo ===========================================================================

echo 'Feature       : Unknown'
echo 'Description   : '
echo 'Id            : ./test'
echo 'Version       : '
echo 'Documentation : '
echo 'Options       :'
echo ''
echo ===========================================================================

set -a
. ../devcontainer-features.builtin.env
. ./devcontainer-features.env
set +a

chmod +x ./install.sh
./install.sh
`;

		const actual = getFeatureInstallWrapperScript(feature, set, options);
		assert.equal(actual, expected);
    });

	it('returns a valid script when expected feature values do exist', () => {
        const feature: Feature = {
			id: 'test',
			value: {
				version: 'latest',
				otherOption: true
			},
			included: true,
			name: 'My Test Feature',
			description: 'This is an awesome feature (with ""quotes" for \'escaping\' test)',
			version: '1.2.3',
			documentationURL: 'https://my-test-feature.localhost',
		};
		const set: FeatureSet = {
			features: [feature],
			sourceInformation: {
				type: 'oci',
				userFeatureId: 'ghcr.io/my-org/my-repo/test:1',
				userFeatureIdWithoutVersion: 'ghcr.io/my-org/my-repo/test',
				featureRef: {
					registry: 'ghcr.io',
					owner: 'my-org',
					namespace: 'my-org/my-repo',
					path: 'my-org/my-repo/test',
					resource: 'ghcr.io/my-org/my-repo/test',
					id: 'test',
					tag: '1.2.3',
					version: '1.2.3',
				},
				manifest: {
					schemaVersion: 1,
					mediaType: '',
					config: {
						digest: '',
						mediaType: '',
						size: 0,
					},
					layers: [],
				},
				manifestDigest: '',
			}
		};
		const options = [
			'VERSION=latest',
			'OTHEROPTION=true',
		];

		const expected =
`#!/bin/sh
set -e

on_exit () {
	[ $? -eq 0 ] && exit
	echo 'ERROR: Feature "My Test Feature" (ghcr.io/my-org/my-repo/test) failed to install! Look at the documentation at https://my-test-feature.localhost for help troubleshooting this error.'
}

trap on_exit EXIT

echo ===========================================================================

echo 'Feature       : My Test Feature'
echo 'Description   : This is an awesome feature (with ""quotes" for '\\''escaping'\\'' test)'
echo 'Id            : ghcr.io/my-org/my-repo/test'
echo 'Version       : 1.2.3'
echo 'Documentation : https://my-test-feature.localhost'
echo 'Options       :'
echo '    VERSION=latest
    OTHEROPTION=true'
echo ===========================================================================

set -a
. ../devcontainer-features.builtin.env
. ./devcontainer-features.env
set +a

chmod +x ./install.sh
./install.sh
`;

		const actual = getFeatureInstallWrapperScript(feature, set, options);
		assert.equal(actual, expected);
    });

	it('returns a valid script with warnings for deprecated Features', () => {
        const feature: Feature = {
			id: 'test',
			value: {
				version: 'latest',
				otherOption: true
			},
			included: true,
			name: 'My Test Feature',
			description: 'This is an awesome feature (with ""quotes" for \'escaping\' test)',
			version: '1.2.3',
			documentationURL: 'https://my-test-feature.localhost',
			deprecated: true,
		};
		const set: FeatureSet = {
			features: [feature],
			sourceInformation: {
				type: 'oci',
				userFeatureId: 'ghcr.io/my-org/my-repo/test:1',
				userFeatureIdWithoutVersion: 'ghcr.io/my-org/my-repo/test',
				featureRef: {
					registry: 'ghcr.io',
					owner: 'my-org',
					namespace: 'my-org/my-repo',
					path: 'my-org/my-repo/test',
					resource: 'ghcr.io/my-org/my-repo/test',
					id: 'test',
					tag: '1.2.3',
					version: '1.2.3',
				},
				manifest: {
					schemaVersion: 1,
					mediaType: '',
					config: {
						digest: '',
						mediaType: '',
						size: 0,
					},
					layers: [],
				},
				manifestDigest: '',
			}
		};
		const options = [
			'VERSION=latest',
			'OTHEROPTION=true',
		];

		const expected =
`#!/bin/sh
set -e

on_exit () {
	[ $? -eq 0 ] && exit
	echo 'ERROR: Feature "My Test Feature" (ghcr.io/my-org/my-repo/test) failed to install! Look at the documentation at https://my-test-feature.localhost for help troubleshooting this error.'
}

trap on_exit EXIT

echo ===========================================================================
echo '(!) WARNING: Using the deprecated Feature "test". This Feature will no longer receive any further updates/support.\n'
echo 'Feature       : My Test Feature'
echo 'Description   : This is an awesome feature (with ""quotes" for '\\''escaping'\\'' test)'
echo 'Id            : ghcr.io/my-org/my-repo/test'
echo 'Version       : 1.2.3'
echo 'Documentation : https://my-test-feature.localhost'
echo 'Options       :'
echo '    VERSION=latest
    OTHEROPTION=true'
echo ===========================================================================

set -a
. ../devcontainer-features.builtin.env
. ./devcontainer-features.env
set +a

chmod +x ./install.sh
./install.sh
`;

		const actual = getFeatureInstallWrapperScript(feature, set, options);
		assert.equal(actual, expected);
    });

	it('returns a valid script with warnings for renamed Features', () => {
        const feature: Feature = {
			id: 'test',
			value: {
				version: 'latest',
				otherOption: true
			},
			included: true,
			name: 'My New Test Feature',
			description: 'This is an awesome feature (with ""quotes" for \'escaping\' test)',
			version: '1.2.3',
			documentationURL: 'https://my-new-test-feature.localhost',
			legacyIds: [
				'test'
			],
			currentId: 'ghcr.io/my-org/my-repo/new-test'
		};
		const set: FeatureSet = {
			features: [feature],
			sourceInformation: {
				type: 'oci',
				userFeatureId: 'ghcr.io/my-org/my-repo/test:1',
				userFeatureIdWithoutVersion: 'ghcr.io/my-org/my-repo/test',
				featureRef: {
					registry: 'ghcr.io',
					owner: 'my-org',
					namespace: 'my-org/my-repo',
					path: 'my-org/my-repo/test',
					resource: 'ghcr.io/my-org/my-repo/test',
					id: 'test',
					tag: '1.2.3',
					version: '1.2.3',
				},
				manifest: {
					schemaVersion: 1,
					mediaType: '',
					config: {
						digest: '',
						mediaType: '',
						size: 0,
					},
					layers: [],
				},
				manifestDigest: '',
			}
		};
		const options = [
			'VERSION=latest',
			'OTHEROPTION=true',
		];

		const expected =
`#!/bin/sh
set -e

on_exit () {
	[ $? -eq 0 ] && exit
	echo 'ERROR: Feature "My New Test Feature" (ghcr.io/my-org/my-repo/test) failed to install! Look at the documentation at https://my-new-test-feature.localhost for help troubleshooting this error.'
}

trap on_exit EXIT

echo ===========================================================================
echo '(!) WARNING: This feature has been renamed. Please update the reference in devcontainer.json to "ghcr.io/my-org/my-repo/new-test".'
echo 'Feature       : My New Test Feature'
echo 'Description   : This is an awesome feature (with ""quotes" for '\\''escaping'\\'' test)'
echo 'Id            : ghcr.io/my-org/my-repo/test'
echo 'Version       : 1.2.3'
echo 'Documentation : https://my-new-test-feature.localhost'
echo 'Options       :'
echo '    VERSION=latest
    OTHEROPTION=true'
echo ===========================================================================

set -a
. ../devcontainer-features.builtin.env
. ./devcontainer-features.env
set +a

chmod +x ./install.sh
./install.sh
`;

		const actual = getFeatureInstallWrapperScript(feature, set, options);
		assert.equal(actual, expected);
    });
});

describe('findContainerUsers', () => {
	it('returns last metadata containerUser as containerUser and remoteUser', () => {
		assert.deepEqual(findContainerUsers(configWithRaw([
			{
				containerUser: 'metadataTestUser1',
			},
			{
				containerUser: 'metadataTestUser2',
			},
		]), 'composeTestUser', 'imageTestUser'), {
			containerUser: 'metadataTestUser2',
			remoteUser: 'metadataTestUser2',
		});
	});
	it('returns compose service user as containerUser and remoteUser', () => {
		assert.deepEqual(findContainerUsers(configWithRaw<ImageMetadataEntry[]>([
			{
				remoteEnv: { foo: 'bar' },
			},
			{
				remoteEnv: { bar: 'baz' },
			},
		]), 'composeTestUser', 'imageTestUser'), {
			containerUser: 'composeTestUser',
			remoteUser: 'composeTestUser',
		});
	});
	it('returns image user as containerUser and remoteUser', () => {
		assert.deepEqual(findContainerUsers(configWithRaw<ImageMetadataEntry[]>([
			{
				remoteEnv: { foo: 'bar' },
			},
			{
				remoteEnv: { bar: 'baz' },
			},
		]), undefined, 'imageTestUser'), {
			containerUser: 'imageTestUser',
			remoteUser: 'imageTestUser',
		});
	});
	it('returns last metadata remoteUser', () => {
		assert.deepEqual(findContainerUsers(configWithRaw([
			{
				remoteUser: 'metadataTestUser1',
			},
			{
				remoteUser: 'metadataTestUser2',
			},
		]), 'composeTestUser', 'imageTestUser'), {
			containerUser: 'composeTestUser',
			remoteUser: 'metadataTestUser2',
		});
	});
});

function configWithRaw<T extends DevContainerConfig | ImageMetadataEntry[]>(config: T): SubstitutedConfig<T> {
	return {
		config,
		raw: config,
		substitute: config => config,
	};
}
</file>

<file path="src/test/container-features/featuresCLICommands.test.ts">
import { assert } from 'chai';
import path from 'path';
import { createPlainLog, LogLevel, makeLog } from '../../spec-utils/log';
import { isLocalFile, readLocalFile } from '../../spec-utils/pfs';
import { ExecResult, shellExec } from '../testUtils';
import { getSemanticTags } from '../../spec-node/collectionCommonUtils/publishCommandImpl';
import { getRef, getPublishedTags, getVersionsStrictSorted } from '../../spec-configuration/containerCollectionsOCI';
import { generateFeaturesDocumentation } from '../../spec-node/collectionCommonUtils/generateDocsCommandImpl';
export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));

const pkg = require('../../../package.json');

describe('CLI features subcommands', async function () {
	this.timeout('240s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp2'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`rm -rf ${tmp}/output`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('features test', async function () {

		it('succeeds when using --project-folder', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/simple`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --project-folder ${collectionFolder} --base-image mcr.microsoft.com/devcontainers/base:ubuntu --log-level trace`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			// '--preserve-test-containers' is not set, so containers from this test run should be deleted.
			const expectedCleanupString = /Cleaning up \d test containers/;
			assert.match(result.stdout, expectedCleanupString);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'color'
✅ Passed:      'specific_color_scenario'
✅ Passed:      'color executed twice with randomized options'
✅ Passed:      'hello'
✅ Passed:      'custom_options'
✅ Passed:      'with_external_feature'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);
		});

		it('succeeds when setting --remote-user', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/autogenerated-set-flags`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --project-folder ${collectionFolder} --base-image mcr.microsoft.com/devcontainers/base:ubuntu --remote-user root --log-level trace --preserve-test-containers`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}


			// '--preserve-test-containers' IS set, so containers from this test run should NOT be deleted.
			const expectedCleanupString = /Cleaning up \d test containers/;
			assert.notMatch(result.stdout, expectedCleanupString);

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'hey'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			assert.isTrue(result.stdout.includes('Good day, root'));
		});

		it('succeeds when invoking another script from the same test folder', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/sharing-test-scripts`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --project-folder ${collectionFolder} --base-image mcr.microsoft.com/devcontainers/base:ubuntu --log-level trace`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'util'
✅ Passed:      'some_scenario'
✅ Passed:      'some_scenario_2'
✅ Passed:      'random_scenario'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			assert.isTrue(result.stdout.includes('I AM A DIFFERENT SCRIPT'));
			assert.isTrue(result.stdout.includes('I AM A HELPER SCRIPT FOR A SCENARIO'));
		});

		it('succeeds when passing --filter some_scenario', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/sharing-test-scripts`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --filter some_scenario --project-folder ${collectionFolder} --base-image mcr.microsoft.com/devcontainers/base:ubuntu --log-level trace`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'util'
✅ Passed:      'some_scenario'
✅ Passed:      'some_scenario_2'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			// Assert the output does not contain the random scenario we filtered out
			assert.isFalse(result.stdout.includes('random_scenario'));
		});

		it('succeeds with defaults', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/simple`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --base-image mcr.microsoft.com/devcontainers/base:ubuntu --log-level trace ${collectionFolder}`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'color'
✅ Passed:      'specific_color_scenario'
✅ Passed:      'color executed twice with randomized options'
✅ Passed:      'hello'
✅ Passed:      'custom_options'
✅ Passed:      'with_external_feature'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			assert.isTrue(result.stdout.includes('my favorite color is red'));
			assert.isTrue(result.stdout.includes('hey, vscode?????'));

			assert.isTrue(result.stdout.includes('my favorite color is Magenta'));
			assert.isTrue(result.stdout.includes('Ciao, vscode?????'));
		});

		it('succeeds --skip-autogenerated and subset of features and --skip-duplicated', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/simple`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test -f color --skip-autogenerated --skip-duplicated --log-level trace ${collectionFolder}`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'specific_color_scenario'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			assert.isTrue(result.stdout.includes('my favorite color is green'));

			// Given the '--skip-autogenerated' and '-f color' switches, these cases should not be exercised.
			assert.isFalse(result.stdout.includes('my favorite color is red'));
			assert.isFalse(result.stdout.includes('hey, root?????'));
			assert.isFalse(result.stdout.includes('Ciao, root?????'));
		});

		it('succeeds testing remoteUser', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/remote-user`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --filter add_with_common_utils --projectFolder ${collectionFolder}`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'whoisremoteuser'
✅ Passed:      'add_with_common_utils'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);
		});

		it('succeeds with --global-scenarios-only', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/simple`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --global-scenarios-only --log-level trace ${collectionFolder}`);
				success = true;
			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'custom_options'
✅ Passed:      'with_external_feature'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			// With --global-scenarios-only, 
			// the default values should NOT be included in the test
			// and therefore we should NOT see the following outputs.
			assert.isFalse(result.stdout.includes('my favorite color is red'));
			assert.isFalse(result.stdout.includes('hey, vscode?????!'));

			assert.isTrue(result.stdout.includes('my favorite color is Magenta'));
			assert.isTrue(result.stdout.includes('Ciao, vscode?????'));

		});

		it('successfully reports a failing test', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/failing-test`;
			// shellExec's doNotThrow set to 'true'
			const result = await shellExec(`${cli} features test --base-image mcr.microsoft.com/devcontainers/base:ubuntu --log-level trace ${collectionFolder}`, undefined, undefined, true);

			const expectedTestReport = `  ================== TEST REPORT ==================
❌ Failed:      'hello'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);

			assert.isTrue(result.stderr.includes('❌ testThatShouldFail check failed.'));
			assert.isDefined(result.error);
		});

		// Feature A will crash in its install.sh if B has not already run.
		it('installsAfter B -> A', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/a-installs-after-b`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --log-level trace ${collectionFolder}`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'a'
✅ Passed:      'b'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);
		});

		// Feature B will crash in its install.sh if A has not already run.
		it('installsAfter A -> B', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/b-installs-after-a`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --log-level trace ${collectionFolder}`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'a'
✅ Passed:      'b'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);
		});

		it('lifecycle-hooks', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/lifecycle-hooks`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --log-level trace ${collectionFolder}`);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const onCreateFiredFeatureA = result.stderr.includes('A-ON-CREATE-COMMAND');
			assert.isTrue(onCreateFiredFeatureA);
			const onCreateFiredFeatureB = result.stderr.includes('B-ON-CREATE-COMMAND');
			assert.isTrue(onCreateFiredFeatureB);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'a'
✅ Passed:      'b'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);
		});

		it('installsAfter fruit -> hello', async function () {
			const collectionFolder = `${__dirname}/configs/example-installsAfter`;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} up --workspace-folder ${collectionFolder} --log-level trace`);

			} catch (error) {
				assert.fail('devcontainers up should not throw - installsAfter logic failed');
			}

			const response = JSON.parse(result.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;

			await shellExec(`docker rm -f ${containerId}`);
		});

		// 'hello' contains 'installsAfter' with a 'legacyId: color' https://github.com/codspace/features/blob/main/src/hello/devcontainer-feature.json#L20
		// 'color' is renamed to 'new-color' https://github.com/codspace/features/blob/main/src/new-color/devcontainer-feature.json#L19
		// .devcontainer.json
		// "features": {
		// 	  "ghcr.io/codspace/features/hello:1": {},
		// 	  "ghcr.io/codspace/features/new-color:1": {}
		// }
		it('installsAfter hello -> new-color (back compat check for legacyIds)', async function () {
			const collectionFolder = `${__dirname}/configs/example-legacyIds`;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} up --workspace-folder ${collectionFolder} --log-level trace`);

			} catch (error) {
				assert.fail('devcontainers up should not throw - installsAfter logic failed');
			}

			const response = JSON.parse(result.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;

			await shellExec(`docker rm -f ${containerId}`);
		});

		// 'flower' contains 'installsAfter' with new ID 'new-color' https://github.com/codspace/features/blob/main/src/flower/devcontainer-feature.json#L19
		// 'color' is renamed to 'new-color' https://github.com/codspace/features/blob/main/src/new-color/devcontainer-feature.json#L19
		// .devcontainer.json
		// "features": {
		// 	  "ghcr.io/codspace/features/flower:1": {},
		// 	  "ghcr.io/codspace/features/color:1": {}
		// }
		it('installsAfter flower -> color (forward compat check for legacyIds)', async function () {
			const collectionFolder = `${__dirname}/configs/example-legacyIds-2`;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} up --workspace-folder ${collectionFolder} --log-level trace`);

			} catch (error) {
				assert.fail('devcontainers up should not throw - installsAfter logic failed');
			}

			const response = JSON.parse(result.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;

			await shellExec(`docker rm -f ${containerId}`);
		});

		it('succeeds testing a scenario with a Dockerfile', async function () {
			const collectionFolder = `${__dirname}/example-v2-features-sets/dockerfile-scenario-test`;
			let success = false;
			let result: ExecResult | undefined = undefined;
			try {
				result = await shellExec(`${cli} features test --project-folder ${collectionFolder} --skip-autogenerated --log-level trace `);
				success = true;

			} catch (error) {
				assert.fail('features test sub-command should not throw');
			}

			assert.isTrue(success);
			assert.isDefined(result);

			const expectedTestReport = `  ================== TEST REPORT ==================
✅ Passed:      'smiling'
✅ Passed:      'frowning'
✅ Passed:      'frowning_with_a_dockerfile'`;
			const hasExpectedTestReport = result.stdout.includes(expectedTestReport);
			assert.isTrue(hasExpectedTestReport);
		});
	});

	describe('features package', function () {

		it('features package subcommand by collection', async function () {
			const srcFolder = `${__dirname}/example-v2-features-sets/simple/src`;
			let success = false;
			try {
				await shellExec(`${cli} features package -o ${tmp}/output/test01 -f --log-level trace  ${srcFolder} `);
				success = true;
			} catch (error) {
				assert.fail('features package sub-command should not throw');
			}
			assert.isTrue(success);

			const colorTgzExists = await isLocalFile(`${tmp}/output/test01/devcontainer-feature-color.tgz`);
			assert.isTrue(colorTgzExists);
			const tgzArchiveContentsColor = await shellExec(`tar -tvf ${tmp}/output/test01/devcontainer-feature-color.tgz`);
			assert.match(tgzArchiveContentsColor.stdout, /devcontainer-feature.json/);
			assert.match(tgzArchiveContentsColor.stdout, /install.sh/);

			const helloTgzExists = await isLocalFile(`${tmp}/output/test01/devcontainer-feature-hello.tgz`);
			assert.isTrue(helloTgzExists);
			const tgzArchiveContentsHello = await shellExec(`tar -tvf ${tmp}/output/test01/devcontainer-feature-hello.tgz`);
			assert.match(tgzArchiveContentsHello.stdout, /devcontainer-feature.json/);
			assert.match(tgzArchiveContentsHello.stdout, /install.sh/);

			const collectionFileExists = await isLocalFile(`${tmp}/output/test01/devcontainer-collection.json`);
			const json = JSON.parse((await readLocalFile(`${tmp}/output/test01/devcontainer-collection.json`)).toString());
			assert.strictEqual(json.features.length, 2);
			assert.isTrue(collectionFileExists);
		});

		it('features package subcommand by single feature', async function () {
			const singleFeatureFolder = `${__dirname}/example-v2-features-sets/simple/src/color`;
			let success = false;
			try {
				await shellExec(`${cli} features package -o ${tmp}/output/test02 -f --log-level trace  ${singleFeatureFolder} `);
				success = true;
			} catch (error) {
				assert.fail('features package sub-command should not throw');
			}
			assert.isTrue(success);

			const colorTgzExists = await isLocalFile(`${tmp}/output/test02/devcontainer-feature-color.tgz`);
			assert.isTrue(colorTgzExists);
			const tgzArchiveContentsColor = await shellExec(`tar -tvf ${tmp}/output/test02/devcontainer-feature-color.tgz`);
			assert.match(tgzArchiveContentsColor.stdout, /devcontainer-feature.json/);
			assert.match(tgzArchiveContentsColor.stdout, /install.sh/);

			const collectionFileExists = await isLocalFile(`${tmp}/output/test02/devcontainer-collection.json`);
			assert.isTrue(collectionFileExists);
			const json = JSON.parse((await readLocalFile(`${tmp}/output/test02/devcontainer-collection.json`)).toString());
			assert.strictEqual(json.features.length, 1);
			assert.isTrue(collectionFileExists);
		});
	});
});

describe('test function getSermanticVersions', () => {

	it('should generate correct semantic versions for first publishing', async () => {
		let version = '1.0.0';
		let publishedTags: string[] = [];
		let expectedSemVer = ['1', '1.0', '1.0.0', 'latest'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.equal(semanticVersions?.toString(), expectedSemVer.toString());
	});

	it('should generate correct semantic versions for publishing new patch version', async () => {
		let version = '1.0.1';
		let publishedTags = ['1', '1.0', '1.0.0', 'latest'];
		let expectedSemVer = ['1', '1.0', '1.0.1', 'latest'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.equal(semanticVersions?.toString(), expectedSemVer.toString());
	});

	it('should generate correct semantic versions for publishing new minor version', async () => {
		let version = '1.1.0';
		let publishedTags = ['1', '1.0', '1.0.0', '1.0.1', 'latest'];
		let expectedSemVer = ['1', '1.1', '1.1.0', 'latest'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.equal(semanticVersions?.toString(), expectedSemVer.toString());
	});

	it('should generate correct semantic versions for publishing new major version', async () => {
		let version = '2.0.0';
		let publishedTags = ['1', '1.0', '1.0.0', 'latest'];
		let expectedSemVer = ['2', '2.0', '2.0.0', 'latest'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.equal(semanticVersions?.toString(), expectedSemVer.toString());
	});

	it('should generate correct semantic versions for publishing hotfix patch version', async () => {
		let version = '1.0.2';
		let publishedTags = ['1', '1.0', '1.0.0', '1.0.1', '1.1', '1.1.0', '2', '2.0', '2.0.0', 'latest'];
		let expectedSemVer = ['1.0', '1.0.2'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.equal(semanticVersions?.toString(), expectedSemVer.toString());
	});

	it('should generate correct semantic versions for publishing hotfix minor version', async () => {
		let version = '1.0.1';
		let publishedTags = ['1', '1.0', '1.0.0', '2', '2.0', '2.0.0', 'latest'];
		let expectedSemVer = ['1', '1.0', '1.0.1'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.equal(semanticVersions?.toString(), expectedSemVer.toString());
	});

	it('should return undefined for already published version', async () => {
		let version = '1.0.1';
		let publishedTags = ['1', '1.0', '1.0.0', '1.0.1', '2', '2.0', '2.0.0', 'latest'];

		let semanticVersions = getSemanticTags(version, publishedTags, output);
		assert.isUndefined(semanticVersions);
	});
});

describe('test functions getVersionsStrictSorted and getPublishedTags', async () => {
	it('should list published versions', async () => {
		const resource = 'ghcr.io/devcontainers/features/node';
		const featureRef = getRef(output, resource);
		if (!featureRef) {
			assert.fail('featureRef should not be undefined');
		}
		const publishedTags = await getPublishedTags({ output, env: process.env }, featureRef) ?? [];
		assert.includeMembers(publishedTags, ['1', '1.0', '1.0.0', 'latest']);
	});

	it('should list published versions in an advanced case', async () => {
		// https://github.com/codspace/versioning/pkgs/container/versioning%2Ffoo/versions
		const resource = 'ghcr.io/codspace/versioning/foo';
		const ref = getRef(output, resource);
		if (!ref) {
			assert.fail('ref should not be undefined');
		}
		const versionsList = await getVersionsStrictSorted({ output, env: process.env }, ref) ?? [];
		console.log(versionsList);
		const expectedVersions = [
			'0.0.0',
			'0.0.1',
			'0.0.2',
			'0.1.0',
			'0.2.0',
			'0.3.0',
			'0.3.1',
			'0.3.2',
			'0.3.3',
			'0.3.4',
			'0.3.5',
			'0.3.6',
			'0.3.7',
			'0.3.8',
			'0.3.9',
			'0.3.10',
			'0.3.11',
			'0.3.12',
			'0.4.0',
			'1.0.0',
			'1.1.0',
			'2.0.0',
			'2.1.0',
			'2.2.0',
			'2.2.1',
			'2.3.0',
			'2.4.0',
			'2.5.0',
			'2.6.0',
			'2.7.0',
			'2.8.0',
			'2.9.0',
			'2.10.0',
			'2.10.1',
			'2.11.0',
			'2.11.1',
		];
		// Order matters here
		assert.deepStrictEqual(versionsList, expectedVersions);


		const publishedTags = await getPublishedTags({ output, env: process.env }, ref) ?? [];
		const expectedTags = [
			'latest',
			'0',
			'1',
			'2',
			'0.0',
			'0.0.0',
			'0.0.1',
			'0.0.2',
			'0.1',
			'0.1.0',
			'0.2',
			'0.2.0',
			'0.3',
			'0.3.0',
			'0.3.1',
			'0.3.10',
			'0.3.11',
			'0.3.12',
			'0.3.2',
			'0.3.3',
			'0.3.4',
			'0.3.5',
			'0.3.6',
			'0.3.7',
			'0.3.8',
			'0.3.9',
			'0.4',
			'0.4.0',
			'1.0',
			'1.0.0',
			'1.1',
			'1.1.0',
			'2.0',
			'2.0.0',
			'2.1',
			'2.1.0',
			'2.10',
			'2.10.0',
			'2.10.1',
			'2.11',
			'2.11.0',
			'2.11.1',
			'2.2',
			'2.2.0',
			'2.2.1',
			'2.3',
			'2.3.0',
			'2.4',
			'2.4.0',
			'2.5',
			'2.5.0',
			'2.6',
			'2.6.0',
			'2.7',
			'2.7.0',
			'2.8',
			'2.8.0',
			'2.9',
			'2.9.0'
		];
		// Order is not guaranteed here (up to however the registry returns the tags)
		assert.strictEqual(publishedTags.length, expectedTags.length);
		assert.includeMembers(publishedTags, expectedTags);

	});

});

describe('tests generateFeaturesDocumentation()', async function () {
	this.timeout('120s');

	const projectFolder = `${__dirname}/example-v2-features-sets/simple/src`;

	after('clean', async () => {
		await shellExec(`rm ${projectFolder}/**/README.md`);
	});

	it('tests generate-docs', async function () {
		await generateFeaturesDocumentation(projectFolder, 'ghcr.io', 'devcontainers/cli', 'devcontainers', 'cli', output);

		const colorDocsExists = await isLocalFile(`${projectFolder}/color/README.md`);
		assert.isTrue(colorDocsExists);

		const helloDocsExists = await isLocalFile(`${projectFolder}/hello/README.md`);
		assert.isTrue(helloDocsExists);

		const invalidDocsExists = await isLocalFile(`${projectFolder}/not-a-feature/README.md`);
		assert.isFalse(invalidDocsExists);
	});
});
</file>

<file path="src/test/container-features/generateFeaturesConfig.test.ts">
import { assert } from 'chai';
import { generateFeaturesConfig, getFeatureLayers, FeatureSet } from '../../spec-configuration/containerFeaturesConfiguration';
import { createPlainLog, LogLevel, makeLog } from '../../spec-utils/log';
import * as path from 'path';
import * as process from 'process';
import * as os from 'os';
import * as crypto from 'crypto';
import { mkdirpLocal } from '../../spec-utils/pfs';
import { DevContainerConfig } from '../../spec-configuration/configuration';
import { URI } from 'vscode-uri';
import { getLocalCacheFolder } from '../../spec-node/utils';
import { shellExec } from '../testUtils';
import { getEntPasswdShellCommand } from '../../spec-common/commonUtils';

export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));

// Test fetching/generating the devcontainer-features.json config
describe('validate generateFeaturesConfig()', function () {

    // Setup
    const env = { 'SOME_KEY': 'SOME_VAL' };
    const platform = process.platform;
	const cacheFolder = path.join(os.tmpdir(), `devcontainercli-test-${crypto.randomUUID()}`);
    const params = { extensionPath: '', cwd: '', output, env, cacheFolder, persistedFolder: '', skipFeatureAutoMapping: false, platform };

    it('should correctly return a featuresConfig with v2 local features', async function () {
        const version = 'unittest';
        const tmpFolder: string = path.join(await getLocalCacheFolder(), 'container-features', `${version}-${Date.now()}`);
        await mkdirpLocal(tmpFolder);

        const devcontainerFolder = path.resolve(tmpFolder, '.devcontainer');
        await mkdirpLocal(devcontainerFolder);
        await shellExec(`cp -R ./src/test/container-features/example-v2-features-sets/simple/src/* ${devcontainerFolder}`);

        const config: DevContainerConfig = {
            configFilePath: URI.from({ 'path': path.resolve(devcontainerFolder, 'devcontainer.json'), scheme: 'file' }),
            dockerFile: '.',
            features: {
                './color': {
                    'favorite': 'gold'
                },
                './hello': {
                    'greeting': 'howdy'
                },
            },
        };
        
        const featuresConfig = await generateFeaturesConfig({ ...params, cwd: tmpFolder }, tmpFolder, config, {});
        if (!featuresConfig) {
            assert.fail();
        }

        assert.strictEqual(featuresConfig?.featureSets.length, 2);

        const first = featuresConfig.featureSets[0].features.find((f) => f.id === 'color');
        assert.exists(first);

        const second = featuresConfig.featureSets[1].features.find((f) => f.id === 'hello');
        assert.exists(second);

        assert.isObject(first?.value);
        assert.isObject(second?.value);

        // -- Test containerFeatures.ts helper functions

        // getFeatureLayers
        const actualLayers = getFeatureLayers(featuresConfig, 'testContainerUser', 'testRemoteUser');
        const expectedLayers = `RUN \\
echo "_CONTAINER_USER_HOME=$(${getEntPasswdShellCommand('testContainerUser')} | cut -d: -f6)" >> /tmp/dev-container-features/devcontainer-features.builtin.env && \\
echo "_REMOTE_USER_HOME=$(${getEntPasswdShellCommand('testRemoteUser')} | cut -d: -f6)" >> /tmp/dev-container-features/devcontainer-features.builtin.env


COPY --chown=root:root --from=dev_containers_feature_content_source /tmp/build-features/color_0 /tmp/dev-container-features/color_0
RUN chmod -R 0755 /tmp/dev-container-features/color_0 \\
&& cd /tmp/dev-container-features/color_0 \\
&& chmod +x ./devcontainer-features-install.sh \\
&& ./devcontainer-features-install.sh


COPY --chown=root:root --from=dev_containers_feature_content_source /tmp/build-features/hello_1 /tmp/dev-container-features/hello_1
RUN chmod -R 0755 /tmp/dev-container-features/hello_1 \\
&& cd /tmp/dev-container-features/hello_1 \\
&& chmod +x ./devcontainer-features-install.sh \\
&& ./devcontainer-features-install.sh

`;
        assert.strictEqual(actualLayers, expectedLayers);
    });

    it('should correctly return featuresConfig with customizations', async function () {
        this.timeout('20s');
        const version = 'unittest';
        const tmpFolder: string = path.join(await getLocalCacheFolder(), 'container-features', `${version}-${Date.now()}`);
        await mkdirpLocal(tmpFolder);

        const config: DevContainerConfig = {
            configFilePath: URI.from({ 'path': './.devcontainer/devcontainer.json', scheme: 'file' }),
            dockerFile: '.',
            features: {
                node: {
                    'version': 'none'
                },
                'ghcr.io/devcontainers/features/docker-in-docker:1': {
                    'version': 'latest'
                },
                'ghcr.io/devcontainers/features/java:1': {
                    'version': 'none'
                }
            },
        };

        params.skipFeatureAutoMapping = true;

        const featuresConfig = await generateFeaturesConfig(params, tmpFolder, config, {});
        if (!featuresConfig) {
            assert.fail();
        }

        assert.strictEqual(featuresConfig?.featureSets.length, 3);

        const dind = featuresConfig.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'docker-in-docker');
        assert.exists(dind);
        const dindExtensions = dind?.features[0]?.customizations?.vscode?.extensions || [''];
        assert.includeMembers(dindExtensions, ['ms-azuretools.vscode-docker']);

        const node = featuresConfig.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'node');
        assert.exists(node);
        const nodeExtensions = node?.features[0]?.customizations?.vscode?.extensions || [''];
        assert.includeMembers(nodeExtensions, ['dbaeumer.vscode-eslint']);

        const java = featuresConfig.featureSets.find((f: FeatureSet) => f?.features[0]?.id === 'java');
        assert.exists(java);
        const javaExtensions = java?.features[0]?.customizations?.vscode?.extensions || [''];
        assert.includeMembers(javaExtensions, ['vscjava.vscode-java-pack']);
        const javaSettings = java?.features[0]?.customizations?.vscode?.settings;
        assert.isObject(javaSettings);
    });
});
</file>

<file path="src/test/container-features/lifecycleHooks.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { assert } from 'chai';
import * as path from 'path';
import { Feature } from '../../spec-configuration/containerFeaturesConfiguration';
import { devContainerDown, devContainerStop, devContainerUp, shellExec } from '../testUtils';

const pkg = require('../../../package.json');

describe('Feature lifecycle hooks', function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp5'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('lifecycle-hooks-inline-commands', () => {
		const testFolder = `${__dirname}/configs/lifecycle-hooks-inline-commands`;

		describe('devcontainer up', () => {
			let containerId: string | null = null;

			before(async () => {
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
				containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId;
			});

			after(async () => {
				await devContainerDown({ containerId });
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
			});

			it('marker files should exist, be executed in stable order, and hooks should postStart/attach should trigger on a resume', async () => {

				{
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
 					assert.strictEqual(res.error, null);

					const outputOfExecCommand = res.stdout;
					console.log(outputOfExecCommand);

					assert.match(outputOfExecCommand, /0.panda.onCreateCommand.testMarker/);
					assert.match(outputOfExecCommand, /3.panda.updateContentCommand.testMarker/);
					assert.match(outputOfExecCommand, /6.panda.postCreateCommand.testMarker/);
					assert.match(outputOfExecCommand, /9.panda.postStartCommand.testMarker/);
					assert.match(outputOfExecCommand, /12.panda.postAttachCommand.testMarker/);

					assert.match(outputOfExecCommand, /1.tiger.onCreateCommand.testMarker/);
					assert.match(outputOfExecCommand, /4.tiger.updateContentCommand.testMarker/);
					assert.match(outputOfExecCommand, /7.tiger.postCreateCommand.testMarker/);
					assert.match(outputOfExecCommand, /10.tiger.postStartCommand.testMarker/);
					assert.match(outputOfExecCommand, /13.tiger.postAttachCommand.testMarker/);

					assert.match(outputOfExecCommand, /2.devContainer.onCreateCommand.testMarker/);
					assert.match(outputOfExecCommand, /5.devContainer.updateContentCommand.testMarker/);
					assert.match(outputOfExecCommand, /8.devContainer.postCreateCommand.testMarker/);
					assert.match(outputOfExecCommand, /11.devContainer.postStartCommand.testMarker/);
					assert.match(outputOfExecCommand, /14.devContainer.postAttachCommand.testMarker/);

					// This shouldn't have happened _yet_.
					assert.notMatch(outputOfExecCommand, /15.panda.postStartCommand.testMarker/);
				}

				// Stop the container.
				await devContainerStop({ containerId });

				{
					// Attempt to bring the same container up, which should just re-run the postStart and postAttach hooks
					const resume = await devContainerUp(cli, testFolder, { logLevel: 'trace' });
					assert.equal(resume.containerId, containerId); // Restarting the same container.
					assert.equal(resume.outcome, 'success');

					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
					assert.strictEqual(res.error, null);

					const outputOfExecCommand = res.stdout;
					console.log(outputOfExecCommand);

					assert.match(outputOfExecCommand, /15.panda.postStartCommand.testMarker/);
					assert.match(outputOfExecCommand, /16.tiger.postStartCommand.testMarker/);
					assert.match(outputOfExecCommand, /17.devContainer.postStartCommand.testMarker/);
					assert.match(outputOfExecCommand, /18.panda.postAttachCommand.testMarker/);
					assert.match(outputOfExecCommand, /19.tiger.postAttachCommand.testMarker/);
					assert.match(outputOfExecCommand, /20.devContainer.postAttachCommand.testMarker/);
				}


			});
		});
	});

	describe('lifecycle-hooks-inline-commands with secrets', () => {
		const testFolder = `${__dirname}/configs/lifecycle-hooks-inline-commands`;

		describe('devcontainer up with secrets', () => {
			let containerId: string | null = null;

			before(async () => {
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
				const secrets = {
					'SECRET1': 'SecretValue1',
				};
				await shellExec(`printf '${JSON.stringify(secrets)}' > ${testFolder}/test-secrets-temp.json`, undefined, undefined, true);
				containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace', extraArgs: `--secrets-file ${testFolder}/test-secrets-temp.json` })).containerId;
			});

			after(async () => {
				await devContainerDown({ containerId });
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
				await shellExec(`rm -f ${testFolder}/test-secrets-temp.json`, undefined, undefined, true);
			});

			it('secrets should be availale to the lifecycle hooks during up command', async () => {
				{
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
					assert.strictEqual(res.error, null);

					const actualMarkerFiles = res.stdout;
					console.log(actualMarkerFiles);

					const expectedTestMarkerFiles = [
						'0.panda.onCreateCommand.testMarker',
						'3.panda.updateContentCommand.testMarker',
						'6.panda.postCreateCommand.testMarker',
						'9.panda.postStartCommand.testMarker',
						'12.panda.postAttachCommand.testMarker',

						'1.tiger.onCreateCommand.testMarker',
						'4.tiger.updateContentCommand.testMarker',
						'7.tiger.postCreateCommand.testMarker',
						'10.tiger.postStartCommand.testMarker',
						'13.tiger.postAttachCommand.testMarker',

						'2.devContainer.onCreateCommand.testMarker',
						'5.devContainer.updateContentCommand.testMarker',
						'8.devContainer.postCreateCommand.testMarker',
						'11.devContainer.postStartCommand.testMarker',
						'14.devContainer.postAttachCommand.testMarker',
					];

					for (const file of expectedTestMarkerFiles) {
						assert.match(actualMarkerFiles, new RegExp(file));

						// assert file contents to ensure secrets were available to the command
						const catResp = await shellExec(`${cli} exec --workspace-folder ${testFolder} cat ${file}`);
						assert.strictEqual(catResp.error, null);
						assert.match(catResp.stdout, /SECRET1=SecretValue1/);
					}

					// This shouldn't have happened _yet_.
					assert.notMatch(actualMarkerFiles, /15.panda.postStartCommand.testMarker/);
				}

				// Stop the container.
				await devContainerStop({ containerId });

				{
					// Attempt to bring the same container up, which should just re-run the postStart and postAttach hooks
					const resume = await devContainerUp(cli, testFolder, { logLevel: 'trace', extraArgs: `--secrets-file ${testFolder}/test-secrets-temp.json` });
					assert.equal(resume.containerId, containerId); // Restarting the same container.
					assert.equal(resume.outcome, 'success');

					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
					assert.strictEqual(res.error, null);

					const actualMarkerFiles = res.stdout;
					console.log(actualMarkerFiles);

					const expectedTestMarkerFiles = [
						'15.panda.postStartCommand.testMarker',
						'16.tiger.postStartCommand.testMarker',
						'17.devContainer.postStartCommand.testMarker',
						'18.panda.postAttachCommand.testMarker',
						'19.tiger.postAttachCommand.testMarker',
						'20.devContainer.postAttachCommand.testMarker',
					];

					for (const file of expectedTestMarkerFiles) {
						assert.match(actualMarkerFiles, new RegExp(file));

						// assert file contents to ensure secrets were available to the command
						const catResp = await shellExec(`${cli} exec --workspace-folder ${testFolder} cat ${file}`);
						assert.strictEqual(catResp.error, null);
						assert.match(catResp.stdout, /SECRET1=SecretValue1/);
					}
				}
			});
		});

		describe('devcontainer run-user-commands with secrets', () => {
			let containerId: string | null = null;

			before(async () => {
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
				const secrets = {
					'SECRET1': 'SecretValue1',
					'MASK_IT': 'cycle',
				};
				await shellExec(`printf '${JSON.stringify(secrets)}' > ${testFolder}/test-secrets-temp.json`, undefined, undefined, true);
				containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace', extraArgs: `--secrets-file ${testFolder}/test-secrets-temp.json --skip-post-create` })).containerId;
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
			});

			after(async () => {
				await devContainerDown({ containerId });
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
				await shellExec(`rm -f ${testFolder}/test-secrets-temp.json`, undefined, undefined, true);
			});

			it('secrets should be availale to the lifecycle hooks during run-user-commands command', async () => {
				{
					const expectedTestMarkerFiles = [
						'0.panda.onCreateCommand.testMarker',
						'3.panda.updateContentCommand.testMarker',
						'6.panda.postCreateCommand.testMarker',
						'9.panda.postStartCommand.testMarker',
						'12.panda.postAttachCommand.testMarker',

						'1.tiger.onCreateCommand.testMarker',
						'4.tiger.updateContentCommand.testMarker',
						'7.tiger.postCreateCommand.testMarker',
						'10.tiger.postStartCommand.testMarker',
						'13.tiger.postAttachCommand.testMarker',

						'2.devContainer.onCreateCommand.testMarker',
						'5.devContainer.updateContentCommand.testMarker',
						'8.devContainer.postCreateCommand.testMarker',
						'11.devContainer.postStartCommand.testMarker',
						'14.devContainer.postAttachCommand.testMarker',
					];

					// Marker files should not exist, as we are yet to run the `run-user-commands` command
					const lsResBefore = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
					assert.strictEqual(lsResBefore.error, null);
					const actualMarkerFilesBefore = lsResBefore.stdout;
					console.log(actualMarkerFilesBefore);
					for (const file of expectedTestMarkerFiles) {
						assert.notMatch(actualMarkerFilesBefore, new RegExp(file));
					}

					// Run `run-user-commands` command with secrets
					const res = await shellExec(`${cli} run-user-commands --workspace-folder ${testFolder} --log-level trace --secrets-file ${testFolder}/test-secrets-temp.json`);
					assert.strictEqual(res.error, null);

					// Assert marker files
					const lsResAfter = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
					assert.strictEqual(lsResAfter.error, null);
					const actualMarkerFilesAfter = lsResAfter.stdout;
					console.log(actualMarkerFilesAfter);
					for (const file of expectedTestMarkerFiles) {
						assert.match(actualMarkerFilesAfter, new RegExp(file));

						// assert file contents to ensure secrets were available to the command
						const catResp = await shellExec(`${cli} exec --workspace-folder ${testFolder} cat ${file}`);
						assert.strictEqual(catResp.error, null);
						assert.match(catResp.stdout, /SECRET1=SecretValue1/);
					}

					// assert secret masking
					// We log the string `LifecycleCommandExecutionMap: ...` from CLI. Since the word `cycle` is specified as a secret here, that should get masked
					const logs = res.stderr;
					assert.match(logs, /Life\*\*\*\*\*\*\*\*CommandExecutionMap: /);
					assert.notMatch(logs, /LifecycleCommandExecutionMap: /);
				}
			});
		});
	});

	describe('lifecycle-hooks-alternative-order', () => {
		// This is the same test as 'lifecycle-hooks-inline-commands'
		// but with the the 'installsAfter' order changed (tiger -> panda -> devContainer).

		let containerId: string | null = null;
		const testFolder = `${__dirname}/configs/temp_lifecycle-hooks-alternative-order`;

		before(async () => {
			await shellExec(`rm -rf ${testFolder}`, undefined, undefined, true);
			await shellExec(`mkdir -p ${testFolder}`);
			await shellExec(`bash -c 'cp -r . ${testFolder}'`, { cwd: `${__dirname}/configs/lifecycle-hooks-inline-commands` });

			// Read in the JSON from the two Feature's devcontainer-feature.json
			const pandaFeatureJson: Feature = JSON.parse((await shellExec(`cat ${testFolder}/.devcontainer/panda/devcontainer-feature.json`)).stdout);
			const tigerFeatureJson: Feature = JSON.parse((await shellExec(`cat ${testFolder}/.devcontainer/tiger/devcontainer-feature.json`)).stdout);

			// Remove the installsAfter from the tiger's devcontainer-feature.json and add it to the panda's devcontainer-feature.json
			delete tigerFeatureJson.installsAfter;
			pandaFeatureJson.installsAfter = ['./tiger'];

			// Write the JSON back to the two Feature's devcontainer-feature.json
			await shellExec(`echo '${JSON.stringify(pandaFeatureJson)}' > ${testFolder}/.devcontainer/panda/devcontainer-feature.json`);
			await shellExec(`echo '${JSON.stringify(tigerFeatureJson)}' > ${testFolder}/.devcontainer/tiger/devcontainer-feature.json`);

			containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId;
		});

		after(async () => {
			await devContainerDown({ containerId });
			await shellExec(`rm -rf ${testFolder}`, undefined, undefined, true);
		});

		it('marker files should exist and executed in stable order', async () => {
			const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
			assert.strictEqual(res.error, null);

			const outputOfExecCommand = res.stdout;
			console.log(outputOfExecCommand);

			assert.match(outputOfExecCommand, /0.tiger.onCreateCommand.testMarker/);
			assert.match(outputOfExecCommand, /3.tiger.updateContentCommand.testMarker/);
			assert.match(outputOfExecCommand, /6.tiger.postCreateCommand.testMarker/);
			assert.match(outputOfExecCommand, /9.tiger.postStartCommand.testMarker/);
			assert.match(outputOfExecCommand, /12.tiger.postAttachCommand.testMarker/);

			assert.match(outputOfExecCommand, /1.panda.onCreateCommand.testMarker/);
			assert.match(outputOfExecCommand, /4.panda.updateContentCommand.testMarker/);
			assert.match(outputOfExecCommand, /7.panda.postCreateCommand.testMarker/);
			assert.match(outputOfExecCommand, /10.panda.postStartCommand.testMarker/);
			assert.match(outputOfExecCommand, /13.panda.postAttachCommand.testMarker/);

			assert.match(outputOfExecCommand, /2.devContainer.onCreateCommand.testMarker/);
			assert.match(outputOfExecCommand, /5.devContainer.updateContentCommand.testMarker/);
			assert.match(outputOfExecCommand, /8.devContainer.postCreateCommand.testMarker/);
			assert.match(outputOfExecCommand, /11.devContainer.postStartCommand.testMarker/);
			assert.match(outputOfExecCommand, /14.devContainer.postAttachCommand.testMarker/);
		});

	});

	describe('lifecycle-hooks-resume-existing-container', () => {
		let containerId: string | null = null;
		const testFolder = `${__dirname}/configs/lifecycle-hooks-resume-existing-container`;

		// Clean up
		before(async () => {
			await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
			containerId = (await devContainerUp(cli, testFolder, { 'logLevel': 'trace' })).containerId;
		});

		// Ensure clean after running.
		after(async () => {
			await devContainerDown({ containerId, doNotThrow: true });
			await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
		});

		it('the appropriate lifecycle hooks are executed when resuming an existing container', async () => {

			await devContainerStop({ containerId });
			// Attempt to bring the same container up, which should just re-run the postStart and postAttach hooks
			const resume = await devContainerUp(cli, testFolder, { logLevel: 'trace' });
			assert.equal(resume.containerId, containerId); // Restarting the same container.
			assert.equal(resume.outcome, 'success');

			const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
			assert.strictEqual(res.error, null);

			const outputOfExecCommand = res.stdout;
			console.log(outputOfExecCommand);

			assert.match(outputOfExecCommand, /0.hippo.postStartCommand.testMarker/);
			assert.match(outputOfExecCommand, /1.hippo.postAttachCommand.testMarker/);
			assert.match(outputOfExecCommand, /2.hippo.postStartCommand.testMarker/);
			assert.match(outputOfExecCommand, /3.hippo.postAttachCommand.testMarker/);
		});
	});

	describe('lifecycle-hooks-advanced', () => {

		describe(`devcontainer up`, () => {
			let containerId: string | null = null;
			let containerUpStandardError: string;
			const testFolder = `${__dirname}/configs/lifecycle-hooks-advanced`;

			before(async () => {
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
				const res = await devContainerUp(cli, testFolder, { 'logLevel': 'trace' });
				containerId = res.containerId;
				containerUpStandardError = res.stderr;
			});

			after(async () => {
				await devContainerDown({ containerId });
				await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
			});

			it('executes lifecycle hooks in advanced cases', async () => {
				const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ls -altr`);
				assert.strictEqual(res.error, null);

				const outputOfExecCommand = res.stdout;
				console.log(outputOfExecCommand);

				// Executes the command that was installed by each Feature's 'install.sh'.
				// The command is installed to a directory on the $PATH so it can be executed from the lifecycle script.
				assert.match(outputOfExecCommand, /i-am-a-rabbit.postStartCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the postCreateCommand from devcontainer.json/);

				assert.match(outputOfExecCommand, /i-am-an-otter.postAttachCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the postAttachCommand from devcontainer.json/);

				assert.match(outputOfExecCommand, /helperScript.devContainer.parallel_postCreateCommand_1.testMarker/);
				assert.match(containerUpStandardError, /Running parallel1 of postCreateCommand from devcontainer.json.../);

				assert.match(outputOfExecCommand, /helperScript.devContainer.parallel_postCreateCommand_2.testMarker/);
				assert.match(containerUpStandardError, /Running parallel2 of postCreateCommand from devcontainer.json.../);

				// Since lifecycle scripts are executed relative to the workspace folder,
				// to run a script bundled with the Feature, the Feature author needs to copy that script to a persistent directory.
				// These Features' install scripts do that.

				// -- 'Rabbit' Feature
				assert.match(outputOfExecCommand, /helperScript.rabbit.onCreateCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the onCreateCommand from Feature '\.\/rabbit'/);

				assert.match(outputOfExecCommand, /helperScript.rabbit.updateContentCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the updateContentCommand from Feature '\.\/rabbit'/);

				assert.match(outputOfExecCommand, /helperScript.rabbit.postStartCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the postStartCommand from Feature '\.\/rabbit'/);

				assert.match(outputOfExecCommand, /helperScript.rabbit.postAttachCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the postAttachCommand from Feature '\.\/rabbit'/);

				assert.match(outputOfExecCommand, /helperScript.rabbit.parallel_postCreateCommand_1.testMarker/);
				assert.match(containerUpStandardError, /Running parallel1 of postCreateCommand from Feature '\.\/rabbit'/);

				assert.match(outputOfExecCommand, /helperScript.rabbit.parallel_postCreateCommand_2.testMarker/);
				assert.match(containerUpStandardError, /Running parallel2 of postCreateCommand from Feature '\.\/rabbit'/);


				// -- 'Otter' Feature
				assert.match(outputOfExecCommand, /helperScript.otter.onCreateCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the onCreateCommand from Feature '\.\/otter'/);

				assert.match(outputOfExecCommand, /helperScript.otter.updateContentCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the updateContentCommand from Feature '\.\/otter'/);

				assert.match(outputOfExecCommand, /helperScript.otter.postStartCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the postStartCommand from Feature '\.\/otter'/);

				assert.match(outputOfExecCommand, /helperScript.otter.postAttachCommand.testMarker/);
				assert.match(containerUpStandardError, /Running the postAttachCommand from Feature '\.\/otter'/);

				assert.match(outputOfExecCommand, /helperScript.otter.parallel_postCreateCommand_1.testMarker/);
				assert.match(containerUpStandardError, /Running parallel1 of postCreateCommand from Feature '\.\/otter'/);

				assert.match(outputOfExecCommand, /helperScript.otter.parallel_postCreateCommand_2.testMarker/);
				assert.match(containerUpStandardError, /Running parallel2 of postCreateCommand from Feature '\.\/otter'/);

				// -- Assert that at no point did logging the lifecycle hook fail.
				assert.notMatch(containerUpStandardError, /Running the (.*) from \?\?\?/);
			});
		});
	});
});
</file>

<file path="src/test/container-features/lockfile.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import * as semver from 'semver';
import { shellExec } from '../testUtils';
import { cpLocal, readLocalFile, rmLocal } from '../../spec-utils/pfs';

const pkg = require('../../../package.json');

describe('Lockfile', function () {
	this.timeout('240s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	it('write lockfile', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile');

		const lockfilePath = path.join(workspaceFolder, '.devcontainer-lock.json');
		await rmLocal(lockfilePath, { force: true });

		const res = await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		const actual = await readLocalFile(lockfilePath);
		const expected = await readLocalFile(path.join(workspaceFolder, 'expected.devcontainer-lock.json'));
		assert.equal(actual.toString(), expected.toString());
	});

	it('lockfile with dependencies', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-dependson');

		const lockfilePath = path.join(workspaceFolder, '.devcontainer-lock.json');
		await rmLocal(lockfilePath, { force: true });

		const res = await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		const actual = await readLocalFile(lockfilePath);
		const expected = await readLocalFile(path.join(workspaceFolder, 'expected.devcontainer-lock.json'));
		assert.equal(actual.toString(), expected.toString());
	});

	it('frozen lockfile', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-frozen');
		const lockfilePath = path.join(workspaceFolder, '.devcontainer-lock.json');
		const expected = await readLocalFile(lockfilePath);
		const res = await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile --experimental-frozen-lockfile`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		const actual = await readLocalFile(lockfilePath);
		assert.equal(actual.toString(), expected.toString());
	});

	it('outdated lockfile', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-outdated');

		const lockfilePath = path.join(workspaceFolder, '.devcontainer-lock.json');
		await cpLocal(path.join(workspaceFolder, 'original.devcontainer-lock.json'), lockfilePath);

		{
			try {
				throw await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile --experimental-frozen-lockfile`);
			} catch (res) {
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'error');
			}
		}

		{
			const res = await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const actual = await readLocalFile(lockfilePath);
			const expected = await readLocalFile(path.join(workspaceFolder, 'expected.devcontainer-lock.json'));
			assert.equal(actual.toString(), expected.toString());
		}
	});

	it('outdated command with json output', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-outdated-command');

		const res = await shellExec(`${cli} outdated --workspace-folder ${workspaceFolder} --output-format json`);
		const response = JSON.parse(res.stdout);
		
		const git = response.features['ghcr.io/devcontainers/features/git:1.0'];
		assert.ok(git);
		assert.strictEqual(git.current, '1.0.4');
		assert.ok(semver.gt(git.wanted, git.current), `semver.gt(${git.wanted}, ${git.current}) is false`);
		assert.ok(semver.gt(git.latest, git.wanted), `semver.gt(${git.latest}, ${git.wanted}) is false`);

		const lfs = response.features['ghcr.io/devcontainers/features/git-lfs@sha256:24d5802c837b2519b666a8403a9514c7296d769c9607048e9f1e040e7d7e331c'];
		assert.ok(lfs);
		assert.strictEqual(lfs.current, '1.0.6');
		assert.strictEqual(lfs.current, lfs.wanted);
		assert.ok(semver.gt(lfs.latest, lfs.wanted), `semver.gt(${lfs.latest}, ${lfs.wanted}) is false`);

		const github = response.features['ghcr.io/devcontainers/features/github-cli'];
		assert.ok(github);
		assert.strictEqual(github.current, github.latest);
		assert.strictEqual(github.wanted, github.latest);

		const azure = response.features['ghcr.io/devcontainers/features/azure-cli:0'];
		assert.ok(azure);
		assert.strictEqual(azure.current, undefined);
		assert.strictEqual(azure.wanted, undefined);
		assert.ok(azure.latest);

		const foo = response.features['ghcr.io/codspace/versioning/foo:0.3.1'];
		assert.ok(foo);
		assert.strictEqual(foo.current, '0.3.1');
		assert.strictEqual(foo.wanted, '0.3.1');
		assert.strictEqual(foo.wantedMajor, '0');
		assert.strictEqual(foo.latest, '2.11.1');
		assert.strictEqual(foo.latestMajor, '2');

		const doesnotexist = response.features['ghcr.io/codspace/doesnotexist:0.1.2'];
		assert.ok(doesnotexist);
		assert.strictEqual(doesnotexist.current, undefined);
		assert.strictEqual(doesnotexist.wanted, undefined);
		assert.strictEqual(doesnotexist.wantedMajor, undefined);
		assert.strictEqual(doesnotexist.latest, undefined);
		assert.strictEqual(doesnotexist.latestMajor, undefined);
	});

	it('outdated command with text output', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-outdated-command');

		const res = await shellExec(`${cli} outdated --workspace-folder ${workspaceFolder} --output-format text`);
		const response = res.stdout;
		// Count number of lines of output
		assert.strictEqual(response.split('\n').length, 8); // 5 valid Features + header + empty line

		// Check that the header is present
		assert.ok(response.includes('Current'), 'Current column is missing');
		assert.ok(response.includes('Wanted'), 'Wanted column is missing');
		assert.ok(response.includes('Latest'), 'Latest column is missing');

		// Check that the features are present
		// The version values are checked for correctness in the json variant of this test
		assert.ok(response.includes('ghcr.io/devcontainers/features/git'), 'git Feature is missing');
		assert.ok(response.includes('ghcr.io/devcontainers/features/git-lfs'), 'git-lfs Feature is missing');
		assert.ok(response.includes('ghcr.io/devcontainers/features/github-cli'), 'github-cli Feature is missing');
		assert.ok(response.includes('ghcr.io/devcontainers/features/azure-cli'), 'azure-cli Feature is missing');
		assert.ok(response.includes('ghcr.io/codspace/versioning/foo'), 'foo Feature is missing');
		assert.ok(response.includes('ghcr.io/codspace/doesnotexist'), 'doesnotexist Feature is missing');

		// Check that filtered Features are not present
		assert.ok(!response.includes('mylocalfeature'));
		assert.ok(!response.includes('terraform'));
		assert.ok(!response.includes('myfeatures'));
	});

	it('upgrade command', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-upgrade-command');

		const lockfilePath = path.join(workspaceFolder, '.devcontainer-lock.json');
		await cpLocal(path.join(workspaceFolder, 'outdated.devcontainer-lock.json'), lockfilePath);

		await shellExec(`${cli} upgrade --workspace-folder ${workspaceFolder}`);
		const actual = await readLocalFile(lockfilePath);
		const expected = await readLocalFile(path.join(workspaceFolder, 'upgraded.devcontainer-lock.json'));
		assert.equal(actual.toString(), expected.toString());
	});

	it('upgrade command in --dry-run mode', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-dependson');
		const res = await shellExec(`${cli} upgrade --dry-run --workspace-folder ${workspaceFolder}`);
		const lockfile = JSON.parse(res.stdout);
		assert.ok(lockfile);
		assert.ok(lockfile.features);
		assert.ok(lockfile.features['ghcr.io/codspace/dependson/A:2']);
	});

	it('upgrade command with --feature', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-upgrade-feature');
		await cpLocal(path.join(workspaceFolder, 'input.devcontainer.json'), path.join(workspaceFolder, '.devcontainer.json'));

		const res = await shellExec(`${cli} upgrade --dry-run --workspace-folder ${workspaceFolder} --feature ghcr.io/codspace/versioning/foo --target-version 2`);

		// Check devcontainer.json was updated
		const actual = await readLocalFile(path.join(workspaceFolder, '.devcontainer.json'));
		const expected = await readLocalFile(path.join(workspaceFolder, 'expected.devcontainer.json'));
		assert.equal(actual.toString(), expected.toString());

		// Check lockfile was updated
		const lockfile = JSON.parse(res.stdout);
		assert.ok(lockfile);
		assert.ok(lockfile.features);
		assert.ok(lockfile.features['ghcr.io/codspace/versioning/foo:2'].version === '2.11.1');
	});

	it('OCI feature integrity', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-oci-integrity');

		try {
			throw await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile`);
		} catch (res) {
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'error');
		}
	});

	it('tarball URI feature integrity', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-tarball-integrity');

		try {
			throw await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-lockfile`);
		} catch (res) {
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'error');
		}
	});

	it('empty lockfile should init', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-generate-from-empty-file');
		const lockfilePath = path.join(workspaceFolder, '.devcontainer', 'devcontainer-lock.json');
		const cleanup = async () => {
			await rmLocal(lockfilePath, { force: true });
			await shellExec(`touch ${lockfilePath}`);
		};

		await cleanup();
		const res = await shellExec(`${cli} build --workspace-folder ${workspaceFolder}`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		const actual = JSON.parse((await readLocalFile(lockfilePath)).toString());
		assert.ok(actual.features['ghcr.io/devcontainers/features/dotnet:2']);
		await cleanup();
	});

	it('empty lockfile should not init when frozen', async () => {
		const workspaceFolder = path.join(__dirname, 'configs/lockfile-generate-from-empty-file-frozen');
		const lockfilePath = path.join(workspaceFolder, '.devcontainer', 'devcontainer-lock.json');
		const cleanup = async () => {
			await rmLocal(lockfilePath, { force: true });
			await shellExec(`touch ${lockfilePath}`);
		};

		await cleanup();
		try {
			await shellExec(`${cli} build --workspace-folder ${workspaceFolder} --experimental-frozen-lockfile`);
			await cleanup();
		} catch (res) {
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'error');
			assert.equal(response.message, 'Lockfile does not match.');
			await cleanup();
		}
	});
});
</file>

<file path="src/test/container-features/registryCompatibilityOCI.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { assert } from 'chai';
import * as os from 'os';
import * as path from 'path';
import { devContainerDown, devContainerUp, shellExec } from '../testUtils';

const pkg = require('../../../package.json');

enum AuthStrategy {
	Anonymous,
	GitHubToken,
	DockerConfigAuthFile,
	// PlatformCredentialHelper,
	// RefreshToken,
}

interface TestPlan {
	name: string;
	configName: string;
	testFeatureId: string;
	testCommand?: string;
	testCommandResult?: RegExp;
	// Optionally tell the test to set up with a specfic auth strategy.
	// If not set, the test will run with anonymous.
	// NOTE: These will be skipped unless the environment has the relevant 'authStrategyKey' set in the environment.
	//       This data is specific to each strategy and parsed about below accordingly.
	useAuthStrategy?: AuthStrategy;
	authStrategyKey?: string;
}

const defaultTestPlan = {
	testCommand: 'color',
	testCommandResult: /my favorite color is pink/,
};

const registryCompatibilityTestPlan: TestPlan[] = [
	{
		name: 'Anonymous access of Azure Container Registry',
		configName: 'azure-anonymous',
		testFeatureId: 'devcontainercli.azurecr.io/features/color',
	},
	{
		name: 'Anonymous access of GHCR',
		configName: 'github-anonymous',
		testFeatureId: 'ghcr.io/devcontainers/feature-starter/color',
	},
	// https://learn.microsoft.com/en-us/azure/container-registry/container-registry-repository-scoped-permissions
	{
		name: 'Authenticated access of Azure Container Registry with registry scoped token',
		configName: 'azure-registry-scoped',
		testFeatureId: 'privatedevcontainercli.azurecr.io/features/rabbit',
		useAuthStrategy: AuthStrategy.DockerConfigAuthFile,
		authStrategyKey: 'FEATURES_TEST__AZURE_REGISTRY_SCOPED_CREDENTIAL',
		testCommand: 'rabbit',
		testCommandResult: /rabbit-is-the-best-animal/,
	},
	// Via GHCR visibility settings, this repo's GitHub Actions CI should be able to access this Feature via its GITHUB_TOKEN.
	{
		name: 'Private access of GHCR via an environment GITHUB_TOKEN',
		configName: 'github-private',
		testFeatureId: 'ghcr.io/devcontainers/private-feature-set-for-tests/color',
		useAuthStrategy: AuthStrategy.GitHubToken,
		authStrategyKey: 'RUNNING_IN_DEVCONTAINERS_CLI_REPO_CI'
	}
];

function envVariableExists(key: string): boolean {
	return !!process.env[key] && process.env[key] !== '';
}

function constructAuthFromStrategy(tmpFolder: string, authStrategy: AuthStrategy, authStrategyKey?: string): string | undefined {
	const generateAuthFolder = () => {
		const randomChars = Math.random().toString(36).substring(2, 6);
		const tmpAuthFolder = path.join(tmpFolder, randomChars, 'auth');
		shellExec(`mkdir -p ${tmpAuthFolder}`);
		return tmpAuthFolder;
	};

	switch (authStrategy) {
		case AuthStrategy.Anonymous:
		case AuthStrategy.GitHubToken:
			return;
		case AuthStrategy.DockerConfigAuthFile:
			// Format: registry|username|passwordOrToken
			if (!authStrategyKey) {
				return;
			}
			const split = process.env[authStrategyKey]?.split('|');
			if (!split || split.length !== 3) {
				return;
			}
			const tmpAuthFolder = generateAuthFolder();

			const registry = split?.[0];
			const username = split?.[1];
			const passwordOrToken = split?.[2];
			const encodedAuth = Buffer.from(`${username}:${passwordOrToken}`).toString('base64');

			shellExec(`echo '{"auths":{"${registry}":{"auth": "${encodedAuth}"}}}' > ${tmpAuthFolder}/config.json`);
			return tmpAuthFolder;
		default:
			return;
	}
}

describe('Registry Compatibility', function () {
	this.timeout('120s');
	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	registryCompatibilityTestPlan.forEach(({ name, configName, testFeatureId, testCommand, testCommandResult, useAuthStrategy, authStrategyKey }) => {
		this.timeout('120s');
		describe(name, async function () {
			((authStrategyKey && !envVariableExists(authStrategyKey)) ? describe.skip : describe)('devcontainer up', async function () {

				const authFolder = constructAuthFromStrategy(tmp, useAuthStrategy ?? AuthStrategy.Anonymous, authStrategyKey) || path.join(os.homedir(), 'fake-path');
				const gitHubToken = (useAuthStrategy === AuthStrategy.GitHubToken) ? (process.env.GITHUB_TOKEN ?? '') : '';

				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/registry-compatibility/${configName}`;

				before(async () => containerId = (await devContainerUp(cli, testFolder, {
					'logLevel': 'trace', prefix: `DOCKER_CONFIG=${authFolder} GITHUB_TOKEN=${gitHubToken}`
				})).containerId);
				after(async () => await devContainerDown({ containerId }));

				const cmd = testCommand ?? defaultTestPlan.testCommand;
				const expected = testCommandResult ?? defaultTestPlan.testCommandResult;

				it(`should exec the ${cmd} command`, async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} ${cmd} `);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, expected);
				});
			});

			((authStrategyKey && !envVariableExists(authStrategyKey)) ? describe.skip : describe)(`devcontainer features info manifest`, async function () {

				const authFolder = constructAuthFromStrategy(tmp, useAuthStrategy ?? AuthStrategy.Anonymous, authStrategyKey) || path.join(os.homedir(), 'fake-path');
				const gitHubToken = (useAuthStrategy === AuthStrategy.GitHubToken) ? (process.env.GITHUB_TOKEN ?? '') : '';

				it('fetches manifest', async function () {
					let infoManifestResult: { stdout: string; stderr: string } | null = null;
					let success = false;
					try {
						infoManifestResult =
							await shellExec(`DOCKER_CONFIG=${authFolder} GITHUB_TOKEN=${gitHubToken} ${cli} features info manifest ${testFeatureId} --log-level trace`);
						success = true;
					} catch (error) {
						assert.fail('features info tags sub-command should not throw');
					}

					assert.isTrue(success);
					assert.isDefined(infoManifestResult);
					const manifest = infoManifestResult.stdout;
					const regex = /application\/vnd\.devcontainers\.layer\.v1\+tar/;
					assert.match(manifest, regex);
				});
			});
		});
	});

});
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/alpine/.devcontainer.json">
{
	"name": "alpine",
	"image": "mcr.microsoft.com/devcontainers/base:0-alpine-${templateOption:imageVariant}"
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/alpine/devcontainer-template.json">
{
    "id": "alpine",
    "version": "1.0.0",
    "name": "Alpine",
    "options": {
        "imageVariant": {
            "type": "string",
            "description": "Alpine version:",
            "proposals": [
                "3.16",
                "3.15",
                "3.14",
                "3.13"
            ],
            "default": "3.16"
        }
    },
    "platforms": [
        "Any"
    ]
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/cpp/.devcontainer/devcontainer.json">
{
	"name": "C++",
	"build": {
		"dockerfile": "Dockerfile"
	},
	"features": {
		"ghcr.io/devcontainers/features/common-utils:1": {}
	}
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/cpp/.devcontainer/Dockerfile">
FROM mcr.microsoft.com/devcontainers/cpp:0-${templateOption:imageVariant}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/cpp/devcontainer-template.json">
{
    "id": "cpp",
    "version": "1.0.0",
    // I am a comment inside JSON
    "name": "C++",
    "options": {
        "imageVariant": {
            "type": "string",
            "description": "Debian / Ubuntu version (use Debian 11, Ubuntu 18.04/22.04 on local arm64/Apple Silicon):",
            "proposals": [
                "debian-11",
                "debian-10",
                "ubuntu-22.04",
                "ubuntu-20.04",
                "ubuntu-18.04"
            ],
            "default": "debian-11"
        }
    },
    "platforms": [
        "C++"
    ]
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/.devcontainer/devcontainer.json">
{
    "image": "mcr.microsoft.com/devcontainers/base",
    "containerEnv": {
        "MY_ENV_VAR": "${templateOption:anOption}"
    },
    "features": {
        "ghcr.io/devcontainers/features/azure-cli": {
            "installBicep": false
        },
        "ghcr.io/devcontainers/features/aws-cli:1": {},
        "ghcr.io/devcontainers/features/common-utils:2.5.1": {
            "userUid": "${templateOption:userUid}"
        },
        "ghcr.io/devcontainers/features/docker-in-docker@sha256:503f23cd692325b3cbb8c20a0ecfabb3444b0c786b363e0c82572bd7d71dc099": {}
    }
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/.github/dependabot.yml">
version: 2
updates:
  - package-ecosystem: "devcontainers" # See documentation for possible values
    directory: "/"
    schedule:
      interval: weekly
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/assets/hello.md">
Hello
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/assets/hi.md">
Hi
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/example-projects/exampleA/.github/dependabot.yml">
version: 2
updates:
  - package-ecosystem: "devcontainers" # See documentation for possible values
    directory: "/"
    schedule:
      interval: weekly
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/example-projects/exampleA/subFolderA/a2.ts">
export class A2 {
	constructor() {
		// Add your code here
	}

	// Add your methods here
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/example-projects/exampleA/a1.ts">
export class A1 {
	constructor() {
		// Add your code here
	}

	// Add your methods here
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/example-projects/exampleB/.github/dependabot.yml">
version: 2
updates:
  - package-ecosystem: "devcontainers" # See documentation for possible values
    directory: "/"
    schedule:
      interval: weekly
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/example-projects/exampleB/subFolderB/b2.ts">
export class B2 {
	constructor() {
		// Add your code here
	}

	// Add your methods here
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/c1.ts">
export class C1 {
	constructor() {
		// Add your code here
	}

	// Add your methods here
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/c2.ts">
export class C2 {
	constructor() {
		// Add your code here
	}

	// Add your methods here
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/c3.ts">
export class C3 {
	constructor() {
		// Add your code here
	}

	// Add your methods here
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/mytemplate/devcontainer-template.json">
{
    "id": "mytemplate",
    "version": "1.0.0",
    "name": "My Template",
    "description": "Simple test",
    "documentationURL": "https://github.com/codspace/templates/tree/main/src/test",
    "publisher": "codspace",
    "licenseURL": "https://github.com/devcontainers/templates/blob/main/LICENSE",
    "platforms": [
        "Any"
    ],
    "options": {
        "anOption": {
            "type": "string",
            "description": "A great option",
            "proposals": [
                "8.0",
                "7.0",
                "6.0"
            ],
            "default": "8.0"
        },
        "userUid": {
            "type": "string",
            "description": "The user's UID",
            "proposals": [
                "1000",
                "1001",
                "1002"
            ],
            "default": "1000"
        }
    },
    "optionalPaths": [
        ".github/*",
        "example-projects/exampleA/*",
        "c1.ts"
    ]
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/node-mongo/.devcontainer/devcontainer.json">
// Update the VARIANT arg in docker-compose.yml to pick a Node.js version
{
	"name": "Node.js & Mongo DB",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}",

	// Configure tool-specific properties.
	"customizations": {
		// Configure properties specific to VS Code.
		"vscode": {
			// Add the IDs of extensions you want installed when the container is created.
			"extensions": [
				"mongodb.mongodb-vscode"
			]
		}
	},
	"features": {
		"ghcr.io/devcontainers/features/common-utils:1": {},
		"ghcr.io/devcontainers/features/git:1": {}
	},

	// Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
	"remoteUser": "node"
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/node-mongo/.devcontainer/docker-compose.yml">
version: '3.8'

services:
  app:
    image: mcr.microsoft.com/vscode/devcontainers/javascript-node:0-16-bullseye
    volumes:
      - ..:/workspace:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db
    # Uncomment the next line to use a non-root user for all processes.
    # user: node

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally. 
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: mongo:latest
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    # Uncomment to change startup options
    # environment:
    #  MONGO_INITDB_ROOT_USERNAME: root
    #  MONGO_INITDB_ROOT_PASSWORD: example
    #  MONGO_INITDB_DATABASE: your-database-here

    # Add "forwardPorts": ["27017"] to **devcontainer.json** to forward MongoDB locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  mongodb-data: null
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/node-mongo/devcontainer-template.json">
{
    "id": "node-mongo",
    "version": "1.0.0",
    "name": "Node.js & Mongo DB",
    "options": {
        "imageVariant": {
            "type": "string",
            "description": "Node.js version (use -bullseye variants on local arm64/Apple Silicon):",
            "proposals": [
                "18",
                "16",
                "14",
                "18-bullseye",
                "16-bullseye",
                "14-bullseye",
                "18-buster",
                "16-buster",
                "14-buster"
            ],
            "default": "16-bullseye"
        }
    },
    "platforms": [
        "Node.js",
        "JavaScript",
        "Mongo DB"
    ]
}
</file>

<file path="src/test/container-templates/example-templates-sets/simple/src/not-a-template/not-a-template.sh">
# Added for testing - should log warning when packaging collection of Templates with missing `devcontainer-template.json` and continue.
</file>

<file path="src/test/container-templates/containerTemplatesOCI.test.ts">
import * as assert from 'assert';
import * as os from 'os';
import * as path from 'path';
import { createPlainLog, LogLevel, makeLog } from '../../spec-utils/log';
export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));
import { fetchTemplate, SelectedTemplate } from '../../spec-configuration/containerTemplatesOCI';
import { readLocalFile } from '../../spec-utils/pfs';

describe('fetchTemplate', async function () {
	this.timeout('120s');

	it('template apply docker-from-docker without features and with user options', async () => {

		// https://github.com/devcontainers/templates/tree/main/src/docker-from-docker
		const selectedTemplate: SelectedTemplate = {
			id: 'ghcr.io/devcontainers/templates/docker-from-docker:latest',
			options: { 'installZsh': 'false', 'upgradePackages': 'true', 'dockerVersion': '20.10', 'moby': 'true' },
			features: [],
			omitPaths: [],
		};

		const dest = path.relative(process.cwd(), path.join(__dirname, 'tmp1'));
		const files = await fetchTemplate({ output, env: process.env }, selectedTemplate, dest);
		assert.ok(files);
		// Should only container 1 file '.devcontainer.json'.  The other 3 in this repo should be ignored.
		assert.strictEqual(files.length, 1);

		// Read File
		const file = (await readLocalFile(path.join(dest, files[0]))).toString();
		assert.match(file, /"name": "Docker from Docker"/);
		assert.match(file, /"installZsh": "false"/);
		assert.match(file, /"upgradePackages": "true"/);
		assert.match(file, /"version": "20.10"/);
		assert.match(file, /"moby": "true"/);
		assert.match(file, /"enableNonRootDocker": "true"/);

		// Assert that the Features included in the template were not removed.
		assert.match(file, /"ghcr.io\/devcontainers\/features\/common-utils:1": {\n/);
		assert.match(file, /"ghcr.io\/devcontainers\/features\/docker-from-docker:1": {\n/);
	});

	it('template apply docker-from-docker without features and without user options (default only)', async () => {

		// https://github.com/devcontainers/templates/tree/main/src/docker-from-docker
		const selectedTemplate: SelectedTemplate = {
			id: 'ghcr.io/devcontainers/templates/docker-from-docker:latest',
			options: {},
			features: [],
			omitPaths: [],
		};

		const dest = path.relative(process.cwd(), path.join(__dirname, 'tmp2'));
		const files = await fetchTemplate({ output, env: process.env }, selectedTemplate, dest);
		assert.ok(files);
		// Should only container 1 file '.devcontainer.json'.  The other 3 in this repo should be ignored.
		assert.strictEqual(files.length, 1);

		// Read File
		const file = (await readLocalFile(path.join(dest, files[0]))).toString();
		assert.match(file, /"name": "Docker from Docker"/);
		assert.match(file, /"installZsh": "true"/);
		assert.match(file, /"upgradePackages": "false"/);
		assert.match(file, /"version": "latest"/);
		assert.match(file, /"moby": "true"/);
		assert.match(file, /"enableNonRootDocker": "true"/);

		// Assert that the Features included in the template were not removed.
		assert.match(file, /"ghcr.io\/devcontainers\/features\/common-utils:1": {\n/);
		assert.match(file, /"ghcr.io\/devcontainers\/features\/docker-from-docker:1": {\n/);
	});

	it('template apply docker-from-docker with features and with user options', async () => {

		// https://github.com/devcontainers/templates/tree/main/src/docker-from-docker
		const selectedTemplate: SelectedTemplate = {
			id: 'ghcr.io/devcontainers/templates/docker-from-docker:latest',
			options: { 'installZsh': 'false', 'upgradePackages': 'true', 'dockerVersion': '20.10', 'moby': 'true', 'enableNonRootDocker': 'true' },
			features: [{ id: 'ghcr.io/devcontainers/features/azure-cli:1', options: {} }],
			omitPaths: [],
		};

		const dest = path.relative(process.cwd(), path.join(__dirname, 'tmp3'));
		const files = await fetchTemplate({ output, env: process.env }, selectedTemplate, dest);
		assert.ok(files);
		// Should only container 1 file '.devcontainer.json'.  The other 3 in this repo should be ignored.
		assert.strictEqual(files.length, 1);

		// Read File
		const file = (await readLocalFile(path.join(dest, files[0]))).toString();
		assert.match(file, /"name": "Docker from Docker"/);
		assert.match(file, /"installZsh": "false"/);
		assert.match(file, /"upgradePackages": "true"/);
		assert.match(file, /"version": "20.10"/);
		assert.match(file, /"moby": "true"/);
		assert.match(file, /"enableNonRootDocker": "true"/);

		// Assert that the Features included in the template were not removed.
		assert.match(file, /"ghcr.io\/devcontainers\/features\/common-utils:1": {\n/);
		assert.match(file, /"ghcr.io\/devcontainers\/features\/docker-from-docker:1": {\n/);

		// Assert that our new Feature is included
		assert.match(file, /"ghcr.io\/devcontainers\/features\/azure-cli:1": {}/);
	});

	it('template apply docker-from-docker with features and with user options', async () => {

		// https://github.com/devcontainers/templates/tree/main/src/anaconda-postgres
		const selectedTemplate: SelectedTemplate = {
			id: 'ghcr.io/devcontainers/templates/anaconda-postgres:latest',
			options: { 'nodeVersion': 'lts/*' },
			features: [{ id: 'ghcr.io/devcontainers/features/azure-cli:1', options: {} }, { id: 'ghcr.io/devcontainers/features/git:1', options: { 'version': 'latest', ppa: true } }],
			omitPaths: [],
		};

		const dest = path.relative(process.cwd(), path.join(__dirname, 'tmp4'));
		const files = await fetchTemplate({ output, env: process.env }, selectedTemplate, dest);
		assert.ok(files);
		// Expected:
		// ./environment.yml, ./.devcontainer/.env, ./.devcontainer/Dockerfile, ./.devcontainer/devcontainer.json, ./.devcontainer/docker-compose.yml, ./.devcontainer/noop.txt, ./.github/dependabot.yml
		assert.strictEqual(files.length, 7);

		// Read file modified by templated value
		const dockerfile = (await readLocalFile(path.join(dest, '.devcontainer', 'Dockerfile'))).toString();
		assert.match(dockerfile, /FROM mcr.microsoft.com\/devcontainers\/anaconda:/);

		// Read file modified by adding Features
		const devcontainer = (await readLocalFile(path.join(dest, '.devcontainer', 'devcontainer.json'))).toString();
		assert.match(devcontainer, /"ghcr.io\/devcontainers\/features\/azure-cli:1": {}/);
		assert.match(devcontainer, /"ghcr.io\/devcontainers\/features\/git:1": {\n\t\t\t"version": "latest",\n\t\t\t"ppa": true/);
	});

	describe('omit-path', async function () {
		this.timeout('120s');

		// https://github.com/codspace/templates/pkgs/container/templates%2Fmytemplate/255979159?tag=1.0.4
		const id = 'ghcr.io/codspace/templates/mytemplate@sha256:57cbf968907c74c106b7b2446063d114743ab3f63345f7c108c577915c535185';
		const templateFiles = [
			'./c1.ts',
			'./c2.ts',
			'./c3.ts',
			'./.devcontainer/devcontainer.json',
			'./.github/dependabot.yml',
			'./assets/hello.md',
			'./assets/hi.md',
			'./example-projects/exampleA/a1.ts',
			'./example-projects/exampleA/.github/dependabot.yml',
			'./example-projects/exampleA/subFolderA/a2.ts',
			'./example-projects/exampleB/b1.ts',
			'./example-projects/exampleB/.github/dependabot.yml',
			'./example-projects/exampleB/subFolderB/b2.ts',
		];

		// NOTE: Certain files, like the 'devcontainer-template.json', are always filtered
		//	     out as they are not part of the Template.
		it('Omit nothing', async () => {
			const selectedTemplate: SelectedTemplate = {
				id,
				options: {},
				features: [],
				omitPaths: [],
			};

			const files = await fetchTemplate(
				{ output, env: process.env },
				selectedTemplate,
				path.join(os.tmpdir(), 'vsch-test-template-temp', `${Date.now()}`)
			);

			assert.ok(files);
			assert.strictEqual(files.length, templateFiles.length);
			for (const file of templateFiles) {
				assert.ok(files.includes(file));
			}
		});

		it('Omit nested folder', async () => {
			const selectedTemplate: SelectedTemplate = {
				id,
				options: {},
				features: [],
				omitPaths: ['example-projects/exampleB/*'],
			};

			const files = await fetchTemplate(
				{ output, env: process.env },
				selectedTemplate,
				path.join(os.tmpdir(), 'vsch-test-template-temp', `${Date.now()}`)
			);

			const expectedRemovedFiles = [
				'./example-projects/exampleB/b1.ts',
				'./example-projects/example/.github/dependabot.yml',
				'./example-projects/exampleB/subFolderB/b2.ts',
			];

			assert.ok(files);
			assert.strictEqual(files.length, templateFiles.length - 3);
			for (const file of expectedRemovedFiles) {
				assert.ok(!files.includes(file));
			}
		});

		it('Omit single file, root folder, and nested folder', async () => {
			const selectedTemplate: SelectedTemplate = {
				id,
				options: {},
				features: [],
				omitPaths: ['.github/*', 'example-projects/exampleA/*', 'c1.ts'],
			};

			const files = await fetchTemplate(
				{ output, env: process.env },
				selectedTemplate,
				path.join(os.tmpdir(), 'vsch-test-template-temp', `${Date.now()}`)
			);

			const expectedRemovedFiles = [
				'./c1.ts',
				'./.github/dependabot.yml',
				'./example-projects/exampleA/a1.ts',
				'./example-projects/exampleA/.github/dependabot.yml',
				'./example-projects/exampleA/subFolderA/a2.ts',
			];

			assert.ok(files);
			assert.strictEqual(files.length, templateFiles.length - 5);
			for (const file of expectedRemovedFiles) {
				assert.ok(!files.includes(file));
			}
		});
	});


});
</file>

<file path="src/test/container-templates/templatesCLICommands.test.ts">
import { assert } from 'chai';
import path from 'path';
import { createPlainLog, LogLevel, makeLog } from '../../spec-utils/log';
import { isLocalFile, readLocalFile } from '../../spec-utils/pfs';
import { ExecResult, shellExec } from '../testUtils';
import { DevContainerCollectionMetadata, packageTemplates } from '../../spec-node/templatesCLI/packageImpl';
import { Template } from '../../spec-configuration/containerTemplatesConfiguration';
import { PackageCommandInput } from '../../spec-node/collectionCommonUtils/package';
import { getCLIHost } from '../../spec-common/cliHost';
import { loadNativeModule } from '../../spec-common/commonUtils';
import { generateTemplatesDocumentation } from '../../spec-node/collectionCommonUtils/generateDocsCommandImpl';

export const output = makeLog(createPlainLog(text => process.stderr.write(text), () => LogLevel.Trace));

const pkg = require('../../../package.json');

describe('tests apply command', async function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp6'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`rm -rf ${tmp}/output`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	it('templates apply subcommand', async function () {
		let success = false;
		let result: ExecResult | undefined = undefined;
		try {
			result = await shellExec(`${cli} templates apply --workspace-folder ${path.join(tmp, 'template-output')} \
			--template-id     ghcr.io/devcontainers/templates/docker-from-docker:latest \
			--template-args   '{ "installZsh": "false", "upgradePackages": "true", "dockerVersion": "20.10", "moby": "true", "enableNonRootDocker": "true" }' \
			--features        '[{ "id": "ghcr.io/devcontainers/features/azure-cli:1", "options": { "version" : "1" } }]' \
			--log-level trace`);
			success = true;

		} catch (error) {
			assert.fail('features test sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(result);
		assert.strictEqual(result.stdout.trim(), '{"files":["./.devcontainer/devcontainer.json"]}');

		const file = (await readLocalFile(path.join(tmp, 'template-output', '.devcontainer', 'devcontainer.json'))).toString();

		assert.match(file, /"name": "Docker from Docker"/);
		assert.match(file, /"installZsh": "false"/);
		assert.match(file, /"upgradePackages": "true"/);
		assert.match(file, /"version": "20.10"/);
		assert.match(file, /"moby": "true"/);
		assert.match(file, /"enableNonRootDocker": "true"/);

		// Assert that the Features included in the template were not removed.
		assert.match(file, /"ghcr.io\/devcontainers\/features\/common-utils:1": {\n/);
		assert.match(file, /"ghcr.io\/devcontainers\/features\/docker-from-docker:1": {\n/);

		// Assert that the Feature included in the command was added.
		assert.match(file, /"ghcr.io\/devcontainers\/features\/azure-cli:1": {\n/);
	});
});

describe('tests packageTemplates()', async function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp3'));

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`rm -rf ${tmp}/output`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

    const cwd = process.cwd();
    const cliHost = await getCLIHost(cwd, loadNativeModule, true);

	let args: PackageCommandInput = {
		targetFolder: '',
		outputDir: '',
		output,
		cliHost,
		disposables: [],
		forceCleanOutputDir: true
	};

	// -- Packaging

	it('tests packaging for templates collection', async function () {
		const srcFolder = `${__dirname}/example-templates-sets/simple/src`;
		const outputDir = `${tmp}/output/test01`;

		args.targetFolder = srcFolder;
		args.outputDir = outputDir;

		const metadata = await packageTemplates(args);
		assert.isDefined(metadata);

		const alpineTgzExists = await isLocalFile(`${outputDir}/devcontainer-template-alpine.tgz`);
		assert.isTrue(alpineTgzExists);
		const tgzArchiveContentsAlpine = await shellExec(`tar -tvf ${outputDir}/devcontainer-template-alpine.tgz`);
		assert.match(tgzArchiveContentsAlpine.stdout, /devcontainer-template.json/);
		assert.match(tgzArchiveContentsAlpine.stdout, /.devcontainer.json/);

		const cppTgzExists = await isLocalFile(`${outputDir}/devcontainer-template-cpp.tgz`);
		assert.isTrue(cppTgzExists);
		const tgzArchiveContentsHello = await shellExec(`tar -tvf ${outputDir}/devcontainer-template-cpp.tgz`);
		assert.match(tgzArchiveContentsHello.stdout, /devcontainer-template.json/);
		assert.match(tgzArchiveContentsHello.stdout, /.devcontainer/);
		assert.match(tgzArchiveContentsHello.stdout, /.devcontainer\/Dockerfile/);
		assert.match(tgzArchiveContentsHello.stdout, /.devcontainer\/devcontainer.json/);

		const collectionFileExists = await isLocalFile(`${outputDir}/devcontainer-collection.json`);
		const json: DevContainerCollectionMetadata = JSON.parse((await readLocalFile(`${outputDir}/devcontainer-collection.json`)).toString());
		assert.strictEqual(json.templates.length, 4);
		assert.isTrue(collectionFileExists);

		// Checks if the automatically added properties are set correctly.
		const alpineProperties: Template | undefined = json?.templates.find(t => t.id === 'alpine');
		assert.isNotEmpty(alpineProperties);
		assert.equal(alpineProperties?.type, 'image');
		assert.equal(alpineProperties?.fileCount, 2);
		assert.equal(alpineProperties?.featureIds?.length, 0);

		const cppProperties: Template | undefined = json?.templates.find(t => t.id === 'cpp');
		assert.isNotEmpty(cppProperties);
		assert.equal(cppProperties?.type, 'dockerfile');
		assert.equal(cppProperties?.fileCount, 3);
		assert.equal(cppProperties?.featureIds?.length, 1);
		assert.equal(cppProperties?.featureIds?.[0], 'ghcr.io/devcontainers/features/common-utils');

		const nodeProperties: Template | undefined = json?.templates.find(t => t.id === 'node-mongo');
		assert.isNotEmpty(nodeProperties);
		assert.equal(nodeProperties?.type, 'dockerCompose');
		assert.equal(nodeProperties?.fileCount, 3);
		assert.equal(nodeProperties?.featureIds?.length, 2);
		assert.isTrue(nodeProperties?.featureIds?.some(f => f === 'ghcr.io/devcontainers/features/common-utils'));
		assert.isTrue(nodeProperties?.featureIds?.some(f => f === 'ghcr.io/devcontainers/features/git'));

		const mytemplateProperties: Template | undefined = json?.templates.find(t => t.id === 'mytemplate');
		console.log(JSON.stringify(mytemplateProperties, null, 4));
		assert.isNotEmpty(mytemplateProperties);
		// -- optionalPaths
		assert.strictEqual(mytemplateProperties?.optionalPaths?.length, 3);
		assert.deepEqual(mytemplateProperties?.optionalPaths,
			[
				'.github/dependabot.yml',  // NOTE: Packaging step replaces the original value '.github/*' here since there's only a single file in the folder
				'example-projects/exampleA/*',
				'c1.ts'
			]);
		// -- files
		assert.strictEqual(mytemplateProperties?.files?.length, 14);
		assert.deepEqual(mytemplateProperties?.files.sort(), [
			'c1.ts',
			'c2.ts',
			'c3.ts',
			'devcontainer-template.json',
			'.devcontainer/devcontainer.json',
			'.github/dependabot.yml',
			'assets/hello.md',
			'assets/hi.md',
			'example-projects/exampleA/a1.ts',
			'example-projects/exampleA/.github/dependabot.yml',
			'example-projects/exampleA/subFolderA/a2.ts',
			'example-projects/exampleB/b1.ts',
			'example-projects/exampleB/.github/dependabot.yml',
			'example-projects/exampleB/subFolderB/b2.ts'
		].sort()); // Order isn't guaranteed
		// -- featureIds
		assert.strictEqual(mytemplateProperties?.featureIds?.length, 4);
		assert.deepEqual(mytemplateProperties?.featureIds, [
			'ghcr.io/devcontainers/features/azure-cli',
			'ghcr.io/devcontainers/features/aws-cli',
			'ghcr.io/devcontainers/features/common-utils',
			'ghcr.io/devcontainers/features/docker-in-docker'
		]);


	});

	it('tests packaging for single template', async function () {
		const singleTemplateFolder = `${__dirname}/example-templates-sets/simple/src/alpine`;
		const outputDir = `${tmp}/output/test02`;

		args.targetFolder = singleTemplateFolder;
		args.outputDir = outputDir;

		const metadata = await packageTemplates(args);
		assert.isDefined(metadata);

		const alpineTgzExists = await isLocalFile(`${outputDir}/devcontainer-template-alpine.tgz`);
		assert.isTrue(alpineTgzExists);
		const tgzArchiveContentsAlpine = await shellExec(`tar -tvf ${outputDir}/devcontainer-template-alpine.tgz`);
		assert.match(tgzArchiveContentsAlpine.stdout, /devcontainer-template.json/);
		assert.match(tgzArchiveContentsAlpine.stdout, /.devcontainer.json/);

		const collectionFileExists = await isLocalFile(`${outputDir}/devcontainer-collection.json`);
		assert.isTrue(collectionFileExists);
		const json: DevContainerCollectionMetadata = JSON.parse((await readLocalFile(`${outputDir}/devcontainer-collection.json`)).toString());
		assert.strictEqual(json.templates.length, 1);
		assert.isTrue(collectionFileExists);

		// Checks if the automatically added `type` property is set correctly.
		const alpineProperties: Template | undefined = json?.templates.find(t => t.id === 'alpine');
		assert.isNotEmpty(alpineProperties);
		assert.equal(alpineProperties?.type, 'image');
		assert.equal(alpineProperties?.fileCount, 2);
	});
});

describe('tests generateTemplateDocumentation()', async function () {
	this.timeout('120s');

	const projectFolder = `${__dirname}/example-templates-sets/simple/src`;

	after('clean', async () => {
		await shellExec(`rm ${projectFolder}/**/README.md`);
	});

	it('tests generate-docs', async function () {
		await generateTemplatesDocumentation(projectFolder, 'devcontainers', 'cli', output);

		const alpineDocsExists = await isLocalFile(`${projectFolder}/alpine/README.md`);
		assert.isTrue(alpineDocsExists);

		const cppDocsExists = await isLocalFile(`${projectFolder}/cpp/README.md`);
		assert.isTrue(cppDocsExists);

		const nodeMongoDocsExists = await isLocalFile(`${projectFolder}/node-mongo/README.md`);
		assert.isTrue(nodeMongoDocsExists);

		const invalidDocsExists = await isLocalFile(`${projectFolder}/not-a-template/README.md`);
		assert.isFalse(invalidDocsExists);
	});
});

describe('template metadata', async function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp7'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	// https://github.com/codspace/templates/pkgs/container/templates%2Fmytemplate/255979159?tag=1.0.4
	const templateId = 'ghcr.io/codspace/templates/mytemplate@sha256:57cbf968907c74c106b7b2446063d114743ab3f63345f7c108c577915c535185';

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`rm -rf ${tmp}/output`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	it('successfully fetches metdata off a published Template', async function () {
		let success = false;
		let result: ExecResult | undefined = undefined;
		try {
			result = await shellExec(`${cli} templates metadata ${templateId} --log-level trace`);
			success = true;

		} catch (error) {
			assert.fail('features test sub-command should not throw');
		}

		assert.isTrue(success);
		assert.isDefined(result);
		const json = JSON.parse(result.stdout);
		assert.strictEqual('mytemplate', json.id);
		assert.strictEqual('Simple test', json.description);

	});
});
</file>

<file path="src/test/cli.build.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as fs from 'fs';
import * as assert from 'assert';
import * as path from 'path';
import * as os from 'os';
import { buildKitOptions, shellExec } from './testUtils';
import { ImageDetails } from '../spec-shutdown/dockerUtils';
import { envListToObj } from '../spec-node/utils';

const pkg = require('../../package.json');

describe('Dev Containers CLI', function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('Command build', () => {

		it('should build successfully with valid image metadata --label property', async () => {
			const testFolder = `${__dirname}/configs/example`;
			const response = await shellExec(`${cli} build --workspace-folder ${testFolder} --label 'name=label-test' --label 'type=multiple-labels'`);
			const res = JSON.parse(response.stdout);
			assert.equal(res.outcome, 'success');
			const labels = await shellExec(`docker inspect --format '{{json .Config.Labels}}' ${res.imageName} | jq`);
			assert.match(labels.stdout.toString(), /\"name\": \"label-test\"/);
		});

		it('should fail to build with correct error message for local feature', async () => {
			const testFolder = `${__dirname}/configs/image-with-local-feature`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --image-name demo:v1`);
			} catch (error) {
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /prepend your Feature name with/);
			}
		});

		it('should correctly configure the image name to push from --image-name with --push true', async () => {
			const testFolder = `${__dirname}/configs/example`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --image-name demo:v1`);
				const tags = await shellExec(`docker images --format "{{.Tag}}" demo`);
				const imageTags = tags.stdout.trim().split('\n').filter(tag => tag !== '<none>');
				assert.equal(imageTags.length, 1, 'There should be only one tag for demo:v1'); 
			} catch (error) {
				assert.equal(error.code, 'ERR_ASSERTION', 'Should fail with ERR_ASSERTION');
			}
		});

		buildKitOptions.forEach(({ text, options }) => {
			it(`should execute successfully with valid image config  [${text}]`, async () => {
				const testFolder = `${__dirname}/configs/image`;
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder}${buildKitOption}`);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
			});
			it(`should execute successfully with valid docker-compose (image) config [${text}]`, async () => {
				const testFolder = `${__dirname}/configs/compose-image-with-features`;
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder}${buildKitOption} --log-level trace`);
				console.log(res.stdout);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
			});
			it(`should execute successfully with valid image config and extra cacheFrom [${text}]`, async () => {
				const testFolder = `${__dirname}/configs/image`;
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				// validate the build succeeds with an extra cacheFrom that isn't found
				// (example scenario: CI builds for PRs)
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --cache-from ghcr.io/devcontainers/notFound ${buildKitOption}`);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
			});
			it(`should execute successfully with valid docker-compose (image) config and extra cacheFrom [${text}]`, async () => {
				const testFolder = `${__dirname}/configs/compose-image-with-features`;
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				// validate the build succeeds with an extra cacheFrom that isn't found
				// (example scenario: CI builds for PRs)
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --cache-from ghcr.io/devcontainers/notFound ${buildKitOption}`);
				console.log(res.stdout);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
			});
		});

		it('should not use docker cache for features when `--no-cache` flag is passed', async () => {
			// Arrange
			const testFolder = `${__dirname}/configs/image-with-features`;
			const devContainerJson = `${testFolder}/.devcontainer.json`;

			const devContainerFileContents = JSON.parse(fs.readFileSync(devContainerJson, 'utf8'));
			const baseImage = devContainerFileContents.image;

			const originalImageName = 'feature-cache-test-original-image';
			const cachedImageName = 'feature-cache-test-rerun-image';
			const nonCachedImageName = 'feature-cache-test-no-cache-image';

			const commandBase = `${cli} build --workspace-folder ${testFolder}`;
			const buildCommand = `${commandBase} --image-name ${originalImageName}`;
			const cachedBuildCommand = `${commandBase} --image-name ${cachedImageName}`;
			const buildWithoutCacheCommand = `${commandBase} --image-name ${nonCachedImageName} --no-cache`;

			function arrayStartsWithArray(subject: string[], startsWith: string[]) {
				if (subject.length < startsWith.length) {
					return false;
				}
				for (let i = 0; i < startsWith.length; i++) {
					if (subject[i] !== startsWith[i]) {
						return false;
					}
				}
				return true;
			}

			function haveCommonEntries(arr1: string[], arr2: string[]) {
				return arr1.every(item => arr2.includes(item));
			}

			// Act
			await shellExec(`docker pull ${baseImage}`); // pull base image so we can inspect it later
			await shellExec(buildCommand);
			await shellExec(cachedBuildCommand);
			await shellExec(buildWithoutCacheCommand);

			// Assert
			const baseImageInspectCommandResult = await shellExec(`docker inspect ${baseImage}`);
			const originalImageInspectCommandResult = await shellExec(`docker inspect ${originalImageName}`);
			const cachedImageInspectCommandResult = await shellExec(`docker inspect ${cachedImageName}`);
			const noCacheImageInspectCommandResult = await shellExec(`docker inspect ${nonCachedImageName}`);

			const baseImageDetails = JSON.parse(baseImageInspectCommandResult.stdout);
			const originalImageDetails = JSON.parse(originalImageInspectCommandResult.stdout);
			const cachedImageDetails = JSON.parse(cachedImageInspectCommandResult.stdout);
			const noCacheImageDetails = JSON.parse(noCacheImageInspectCommandResult.stdout);

			const baseImageLayers: string[] = baseImageDetails[0].RootFS.Layers;
			const originalImageLayers: string[] = originalImageDetails[0].RootFS.Layers;
			const cachedImageLayers: string[] = cachedImageDetails[0].RootFS.Layers;
			const nonCachedImageLayers: string[] = noCacheImageDetails[0].RootFS.Layers;

			assert.equal(arrayStartsWithArray(originalImageLayers, baseImageLayers), true, 'because the image is made up of feature layers on top of the base image');
			assert.equal(arrayStartsWithArray(cachedImageLayers, baseImageLayers), true, 'because the image is made up of feature layers on top of the base image');
			assert.equal(arrayStartsWithArray(nonCachedImageLayers, baseImageLayers), true, 'because the image is made up of feature layers on top of the base image');

			const originalImageWithoutBaseImageLayers = originalImageLayers.slice(baseImageLayers.length);
			const cachedImageWithoutBaseImageLayers = cachedImageLayers.slice(baseImageLayers.length);
			const nonCachedImageWithoutBaseImageLayers = nonCachedImageLayers.slice(baseImageLayers.length);

			assert.deepEqual(originalImageWithoutBaseImageLayers, cachedImageWithoutBaseImageLayers, 'because they are the same image built sequentially therefore the second should have used caching');
			assert.equal(haveCommonEntries(cachedImageWithoutBaseImageLayers, nonCachedImageWithoutBaseImageLayers), false, 'because we passed the --no-cache argument which disables the use of the cache, therefore the non-base image layers should have nothin in common');
		});

		it('should fail with "not found" error when config is not found', async () => {
			let success = false;
			try {
				await shellExec(`${cli} build --workspace-folder path-that-does-not-exist`);
				success = true;
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /Dev container config \(.*\) not found./);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('should succeed (dockerfile) with supported --platform', async () => {
			const testFolder = `${__dirname}/configs/dockerfile-with-target`;
			const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --platform linux/amd64`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
		});

		it('should succeed (image) with supported --platform', async () => {
			const testFolder = `${__dirname}/configs/image-with-features`;
			const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --platform linux/amd64`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
		});

		it('should fail --platform without dockerfile', async () => {
			let success = false;
			const testFolder = `${__dirname}/configs/image`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --platform linux/amd64`);
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /require dockerfilePath/);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('should fail with unsupported --platform', async () => {
			let success = false;
			const testFolder = `${__dirname}/configs/dockerfile-with-target`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --platform fake/platform`);
				success = true;
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /Command failed/);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('should fail with BuildKit never and --platform', async () => {
			let success = false;
			const testFolder = `${__dirname}/configs/dockerfile-with-target`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --buildkit=never --platform linux/amd64`);
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /require BuildKit enabled/);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('should fail with docker-compose and --platform not supported', async () => {
			let success = false;
			const testFolder = `${__dirname}/configs/compose-image-with-features`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --platform linux/amd64`);
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /not supported/);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('should succeed with multiple --image-name parameters when DockerFile is present', async () => {
			const testFolder = `${__dirname}/configs/dockerfile-with-features`;
			const image1 = 'image-1';
			const image2 = 'image-2';
			await shellExec(`docker rmi -f ${image1} ${image2}`);
			const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --image-name ${image1} --image-name ${image2}`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.equal(response.imageName[0], image1);
			assert.equal(response.imageName[1], image2);
			await shellExec(`docker inspect --type image ${image1} ${image2}`);
		});

		it('should succeed with multiple --image-name parameters when dockerComposeFile is present', async () => {
			const testFolder = `${__dirname}/configs/compose-Dockerfile-alpine`;
			const image1 = 'image-1';
			const image2 = 'image-2';
			await shellExec(`docker rmi -f ${image1} ${image2}`);
			const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --image-name ${image1} --image-name ${image2}`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.equal(response.imageName[0], image1);
			assert.equal(response.imageName[1], image2);
			await shellExec(`docker inspect --type image ${image1} ${image2}`);
		});

		it('should succeed with multiple --image-name parameters when image is present', async () => {
			const testFolder = `${__dirname}/configs/image`;
			const image1 = 'image-1';
			const image2 = 'image-2';
			await shellExec(`docker rmi -f ${image1} ${image2}`);
			const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --image-name ${image1} --image-name ${image2}`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.equal(response.imageName[0], image1);
			assert.equal(response.imageName[1], image2);
			await shellExec(`docker inspect --type image ${image1} ${image2}`);
		});

		it('should fail with --push true and --output', async () => {
			let success = false;
			const testFolder = `${__dirname}/configs/dockerfile-with-target`;
			try {
				await shellExec(`${cli} build --workspace-folder ${testFolder} --output type=oci,dest=output.tar --push true`);
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /cannot be used with/);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('file ${os.tmpdir()}/output.tar should exist when using --output type=oci,dest=${os.tmpdir()/output.tar', async () => {
			const testFolder = `${__dirname}/configs/dockerfile-with-target`;
			const outputPath = `${os.tmpdir()}/output.tar`;
			try {
				await shellExec('docker buildx create --name ocitest');
				await shellExec('docker buildx use ocitest');
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --output 'type=oci,dest=${outputPath}'`);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
				assert.equal(fs.existsSync(outputPath), true);
			} finally {
				await shellExec('docker buildx use default');
				await shellExec('docker buildx rm ocitest');
			}
		});

		it(`should execute successfully and export buildx cache with container builder`, async () => {
			const builderName = 'test-container-builder';
			try {
				await shellExec(`docker buildx create --name ${builderName} --driver docker-container --use`);

				const testFolder = `${__dirname}/configs/dockerfile-with-features`;
				const outputPath = `${os.tmpdir()}/test-build-cache`;
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --log-level trace --cache-to=type=local,dest=${outputPath}`);
				console.log(res.stdout);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
				assert.equal(fs.existsSync(`${outputPath}/index.json`), true);
			} finally {
				await shellExec(`docker buildx rm ${builderName}`);
			}
		});

		it(`should execute successfully and export buildx cache with container builder and image`, async () => {
			const builderName = 'test-container-builder-image';
			try {
				await shellExec(`docker buildx create --name ${builderName} --driver docker-container --use`);

				const testFolder = `${__dirname}/configs/image-with-features`;
				const outputPath = `${os.tmpdir()}/test-build-cache-image`;
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --log-level trace --cache-to=type=local,dest=${outputPath}`);
				console.log(res.stdout);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
				assert.equal(fs.existsSync(`${outputPath}/index.json`), true);
			} finally {
				await shellExec(`docker buildx rm ${builderName}`);
			}
		});

		it('should fail with docker-compose and --cache-to not supported', async () => {
			let success = false;
			const testFolder = `${__dirname}/configs/compose-image-with-features`;
			const builderName = 'test-container-builder';
			const outputPath = `${os.tmpdir()}/test-build-cache`;

			try {
				await shellExec(`docker buildx create --name ${builderName} --driver docker-container --use`);

				await shellExec(`${cli} build --workspace-folder ${testFolder} --log-level trace --cache-to=type=local,dest=${outputPath}`);
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /not supported/);
			} finally {
				await shellExec(`docker buildx rm ${builderName}`);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it(`should execute successfully docker-compose without features with container builder`, async () => {
			const builderName = 'test-container-builder';
			try {
				await shellExec(`docker buildx create --name ${builderName} --driver docker-container --use`);

				const testFolder = `${__dirname}/configs/compose-image-without-features-minimal`;
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --log-level trace`);
				console.log(res.stdout);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');

			} finally {
				await shellExec(`docker buildx rm ${builderName}`);
			}
		});

		it('should follow the correct merge logic for containerEnv', async () => {
			const res = await shellExec(`${cli} build --workspace-folder ${__dirname}/configs/image-metadata-containerEnv --image-name "test-metadata"`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');

			const resRun = await shellExec(`docker run -it -d "test-metadata"`);
			const containerId: string = resRun.stdout.split('\n')[0];
			assert.ok(containerId, 'Container id not found.');

			const expectedContainerEnv = {
				'JAVA_HOME': '/usr/lib/jvm/msopenjdk-current',
				'VAR_WITH_SPACES': 'value with spaces',
				'VAR_WITH_LOTS_OF_SPACES': '    value with lots of spaces.   ',
				'VAR_WITH_QUOTES_WE_WANT_TO_KEEP': 'value with "quotes" we want to keep',
				'VAR_WITH_DOLLAR_SIGN': 'value with $dollar sign',
				'VAR_WITH_BACK_SLASH': 'value with \\back slash',
				'ENV_WITH_COMMAND': 'bash -c \'echo -n "Hello, World!"\''
			};

			for (const [key, value] of Object.entries(expectedContainerEnv)) {
				const result = await shellExec(`docker exec ${containerId} bash -c 'echo $${key}'`);
				assert.equal(result.stdout, `${value.trim()}\n`);
			}

			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should build with config in subfolder', async () => {
			const res = await shellExec(`${cli} build --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json --image-name test-subfolder-config`);
			const response = JSON.parse(res.stdout);
			assert.strictEqual(response.outcome, 'success');

			const details = JSON.parse((await shellExec(`docker inspect test-subfolder-config`)).stdout)[0] as ImageDetails;
			assert.strictEqual(envListToObj(details.Config.Env).SUBFOLDER_CONFIG_IMAGE_ENV, 'true');
		});

		it('should apply build options', async () => {
			const testFolder = `${__dirname}/configs/dockerfile-with-target`;
			const res = await shellExec(`${cli} build --workspace-folder ${testFolder}`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.ok(response.imageName);
			const details = JSON.parse((await shellExec(`docker inspect ${response.imageName}`)).stdout)[0] as ImageDetails;
			assert.strictEqual(details.Config.Labels?.test_build_options, 'success');
		});
	});
});
</file>

<file path="src/test/cli.exec.base.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { BuildKitOption, commandMarkerTests, devContainerDown, devContainerStop, devContainerUp, pathExists, shellBufferExec, shellExec, shellPtyExec } from './testUtils';

const pkg = require('../../package.json');

export function describeTests1({ text, options }: BuildKitOption) {

	describe('Dev Containers CLI', function () {
		this.timeout('360s');

		const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
		const cli = `npx --prefix ${tmp} devcontainer`;

		before('Install', async () => {
			await shellExec(`rm -rf ${tmp}/node_modules`);
			await shellExec(`mkdir -p ${tmp}`);
			await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
		});

		describe('Command exec', () => {

			describe(`with valid (image) config [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/image`;
				beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, options)).containerId);
				afterEach(async () => await devContainerDown({ containerId }));
				it('should execute successfully', async () => {
					const res = await shellBufferExec(`${cli} exec --workspace-folder ${testFolder} echo hi`);
					assert.strictEqual(res.code, 0);
					assert.equal(res.signal, undefined);
					assert.strictEqual(res.stdout.toString(), 'hi\n');
				});
				it('should not run in a terminal', async () => {
					const res = await shellBufferExec(`${cli} exec --workspace-folder ${testFolder} [ ! -t 1 ]`);
					assert.strictEqual(res.code, 0);
					assert.equal(res.signal, undefined);
				});
				it('should return exit code without terminal', async () => {
					const res = await shellBufferExec(`${cli} exec --workspace-folder ${testFolder} sh -c 'exit 123'`);
					assert.strictEqual(res.code, 123);
					assert.equal(res.signal, undefined);
				});
				it('stream binary data', async () => {
					const stdin = Buffer.alloc(256);
					stdin.forEach((_, i) => stdin[i] = i);
					const res = await shellBufferExec(`${cli} exec --workspace-folder ${testFolder} cat`, { stdin });
					assert.strictEqual(res.code, 0);
					assert.equal(res.signal, undefined);
					assert.ok(res.stdout.equals(stdin), 'stdout does not match stdin: ' + res.stdout.toString('hex'));
				});
				it('should run in a terminal', async () => {
					const res = await shellPtyExec(`${cli} exec --workspace-folder ${testFolder} [ -t 1 ]`);
					assert.strictEqual(res.code, 0);
					assert.equal(res.signal, undefined);
				});
				it('should return exit code without terminal', async () => {
					const res = await shellPtyExec(`${cli} exec --workspace-folder ${testFolder} sh -c 'exit 123'`);
					assert.strictEqual(res.code, 123);
					assert.equal(res.signal, 0);
				});
				it('should connect stdin', async () => {
					const res = await shellPtyExec(`${cli} exec --workspace-folder ${testFolder} sh`, { stdin: 'FOO=BAR\necho ${FOO}hi${FOO}\nexit\n' });
					assert.strictEqual(res.code, 0);
					assert.equal(res.signal, undefined);
					assert.match(res.cmdOutput, /BARhiBAR/);
				});
				it('should pass along --remote-env', async () => {
					const res = await shellBufferExec(`${cli} exec --workspace-folder ${testFolder} --remote-env FOO=BAR --remote-env BAZ= printenv`);
					assert.strictEqual(res.code, 0);
					assert.equal(res.signal, undefined);
					const stdout = res.stdout.toString();
					const env = stdout
						.split('\n')
						.map(l => l.split('='))
						.reduce((m, [k, v]) => { m[k] = v; return m; }, {} as { [key: string]: string });
					assert.strictEqual(env.FOO, 'BAR');
					assert.strictEqual(env.BAZ, '');
				});
			});
			describe(`with valid (image) config containing features [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/image-with-features`;
				beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, options)).containerId);
				afterEach(async () => await devContainerDown({ containerId }));
				it('should have access to installed features (docker)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker --version`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /Docker version/);
				});
				it('should have access to installed features (hello)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /howdy, node/);
				});
			});
			describe(`with valid (Dockerfile) config containing features [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/dockerfile-with-features`;
				beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, options)).containerId);
				afterEach(async () => await devContainerDown({ containerId }));
				it('should have access to installed features (docker)', async () => {
					// NOTE: Doing a docker ps will ensure that the --privileged flag was set by the feature
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker ps`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /CONTAINER ID/);
				});
				it('should have access to installed features (hello)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /howdy, node/);
				});
			});
			describe(`with valid (image) config and parallel initializeCommand [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/image-with-parallel-initialize-command`;
				beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, options)).containerId);
				afterEach(async () => {
					await devContainerDown({ containerId });
					await shellExec(`rm -f ${testFolder}/*.testMarker`);
				});
				it('should create testMarker files', async () => {
					{
						const res = await shellExec(`cat ${testFolder}/initializeCommand.1.testMarker`);
						assert.strictEqual(res.error, null);
						assert.strictEqual(res.stderr, '');
					}
					{
						const res = await shellExec(`cat ${testFolder}/initializeCommand.2.testMarker`);
						assert.strictEqual(res.error, null);
						assert.strictEqual(res.stderr, '');
					}
				});
			});
			describe(`with valid (Dockerfile) config with target [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/dockerfile-with-target`;
				beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, options)).containerId);
				afterEach(async () => await devContainerDown({ containerId }));
				it('should have build marker content', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} cat /var/test-marker`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /||test-content||/);
				});
				it('should have access to installed features (hello)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /howdy, node/);
				});
			});

			describe(`with valid (docker-compose with image) config containing v1 features [${text}]`, () => {
				let composeProjectName: string | undefined = undefined;
				const testFolder = `${__dirname}/configs/compose-image-with-features`;
				beforeEach(async () => composeProjectName = (await devContainerUp(cli, testFolder, options)).composeProjectName);
				afterEach(async () => await devContainerDown({ composeProjectName }));
				it('should have access to installed features (docker)', async () => {
					// NOTE: Doing a docker ps will ensure that the --privileged flag was set by the feature
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker ps`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /CONTAINER ID/);
				});
				it('should have access to installed features (hello)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /howdy, node/);
				});
			});

			describe(`with valid (docker-compose with Dockerfile) config containing features [${text}]`, () => {
				let composeProjectName: string | undefined = undefined;
				const testFolder = `${__dirname}/configs/compose-Dockerfile-with-features`;
				beforeEach(async () => composeProjectName = (await devContainerUp(cli, testFolder, options)).composeProjectName);
				afterEach(async () => await devContainerDown({ composeProjectName }));
				it('should have access to installed features (docker)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker --version`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /Docker version/);
				});
				it('should have access to installed features (hello)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /howdy, node/);
				});
			});
		});
	});
}

export function describeTests2({ text, options }: BuildKitOption) {

	describe('Dev Containers CLI', function () {
		this.timeout('300s');

		const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
		const cli = `npx --prefix ${tmp} devcontainer`;

		before('Install', async () => {
			await shellExec(`rm -rf ${tmp}/node_modules`);
			await shellExec(`mkdir -p ${tmp}`);
			await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
		});

		describe('Command exec', () => {

			describe(`with valid (docker-compose with Dockerfile and target) config containing features [${text}]`, () => {
				let composeProjectName: string | undefined = undefined;
				const testFolder = `${__dirname}/configs/compose-Dockerfile-with-target`;
				beforeEach(async () => composeProjectName = (await devContainerUp(cli, testFolder, options)).composeProjectName);
				afterEach(async () => await devContainerDown({ composeProjectName }));
				it('should have access to installed features (docker)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker --version`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /Docker version/);
				});
				it('should have access to installed features (hello)', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /howdy, node/);
				});
				it('should have marker content', async () => {
					const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} cat /var/test-marker`);
					assert.strictEqual(res.error, null);
					assert.match(res.stdout, /||test-content||/);
				});
			});


			describe(`Dockerfile with post*Commands specified [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/dockerfile-with-target`;
				afterEach(async () => await devContainerDown({ containerId }));
				it('should have all command markers at appropriate times', async () => {
					containerId = (await devContainerUp(cli, testFolder, options)).containerId;
					// Should have all markers (Create + Start + Attach)
					await commandMarkerTests(cli, testFolder, { postCreate: true, postStart: true, postAttach: true }, 'Markers on first create');

					// Clear markers and stop
					await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					await devContainerStop({ containerId });

					// Restart container - should have Start + Attach
					containerId = (await devContainerUp(cli, testFolder, options)).containerId;
					await commandMarkerTests(cli, testFolder, { postCreate: false, postStart: true, postAttach: true }, 'Markers on restart');

					// TODO - investigate what triggers postAttachCommand and check test is valid
					// // Clear markers and re-test - should have Attach
					// await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					// await commandMarkerTests(testFolder, { postCreate: false, postStart: false, postAttach: true }, 'Markers on attach');
				});
				it('should not run postAttachCommand when --skip-post-attach is given', async () => {
					const testOptions = { ...options, extraArgs: '--skip-post-attach' };
					containerId = (await devContainerUp(cli, testFolder, testOptions)).containerId;
					// Should have Create + Start but not Attach
					await commandMarkerTests(cli, testFolder, { postCreate: true, postStart: true, postAttach: false }, 'Markers on first create');

					// Clear markers and stop
					await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					await devContainerStop({ containerId });

					// Restart container - should have Start
					containerId = (await devContainerUp(cli, testFolder, testOptions)).containerId;
					await commandMarkerTests(cli, testFolder, { postCreate: false, postStart: true, postAttach: false }, 'Markers on restart');

					await devContainerDown({ containerId });

					// Shouldn't have any markers
					containerId = (await devContainerUp(cli, testFolder, { ...options, extraArgs: '--skip-post-create' })).containerId;
					await commandMarkerTests(cli, testFolder, { postCreate: false, postStart: false, postAttach: false }, 'Markers on --skip-post-create');

					// Should have Create + Start but not Attach
					const res = await shellExec(`${cli} run-user-commands --skip-post-attach --workspace-folder ${testFolder}`);
					assert.strictEqual(res.error, null);
					await commandMarkerTests(cli, testFolder, { postCreate: true, postStart: true, postAttach: false }, 'Markers on run-user-commands');
				});
			});
			describe(`Dockerfile with parallel post*Commands specified [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/dockerfile-with-parallel-commands`;
				after(async () => await devContainerDown({ containerId }));
				it('should have all command markers at appropriate times', async () => {
					containerId = (await devContainerUp(cli, testFolder, options)).containerId;
					// Should have all markers (Create + Start + Attach)
					assert.ok(await pathExists(cli, testFolder, '/tmp/postCreateCommand1.testmarker'));
					assert.ok(await pathExists(cli, testFolder, '/tmp/postCreateCommand2.testmarker'));
					assert.ok(await pathExists(cli, testFolder, '/tmp/postStartCommand1.testmarker'));
					assert.ok(await pathExists(cli, testFolder, '/tmp/postStartCommand2.testmarker'));
					assert.ok(await pathExists(cli, testFolder, '/tmp/postAttachCommand1.testmarker'));
					assert.ok(await pathExists(cli, testFolder, '/tmp/postAttachCommand2.testmarker'));
				});
			});
			describe(`docker-compose with post*Commands specified [${text}]`, () => {
				let composeProjectName: string | undefined = undefined;
				const testFolder = `${__dirname}/configs/compose-Dockerfile-with-target`;
				after(async () => await devContainerDown({ composeProjectName }));
				it('should have all command markers at appropriate times', async () => {
					composeProjectName = (await devContainerUp(cli, testFolder, options)).composeProjectName;
					// Should have all markers (Create + Start + Attach)
					await commandMarkerTests(cli, testFolder, { postCreate: true, postStart: true, postAttach: true }, 'Markers on first create');

					// Clear markers and stop
					await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					await devContainerStop({ composeProjectName });

					// Restart container - should have Start + Attach
					composeProjectName = (await devContainerUp(cli, testFolder, options)).composeProjectName;
					await commandMarkerTests(cli, testFolder, { postCreate: false, postStart: true, postAttach: true }, 'Markers on restart');

					// TODO - investigate what triggers postAttachCommand and check test is valid
					// // Clear markers and re-test - should have Attach
					// await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					// await commandMarkerTests(testFolder, { postCreate: false, postStart: false, postAttach: true }, 'Markers on attach');
				});
			});
			describe(`docker-compose with post*Commands specified (stop individual container) [${text}]`, () => {
				let containerId: string | null = null;
				const testFolder = `${__dirname}/configs/compose-Dockerfile-with-target`;
				after(async () => await devContainerDown({ containerId }));
				it('should have all command markers at appropriate times', async () => {
					containerId = (await devContainerUp(cli, testFolder, options)).containerId;
					// Should have all markers (Create + Start + Attach)
					await commandMarkerTests(cli, testFolder, { postCreate: true, postStart: true, postAttach: true }, 'Markers on first create');

					// Clear markers and stop
					await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					await devContainerStop({ containerId });

					// Restart container - should have Start + Attach
					containerId = (await devContainerUp(cli, testFolder, options)).containerId;
					await commandMarkerTests(cli, testFolder, { postCreate: false, postStart: true, postAttach: true }, 'Markers on restart');

					// TODO - investigate what triggers postAttachCommand and check test is valid
					// // Clear markers and re-test - should have Attach
					// await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
					// await commandMarkerTests(testFolder, { postCreate: false, postStart: false, postAttach: true }, 'Markers on attach');
				});
				describe(`docker-compose alpine with post*Commands [${text}]`, () => {
					let containerId: string | null = null;
					const testFolder = `${__dirname}/configs/compose-Dockerfile-alpine`;
					after(async () => await devContainerDown({ containerId }));
					it('should have all command markers at appropriate times', async () => {
						containerId = (await devContainerUp(cli, testFolder, options)).containerId;
						// Should have all markers (Create + Start + Attach)
						await commandMarkerTests(cli, testFolder, { postCreate: true, postStart: true, postAttach: true }, 'Markers on first create');

						// Clear markers and stop
						await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
						assert.ok(containerId);
						await devContainerStop({ containerId });

						// Restart container - should have Start + Attach
						containerId = (await devContainerUp(cli, testFolder, options)).containerId;
						await commandMarkerTests(cli, testFolder, { postCreate: false, postStart: true, postAttach: true }, 'Markers on restart');

						// TODO - investigate what triggers postAttachCommand and check test is valid
						// // Clear markers and re-test - should have Attach
						// await shellExec(`${cli} exec --workspace-folder ${testFolder} /bin/sh -c "rm /tmp/*.testmarker"`);
						// await commandMarkerTests(testFolder, { postCreate: false, postStart: false, postAttach: true }, 'Markers on attach');
					});
				});
			});

			if (options.useBuildKit) {
				describe('with valid (Dockerfile) config containing #syntax (BuildKit)', () => { // ensure existing '# syntax' lines are handled
					let containerId: string | null = null;
					const testFolder = `${__dirname}/configs/dockerfile-with-syntax`;
					beforeEach(async () => containerId = (await devContainerUp(cli, testFolder, { useBuildKit: true })).containerId);
					afterEach(async () => await devContainerDown({ containerId }));
					it('should have access to installed features (docker)', async () => {
						const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} docker --version`);
						assert.strictEqual(res.error, null);
						assert.match(res.stdout, /Docker version/);
					});
					it('should have access to installed features (hello)', async () => {
						const res = await shellExec(`${cli} exec --workspace-folder ${testFolder} hello`);
						assert.strictEqual(res.error, null);
						assert.match(res.stdout, /howdy, node/);
					});
				});
		
				it('should fail with "not found" error when config is not found', async () => {
					let success = false;
					try {
						await shellExec(`${cli} exec --workspace-folder path-that-does-not-exist echo hi`);
						success = true;
					} catch (error) {
						assert.equal(error.error.code, 1, 'Should fail with exit code 1');
						assert.match(error.stderr, /Dev container config \(.*\) not found./);
					}
					assert.equal(success, false, 'expect non-successful call');
				});
			}

			it('should exec with config in subfolder', async () => {
				const upRes = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json`);
				const response = JSON.parse(upRes.stdout);
				assert.strictEqual(response.outcome, 'success');

				const execRes = await shellExec(`${cli} exec --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json bash -c 'printenv SUBFOLDER_CONFIG_REMOTE_ENV'`);
				assert.strictEqual(execRes.stdout.trim(), 'true');

				await shellExec(`docker rm -f ${response.containerId}`);
			});
		});
	});
}
</file>

<file path="src/test/cli.exec.buildKit.1.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { describeTests1 } from './cli.exec.base';
import { buildKitOption } from './testUtils';

describeTests1(buildKitOption);
</file>

<file path="src/test/cli.exec.buildKit.2.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { describeTests2 } from './cli.exec.base';
import { buildKitOption } from './testUtils';

describeTests2(buildKitOption);
</file>

<file path="src/test/cli.exec.nonBuildKit.1.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { describeTests1 } from './cli.exec.base';
import { nonBuildKitOption } from './testUtils';

describeTests1(nonBuildKitOption);
</file>

<file path="src/test/cli.exec.nonBuildKit.2.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { describeTests2 } from './cli.exec.base';
import { nonBuildKitOption } from './testUtils';

describeTests2(nonBuildKitOption);
</file>

<file path="src/test/cli.podman.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { shellExec } from './testUtils';

const pkg = require('../../package.json');

describe('Dev Containers CLI using Podman', function () {
	this.timeout('240s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('Command up using Podman', () => {

		it('should execute successfully with valid config with features', async () => {
			const res = await shellExec(`${cli} up --docker-path podman --workspace-folder ${__dirname}/configs/image-with-features`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');
			await shellExec(`podman rm -f ${containerId}`);
		});

		it('should execute successfully with valid config with features', async () => {
			const res = await shellExec(`${cli} up --docker-path podman --workspace-folder ${__dirname}/configs/dockerfile-with-features`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');
			await shellExec(`podman rm -f ${containerId}`);
		});
	});
});
</file>

<file path="src/test/cli.set-up.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { shellExec } from './testUtils';

const pkg = require('../../package.json');

describe('Dev Containers CLI', function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('Command set-up', () => {
		it('should succeed and run postAttachCommand from config', async () => {

			const containerId = (await shellExec(`docker run -d -e TEST_CE=TEST_VALUE alpine:3.17 sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} set-up --container-id ${containerId} --config ${__dirname}/configs/set-up-with-config/devcontainer.json --include-configuration --include-merged-configuration`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.equal(response.configuration?.remoteEnv?.TEST_RE, 'TEST_VALUE');
			assert.equal(response.mergedConfiguration?.remoteEnv?.TEST_RE, 'TEST_VALUE');

			await shellExec(`docker exec ${containerId} test -f /postAttachCommand.txt`);
			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should succeed and run postCreateCommand from metadata', async () => {

			await shellExec(`docker build -t devcontainer-set-up-test ${__dirname}/configs/set-up-with-metadata`);
			const containerId = (await shellExec(`docker run -d -e TEST_CE=TEST_VALUE2 devcontainer-set-up-test sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} set-up --container-id ${containerId} --include-configuration --include-merged-configuration`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.equal(Object.keys(response.configuration).length, 0);
			assert.equal(response.mergedConfiguration?.remoteEnv?.TEST_RE, 'TEST_VALUE2');

			await shellExec(`docker exec ${containerId} test -f /postCreateCommand.txt`);
			await shellExec(`docker rm -f ${containerId}`);
		});
	});

	describe('Command run-user-commands', () => {
		it('should succeed and run postAttachCommand from config', async () => {

			const containerId = (await shellExec(`docker run -d alpine:3.17 sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} run-user-commands --container-id ${containerId} --config ${__dirname}/configs/set-up-with-config/devcontainer.json`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');

			await shellExec(`docker exec ${containerId} test -f /postAttachCommand.txt`);
			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should succeed and run postCreateCommand from metadata', async () => {

			await shellExec(`docker build -t devcontainer-set-up-test ${__dirname}/configs/set-up-with-metadata`);
			const containerId = (await shellExec(`docker run -d devcontainer-set-up-test sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} run-user-commands --container-id ${containerId}`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');

			await shellExec(`docker exec ${containerId} test -f /postCreateCommand.txt`);
			await shellExec(`docker rm -f ${containerId}`);
		});
	});

	describe('Command read-configuration', () => {
		it('should succeed and return postAttachCommand from config', async () => {

			const containerId = (await shellExec(`docker run -d alpine:3.17 sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} read-configuration --container-id ${containerId} --config ${__dirname}/configs/set-up-with-config/devcontainer.json --include-merged-configuration`);
			const response = JSON.parse(res.stdout);
			assert.ok(response.configuration.postAttachCommand);
			assert.strictEqual(response.mergedConfiguration.postAttachCommands.length, 1);

			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should succeed and return postCreateCommand from metadata', async () => {

			await shellExec(`docker build -t devcontainer-set-up-test ${__dirname}/configs/set-up-with-metadata`);
			const containerId = (await shellExec(`docker run -d devcontainer-set-up-test sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} read-configuration --container-id ${containerId} --include-merged-configuration`);
			const response = JSON.parse(res.stdout);
			assert.strictEqual(response.mergedConfiguration.postCreateCommands.length, 1);

			await shellExec(`docker rm -f ${containerId}`);
		});
	});

	describe('Command exec', () => {
		it('should succeed with config', async () => {

			const containerId = (await shellExec(`docker run -d alpine:3.17 sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} exec --container-id ${containerId} --config ${__dirname}/configs/set-up-with-config/devcontainer.json echo test-output`);
			assert.strictEqual(res.error, null);
			assert.match(res.stdout, /test-output/);

			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should succeed with metadata', async () => {

			await shellExec(`docker build -t devcontainer-set-up-test ${__dirname}/configs/set-up-with-metadata`);
			const containerId = (await shellExec(`docker run -d devcontainer-set-up-test sleep inf`)).stdout.trim();

			const res = await shellExec(`${cli} exec --container-id ${containerId} echo test-output`);
			assert.strictEqual(res.error, null);
			assert.match(res.stdout, /test-output/);

			await shellExec(`docker rm -f ${containerId}`);
		});
	});
});
</file>

<file path="src/test/cli.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { devContainerDown, devContainerUp, shellExec } from './testUtils';

const pkg = require('../../package.json');

describe('Dev Containers CLI', function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	it('Global --help', async () => {
		const res = await shellExec(`${cli} --help`);
		assert.ok(res.stdout.indexOf('run-user-commands'), 'Help text is not mentioning run-user-commands.');
	});

	describe('Command run-user-commands', () => {
		describe('with valid config', () => {
			let containerId: string | null = null;
			const testFolder = `${__dirname}/configs/image`;
			beforeEach(async () => containerId = (await devContainerUp(cli, testFolder)).containerId);
			afterEach(async () => await devContainerDown({ containerId }));
			it('should execute successfully', async () => {
				const res = await shellExec(`${cli} run-user-commands --workspace-folder ${testFolder}`);
				const response = JSON.parse(res.stdout);
				assert.equal(response.outcome, 'success');
			});
		});

		it('should fail with "not found" error when config is not found', async () => {
			let success = false;
			try {
				await shellExec(`${cli} run-user-commands --workspace-folder path-that-does-not-exist`);
				success = true;
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /Dev container config \(.*\) not found./);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		it('should run with config in subfolder', async () => {
			const upRes = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json --skip-post-create`);
			const upResponse = JSON.parse(upRes.stdout);
			assert.strictEqual(upResponse.outcome, 'success');

			await shellExec(`docker exec ${upResponse.containerId} bash -c '! test -f /subfolderConfigPostCreateCommand.txt'`);

			const runRes = await shellExec(`${cli} run-user-commands --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json`);
			const runResponse = JSON.parse(runRes.stdout);
			assert.strictEqual(runResponse.outcome, 'success');

			await shellExec(`docker exec ${upResponse.containerId} test -f /subfolderConfigPostCreateCommand.txt`);

			await shellExec(`docker rm -f ${upResponse.containerId}`);
		});
	});

	describe('Command read-configuration', () => {
		it('should replace environment variables', async () => {
			const res1 = await shellExec(`${cli} read-configuration --workspace-folder ${__dirname}/configs/image`);
			const response1 = JSON.parse(res1.stdout);
			const remoteEnv1: Record<string, string> | undefined = response1.configuration.remoteEnv;
			assert.ok(remoteEnv1?.LOCAL_PATH?.startsWith('/'), `localEnv not replaced. (Was: ${remoteEnv1?.LOCAL_PATH})`);
			assert.strictEqual(remoteEnv1?.CONTAINER_PATH, '${containerEnv:PATH}');

			const res2 = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image`);
			const response2 = JSON.parse(res2.stdout);
			assert.equal(response2.outcome, 'success');
			const containerId: string = response2.containerId;
			assert.ok(containerId, 'Container id not found.');

			try {
				const res3 = await shellExec(`${cli} read-configuration --workspace-folder ${__dirname}/configs/image`);
				const response3 = JSON.parse(res3.stdout);
				const remoteEnv3: Record<string, string> | undefined = response3.configuration.remoteEnv;
				assert.ok(remoteEnv3?.LOCAL_PATH?.startsWith('/'), `localEnv not replaced. (Was: ${remoteEnv3?.LOCAL_PATH})`);
				assert.ok(remoteEnv3?.CONTAINER_PATH?.startsWith('/'), `containerEnv not replaced. (Was: ${remoteEnv3?.CONTAINER_PATH})`);
			} finally {
				await shellExec(`docker rm -f ${containerId}`);
			}
		});

		it('should replace environment variables with merged config', async () => {
			const res1 = await shellExec(`${cli} read-configuration --workspace-folder ${__dirname}/configs/image --include-merged-configuration`);
			const response1 = JSON.parse(res1.stdout);
			const remoteEnv1: Record<string, string> | undefined = response1.mergedConfiguration.remoteEnv;
			assert.ok(remoteEnv1?.LOCAL_PATH?.startsWith('/'), `localEnv not replaced. (Was: ${remoteEnv1?.LOCAL_PATH})`);
			assert.strictEqual(remoteEnv1?.CONTAINER_PATH, '${containerEnv:PATH}');

			const res2 = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image`);
			const response2 = JSON.parse(res2.stdout);
			assert.equal(response2.outcome, 'success');
			const containerId: string = response2.containerId;
			assert.ok(containerId, 'Container id not found.');

			try {
				const res3 = await shellExec(`${cli} read-configuration --workspace-folder ${__dirname}/configs/image --include-merged-configuration`);
				const response3 = JSON.parse(res3.stdout);
				const remoteEnv3: Record<string, string> | undefined = response3.mergedConfiguration.remoteEnv;
				assert.ok(remoteEnv3?.LOCAL_PATH?.startsWith('/'), `localEnv not replaced. (Was: ${remoteEnv3?.LOCAL_PATH})`);
				assert.ok(remoteEnv3?.CONTAINER_PATH?.startsWith('/'), `containerEnv not replaced. (Was: ${remoteEnv3?.CONTAINER_PATH})`);
			} finally {
				await shellExec(`docker rm -f ${containerId}`);
			}
		});

		it('should read config in subfolder', async () => {
			const res = await shellExec(`${cli} read-configuration --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json`);
			const response = JSON.parse(res.stdout);
			assert.strictEqual(response.configuration.remoteEnv.SUBFOLDER_CONFIG_REMOTE_ENV, 'true');
		});
	});
});
</file>

<file path="src/test/cli.up.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import * as fs from 'fs';
import * as os from 'os';
import { devContainerDown, devContainerUp, shellExec, UpResult } from './testUtils';

const pkg = require('../../package.json');

describe('Dev Containers CLI', function () {
	this.timeout('240s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;


	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('Command up', () => {

		it('should execute successfully with valid config', async () => {
			const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image --include-configuration --include-merged-configuration`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			assert.equal(response.configuration?.remoteEnv?.TEST_RE, 'TEST_VALUE3');
			assert.equal(response.mergedConfiguration?.remoteEnv?.TEST_RE, 'TEST_VALUE3');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');
			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should execute successfully with valid config with a Feature', async () => {
			const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');
			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should execute successfully with valid config with features', async () => {
			const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-features`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');
			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should fail with "not found" error when config is not found', async () => {
			let success = false;
			try {
				await shellExec(`${cli} up --workspace-folder path-that-does-not-exist`);
				success = true;
			} catch (error) {
				assert.equal(error.error.code, 1, 'Should fail with exit code 1');
				const res = JSON.parse(error.stdout);
				assert.equal(res.outcome, 'error');
				assert.match(res.message, /Dev container config \(.*\) not found./);
			}
			assert.equal(success, false, 'expect non-successful call');
		});

		// docker-compose variations _without_ features are here (under 'up' tests)
		// docker-compose variations _with_ features are under 'exec' to test features are installed
		describe('for docker-compose with image without features', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-image-without-features`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder);
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
			});
		});
		describe('for docker-compose with Dockerfile without features', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-Dockerfile-without-features`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder);
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
			});
		});
		describe('for minimal docker-compose with custom project name', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-with-name`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder, { 'logLevel': 'trace', extraArgs: `--docker-compose-path trigger-compose-v2` });
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
				assert.equal(upResult!.composeProjectName, 'custom-project-name');
			});
		});
		describe('for minimal docker-compose with custom project name using environment variable', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-with-name-using-env-var`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder, {
					logLevel: 'trace',
					extraArgs: `--docker-compose-path trigger-compose-v2`,
					env: {
						...process.env,
						'CUSTOM_NAME': 'custom-name-with-env-var'
					}
				});
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
				assert.equal(upResult!.composeProjectName, 'custom-name-with-env-var');
			});
		});
		describe('for minimal docker-compose with custom project name "devcontainer" using environment variable', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-with-name-using-env-var`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder, {
					logLevel: 'trace',
					extraArgs: `--docker-compose-path trigger-compose-v2`,
					env: {
						...process.env,
						'CUSTOM_NAME': 'devcontainer'
					}
				});
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
				assert.equal(upResult!.composeProjectName, 'devcontainer');
			});
		});
		describe('for minimal docker-compose with custom project name and custom yaml', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-with-name-and-custom-yaml`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder, { 'logLevel': 'trace', extraArgs: `--docker-compose-path trigger-compose-v2` });
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
				assert.equal(upResult!.composeProjectName, 'custom-project-name-custom-yaml');
			});
		});
		describe('for minimal docker-compose without custom project name', () => {
			let upResult: UpResult | null = null;
			const testFolder = `${__dirname}/configs/compose-without-name`;
			before(async () => {
				// build and start the container
				upResult = await devContainerUp(cli, testFolder, { 'logLevel': 'trace', extraArgs: `--docker-compose-path trigger-compose-v2` });
			});
			after(async () => await devContainerDown({ composeProjectName: upResult?.composeProjectName }));
			it('should succeed', () => {
				assert.equal(upResult!.outcome, 'success');
				assert.equal(upResult!.composeProjectName, 'compose-without-name_devcontainer');
			});
		});

		// Additional tests to verify the handling of persisted files
		describe('for docker-compose with Dockerfile with features', () => {
			describe('with existing container and persisted override files', () => {
				let upResult1: UpResult | null = null;
				let upResult2: UpResult | null = null;
				let userDataFolder: string | null = null;
				const testFolder = `${__dirname}/configs/compose-Dockerfile-with-features`;
				before(async () => {
					// Create a new temp folder for persisted files for this test
					// so that we can check the contents...
					const tmpDir = os.tmpdir();
					userDataFolder = fs.mkdtempSync(path.join(tmpDir, 'dc-cli-test-'));

					// build and start the container
					upResult1 = await devContainerUp(cli, testFolder, { userDataFolder });

					// stop the container but don't delete it
					await shellExec(`docker compose --project-name ${upResult1.composeProjectName} stop`);

					// restart the container
					upResult2 = await devContainerUp(cli, testFolder, { userDataFolder });

				});
				after(async () => await devContainerDown({ composeProjectName: upResult2?.composeProjectName }));
				it('should succeed', () => {
					assert.equal(upResult2?.outcome, 'success');
				});
				it('should re-used stopped container', () => {
					assert.equal(upResult2?.containerId, upResult1?.containerId);
				});
				it('should re-used the persisted override file', async () => {
					const userDataFiles = fs.readdirSync(path.join(userDataFolder!, 'docker-compose'));
					assert.equal(userDataFiles.length, 2); // build override and start override
					assert.ok(userDataFiles.findIndex(f => f.startsWith('docker-compose.devcontainer.build-')) >= 0);
					assert.ok(userDataFiles.findIndex(f => f.startsWith('docker-compose.devcontainer.containerFeatures-')) >= 0);
				});
			});
			describe('with existing container and without persisted override files', () => {
				let upResult1: UpResult | null = null;
				let upResult2: UpResult | null = null;
				const testFolder = `${__dirname}/configs/compose-Dockerfile-with-features`;
				before(async () => {
					// Create a new temp folder for persisted files for this test
					// so that we can delete them and check all works ok
					const tmpDir = os.tmpdir();
					const userDataFolder = fs.mkdtempSync(path.join(tmpDir, 'dc-cli-test-'));

					// build and start the container
					upResult1 = await devContainerUp(cli, testFolder, { userDataFolder });

					// stop the container but don't delete it
					await shellExec(`docker compose --project-name ${upResult1.composeProjectName} stop`);
					assert.ok(upResult1?.composeProjectName);

					// recreate directory to delete cached files
					fs.rmSync(userDataFolder, { force: true, recursive: true });
					fs.mkdirSync(userDataFolder);

					// restart the container
					upResult2 = await devContainerUp(cli, testFolder, { userDataFolder });

				});
				after(async () => await devContainerDown({ composeProjectName: upResult2?.composeProjectName }));
				it('should succeed', () => {
					assert.equal(upResult2?.outcome, 'success');
				});
				it('should re-use stopped container', () => {
					assert.equal(upResult2?.containerId, upResult1?.containerId);
				});
			});
		});

		it('should follow the correct merge logic for containerEnv', async () => {
			const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-metadata-containerEnv`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');

			const javaHome = await shellExec(`docker exec ${containerId} bash -c 'echo -n $JAVA_HOME'`);
			assert.equal('/usr/lib/jvm/msopenjdk-current', javaHome.stdout);

			const envWithSpaces = await shellExec(`docker exec ${containerId} bash -c 'echo -n $VAR_WITH_SPACES'`);
			assert.equal('value with spaces', envWithSpaces.stdout);

			const evalEnvWithCommand = await shellExec(`docker exec ${containerId} bash -c 'eval $ENV_WITH_COMMAND'`);
			assert.equal('Hello, World!', evalEnvWithCommand.stdout);

			await shellExec(`docker rm -f ${containerId}`);
		});

		it('should follow the correct merge logic for containerEnv using docker compose', async () => {
			const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-containerEnv-issue`);
			const response = JSON.parse(res.stdout);
			assert.equal(response.outcome, 'success');
			const containerId: string = response.containerId;
			assert.ok(containerId, 'Container id not found.');

			const somePath = await shellExec(`docker exec ${containerId} bash -c 'echo -n $SOME_PATH'`);
			assert.equal('/tmp/path/doc-ver/loc', somePath.stdout);

			const envWithSpaces = await shellExec(`docker exec ${containerId} bash -c 'echo -n $VAR_WITH_SPACES'`);
			assert.equal('value with spaces', envWithSpaces.stdout);

			const evalEnvWithCommand = await shellExec(`docker exec ${containerId} bash -c 'eval $ENV_WITH_COMMAND'`);
			assert.equal('Hello, World!', evalEnvWithCommand.stdout);

			const envWithTestMessage = await shellExec(`docker exec ${containerId} bash -c 'echo -n $Test_Message'`);
			assert.equal('H"\\n\\ne"\'\'\'llo M:;a/t?h&^iKa%#@!``ni,sk_a-', envWithTestMessage.stdout);			

			const envWithFormat = await shellExec(`docker exec ${containerId} bash -c 'echo -n $ROSCONSOLE_FORMAT'`);
			assert.equal('[$${severity}] [$${walltime:%Y-%m-%d %H:%M:%S}] [$${node}]: $${message}', envWithFormat.stdout);

			const envWithDoubleQuote = await shellExec(`docker exec ${containerId} bash -c 'echo -n $VAR_WITH_QUOTES_WE_WANT_TO_KEEP'`);
			assert.equal('value with \"quotes\" we want to keep', envWithDoubleQuote.stdout);

			const envWithDollar = await shellExec(`docker exec ${containerId} bash -c 'echo -n $VAR_WITH_DOLLAR_SIGN'`);
			assert.equal('value with $dollar sign', envWithDollar.stdout);

			const envWithBackSlash = await shellExec(`docker exec ${containerId} bash -c 'echo -n $VAR_WITH_BACK_SLASH'`);
			assert.equal('value with \\back slash', envWithBackSlash.stdout);	

			await shellExec(`docker rm -f ${containerId}`);
		});		

		it('should run with config in subfolder', async () => {
			const upRes = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/dockerfile-without-features --config ${__dirname}/configs/dockerfile-without-features/.devcontainer/subfolder/devcontainer.json`);
			const response = JSON.parse(upRes.stdout);
			assert.strictEqual(response.outcome, 'success');

			await shellExec(`docker exec ${response.containerId} test -f /subfolderConfigPostCreateCommand.txt`);

			await shellExec(`docker rm -f ${response.containerId}`);
		});
	});
});
</file>

<file path="src/test/disallowedFeatures.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import * as jsonc from 'jsonc-parser';

import { ensureNoDisallowedFeatures, findDisallowedFeatureEntry } from '../spec-node/disallowedFeatures';
import { readLocalFile } from '../spec-utils/pfs';
import { ContainerError } from '../spec-common/errors';
import { createCLIParams } from './testUtils';


describe(`Disallowed features check`, function () {

	it(`passes with allowed features`, async () => {
		const hostPath = path.join(__dirname, 'configs', 'disallowed-features');
		const configFile = path.join(hostPath, '.devcontainer', 'allowed', 'devcontainer.json');
		const config = jsonc.parse((await readLocalFile(configFile)).toString());
		const cliParams = await createCLIParams(hostPath);

		await ensureNoDisallowedFeatures(cliParams, config, {}, []);
	});

	it(`fails with disallowed features`, async () => {
		const hostPath = path.join(__dirname, 'configs', 'disallowed-features');
		const configFile = path.join(hostPath, '.devcontainer', 'disallowed', 'devcontainer.json');
		const config = jsonc.parse((await readLocalFile(configFile)).toString());
		const cliParams = await createCLIParams(hostPath);

		let error: Error | undefined;
		try {
			await ensureNoDisallowedFeatures(cliParams, config, {}, []);
		} catch (err) {
			error = err;
		}
		assert.ok(error, 'Expected error');
		assert.ok(error instanceof ContainerError, `Expected ContainerError got: ${error.message}`);
	});

	it(`matches equal feature id and prefix`, () => {
		const controlManifest = {
			disallowedFeatures: [
				{
					featureIdPrefix: 'example.io/test/node',
				},
			],
			featureAdvisories: [],
		};
		assert.ok(findDisallowedFeatureEntry(controlManifest, 'example.io/test/node'));
		assert.strictEqual(findDisallowedFeatureEntry(controlManifest, 'example.io/test/nodej'), undefined);
		assert.strictEqual(findDisallowedFeatureEntry(controlManifest, 'example.io/test/nod'), undefined);
		
		assert.ok(findDisallowedFeatureEntry(controlManifest, 'example.io/test/node:1'));
		assert.ok(findDisallowedFeatureEntry(controlManifest, 'example.io/test/node/js'));
		assert.ok(findDisallowedFeatureEntry(controlManifest, 'example.io/test/node@abc'));
		assert.strictEqual(findDisallowedFeatureEntry(controlManifest, 'example.io/test/node.js'), undefined);
	});
});
</file>

<file path="src/test/dockerComposeUtils.test.ts">
import { assert } from 'chai';
import * as yaml from 'js-yaml';
import * as path from 'path';
import { getBuildInfoForService } from '../spec-node/dockerCompose';

const testComposeFile = path.join('somepath', 'docker-compose.yml');

function loadYamlAndGetBuildInfoForService(input: string) {
    const yamlInput = yaml.load(input);
    return getBuildInfoForService(yamlInput, path, [testComposeFile]);
}

describe('docker-compose - getBuildInfoForService', () => {

    it('Parses fully specified info', () => {
        const input = `
image: my-image
build:
  context: context-path
  dockerfile: my-dockerfile
  target: a-target
  args:
    arg1: value1
`;
        const info = loadYamlAndGetBuildInfoForService(input);
        assert.deepEqual(info, {
            image: 'my-image',
            build: {
                context: 'context-path',
                dockerfilePath: 'my-dockerfile',
                target: 'a-target',
                args: {
                    arg1: 'value1',
                },
            }
        });
    });

    it('Parses image-only info', () => {
        const input = `
image: my-image
`;
        const info = loadYamlAndGetBuildInfoForService(input);
        assert.deepEqual(info, {
            image: 'my-image'
        });
    });

    it('Parses string build info', () => {
        const input = `
image: my-image
build: ./a-path
`;
        const info = loadYamlAndGetBuildInfoForService(input);
        assert.deepEqual(info, {
            image: 'my-image',
            build: {
                context: './a-path',
                dockerfilePath: 'Dockerfile'
            }
        });
    });

    it('Supplies default dockerFilePath when not set', () => {
        const input = `
build:
  context: ./a-path
`;
        const info = loadYamlAndGetBuildInfoForService(input);
        assert.deepEqual(info, {
            image: undefined,
            build: {
                context: './a-path',
                dockerfilePath: 'Dockerfile',
                target: undefined,
                args: undefined,
            }
        });
    });

    it('Supplies default context when not set', () => {
        const input = `
build:
  dockerfile: my-dockerfile
`;
        const info = loadYamlAndGetBuildInfoForService(input);
        assert.deepEqual(info, {
            image: undefined,
            build: {
                context: path.dirname(testComposeFile),
                dockerfilePath: 'my-dockerfile',
                target: undefined,
                args: undefined,
            }
        });
    });


});
</file>

<file path="src/test/dockerfileUtils.test.ts">
import { assert, expect } from 'chai';
import { imageMetadataLabel, internalGetImageBuildInfoFromDockerfile } from '../spec-node/imageMetadata';
import { ensureDockerfileHasFinalStageName, extractDockerfile, findBaseImage, findUserStatement, supportsBuildContexts } from '../spec-node/dockerfileUtils';
import { ImageDetails } from '../spec-shutdown/dockerUtils';
import { nullLog } from '../spec-utils/log';
import { testSubstitute } from './testUtils';

describe('ensureDockerfileHasFinalStageName', () => {

    describe('with named last stage it should return the stage name and no modifications', () => {
        it('for a simple FROM line', () => {
            const dockerfile = `
FROM ubuntu:latest as base

RUN some command

FROM base as final

COPY src dest
RUN another command
`;
            const { lastStageName, modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
            assert.equal(lastStageName, 'final');
            assert.isUndefined(modifiedDockerfile);
        });
    });

    describe('for a FROM line indented and followed by a comment', () => {
        it('should return the stage name', () => {
            const dockerfile = `
FROM ubuntu:latest as base

RUN some command

 \tFROM base  as\t  final  #<- deliberately mixing with whitespace and including: as something here

COPY src dest
RUN another command
`;
            const { lastStageName, modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
            assert.equal(lastStageName, 'final');
            assert.isUndefined(modifiedDockerfile);
        });
    });

    describe('for a FROM line with platform and named last stage indented and followed by a comment', () => {
        it('should return the stage name', () => {
            const dockerfile = `
FROM ubuntu:latest as base

RUN some command

 \tFROM  --platform=my-platform \tbase  as\t  final  #<- deliberately mixing with whitespace and including: as something here

COPY src dest
RUN another command
`;
            const { lastStageName, modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
            assert.equal(lastStageName, 'final');
            assert.isUndefined(modifiedDockerfile);
        });
    });


    describe('without a named last stage', () => {
        describe('for a simple FROM line', () => {
            const dockerfile = `
FROM ubuntu:latest as base

RUN some command

FROM base

COPY src dest
RUN another command
`;
            it('should return the placeholder as the last stage name', () => {
                const { lastStageName } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
                assert.equal(lastStageName, 'placeholder');
            });
            it('should return modified Dockerfile with stage name', () => {
                const { modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
                assert.equal(modifiedDockerfile, `
FROM ubuntu:latest as base

RUN some command

FROM base AS placeholder

COPY src dest
RUN another command
`);
            });
        });
        describe('for a simple, trailing FROM line', () => {
            const dockerfile = `
FROM ubuntu:latest as base

RUN some command

FROM base`;
            it('should return the placeholder as the last stage name', () => {
                const { lastStageName } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
                assert.equal(lastStageName, 'placeholder');
            });
            it('should return modified Dockerfile with stage name', () => {
                const { modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
                assert.equal(modifiedDockerfile, `
FROM ubuntu:latest as base

RUN some command

FROM base AS placeholder`);
            });
        });
        describe('for a FROM line with platform and followed by a comment', () => {
            const dockerfile = `
FROM ubuntu:latest as base

RUN some command

 \tFROM  --platform=my-platform \tbase   #<- deliberately mixing with whitespace and including: as something here

COPY src dest
RUN another command
`;
            it('should return the placeholder as the last stage name', () => {
                const { lastStageName } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
                assert.equal(lastStageName, 'placeholder');
            });
            it('should return modified Dockerfile with stage name', () => {
                const { modifiedDockerfile } = ensureDockerfileHasFinalStageName(dockerfile, 'placeholder');
                assert.equal(modifiedDockerfile, `
FROM ubuntu:latest as base

RUN some command

 \tFROM  --platform=my-platform \tbase AS placeholder   #<- deliberately mixing with whitespace and including: as something here

COPY src dest
RUN another command
`);
            });
        });
    });

    describe('without any from stage (invalid Dockerfile)', () => {
        it('should throw a descriptive error', () => {
            const dockerfile = `
RUN some command
`;
            expect(() => ensureDockerfileHasFinalStageName(dockerfile, 'placeholder')).to.throw('Error parsing Dockerfile: Dockerfile contains no FROM instructions');
        });
    });

});

describe('getImageBuildInfo', () => {

    it('for a simple FROM line', async () => {
        const dockerfile = `FROM debian:latest as base
FROM ubuntu:latest as dev
`;
        const details: ImageDetails = {
            Id: '123',
            Config: {
                User: 'imageUser',
                Env: null,
                Labels: {
                    [imageMetadataLabel]: '[{"id":"testid"}]'
                },
                Entrypoint: null,
                Cmd: null
            },
						Os: 'linux',
						Architecture: 'amd64'
        };
        const info = await internalGetImageBuildInfoFromDockerfile(async (imageName) => {
            assert.strictEqual(imageName, 'ubuntu:latest');
            return details;
        }, dockerfile, {}, undefined, testSubstitute, nullLog, false);
        assert.strictEqual(info.user, 'imageUser');
        assert.strictEqual(info.metadata.config.length, 1);
        assert.strictEqual(info.metadata.config[0].id, 'testid-substituted');
        assert.strictEqual(info.metadata.raw.length, 1);
        assert.strictEqual(info.metadata.raw[0].id, 'testid');
    });

    it('for a USER', async () => {
        const dockerfile = `FROM ubuntu:latest as base
USER dockerfileUserA
USER dockerfileUserB
`;
        const details: ImageDetails = {
            Id: '123',
            Config: {
                User: 'imageUser',
                Env: null,
                Labels: null,
                Entrypoint: null,
                Cmd: null
            },
						Os: 'linux',
						Architecture: 'amd64'
        };
        const info = await internalGetImageBuildInfoFromDockerfile(async (imageName) => {
            assert.strictEqual(imageName, 'ubuntu:latest');
            return details;
        }, dockerfile, {}, undefined, testSubstitute, nullLog, false);
        assert.strictEqual(info.user, 'dockerfileUserB');
        assert.strictEqual(info.metadata.config.length, 0);
        assert.strictEqual(info.metadata.raw.length, 0);
    });
});

describe('findBaseImage', () => {

    it('simple FROM', async () => {
        const dockerfile = `FROM image1
USER user1
`;
        const extracted = extractDockerfile(dockerfile);
        const image = findBaseImage(extracted, {}, undefined);
        assert.strictEqual(image, 'image1');
    });

    it('arg FROM', async () => {
        const dockerfile = `ARG BASE_IMAGE="image2"
FROM \${BASE_IMAGE}
ARG IMAGE_USER=user2
USER $IMAGE_USER
`;
        const extracted = extractDockerfile(dockerfile);
        const image = findBaseImage(extracted, {}, undefined);
        assert.strictEqual(image, 'image2');
    });

    it('arg FROM overwritten', async () => {
        const dockerfile = `ARG BASE_IMAGE="image2"
FROM \${BASE_IMAGE}
ARG IMAGE_USER=user2
USER $IMAGE_USER
`;
        const extracted = extractDockerfile(dockerfile);
        const image = findBaseImage(extracted, {
            'BASE_IMAGE': 'image3'
        }, undefined);
        assert.strictEqual(image, 'image3');
    });

    it('Multistage', async () => {
        const dockerfile = `
FROM image1 as stage1
FROM stage3 as stage2
FROM image3 as stage3
FROM image4 as stage4
`;
        const extracted = extractDockerfile(dockerfile);
        const image = findBaseImage(extracted, {}, 'stage2');
        assert.strictEqual(image, 'image3');
    });

    it('Quoted', async () => {
        const dockerfile = `
ARG BASE_IMAGE="ubuntu:latest"

FROM "\${BASE_IMAGE}"
`;
        const extracted = extractDockerfile(dockerfile);
        assert.strictEqual(extracted.stages.length, 1);
        const image = findBaseImage(extracted, {}, undefined);
        assert.strictEqual(image, 'ubuntu:latest');
    });

    describe('Variable substitution', () => {
        it('Positive variable expression with value specified', async () => {
            const dockerfile = `
ARG cloud
FROM \${cloud:+mcr.microsoft.com/}azure-cli:latest
`;
            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(extracted, {
                'cloud': 'true'
            }, undefined);
            assert.strictEqual(image, 'mcr.microsoft.com/azure-cli:latest');
        });

        it('Positive variable expression with no value specified', async () => {
            const dockerfile = `
ARG cloud
FROM \${cloud:+mcr.microsoft.com/}azure-cli:latest
`;
            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(extracted, {}, undefined);
            assert.strictEqual(image, 'azure-cli:latest');
        });

        it('Negative variable expression with value specified', async () => {
            const dockerfile = `
ARG cloud
FROM \${cloud:-mcr.microsoft.com/}azure-cli:latest
`;
            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(extracted, {
                'cloud': 'ghcr.io/'
            }, undefined);
            assert.strictEqual(image, 'ghcr.io/azure-cli:latest');
        });

        it('Negative variable expression with no value specified', async () => {
            const dockerfile = `
ARG cloud
FROM \${cloud:-mcr.microsoft.com/}azure-cli:latest
`;
            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(extracted, {}, undefined);
            assert.strictEqual(image, 'mcr.microsoft.com/azure-cli:latest');
        });

        describe('Quoted', async () => {
          it('Positive variable expression with value specified', async () => {
            const dockerfile = `
ARG cloud
FROM \${cloud:+"mcr.microsoft.com/"}azure-cli:latest"
`;
            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(
              extracted,
              {
                cloud: 'true',
              },
              undefined
            );
            assert.strictEqual(image, 'mcr.microsoft.com/azure-cli:latest');
          });

          it('Positive variable expression with no value specified', async () => {
            const dockerfile = `
ARG cloud
FROM "\${cloud:+"mcr.microsoft.com/"}azure-cli:latest"
`;

            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(extracted, {}, undefined);
            assert.strictEqual(image, 'azure-cli:latest');
          });

          it('Negative variable expression with value specified', async () => {
            const dockerfile = `
ARG cloud
FROM "\${cloud:-"mcr.microsoft.com/"}azure-cli:latest"
`;

            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(
              extracted,
              {
                cloud: 'ghcr.io/',
              },
              undefined
            );
            assert.strictEqual(image, 'ghcr.io/azure-cli:latest');
          });

          it('Negative variable expression with no value specified', async () => {
            const dockerfile = `
ARG cloud
FROM \${cloud:-"mcr.microsoft.com/"}azure-cli:latest as label
`;

            const extracted = extractDockerfile(dockerfile);
            assert.strictEqual(extracted.stages.length, 1);
            const image = findBaseImage(extracted, {}, undefined);
            assert.strictEqual(image, 'mcr.microsoft.com/azure-cli:latest');
          });
        });
    });
});

describe('findUserStatement', () => {

    it('simple USER', async () => {
        const dockerfile = `FROM debian
USER user1
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user1');
    });

    it('arg USER', async () => {
        const dockerfile = `FROM debian
ARG IMAGE_USER=user2
USER $IMAGE_USER
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user2');
    });

    it('arg USER overwritten', async () => {
        const dockerfile = `FROM debian
ARG IMAGE_USER=user2
USER $IMAGE_USER
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {
            IMAGE_USER: 'user3'
        }, {}, undefined);
        assert.strictEqual(user, 'user3');
    });

    it('Multistage', async () => {
        const dockerfile = `
FROM image1 as stage1
USER user1
FROM stage3 as stage2
FROM image3 as stage3
USER user3_1
USER user3_2
FROM image4 as stage4
USER user4
`;
        const extracted = extractDockerfile(dockerfile);
        const image = findUserStatement(extracted, {}, {}, 'stage2');
        assert.strictEqual(image, 'user3_2');
    });

    it('ARG after ENV', async () => {
        const dockerfile = `
FROM debian
ENV USERNAME=user1
ARG USERNAME=user2
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user2');
    });

    it('ARG after ENV in preceding stage', async () => {
        const dockerfile = `
FROM debian as one
ENV USERNAME=user1
ARG USERNAME=user2

FROM one as two
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user1');
    });

    it('ARG in preamble', async () => {
        const dockerfile = `
ARG USERNAME=user1
FROM debian
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user1');
    });

    it('unbound ARG after ENV', async () => {
        const dockerfile = `
FROM debian
ENV USERNAME=user1
ARG USERNAME
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user1');
    });

    it('unbound', async () => {
        const dockerfile = `
FROM debian
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, undefined);
    });

    it('ENV after ARG', async () => {
        const dockerfile = `
FROM debian
ARG USERNAME=user1
ENV USERNAME=user2
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user2');
    });

    it('ENV set from ARG', async () => {
        const dockerfile = `
FROM debian
ARG USERNAME1=user1
ENV USERNAME2=\${USERNAME1}
USER \${USERNAME2}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'user1');
    });

    it('multiple variables', async () => {
        const dockerfile = `
FROM debian
ARG USERNAME1=user1
ENV USERNAME2=user2
USER A\${USERNAME1}A\${USERNAME2}A
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, {}, undefined);
        assert.strictEqual(user, 'Auser1Auser2A');
    });

    it('ENV in base image', async () => {
        const dockerfile = `
FROM mybase
USER \${USERNAME}
`;
        const extracted = extractDockerfile(dockerfile);
        const user = findUserStatement(extracted, {}, { USERNAME: 'user1' }, undefined);
        assert.strictEqual(user, 'user1');
    });
});

describe('supportsBuildContexts', () => {

    it('no syntax directive', async () => {
        const dockerfile = `FROM debian`;
        const extracted = extractDockerfile(dockerfile);
        assert.strictEqual(supportsBuildContexts(extracted), false);
    });

    it('matching syntax directive', async () => {
        const dockerfile = `# syntax=docker/dockerfile:1.4
FROM debian`;
        const extracted = extractDockerfile(dockerfile);
        assert.strictEqual(supportsBuildContexts(extracted), true);
    });

    it('matching syntax directive with docker.io', async () => {
        const dockerfile = `# syntax=docker.io/docker/dockerfile:1.4
FROM debian`;
        const extracted = extractDockerfile(dockerfile);
        assert.strictEqual(supportsBuildContexts(extracted), true);
    });

    it('unknown syntax directive', async () => {
        const dockerfile = `# syntax=mycompany/myimage:1.4
FROM debian`;
        const extracted = extractDockerfile(dockerfile);
        assert.strictEqual(supportsBuildContexts(extracted), 'unknown');
    });

    ['', '-labs'].forEach(prerelease => {
        [
            ['0', false],
            ['1', true],
            ['1.2', false],
            ['1.2.3', false],
            ['1.4', true],
            ['1.4.5', true],
            ['1.5', true],
            ['1.5.0', true],
            ['2', true],
            ['', true],
            ['latest', true],
        ].forEach(([version, expected]) => {
            const tag = `${version}${prerelease}`;
            it(`syntax directive: ${tag}`, async () => {
                const dockerfile = `# syntax=docker.io/docker/dockerfile${tag ? `:${tag}` : ''}
        FROM debian`;
                const extracted = extractDockerfile(dockerfile);
                assert.strictEqual(supportsBuildContexts(extracted), expected);
            });
        });
    });
});

describe('extractDockerfile', () => {

    it('handles ENV with equals', async () => {
        const dockerfile = `FROM debian\nENV A=B`;
        const extracted = extractDockerfile(dockerfile);
        const env = extracted.stages[0].instructions[0];
        assert.strictEqual(env.instruction, 'ENV');
        assert.strictEqual(env.name, 'A');
        assert.strictEqual(env.value, 'B');
    });

    it('handles ENV with equals and spaces', async () => {
        const dockerfile = `FROM debian\nENV A = B`;
        const extracted = extractDockerfile(dockerfile);
        const env = extracted.stages[0].instructions[0];
        assert.strictEqual(env.instruction, 'ENV');
        assert.strictEqual(env.name, 'A');
        assert.strictEqual(env.value, 'B');
    });

    it('handles ENV without equals', async () => {
        const dockerfile = `FROM debian\nENV A B`;
        const extracted = extractDockerfile(dockerfile);
        const env = extracted.stages[0].instructions[0];
        assert.strictEqual(env.instruction, 'ENV');
        assert.strictEqual(env.name, 'A');
        assert.strictEqual(env.value, 'B');
    });

    it('lowercase instructions', async () => {
        const dockerfile = `from E
env A=B
arg C
user D
`;
        const extracted = extractDockerfile(dockerfile);
        assert.strictEqual(extracted.stages.length, 1);

        const stage = extracted.stages[0];
        assert.strictEqual(stage.from.image, 'E');
        assert.strictEqual(stage.instructions.length, 3);

        const env = stage.instructions[0];
        assert.strictEqual(env.instruction, 'ENV');
        assert.strictEqual(env.name, 'A');
        assert.strictEqual(env.value, 'B');

        const arg = stage.instructions[1];
        assert.strictEqual(arg.instruction, 'ARG');
        assert.strictEqual(arg.name, 'C');

        const user = stage.instructions[2];
        assert.strictEqual(user.instruction, 'USER');
        assert.strictEqual(user.name, 'D');
    });
});
</file>

<file path="src/test/dockerUtils.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import { createPlainLog, LogLevel, makeLog } from '../spec-utils/log';
import { inspectImageInRegistry, qualifyImageName } from '../spec-node/utils';
import assert from 'assert';
import { dockerCLI, listContainers, PartialExecParameters, removeContainer, toExecParameters } from '../spec-shutdown/dockerUtils';
import { createCLIParams } from './testUtils';

export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));

describe('Docker utils', function () {
	this.timeout(20 * 1000);

	it('inspect image in docker.io', async () => {
		const imageName = 'docker.io/library/ubuntu:latest';
		const config = await inspectImageInRegistry(output, { arch: 'amd64', os: 'linux' }, imageName);
		assert.ok(config);
		assert.ok(config.Id);
		assert.ok(config.Config.Cmd);
	});

	it('inspect image in mcr.microsoft.com', async () => {
		const imageName = 'mcr.microsoft.com/devcontainers/rust:1';
		const config = await inspectImageInRegistry(output, { arch: 'amd64', os: 'linux' }, imageName);
		assert.ok(config);
		assert.ok(config.Id);
		assert.ok(config.Config.Cmd);
		const metadataStr = config.Config.Labels?.['devcontainer.metadata'];
		assert.ok(metadataStr);
		const obj = JSON.parse(metadataStr);
		assert.ok(obj && typeof obj === 'object');
	});

	it('inspect image in ghcr.io', async () => {
		const imageName = 'ghcr.io/chrmarti/cache-from-test/images/test-cache:latest';
		const config = await inspectImageInRegistry(output, { arch: 'amd64', os: 'linux' }, imageName);
		assert.ok(config);
		assert.ok(config.Id);
		assert.ok(config.Config.Cmd);
	});

	it('qualifies docker.io shorthands', async () => {
		assert.strictEqual(qualifyImageName('ubuntu'), 'docker.io/library/ubuntu');
		assert.strictEqual(qualifyImageName('docker.io/ubuntu'), 'docker.io/library/ubuntu');
		assert.strictEqual(qualifyImageName('random/image'), 'docker.io/random/image');
		assert.strictEqual(qualifyImageName('foo/random/image'), 'foo/random/image');
	});

	it('protects against concurrent removal', async () => {
		const params = await createCLIParams(__dirname);
		const verboseParams = { ...toExecParameters(params), output: makeLog(output, LogLevel.Info), print: 'continuous' as 'continuous' };
		const { stdout } = await dockerCLI(verboseParams, 'run', '-d', 'ubuntu:latest', 'sleep', 'inf');
		const containerId = stdout.toString().trim();
		const start = Date.now();
		await Promise.all([
			testRemoveContainer(verboseParams, containerId),
			testRemoveContainer(verboseParams, containerId),
			testRemoveContainer(verboseParams, containerId),
		]);
		console.log('removal took', Date.now() - start, 'ms');
	});
});

async function testRemoveContainer(params: PartialExecParameters, nameOrId: string) {
	await removeContainer(params, nameOrId);
	const all = await listContainers(params, true);
	if (all.some(shortId => nameOrId.startsWith(shortId))) {
		throw new Error('container still exists');
	}
}
</file>

<file path="src/test/dotfiles.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { shellExec, pathExists } from './testUtils';

const pkg = require('../../package.json');

describe('Dotfiles', function () {

	this.timeout('240s');
	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	let containerId = '';
	this.afterEach('Cleanup', async () => {
		assert.ok(containerId, 'In Cleanup: Container id not found.');
		await shellExec(`docker rm -f ${containerId}`);
		containerId = '';
	});

	it('should execute successfully with valid config and dotfiles', async () => {
		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository https://github.com/codspace/test-dotfiles`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;

		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');
	});

	it('should execute successfully with valid config and dotfiles with custom install path as filename', async () => {
		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository https://github.com/codspace/test-dotfiles --dotfiles-install-command install.sh`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;

		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');
	});

	it('should execute successfully with valid config and dotfiles with custom install path as relative path', async () => {
		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository https://github.com/codspace/test-dotfiles --dotfiles-install-command ./install.sh`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;

		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');
	});

	it('should execute successfully with valid config and dotfiles with custom install path as absolute path', async () => {
		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository https://github.com/codspace/test-dotfiles --dotfiles-install-command /home/node/dotfiles/install.sh`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;

		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');
	});

	it('should execute successfully with valid config and dotfiles with non executable install script', async () => {
		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository codspace/test-dotfiles-non-executable --dotfiles-install-command .run-my-dotfiles-script`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;

		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');
	});

	it('should execute successfully with valid config and dotfiles with non executable absolute path install script', async () => {
		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository codspace/test-dotfiles-non-executable --dotfiles-install-command /home/node/dotfiles/.run-my-dotfiles-script`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;

		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');
	});

	it('should execute successfully with valid config and dotfiles with secrets', async () => {
		const testFolder = `${__dirname}/configs`;
		await shellExec(`rm -f ${testFolder}/*.testMarker`, undefined, undefined, true);
		const secrets = {
			'SECRET1': 'SecretValue1',
			'MASK_IT': 'container',
		};
		await shellExec(`printf '${JSON.stringify(secrets)}' > ${testFolder}/test-secrets-temp.json`, undefined, undefined, true);

		const res = await shellExec(`${cli} up --workspace-folder ${__dirname}/configs/image-with-git-feature --dotfiles-repository https://github.com/codspace/test-dotfiles --secrets-file ${testFolder}/test-secrets-temp.json --log-level trace --log-format json`);
		const response = JSON.parse(res.stdout);
		assert.equal(response.outcome, 'success');
		containerId = response.containerId;
		assert.ok(containerId, 'Container id not found.');
		const dotfiles = await pathExists(cli, `${__dirname}/configs/image-with-git-feature`, `/tmp/.dotfilesMarker`);
		assert.ok(dotfiles, 'Dotfiles not found.');

		// assert file contents to ensure secrets & remoteEnv were available to the command
		const catResp = await shellExec(`${cli} exec --workspace-folder ${__dirname}/configs/image-with-git-feature cat /tmp/.dotfileEnvs`);
		const { stdout, error } = catResp;
		assert.strictEqual(error, null);
		assert.match(stdout, /SECRET1=SecretValue1/);
		assert.match(stdout, /TEST_REMOTE_ENV=Value 1/);

		// assert secret masking
		// We log the message `Starting container` from CLI. Since the word `container` is specified as a secret here, that should get masked
		const logs = res.stderr;
		assert.match(logs, /Starting \*\*\*\*\*\*\*\*/);
		assert.doesNotMatch(logs, /Starting container/);
	});
});
</file>

<file path="src/test/getEntPasswd.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import { shellExec, output } from './testUtils';
import { dockerExecFunction } from '../spec-shutdown/dockerUtils';
import { plainExec } from '../spec-common/commonUtils';
import { launch } from '../spec-common/shellServer';
import { getUserFromPasswdDB } from '../spec-common/injectHeadless';

describe('getEntPasswdShellCommand', function () {
	this.timeout('20s');

	[
		{
			image: 'busybox',
			getentPath: undefined,
			addUserCommand: 'adduser -D -h /home/foo foo\\\\bar',
			userName: 'foo\\bar',
			homeFolder: '/home/foo',
		},
		{
			image: 'debian',
			getentPath: '/usr/bin/getent',
			addUserCommand: 'useradd -m -d /home/foo --badname foo\\\\bar',
			userName: 'foo\\bar',
			homeFolder: '/home/foo',
		},
		{
			image: 'alpine',
			getentPath: '/usr/bin/getent',
			addUserCommand: 'adduser -D -h /home/foo foo_bar',
			userName: 'foo_bar', // Alpine doesn't support backslash in user names.
			homeFolder: '/home/foo',
		},
	].forEach(({ image, getentPath, addUserCommand, userName, homeFolder }) => {
		it(`should work with ${image} ${getentPath ? 'with' : 'without'} getent command`, async () => {
			const res = await shellExec(`docker run -d ${image} sleep inf`);
			const containerId = res.stdout.trim();
			const exec = dockerExecFunction({
				exec: plainExec(undefined),
				cmd: 'docker',
				env: {},
				output,
			}, containerId, 'root');
			const shellServer = await launch(exec, output);

			const which = await shellServer.exec('command -v getent')
				.catch(() => undefined);
			assert.strictEqual(which?.stdout.trim(), getentPath);

			await shellServer.exec(addUserCommand);

			const userByName = await getUserFromPasswdDB(shellServer, userName);
			assert.ok(userByName);
			assert.strictEqual(userByName.name, userName);
			assert.strictEqual(userByName.home, homeFolder);

			const userById = await getUserFromPasswdDB(shellServer, userByName.uid);
			assert.ok(userById);
			assert.strictEqual(userById.name, userName);
			assert.strictEqual(userById.home, homeFolder);

			const nonexistentUser = await getUserFromPasswdDB(shellServer, '123456');
			assert.strictEqual(undefined, nonexistentUser);

			await shellExec(`docker rm -f ${containerId}`);
		});
	});
});
</file>

<file path="src/test/getHomeFolder.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import { shellExec, output } from './testUtils';
import { dockerExecFunction } from '../spec-shutdown/dockerUtils';
import { plainExec } from '../spec-common/commonUtils';
import { launch } from '../spec-common/shellServer';
import { getHomeFolder, getUserFromPasswdDB } from '../spec-common/injectHeadless';

describe('getHomeFolder', function () {
	this.timeout('20s');

	it(`should ignore non-writeable HOME`, async () => {
		const res = await shellExec(`docker run -d mcr.microsoft.com/devcontainers/base:latest sleep inf`);
		const containerId = res.stdout.trim();
		
		const vscodeShellServer = await launchShellServer(containerId, 'vscode');
		const vscodeUser = await getUserFromPasswdDB(vscodeShellServer, 'vscode');
		assert.ok(vscodeUser);

		assert.strictEqual(await getHomeFolder(vscodeShellServer, {}, vscodeUser), '/home/vscode');
		assert.strictEqual(await getHomeFolder(vscodeShellServer, { HOME: '/root' }, vscodeUser), '/home/vscode');
		assert.strictEqual(await getHomeFolder(vscodeShellServer, { HOME: '/home/vscode' }, vscodeUser), '/home/vscode');
		assert.strictEqual(await getHomeFolder(vscodeShellServer, { HOME: '/home/vscode/foo' }, vscodeUser), '/home/vscode/foo');

		const rootServer = await launchShellServer(containerId, 'root');
		const rootUser = await getUserFromPasswdDB(rootServer, 'root');
		assert.ok(rootUser);

		assert.strictEqual(await getHomeFolder(rootServer, {}, rootUser), '/root');
		assert.strictEqual(await getHomeFolder(rootServer, { HOME: '/home/vscode' }, rootUser), '/home/vscode');
	});

	async function launchShellServer(containerId: string, username: string) {
		const exec = dockerExecFunction({
			exec: plainExec(undefined),
			cmd: 'docker',
			env: {},
			output,
		}, containerId, username);
		return launch(exec, output);
	}
});
</file>

<file path="src/test/imageMetadata.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { URI } from 'vscode-uri';
import { DevContainerConfig, HostGPURequirements } from '../spec-configuration/configuration';
import { Feature, FeaturesConfig, FeatureSet, Mount } from '../spec-configuration/containerFeaturesConfiguration';
import { getDevcontainerMetadata, getDevcontainerMetadataLabel, getImageMetadata, getImageMetadataFromContainer, ImageMetadataEntry, imageMetadataLabel, internalGetImageMetadata0, mergeConfiguration } from '../spec-node/imageMetadata';
import { SubstitutedConfig } from '../spec-node/utils';
import { ContainerDetails, ImageDetails } from '../spec-shutdown/dockerUtils';
import { nullLog } from '../spec-utils/log';
import { buildKitOptions, shellExec, testSubstitute } from './testUtils';

const pkg = require('../../package.json');

function configWithRaw<T extends DevContainerConfig | ImageMetadataEntry[]>(raw: T): SubstitutedConfig<T> {
	return {
		config: (Array.isArray(raw) ? raw.map(testSubstitute) : testSubstitute(raw)) as T,
		raw,
		substitute: testSubstitute,
	};
}

describe('Image Metadata', function () {
	this.timeout('180s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;
	const testFolder = `${__dirname}/configs/image-metadata`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
		await shellExec(`docker build -t image-metadata-test-base ${testFolder}/base-image`);
	});

	describe('CLI', () => {

		buildKitOptions.forEach(({ text, options }) => {
			it(`should collect metadata on image label  [${text}]`, async () => {
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				const res = await shellExec(`${cli} build --workspace-folder ${testFolder} --image-name image-metadata-test${buildKitOption}`);
				const response = JSON.parse(res.stdout);
				assert.strictEqual(response.outcome, 'success');
				const details = JSON.parse((await shellExec(`docker inspect image-metadata-test`)).stdout)[0] as ImageDetails;
				const { config: metadata, raw } = getImageMetadata(details, testSubstitute, nullLog);
				assert.strictEqual(metadata.length, 3);
				assert.strictEqual(metadata[0].id, 'baseFeature-substituted');
				assert.strictEqual(metadata[1].id, './localFeatureA-substituted');
				assert.strictEqual(metadata[1].init, true);

				assert.deepStrictEqual(metadata[1].updateContentCommand, ['one', 'two']);
				assert.deepStrictEqual(metadata[1].onCreateCommand, {
					'command': 'three',
					'commandWithArgs': [
						'four',
						'arg1',
						'arg2'
					]
				});
				assert.deepStrictEqual(metadata[1].postCreateCommand, 'five');
				assert.deepStrictEqual(metadata[1].postStartCommand, 'six');
				assert.deepStrictEqual(metadata[1].postAttachCommand, 'seven');

				assert.strictEqual(metadata[2].id, './localFeatureB-substituted');
				assert.strictEqual(metadata[2].privileged, true);
				assert.strictEqual(raw.length, 3);
				assert.strictEqual(raw[0].id, 'baseFeature');
				assert.strictEqual(raw[1].id, './localFeatureA');
				assert.ok(raw[1].customizations);
				assert.strictEqual(raw[1].customizations.vscode.extensions.length, 2);
				assert.strictEqual(raw[1].init, true);
				assert.strictEqual(raw[2].id, './localFeatureB');
				assert.strictEqual(raw[2].privileged, true);
			});
		});

		buildKitOptions.forEach(({ text, options }) => {
			it(`should omit appending Feature customizations with --skip-persisting-customizations-from-features [${text}]`, async () => {
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				const res = await shellExec(`${cli} build --skip-persisting-customizations-from-features --workspace-folder ${testFolder} --image-name skip-persisting-test${buildKitOption}`);
				const response = JSON.parse(res.stdout);
				assert.strictEqual(response.outcome, 'success');
				const details = JSON.parse((await shellExec(`docker inspect skip-persisting-test`)).stdout)[0] as ImageDetails;
				const { config: metadata, raw } = getImageMetadata(details, testSubstitute, nullLog);
				assert.strictEqual(metadata.length, 3);
				assert.strictEqual(metadata[0].id, 'baseFeature-substituted');
				assert.strictEqual(metadata[1].id, './localFeatureA-substituted');
				assert.strictEqual(metadata[1].init, true);
				assert.strictEqual(metadata[2].id, './localFeatureB-substituted');
				assert.strictEqual(metadata[2].privileged, true);
				assert.strictEqual(raw.length, 3);
				assert.strictEqual(raw[0].id, 'baseFeature');
				assert.strictEqual(raw[1].id, './localFeatureA');
				assert.ok(!raw[1].customizations); // Customizations have not been persisted due to the flag
				assert.strictEqual(raw[1].init, true);
				assert.strictEqual(raw[2].id, './localFeatureB');
				assert.strictEqual(raw[2].privileged, true);
			});

			it(`should omit appending Feature customizations with --skip-persisting-customizations-from-features [${text}]`, async () => {
				const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
				const res = await shellExec(`${cli} build --skip-persisting-customizations-from-features --workspace-folder ${testFolder} --image-name skip-persisting-test${buildKitOption}`);
				const response = JSON.parse(res.stdout);
				assert.strictEqual(response.outcome, 'success');
				const details = JSON.parse((await shellExec(`docker inspect skip-persisting-test`)).stdout)[0] as ImageDetails;
				const { config: metadata, raw } = getImageMetadata(details, testSubstitute, nullLog);
				assert.strictEqual(metadata.length, 3);
				assert.strictEqual(metadata[0].id, 'baseFeature-substituted');
				assert.strictEqual(metadata[1].id, './localFeatureA-substituted');
				assert.strictEqual(metadata[1].init, true);
				assert.strictEqual(metadata[2].id, './localFeatureB-substituted');
				assert.strictEqual(metadata[2].privileged, true);
				assert.strictEqual(raw.length, 3);
				assert.strictEqual(raw[0].id, 'baseFeature');
				assert.strictEqual(raw[1].id, './localFeatureA');
				assert.ok(!raw[1].customizations); // Customizations have not been persisted due to the flag
				assert.strictEqual(raw[1].init, true);
				assert.strictEqual(raw[2].id, './localFeatureB');
				assert.strictEqual(raw[2].privileged, true);
			});

			[
				'image',
				'compose-image-without-features-minimal',
			].forEach(testFolderName => {
				const imageTestFolder = `${__dirname}/configs/${testFolderName}`;

				it(`build should collect metadata on image label [${testFolderName}, ${text}]`, async () => {
					await shellExec(`docker pull ubuntu:latest`);
					
					const imageName = `${testFolderName}${options.useBuildKit ? '' : '-buildkit'}-test`;
					const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
					const res = await shellExec(`${cli} build --workspace-folder ${imageTestFolder} --image-name ${imageName}${buildKitOption}`);
					const response = JSON.parse(res.stdout);
					assert.strictEqual(response.outcome, 'success');
					const details = JSON.parse((await shellExec(`docker inspect ${imageName}`)).stdout)[0] as ImageDetails;
					const baseDetails = JSON.parse((await shellExec(`docker inspect ubuntu:latest`)).stdout)[0] as ImageDetails;
					assert.notStrictEqual(details.Id, baseDetails.Id);
					const metadata = internalGetImageMetadata0(details, nullLog);
					assert.strictEqual(metadata.length, 1);
					assert.ok(metadata[0].remoteEnv);
				});

				it(`up should avoid new image when possible [${testFolderName}, ${text}]`, async () => {
					
					const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
					const res = await shellExec(`${cli} up --workspace-folder ${imageTestFolder} --remove-existing-container${buildKitOption}`);
					const response = JSON.parse(res.stdout);
					assert.strictEqual(response.outcome, 'success');
					const details = JSON.parse((await shellExec(`docker inspect ${response.containerId}`)).stdout)[0] as ContainerDetails;
					assert.strictEqual(details.Config.Image, 'ubuntu:latest');
					const metadata = internalGetImageMetadata0(details, nullLog);
					assert.strictEqual(metadata.length, 1);
					assert.ok(metadata[0].remoteEnv);
					assert.strictEqual(metadata[0].remoteEnv.TEST, 'ENV');
					assert.strictEqual(metadata[0].remoteEnv.TEST_ESCAPING, '{\n  "fo$o": "ba\'r"\n}');
					await shellExec(`docker exec ${response.containerId} test -f /postCreateCommand.txt`);
					await shellExec(`docker rm -f ${response.containerId}`);
				});
			});

			[
				'image-with-features',
				'image',
				'compose-image-with-features',
				'compose-image-without-features-minimal',
				'compose-Dockerfile-with-features',
				'compose-Dockerfile-without-features',
				'dockerfile-with-features',
				'dockerfile-without-features',
			].forEach(testFolderName => {
				const imageTestFolder = `${__dirname}/configs/${testFolderName}`;

				it(`up should avoid storing remoteEnv in metadata label with --omit-config-remote-env-from-metadata [${testFolderName}, ${text}]`, async () => {
					
					const buildKitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
					const res = await shellExec(`${cli} up --workspace-folder ${imageTestFolder} --omit-config-remote-env-from-metadata --remove-existing-container${buildKitOption}`);
					const response = JSON.parse(res.stdout);
					assert.strictEqual(response.outcome, 'success');
					const details = JSON.parse((await shellExec(`docker inspect ${response.containerId}`)).stdout)[0] as ContainerDetails;
					const metadata = internalGetImageMetadata0(details, nullLog);
					assert.ok(!metadata[metadata.length - 1].remoteEnv); // remoteEnv from devcontainer config is not stored on container metadata label
					const result = await shellExec(`docker exec ${response.containerId} cat /postCreateCommand.txt`);
					assert.strictEqual(result.stdout, 'Val: ENV\n'); // remoteEnv is available to lifecycle hooks

					const readConfigRes = await shellExec(`${cli} read-configuration --container-id ${response.containerId} --workspace-folder ${imageTestFolder} --include-merged-configuration`);
					const readConfig = JSON.parse(readConfigRes.stdout);
					assert.strictEqual(readConfig.mergedConfiguration.postCreateCommands.length, 1);
					const configRemoteEnv = readConfig.configuration.remoteEnv;
					assert.ok(configRemoteEnv);
					assert.strictEqual(configRemoteEnv.TEST, 'ENV');
					assert.strictEqual(configRemoteEnv.TEST_ESCAPING, '{\n  "fo$o": "ba\'r"\n}');
					const mergedConfigRemoteEnv = readConfig.mergedConfiguration.remoteEnv;
					assert.ok(mergedConfigRemoteEnv);
					assert.strictEqual(mergedConfigRemoteEnv.TEST, 'ENV');
					assert.strictEqual(mergedConfigRemoteEnv.TEST_ESCAPING, '{\n  "fo$o": "ba\'r"\n}');

					await shellExec(`docker rm -f ${response.containerId}`);
				});
			});

			[
				'image-with-mounts',
				'compose-image-with-mounts'
			].forEach(testFolderName => {
				it('docker volume should not be named undefined if the src argument is omitted in mount command', async () => {
					const imageTestFolder = `${__dirname}/configs/${testFolderName}`;
					const cliResult = await shellExec(`${cli} up --workspace-folder ${imageTestFolder}`);
					const response = JSON.parse(cliResult.stdout);
					assert.strictEqual(response.outcome, 'success');
					const details = JSON.parse((await shellExec(`docker inspect ${response.containerId}`)).stdout)[0] as ContainerDetails;
					const targetMount = details.Mounts.find(mount => mount.Destination === '/home/test_devcontainer_config');

					assert.notEqual(targetMount?.Name?.toLowerCase(), 'undefined');

					await shellExec(`docker rm -f ${response.containerId}`);
				});
			});
		});
	});

	describe('Utils', () => {
		it('should collect metadata from devcontainer.json and features', () => {
			const { config: metadata, raw } = getDevcontainerMetadata(configWithRaw([]), configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteUser: 'testUser',
			}), getFeaturesConfig([
				{
					id: 'someFeature',
					value: 'someValue',
					included: true,
					consecutiveId: 'someFeature_0',
				}
			]));
			assert.strictEqual(metadata.length, 2);
			assert.strictEqual(metadata[0].id, 'ghcr.io/my-org/my-repo/someFeature:1-substituted');
			assert.strictEqual(metadata[1].remoteUser, 'testUser');
			assert.strictEqual(raw.length, 2);
			assert.strictEqual(raw[0].id, 'ghcr.io/my-org/my-repo/someFeature:1');
			assert.strictEqual(raw[1].remoteUser, 'testUser');
		});

		it('should omit specified props from devcontainer.json', () => {
			const omitDevcontainerPropertyOverride: (keyof DevContainerConfig & keyof ImageMetadataEntry)[] = ['remoteEnv'];
			const { config: metadata, raw } = getDevcontainerMetadata(configWithRaw([]), configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteUser: 'testUser',
				remoteEnv: {
					DEVCONTENV: 'value',
				}
			}),
				undefined,
				[],
				omitDevcontainerPropertyOverride);
			assert.strictEqual(metadata.length, 1);
			assert.strictEqual(metadata[0].remoteUser, 'testUser');
			assert.ok(!metadata[0].remoteEnv);
			assert.strictEqual(raw.length, 1);
			assert.strictEqual(raw[0].remoteUser, 'testUser');
			assert.ok(!raw[0].remoteEnv);
		});

		const testContainerDetails: ContainerDetails = {
			Id: 'testId',
			Created: '2022-10-11T08:31:30.10478055Z',
			Name: 'testName',
			State: {
				Status: 'running',
				StartedAt: '2022-10-11T08:31:30.369653009Z',
				FinishedAt: '0001-01-01T00:00:00Z',
			},
			Config: {
				Image: 'testImage',
				User: 'testContainerUser',
				Env: null,
				Labels: {},
			},
			Mounts: [],
			NetworkSettings: {
				Ports: {},
			},
			Ports: [],
		};

		it('should read metadata from existing container', () => {
			const { config: metadata, raw } = getImageMetadataFromContainer({
				...testContainerDetails,
				Config: {
					...testContainerDetails.Config,
					Labels: {
						...testContainerDetails.Config.Labels,
						testIdLabel: 'testIdLabelValue',
						[imageMetadataLabel]: JSON.stringify({
							id: 'testId',
							remoteUser: 'testMetadataUser',
						}),
					},
				},
			}, configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteUser: 'testConfigUser',
			}), undefined, ['testIdLabel=testIdLabelValue'], nullLog);
			assert.strictEqual(metadata.length, 2);
			assert.strictEqual(metadata[0].id, 'testId-substituted');
			assert.strictEqual(metadata[0].remoteUser, 'testMetadataUser');
			assert.strictEqual(metadata[1].remoteUser, 'testConfigUser');
			assert.strictEqual(raw.length, 2);
			assert.strictEqual(raw[0].id, 'testId');
			assert.strictEqual(raw[0].remoteUser, 'testMetadataUser');
			assert.strictEqual(raw[1].remoteUser, 'testConfigUser');
		});

		it('should add config for existing container without id labels', () => {
			const { config: metadata, raw } = getImageMetadataFromContainer({
				...testContainerDetails,
				Config: {
					...testContainerDetails.Config,
					Labels: {
						...testContainerDetails.Config.Labels,
						[imageMetadataLabel]: JSON.stringify({
							id: 'testId',
							remoteUser: 'testMetadataUser',
						}),
					},
				},
			}, configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteUser: 'testConfigUser',
			}), undefined, ['testIdLabel=testIdLabelValue'], nullLog);
			assert.strictEqual(metadata.length, 2);
			assert.strictEqual(metadata[0].id, 'testId-substituted');
			assert.strictEqual(metadata[0].remoteUser, 'testMetadataUser');
			assert.strictEqual(metadata[1].remoteUser, 'testConfigUser');
			assert.strictEqual(raw.length, 2);
			assert.strictEqual(raw[0].id, 'testId');
			assert.strictEqual(raw[0].remoteUser, 'testMetadataUser');
			assert.strictEqual(raw[1].remoteUser, 'testConfigUser');
		});

		it('should update config for existing container', () => {
			const { config: metadata, raw } = getImageMetadataFromContainer({
				...testContainerDetails,
				Config: {
					...testContainerDetails.Config,
					Labels: {
						...testContainerDetails.Config.Labels,
						testIdLabel: 'testIdLabelValue',
						[imageMetadataLabel]: JSON.stringify({
							remoteEnv: {
								FOO: 'bar',
							},
						}),
					},
				},
			}, configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteEnv: {
					FOO: 'baz',
					BAR: 'foo',
				},
			}), undefined, ['testIdLabel=testIdLabelValue'], nullLog);
			assert.strictEqual(metadata.length, 2);
			assert.deepStrictEqual(metadata[0].remoteEnv, {
				FOO: 'bar',
			});
			assert.deepStrictEqual(metadata[1].remoteEnv, {
				FOO: 'baz',
				BAR: 'foo',
			});
			assert.strictEqual(raw.length, 2);
			assert.deepStrictEqual(raw[0].remoteEnv, {
				FOO: 'bar',
			});
			assert.deepStrictEqual(raw[1].remoteEnv, {
				FOO: 'baz',
				BAR: 'foo',
			});
		});

		it('should fall back to config for existing container without metadata label', () => {
			const { config: metadata, raw } = getImageMetadataFromContainer(testContainerDetails, configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteUser: 'testConfigUser',
			}), undefined, [], nullLog);
			assert.strictEqual(metadata.length, 1);
			assert.strictEqual(metadata[0].id, undefined);
			assert.strictEqual(metadata[0].remoteUser, 'testConfigUser');
			assert.strictEqual(raw.length, 1);
			assert.strictEqual(raw[0].id, undefined);
			assert.strictEqual(raw[0].remoteUser, 'testConfigUser');
		});

		it('should create label for Dockerfile', () => {
			const label = getDevcontainerMetadataLabel(getDevcontainerMetadata(configWithRaw([
				{
					id: 'baseFeature',
				}
			]), configWithRaw({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteUser: 'testUser',
			}), getFeaturesConfig([
				{
					id: 'someFeature',
					value: 'someValue',
					included: true,
					consecutiveId: 'someFeature_0',
				}
			])));
			const expected = [
				{
					id: 'baseFeature',
				},
				{
					id: 'ghcr.io/my-org/my-repo/someFeature:1',
				},
				{
					remoteUser: 'testUser',
				}
			];
			assert.strictEqual(label.replace(/ \\\n/g, ''), `LABEL devcontainer.metadata="${JSON.stringify(expected).replace(/"/g, '\\"')}"`);
		});

		it('should merge metadata from devcontainer.json and features', () => {
			const merged = mergeConfiguration({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
				remoteEnv: {
					ENV1: 'devcontainer.json',
					ENV3: 'devcontainer.json',
				},
			}, [
				{
					remoteEnv: {
						ENV1: 'feature1',
						ENV2: 'feature1',
						ENV3: 'feature1',
						ENV4: 'feature1',
					}
				},
				{
					remoteEnv: {
						ENV1: 'feature2',
						ENV2: 'feature2',
					}
				},
				{
					remoteEnv: {
						ENV1: 'devcontainer.json',
						ENV3: 'devcontainer.json',
					},
				}
			]);
			assert.strictEqual(merged.remoteEnv?.ENV1, 'devcontainer.json');
			assert.strictEqual(merged.remoteEnv?.ENV2, 'feature2');
			assert.strictEqual(merged.remoteEnv?.ENV3, 'devcontainer.json');
			assert.strictEqual(merged.remoteEnv?.ENV4, 'feature1');
		});

		it('should deduplicate mounts', () => {
			const merged = mergeConfiguration({
				configFilePath: URI.parse('file:///devcontainer.json'),
				image: 'image',
			}, [
				{
					mounts: [
						'source=source1,dst=target1,type=volume',
						'source=source2,target=target2,type=volume',
						'source=source3,destination=target3,type=volume',
					],
				},
				{
					mounts: [
						{
							source: 'source4',
							target: 'target1',
							type: 'volume'
						},
					],
				},
				{
					mounts: [
						{
							source: 'source5',
							target: 'target3',
							type: 'volume'
						},
					],
				},
			]);
			assert.strictEqual(merged.mounts?.length, 3);
			assert.strictEqual(typeof merged.mounts?.[0], 'string');
			assert.strictEqual(merged.mounts?.[0], 'source=source2,target=target2,type=volume');
			assert.strictEqual(typeof merged.mounts?.[1], 'object');
			assert.strictEqual((merged.mounts?.[1] as Mount).source, 'source4');
			assert.strictEqual(typeof merged.mounts?.[2], 'object');
			assert.strictEqual((merged.mounts?.[2] as Mount).source, 'source5');
		});
	});

	it('should merge gpu requirements from devcontainer.json and features', () => {
		const merged = mergeConfiguration({
			configFilePath: URI.parse('file:///devcontainer.json'),
			image: 'image',
			hostRequirements: {
				gpu: 'optional'
			}
		}, [
			{
				hostRequirements: {
					gpu: true
				}
			},
			{
				hostRequirements: {
					gpu: {
						cores: 4
					}
				}
			},
			{
				hostRequirements: {
					gpu: {
						memory: '8gb'
					}
				}
			}
		]);
		const gpuRequirement = merged.hostRequirements?.gpu as HostGPURequirements;
		assert.strictEqual(gpuRequirement?.cores, 4);
		assert.strictEqual(gpuRequirement?.memory, '8589934592');
	});
});

function getFeaturesConfig(features: Feature[]): FeaturesConfig {
	return {
		featureSets: features.map((feature): FeatureSet => ({
			features: [feature],
			sourceInformation: {
				type: 'oci',
				userFeatureId: `ghcr.io/my-org/my-repo/${feature.id}:1`,
				userFeatureIdWithoutVersion: `ghcr.io/my-org/my-repo/${feature.id}`,
				featureRef: {
					registry: 'ghcr.io',
					owner: 'my-org',
					namespace: 'my-org/my-repo',
					path: 'my-org/my-repo/test',
					resource: 'ghcr.io/my-org/my-repo/test',
					id: 'test',
					tag: '1.2.3',
					version: '1.2.3',
				},
				manifest: {
					schemaVersion: 1,
					mediaType: '',
					config: {
						digest: '',
						mediaType: '',
						size: 0,
					},
					layers: [],
				},
				manifestDigest: '',
			}
		}))
	};
}
</file>

<file path="src/test/testUtils.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as cp from 'child_process';
import { getCLIHost, loadNativeModule, plainExec, plainPtyExec, runCommand, runCommandNoPty } from '../spec-common/commonUtils';
import { SubstituteConfig } from '../spec-node/utils';
import { LogLevel, createPlainLog, makeLog, nullLog } from '../spec-utils/log';
import { dockerComposeCLIConfig } from '../spec-node/dockerCompose';
import { DockerCLIParameters } from '../spec-shutdown/dockerUtils';
import { mapNodeArchitectureToGOARCH, mapNodeOSToGOOS } from '../spec-configuration/containerCollectionsOCI';

export interface BuildKitOption {
    text: string;
    options: {
        useBuildKit: boolean;
    };
}

export const nonBuildKitOption: BuildKitOption = { text: 'non-BuildKit', options: { useBuildKit: false }, };
export const buildKitOption: BuildKitOption = { text: 'BuildKit', options: { useBuildKit: true }, };

export const buildKitOptions: ReadonlyArray<BuildKitOption> = [
    nonBuildKitOption,
    buildKitOption,
] as const;

export interface UpResult {
    outcome: string;
    containerId: string;
    composeProjectName: string | undefined;
    stderr: string;
}

export interface ExecResult {
    error: Error | null;
    stdout: string;
    stderr: string;
}

export function shellExec(command: string, options: cp.ExecOptionsWithStringEncoding = {}, suppressOutput: boolean = false, doNotThrow: boolean = false): Promise<ExecResult> {
    return new Promise<ExecResult>((resolve, reject) => {
        cp.exec(command, options, (error, stdout, stderr) => {
            if (!suppressOutput) {
                console.log(stdout);
                console.error(stderr);
            }
            ((error && !doNotThrow) ? reject : resolve)({ error, stdout, stderr });
        });
    });
}

export interface BufferExecResult {
    stdout: Buffer;
    stderr: Buffer;
    message? : string;
    code?: number | null;
    signal?: string | null;
}

export async function shellBufferExec(command: string, options: { stdin?: Buffer } = {}): Promise<BufferExecResult> {
    const exec = await plainExec(undefined);
    return runCommandNoPty({
        exec,
        cmd: '/bin/sh',
        args: ['-c', command],
        stdin: options.stdin,
        output: nullLog,
    }).then(res => ({ code: 0, ...res }), error => error);
}

export interface ExecPtyResult {
    cmdOutput: string;
    message? : string;
    code?: number;
    signal?: number;
}

export async function shellPtyExec(command: string, options: { stdin?: string } = {}): Promise<ExecPtyResult> {
    const ptyExec = await plainPtyExec(undefined, loadNativeModule, true);
    return runCommand({
        ptyExec,
        cmd: '/bin/sh',
        args: ['-c', command],
        stdin: options.stdin,
        output: nullLog,
    }).then(res => ({ code: 0, ...res }), error => error);
}

export async function devContainerUp(cli: string, workspaceFolder: string, options?: { cwd?: string; useBuildKit?: boolean; userDataFolder?: string; logLevel?: string; extraArgs?: string; prefix?: string; env?: NodeJS.ProcessEnv }): Promise<UpResult> {
    const buildkitOption = (options?.useBuildKit ?? false) ? '' : ' --buildkit=never';
    const userDataFolderOption = (options?.userDataFolder ?? false) ? ` --user-data-folder=${options?.userDataFolder}` : '';
    const logLevelOption = (options?.logLevel ?? false) ? ` --log-level ${options?.logLevel}` : '';
    const extraArgs = (options?.extraArgs ?? false) ? ` ${options?.extraArgs}` : '';
    const prefix = (options?.prefix ?? false) ? `${options?.prefix} ` : '';
    const shellExecOptions = { cwd: options?.cwd, env: options?.env };
    const res = await shellExec(`${prefix}${cli} up --workspace-folder ${workspaceFolder}${buildkitOption}${userDataFolderOption}${extraArgs} ${logLevelOption}`, shellExecOptions);
    const response = JSON.parse(res.stdout);
    assert.equal(response.outcome, 'success');
    const { outcome, containerId, composeProjectName } = response as UpResult;
    assert.ok(containerId, 'Container id not found.');
    return { outcome, containerId, composeProjectName, stderr: res.stderr };
}
export async function devContainerDown(options: { containerId?: string | null; composeProjectName?: string | null; doNotThrow?: boolean }) {
    if (options.containerId) {
        await shellExec(`docker rm -f ${options.containerId}`, undefined, undefined, options.doNotThrow);
    }
    if (options.composeProjectName) {
        await shellExec(`docker compose --project-name ${options.composeProjectName} down`, undefined, undefined, options.doNotThrow);
    }
}
export async function devContainerStop(options: { containerId?: string | null; composeProjectName?: string | null }) {
    if (options.containerId) {
        await shellExec(`docker stop ${options.containerId}`);
    }
    if (options.composeProjectName) {
        await shellExec(`docker compose --project-name ${options.composeProjectName} stop`);
    }
}
export async function pathExists(cli: string, workspaceFolder: string, location: string) {
    try {
        await shellExec(`${cli} exec --workspace-folder ${workspaceFolder} test -e ${location}`);
        return true;
    } catch (err) {
        return false;
    }
}
export async function commandMarkerTests(cli: string, workspaceFolder: string, expected: { postCreate: boolean; postStart: boolean; postAttach: boolean }, message: string) {
    const actual = {
        postCreate: await pathExists(cli, workspaceFolder, '/tmp/postCreateCommand.testmarker'),
        postStart: await pathExists(cli, workspaceFolder, '/tmp/postStartCommand.testmarker'),
        postAttach: await pathExists(cli, workspaceFolder, '/tmp/postAttachCommand.testmarker'),
    };
    assert.deepStrictEqual(actual, expected, message);
}

export const testSubstitute: SubstituteConfig = value => {
	if ('id' in value) {
		return {
			...value,
			id: (value as any).id + '-substituted'
		};
	}
	return value;
};

export const output = makeLog(createPlainLog(text => process.stdout.write(text), () => LogLevel.Trace));

export async function createCLIParams(hostPath: string) {
	const cliHost = await getCLIHost(hostPath, loadNativeModule, true);
	const dockerComposeCLI = dockerComposeCLIConfig({
		exec: cliHost.exec,
		env: cliHost.env,
		output,
	}, 'docker', 'docker-compose');
	const cliParams: DockerCLIParameters = {
		cliHost,
		dockerCLI: 'docker',
		dockerComposeCLI,
		env: {},
		output,
		platformInfo: {
			os: mapNodeOSToGOOS(cliHost.platform),
			arch: mapNodeArchitectureToGOARCH(cliHost.arch),
		}
};
	return cliParams;
}
</file>

<file path="src/test/tsconfig.json">
{
	"extends": "../../tsconfig.base.json",
	"compilerOptions": {
		"resolveJsonModule": true
	},
	"references": [
		{
			"path": "../spec-configuration"
		},
		{
			"path": "../spec-utils"
		},
		{
			"path": "../spec-node"
		}
	]
}
</file>

<file path="src/test/updateUID.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';
import * as path from 'path';
import { devContainerDown, devContainerUp, shellExec } from './testUtils';

const pkg = require('../../package.json');

(process.platform === 'linux' ? describe : describe.skip)('Dev Containers CLI', function () {
	this.timeout('120s');

	const tmp = path.relative(process.cwd(), path.join(__dirname, 'tmp'));
	const cli = `npx --prefix ${tmp} devcontainer`;

	before('Install', async () => {
		await shellExec(`rm -rf ${tmp}/node_modules`);
		await shellExec(`mkdir -p ${tmp}`);
		await shellExec(`npm --prefix ${tmp} install devcontainers-cli-${pkg.version}.tgz`);
	});

	describe('updateUID', () => {
		it('should update UID and GID', async () => {
			const testFolder = `${__dirname}/configs/updateUID`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});

		it('should update only UID when GID exists', async () => {
			const testFolder = `${__dirname}/configs/updateUIDOnly`;
			const containerId = (await devContainerUp(cli, testFolder, {
				env: {
					...process.env,
					LOCAL_GID: String(process.getgid!())
				}
			})).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(4321));
			await devContainerDown({ containerId });
		});

		it('should update UID and GID when the platform is linux/amd64', async () => {
			const testFolder = `${__dirname}/configs/updateUIDamd64`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});

		it('should update UID and GID when --platform is linux/amd64', async () => {
			const testFolder = `${__dirname}/configs/updateUIDamd64-platform-option`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});

		it('should update UID and GID when the platform is linux/arm64', async () => {
			const testFolder = `${__dirname}/configs/updateUIDarm64`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});

		it('should update UID and GID when --platform is linux/arm64', async () => {
			const testFolder = `${__dirname}/configs/updateUIDarm64-platform-option`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});

		it('should update UID and GID when the platform is linux/arm64/v8', async () => {
			const testFolder = `${__dirname}/configs/updateUIDarm64v8`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});

		it('should update UID and GID when --platform is linux/arm64/v8', async () => {
			const testFolder = `${__dirname}/configs/updateUIDarm64v8-platform-option`;
			const containerId = (await devContainerUp(cli, testFolder)).containerId;
			const uid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -u`);
			assert.strictEqual(uid.stdout.trim(), String(process.getuid!()));
			const gid = await shellExec(`${cli} exec --workspace-folder ${testFolder} id -g`);
			assert.strictEqual(gid.stdout.trim(), String(process.getgid!()));
			await devContainerDown({ containerId });
		});
	});
});
</file>

<file path="src/test/variableSubstitution.test.ts">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *--------------------------------------------------------------------------------------------*/

import * as assert from 'assert';

import { beforeContainerSubstitute, containerSubstitute, substitute } from '../spec-common/variableSubstitution';
import { URI } from 'vscode-uri';

describe('Variable substitution', function () {

	it(`environment variables`, async () => {
		const raw = {
			foo: 'bar${env:baz}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
				baz: 'somevalue'
			},
		}, raw);
		assert.strictEqual(result.foo, 'barsomevaluebar');
	});

	it(`localWorkspaceFolder`, async () => {
		const raw = {
			foo: 'bar${localWorkspaceFolder}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
				baz: 'somevalue'
			},
		}, raw);
		assert.strictEqual(result.foo, 'bar/foo/barbar');
	});

	it(`containerWorkspaceFolder`, async () => {
		const raw = {
			foo: 'bar${containerWorkspaceFolder}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
				baz: 'somevalue'
			},
		}, raw);
		assert.strictEqual(result.foo, 'bar/baz/bluebar');
	});

	it(`localWorkspaceFolderBasename and containerWorkspaceFolder`, async () => {
		const raw = {
			foo: 'bar${containerWorkspaceFolder}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/red',
			containerWorkspaceFolder: '/baz/${localWorkspaceFolderBasename}',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
				baz: 'somevalue'
			},
		}, raw);
		assert.strictEqual(result.foo, 'bar/baz/redbar');
	});

	it(`environment variables with default value if they do not exist`, async () => {
		const raw = {
			foo: 'bar${localEnv:baz:default}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
			},
		}, raw);
		assert.strictEqual(result.foo, 'bardefaultbar');
	});

	it(`environment variables without default value if they do not exist`, async () => {
		const raw = {
			foo: 'bar${localEnv:baz}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
			},
		}, raw);
		assert.strictEqual(result.foo, 'barbar');
	});

	it(`environment variables with default value if they do exist`, async () => {
		const raw = {
			foo: 'bar${localEnv:baz:default}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
				baz: 'somevalue'
			},
		}, raw);
		assert.strictEqual(result.foo, 'barsomevaluebar');
	});

	it(`environment variables with default value if they do not exist`, async () => {
		const raw = {
			foo: 'bar${localEnv:baz:default:a:b:c}bar'
		};
		const result = substitute({
			platform: 'linux',
			localWorkspaceFolder: '/foo/bar',
			containerWorkspaceFolder: '/baz/blue',
			configFile: URI.file('/foo/bar/baz.json'),
			env: {
			},
		}, raw);
		assert.strictEqual(result.foo, 'bardefaultbar');
	});

	it(`container environment variables with default value if they do not exist`, async () => {
		const raw = {
			foo: 'bar${containerEnv:baz:default}bar'
		};
		const result = containerSubstitute('linux', URI.file('/foo/bar/baz.json'), {}, raw);
		assert.strictEqual(result.foo, 'bardefaultbar');
	});

	it(`replaces devcontainerId`, async () => {
		const raw = {
			test: '${devcontainerId}'
		};
		const result = beforeContainerSubstitute({ a: 'b' }, raw);
		assert.ok(/^[0-9a-v]{52}$/.test(result.test), `Got: ${result.test}`);
	});

	it(`replaces devcontainerId and additional id labels matter`, async () => {
		const raw = {
			test: '${devcontainerId}'
		};
		const result1 = beforeContainerSubstitute({ a: 'b' }, raw);
		const result2 = beforeContainerSubstitute({ a: 'b', c: 'd' }, raw);
		assert.notStrictEqual(result1.test, result2.test);
	});

	it(`replaces devcontainerId and label order does not matter`, async () => {
		const raw = {
			test: '${devcontainerId}'
		};
		const result1 = beforeContainerSubstitute({ c: 'd', a: 'b' }, raw);
		const result2 = beforeContainerSubstitute({ a: 'b', c: 'd' }, raw);
		assert.strictEqual(result1.test, result2.test);
	});
});
</file>

<file path=".eslintignore">
**/node_modules/**
</file>

<file path=".eslintrc.js">
module.exports = {
    'env': {
        'browser': true,
        'node': true
    },
    'parser': '@typescript-eslint/parser',
    'parserOptions': {
        'sourceType': 'module'
    },
    'plugins': [
        '@typescript-eslint',
        '@stylistic'
    ],
    'rules': {
        // '@typescript-eslint/class-name-casing': 'warn', https://github.com/typescript-eslint/typescript-eslint/issues/2077
        '@stylistic/member-delimiter-style': [
            'warn',
            {
                'multiline': {
                    'delimiter': 'semi',
                    'requireLast': true
                },
                'singleline': {
                    'delimiter': 'semi',
                    'requireLast': false
                }
            }
        ],
        'semi': [
            'warn',
            'always'
        ],
        'constructor-super': 'warn',
        'curly': 'warn',
        'eqeqeq': [
            'warn',
            'always'
        ],
        'no-async-promise-executor': 'warn',
        'no-buffer-constructor': 'warn',
        'no-caller': 'warn',
        'no-debugger': 'warn',
        'no-duplicate-case': 'warn',
        'no-duplicate-imports': 'warn',
        'no-eval': 'warn',
        'no-extra-semi': 'warn',
        'no-new-wrappers': 'warn',
        'no-redeclare': 'off',
        'no-sparse-arrays': 'warn',
        'no-throw-literal': 'warn',
        'no-unsafe-finally': 'warn',
        'no-unused-labels': 'warn',
        '@typescript-eslint/no-redeclare': 'warn',
        'code-no-unexternalized-strings': 'warn',
        'no-throw-literal': 'warn',
        'no-var': 'warn',
        'code-no-unused-expressions': [
            'warn',
            {
                'allowTernary': true
            }
        ],
    }
};
</file>

<file path=".gitattributes">
* text=auto
*.bat eol=crlf
*.cmd eol=crlf
*.ps1 eol=lf
*.sh eol=lf
</file>

<file path=".gitignore">
dist
built
node_modules
logs
*.log
*.tgz
tmp
tmp[0-9]
tmp/*
build-tmp
.DS_Store
.env
output
*.testMarker
src/test/container-features/configs/temp_lifecycle-hooks-alternative-order
test-secrets-temp.json
src/test/container-*/**/src/**/README.md
!src/test/container-features/assets/*.tgz
</file>

<file path="azure-pipelines.yml">
pool:
  vmImage: "ubuntu-latest"

trigger:
  branches:
    include:
      - 'main'
      - 'release/*'
pr: none

steps:
- checkout: self
  persistCredentials: true
- task: ComponentGovernanceComponentDetection@0
- task: notice@0
  displayName: 'NOTICE File Generator'
  inputs:
    outputformat: 'text'
- task: DownloadPipelineArtifact@2
- script: |
    PIPELINE_WORKSPACE="$(Pipeline.Workspace)"
    if [ "$(sort "$PIPELINE_WORKSPACE/NOTICE.txt/NOTICE.txt" | tr -d '\015')" = "$(sort ThirdPartyNotices.txt | tr -d '\015')" ]
    then
      echo "3rd-party notices unchanged."
    else
      echo "3rd-party notices changed."
      MESSAGE="Auto-update ThirdPartyNotices.txt"
      if [ "$(git log -1 --pretty=%B | head -n 1)" = "$MESSAGE" ]
      then
        echo "Triggered by own commit, exiting."
        exit 0
      fi
      git config --get 'http.https://github.com/devcontainers/cli.extraheader' | cut -d ' ' -f 3 | base64 -d | cut -d : -f 2 | gh auth login --with-token
      SOURCE_BRANCH="$(echo "$(Build.SourceBranch)" | cut -d / -f 3-)"
      echo "Source branch: $SOURCE_BRANCH"
      PR_LIST="$(gh pr list --base "$SOURCE_BRANCH" --jq ".[] | select(.title == \"$MESSAGE\")" --json headRefName,title,url | cat)"
      echo "$PR_LIST"
      if [ ! -z "$PR_LIST" ]
      then
        echo "PR exists, exiting."
        exit 0
      fi
      LOCAL_BRANCH="chrmarti/update-third-party-notices-$(date +%s)"
      git checkout -b "$LOCAL_BRANCH"
      cp "$PIPELINE_WORKSPACE/NOTICE.txt/NOTICE.txt" ThirdPartyNotices.txt
      git status
      git add ThirdPartyNotices.txt
      git config --global user.email "chrmarti@microsoft.com"
      git config --global user.name "Christof Marti"
      git commit -m "$MESSAGE"
      git push -u origin "$LOCAL_BRANCH"
      gh pr create --title "$MESSAGE" --body "Auto-generated PR to update ThirdPartyNotices.txt" --base "$SOURCE_BRANCH"
    fi
</file>

<file path="CHANGELOG.md">
# Change Log

Notable changes.

## July 2025

### [0.80.0]
- Podman: Use label=disable instead of z flag (https://github.com/microsoft/vscode-remote-release/issues/10585)

## June 2025

### [0.79.0]
- Redirect devcontainers-contrib to devcontainers-extra (https://github.com/microsoft/vscode-remote-release/issues/11046)

### [0.78.0]
- Fix: Handle missing features (https://github.com/devcontainers/cli/pull/1040)

## May 2025

### [0.77.0]
- Fix: --uidmap/--gidmap conflict with --userns (https://github.com/microsoft/vscode-remote-release/10954)
- Fix: Omit --userns=keep-id for root (https://github.com/devcontainers/cli/pull/1004)

## April 2025

### [0.76.0]
- Fix: Add Podman options (https://github.com/microsoft/vscode-remote-release/issues/10798)
- Fix: Restore accidental robustness towards numbers (https://github.com/microsoft/vscode-remote-release/issues/10691)

## March 2025

### [0.75.0]
- Fix: add check for missing FROM instructions in Dockerfile parsing (https://github.com/devcontainers/cli/pull/950)
- Update dependencies (https://github.com/devcontainers/cli/pull/954)

## February 2025

### [0.74.0]
- Ignore non-writeable HOME (https://github.com/microsoft/vscode-remote-release/issues/10707)

## January 2025

### [0.73.0]
- Fix: TypeError: Cannot read properties of undefined (reading 'fsPath') (https://github.com/devcontainers/cli/issues/895)
- Fix: Log output of failing lifecycle scripts (https://github.com/devcontainers/cli/issues/845)
- Fix: Escaping of metadata in Docker Compose file (https://github.com/devcontainers/cli/issues/904)
- Fix: Re-authenticate against OCI registry after 403 error (https://github.com/devcontainers/cli/pull/945)

## November 2024

### [0.72.0]
- Fix: change increment syntax in test library script (https://github.com/devcontainers/cli/pull/896)
- Increase timeout to 6 seconds (7 attempts) (https://github.com/microsoft/vscode-remote-release/issues/6509)
- Remove unnecessary log (https://github.com/devcontainers/cli/pull/925)

## September 2024

### [0.71.0]
- Exit with non-zero code on unexpected errors (https://github.com/microsoft/vscode-remote-release/issues/10217)
- Add option for GPU availability (https://github.com/microsoft/vscode-remote-release/issues/9385)

### [0.70.0]
- Add more leniency towards registries that malform WWW-Authenticate (https://github.com/devcontainers/cli/pull/884)
- Handle concurrent removal (https://github.com/microsoft/vscode-remote-release/issues/6509)

## August 2024

### [0.69.0]
- Enhance Template metadata (https://github.com/devcontainers/cli/pull/875)
    - Caches additional Template metadata (such as `files`) onto the manifest
	- Resolves full file paths for `optionalPaths` directories that only contain one file (for better usability in upstream tools)
	- Fixes bugs

### [0.68.0]
- Supporting changes for [Template `optionalPaths` specification](https://github.com/devcontainers/spec/blob/main/docs/specs/devcontainer-templates.md#the-optionalpaths-property) (https://github.com/microsoft/vscode-remote-release/issues/10095)
	- Publish metadata on Template OCI manifests (https://github.com/devcontainers/cli/pull/865)
	- Add `--omit-paths` option to `templates apply` command (https://github.com/devcontainers/cli/pull/868)
	- Add `templates metadata` command (https://github.com/devcontainers/cli/pull/866)

### [0.67.0]
- Fix containerEnv substitution. (https://github.com/microsoft/vscode-remote-release/issues/10033)

## July 2024

### [0.66.0]
- Wait for result to be written to stdout. (https://github.com/microsoft/vscode-remote-release/issues/10029)

## June 2024

### [0.65.0]
- Fix confusing error message with local feature. (https://github.com/devcontainers/cli/issues/834)
- Add `--label` parameter to `devcontainer build` command. (https://github.com/devcontainers/cli/issues/837)
- Prefer Docker Compose v2 over v1. (https://github.com/devcontainers/cli/issues/826)

### [0.64.0]
- Fix project name with env variable. (https://github.com/devcontainers/cli/issues/839)

### [0.63.0]
- Surface additional information in `devcontainer up`. (https://github.com/devcontainers/cli/pull/836)
- Changes the config layer of the Feature manifest to a empty descriptor (https://github.com/devcontainers/cli/pull/815)

## May 2024

### [0.62.0]
- Fix support for project name attribute. (https://github.com/devcontainers/cli/issues/831)

### [0.61.0]
- Use --depth 1 to make dotfiles install process faster (https://github.com/devcontainers/cli/pull/830)
- Enable --cache-to and --cache-from in devcontainer up (https://github.com/devcontainers/cli/pull/813)
- Omit generated image name when `--image-name` is given (https://github.com/devcontainers/cli/pull/812)

### [0.60.0]
- Support project name attribute. (https://github.com/microsoft/vscode-remote-release/issues/512)

## April 2024

### [0.59.1]
- Check if image name has registry host. (https://github.com/microsoft/vscode-remote-release/issues/9748)

### [0.59.0]
- Propagate --cache-from to buildx build. (https://github.com/devcontainers/cli/pull/638)
- Disable cache on feature build when `--build-no-cache` is passed. (https://github.com/devcontainers/cli/pull/790)
- Qualify local image for Podman. (https://github.com/microsoft/vscode-remote-release/issues/9748)
- Stop races docker-compose.devcontainer.containerFeatures file. (https://github.com/devcontainers/cli/issues/801)

## March 2024

### [0.58.0]
- Allow empty value for remote env. (https://github.com/devcontainers/ci/issues/231)
- Add generate-docs subcommand for templates and features. (https://github.com/devcontainers/cli/pull/759)
- Only use SELinux label for Linux hosts. (https://github.com/devcontainers/cli/issues/776)

### [0.57.0]
- Fix crash updating UID/GID when the image's platform is different from the native CPU arch (https://github.com/devcontainers/cli/pull/746)
- Add tags with build command (https://github.com/devcontainers/ci/issues/271)

## February 2024

### [0.56.2]
- Remove dependency on ip package (https://github.com/devcontainers/cli/pull/750)

## January 2024

### [0.56.1]
- Add hidden `--omit-syntax-directive` flag (https://github.com/devcontainers/cli/pull/728) to disable writing `#syntax` directives in intermediate Dockerfiles, even if provided by the user.  This is an advanced flag meant to mitigate issues involving user namespace remapping.  This flag will be removed in a future release. See https://github.com/moby/buildkit/issues/4556 for more information.
- Update dependencies (https://github.com/devcontainers/cli/pull/722)

### [0.56.0]
- Support additional Docker build options (https://github.com/devcontainers/cli/issues/85)

## December 2023

### [0.55.0]
- Adopt additional_contexts in compose (https://github.com/microsoft/vscode-remote-release/issues/7305)
- Log `docker start` output (https://github.com/microsoft/vscode-remote-release/issues/5887)

### [0.54.2]
- Update string in `isBuildKitImagePolicyError` (https://github.com/devcontainers/cli/pull/694)
- Mount build context as shared with buildah (https://github.com/devcontainers/cli/pull/548)

## November 2023

### [0.54.1]

- Fix authentication against Artifactory (https://github.com/devcontainers/cli/pull/692)

### [0.54.0]

- Force deterministic order of `outdated` command (https://github.com/devcontainers/cli/pull/681)
- Remove vscode-dev-containers dependency (https://github.com/devcontainers/cli/pull/682)
- Remove additional unused code (https://github.com/devcontainers/cli/commit/2d24543380dfc4d54e76b582536b52226af133c8)
- Update dependencies including node-pty (https://github.com/devcontainers/cli/pull/685)
- Update Third-party notices (https://github.com/devcontainers/cli/pull/686)
- Edit a Feature pinned version via upgrade command behind hidden flag (https://github.com/devcontainers/cli/pull/684)

### [0.53.0]

- add `--dry-run` to `upgrade` command (https://github.com/devcontainers/cli/pull/679)
- Fix version sorting and report major version in `outdated` command (https://github.com/devcontainers/cli/pull/670)
	- NOTE: This changes the signature of the `features info` command and the output of publishing Features/Templates.  The key `publishedVersions` has been renamed to `publishedTags` to better mirror the key's values.
- Docker compose: Updates create error description to include cause for docker auth plugin errors (https://github.com/devcontainers/cli/pull/660)

## October 2023

### [0.52.1]

- Updates create error description to include cause for docker auth plugin errors (https://github.com/devcontainers/cli/pull/656)

### [0.52.0]

- Add `upgrade` command to generate an updated lockfile (https://github.com/devcontainers/cli/pull/645)

## September 2023

### [0.51.3]

- Update UID only if GID is in use (https://github.com/microsoft/vscode-remote-release/issues/7284)
- Empty lockfile in workspaceFolder will initialize lockfile (https://github.com/devcontainers/cli/pull/637)

## August 2023

### [0.51.2]

- Surface buildkit policy errors (https://github.com/devcontainers/cli/pull/627)

### [0.51.1]
- Handle missing entry in /etc/passwd gracefully (https://github.com/microsoft/vscode-remote-release/issues/8875)

### [0.51.0]
- Add `--cache-to` option to `devcontainer build` command (https://github.com/devcontainers/cli/pull/570)
- Fix: Fallback when getent is not available (https://github.com/microsoft/vscode-remote-release/issues/8811)

## July 2023

### [0.50.2]
- Fix: Only allocate tty for `docker exec` when stdin is a tty (https://github.com/devcontainers/cli/issues/606)

### [0.50.1]
- Fix: Allocate pty for `docker exec` (https://github.com/devcontainers/cli/issues/556)

### [0.50.0]
- Publish without node-pty dependency (https://github.com/devcontainers/cli/pull/585)
- Record feature dependencies in the lockfile (https://github.com/devcontainers/cli/pull/566)
- Record features referenced by tarball URI in lockfile (https://github.com/devcontainers/cli/pull/594)
- Update proxy-agent to avoid vm2 (https://github.com/devcontainers/cli/pull/596)

### [0.49.0]
- Outdated command (https://github.com/devcontainers/cli/pull/565)
- Case-insensitive instructions (https://github.com/microsoft/vscode-remote-release/issues/6850)
- Automatically set execute bit when running dotfiles install script (https://github.com/devcontainers/cli/pull/541)
- Use getent passwd (https://github.com/microsoft/vscode-remote-release/issues/2957)

## June 2023

### [0.48.0]
- Update supported node engines to ^16.13.0 || >=18.0.0 (https://github.com/devcontainers/cli/pull/572)

### [0.47.0]
- Upgrade compiler target to ES2021 (https://github.com/devcontainers/cli/pull/568)
- Secret masking improvements (https://github.com/devcontainers/cli/pull/569)

### [0.46.0]
- Load `NODE_EXTRA_CA_CERTS` in Electron (https://github.com/devcontainers/cli/pull/559)
- Features Test Cmd: "Duplicate" test mode to test Feature Idempotence (https://github.com/devcontainers/cli/pull/553)

### [0.45.0]
- Mask user secrets in logs (https://github.com/devcontainers/cli/pull/551)

### [0.44.0]
- Preview: Feature Dependencies (https://github.com/devcontainers/spec/pull/234)
   - `devcontainer-feature.json` can now specify a `dependsOn` property that lists other Features that must be installed before the current Feature can be installed.
   - Complete rewrite of the Feature dependency resolution model
   - NOTE: This is a feature preview - please submit your feedback!
- Fix containerEnv values with spaces (https://github.com/devcontainers/cli/issues/532)

### [0.43.0]
- Fix a bug in passing users secrets to dotfile clone and install commands (https://github.com/devcontainers/cli/pull/544)
- Fix for mount command string generation (https://github.com/devcontainers/cli/pull/537)

## May 2023

### [0.42.0]

- Add object notation support for `initializeCommand` (https://github.com/devcontainers/cli/pull/514)
- Keep existing lockfile updated (https://github.com/devcontainers/spec/issues/236)
- HttpOci: Retry fetching bearer token anonymously if credentials appear expired (https://github.com/devcontainers/cli/pull/515)
- Bump proxy-agent (https://github.com/devcontainers/cli/pull/534)
- Log feature advisories (https://github.com/devcontainers/cli/pull/528)
- Check for disallowed features (https://github.com/devcontainers/cli/pull/521)

## April 2023

### [0.41.0]

- Secret support for up and run-user-commands (https://github.com/devcontainers/cli/pull/493)

### [0.40.0]

- Experimental lockfile support (https://github.com/devcontainers/cli/pull/495)
- Update vm2 (https://github.com/devcontainers/cli/pull/500)

### [0.39.0]

- Update auth precedence level for fetching Features/Templates. Notably preferring `docker login` credentials. (https://github.com/devcontainers/cli/pull/482)
   - The precedence order (https://github.com/devcontainers/cli/blob/4fde394ac16df1061b731d2d2f226850277cbce2/src/spec-configuration/httpOCIRegistry.ts#L147) is now:
		- parsed out of a special DEVCONTAINERS_OCI_AUTH environment variable
		- Read from a docker credential helper indicated in config
		- Read from a docker cred store indicated in config (https://docs.docker.com/engine/reference/commandline/login/#credentials-store)
		- Read from a docker config file (flat file with base64 encoded credentials)
		- Read from the platform's default credential helper
		- Crafted from the `GITHUB_TOKEN` environment variable
- Features can now be pinned to a digest in `devcontainer.json` (https://github.com/devcontainers/cli/pull/480)
- Automatically clean up test containers when using `devcontainers features test` (https://github.com/devcontainers/cli/pull/450)
   - The `--preserve-test-containers` flag can be used to disable this behavior
- Various internal changes to the Features/Templates OCI registry implementation (https://github.com/devcontainers/cli/pull/490)

### [0.38.0]

- Update vm2 (https://github.com/devcontainers/cli/pull/488)

### [0.37.0]

- Add --config to build command (microsoft/vscode-remote-release#8068)
- Features/Templates: Fix a bug in reading from docker credential helpers (https://github.com/devcontainers/cli/issues/477)

## March 2023

### [0.36.0]

-  Add initial support for docker credential helpers when fetching Features/Templates. (https://github.com/devcontainers/cli/pull/460, contributed by @aaronlehmann)

### [0.35.0]

- Transform maven, gradle and jupyterlab usages to their features v2 counterparts. (https://github.com/devcontainers/cli/issues/461)
- Escape and enclose containerEnv in quotes when writing to Dockerfile. (https://github.com/devcontainers/cli/issues/454)
- Update package dependencies.

### [0.34.0]

- Also require name property in `devcontainer-feature.json`. (https://github.com/devcontainers/cli/pull/447)
- Add `--omit-config-remote-env-from-metadata` to omit remoteEnv from devcontainer config on container metadata label. (https://github.com/devcontainers/cli/pull/453)
- Only include required legacy scripts. (https://github.com/microsoft/vscode-remote-release/issues/7532)

### [0.33.0]

- Connect stdin to executed process. (https://github.com/devcontainers/cli/issues/59)
- Better support for private Features published to Azure Container Registry (https://github.com/devcontainers/cli/pull/444)

### [0.32.0]

- Initial support for Features contributing lifecycle hooks (https://github.com/devcontainers/cli/pull/390)
- Retry docker pull on error (https://github.com/devcontainers/cli/pull/428)
- Fix: `devcontainer feature test` cmd should fail if Feature's sub-folder does not exist (https://github.com/devcontainers/cli/pull/418)

## February 2023

### [0.31.0]

- Add label for config file. (https://github.com/microsoft/vscode-remote-release/issues/7548)
- Add docs for `devcontainer templates publish`. (https://github.com/devcontainers/cli/pull/410)

### [0.30.0]

- Fix: Merge metadata logic for containerEnv for `devcontainer build`. (https://github.com/devcontainers/cli/pull/392)
- Support querying registries that Accept application/vnd.oci.image.index.v1+json. (https://github.com/devcontainers/cli/pull/393)
- Updates Features cache logic - Incrementally copy features near the layer they're installed. (https://github.com/devcontainers/cli/pull/382)

## January 2023

### [0.29.0]

- Add `set-up` command. (https://github.com/microsoft/vscode-remote-release/issues/7872)

### [0.28.0]

- Features preamble: Add warnings for Feature renames & deprecation. (https://github.com/devcontainers/cli/pull/366)
- Add dotfiles functionallity. (https://github.com/devcontainers/cli/pull/362)
- Cache user env for performance improvement. (https://github.com/devcontainers/cli/pull/374)

### [0.27.1]

- Fix: Modify argument regex to only allow certain set of values (https://github.com/devcontainers/cli/pull/361)
- Fix: Fixed fromStatement parsing to parse quotes in variable expressions (https://github.com/devcontainers/cli/pull/356)
- Fix: Allow prebuilding image without a Dockerfile (https://github.com/devcontainers/cli/pull/352)

### [0.27.0]

- Fix: Failed to fetch local disk feature on Windows (https://github.com/devcontainers/cli/pull/333)
- Features: Adds 'deprecated' property (https://github.com/devcontainers/cli/pull/346)
- Features: Adds 'legacyIds' property (https://github.com/devcontainers/cli/pull/335)
- Follow Docker Token Authentication Specification (https://github.com/devcontainers/cli/pull/341)
- Fix: Handle parsing variable expression in dockerfile (https://github.com/devcontainers/cli/pull/337)

## December 2022

### [0.26.1]

- Add more detail to the output of `publish` commands (https://github.com/devcontainers/cli/pull/326)

### [0.26.0]

- A more spec-compliant/resilient OCI distribution implementation. (https://github.com/devcontainers/cli/pull/318)
- Update NPM package dependencies. (https://github.com/devcontainers/cli/pull/315)
- Fix escaping of embedded JSON. (https://github.com/devcontainers/cli/pull/324)

### [0.25.3]

- Emit a JSON summary of the result of the `features publish` and `templates publish` commands (https://github.com/devcontainers/cli/pull/305)
- Fix: "ssh-add: communication with agent failed" (https://github.com/microsoft/vscode-remote-release/issues/7601)

## November 2022

### [0.25.2]

- Fix Feature/Template publishing issue when a capital letter is in the repo name (https://github.com/devcontainers/cli/pull/303)

### [0.25.1]
- Fix regression in https://github.com/devcontainers/cli/pull/298

### [0.25.0]

- `features test`: Respect image label metadata. (https://github.com/devcontainers/cli/pull/288)
- Surface first error (https://github.com/microsoft/vscode-remote-release/issues/7382)
- `templates publish`: Exit for "Failed to PUT manifest for tag x" error. (https://github.com/devcontainers/cli/pull/296)
- Respect devcontainer.json when using image without features. (https://github.com/devcontainers/cli/issues/299)
- Emit response from registry on failed `postUploadSessionId` (https://github.com/devcontainers/cli/pull/298)
- downcase OCI identifiers and validate input of getRef() (https://github.com/devcontainers/cli/pull/293)

### [0.24.1]

- `features test`: Respects testing scenarios where 'remoteUser' is non-root (https://github.com/devcontainers/cli/pull/286)

### [0.24.0]

- Handle quoted base image (https://github.com/microsoft/vscode-remote-release/issues/7323)
- Use plain text when not in terminal (https://github.com/devcontainers/cli/issues/253)
- `features test` documentation (https://github.com/devcontainers/cli/pull/219)
- `features test`: Copy entire test folder on test execution and improve CLI command usage. (https://github.com/devcontainers/cli/pull/265)
- Avoid image build (https://github.com/microsoft/vscode-remote-release/issues/7378)
- Preserve syntax directive (https://github.com/microsoft/vscode-remote-release/issues/7463)
- GPU requirement and auto-detect NVIDIA extensions (https://github.com/devcontainers/cli/pull/173)
- `features test`: Pattern to provide additional files in scenario test. (https://github.com/devcontainers/cli/pull/273)
- Handle Cygwin / Git Bash sockets forwarding on Windows. (https://github.com/devcontainers/cli/issues/62)
- Handle ENV without `=`. (https://github.com/microsoft/vscode-remote-release/issues/7493)
- Bundle CLI for NPM package. (https://github.com/devcontainers/cli/issues/279)
- `features test`: Add --filter to allow for selectively running scenarios. (https://github.com/devcontainers/cli/pull/272)

## October 2022

### [0.23.2]

- Add flag to omit `customizations` from image metadata. (https://github.com/devcontainers/cli/pull/262)
- Normalize feature permissions. (https://github.com/devcontainers/cli/issues/153)
- Skip features code path without features. (https://github.com/devcontainers/cli/pull/258)

### [0.23.1]

- Pick up updated `remoteEnv`, `remoteUser` and `userEnvProbe` properties. (https://github.com/devcontainers/cli/issues/252)

### [0.23.0]

- Consider base image env when looking up USER. (https://github.com/microsoft/vscode-remote-release/issues/7358)
- Handle ENV when looking up USER. (https://github.com/microsoft/vscode-remote-release/issues/7303)
- Last mount source wins. (https://github.com/microsoft/vscode-remote-release/issues/7368)
- Add missing substitutions in run-user-commands. (https://github.com/microsoft/vscode-remote-release/issues/7412)
- Last updateRemoteUserUID value wins. (https://github.com/microsoft/vscode-remote-release/issues/7390)

### [0.22.0]

- Add `${devcontainerId}` configuration variable. (https://github.com/devcontainers/spec/issues/62)
- User environment variables for features. (https://github.com/devcontainers/spec/issues/91)

### [0.21.0]

- New Command: `templates apply` to apply fetch and apply a dev container Template to a project
- Initial support for running lifecycle scripts in parallel
- Improvements to the `features test` command
- Improvements related to packaging dev container Features and Templates

### [0.20.0]

- Handle old and otherwise started containers (https://github.com/microsoft/vscode-remote-release/issues/7307)
- Configure proxy-agent (https://github.com/microsoft/vscode-remote-release/issues/6995)

### [0.19.1]

- Only set target when previously set. (https://github.com/microsoft/vscode-remote-release/issues/7301)
- Check for existing syntax directive. (https://github.com/microsoft/vscode-remote-release/issues/6848)
- Templates & Features Packaging - Throw warning of a missing JSON file and continue. (https://github.com/devcontainers/cli/pull/206)

### [0.19.0]

- Inspect image in registry to avoid pulling it. (https://github.com/microsoft/vscode-remote-release/issues/7273)

### [0.18.0]

- Introduces `templates publish` command. (https://github.com/devcontainers/cli/pull/198)
- Adds `--additional-features` option. (https://github.com/devcontainers/cli/pull/171)
- Adds `--output` option to the `devcontainer build` command. (https://github.com/devcontainers/cli/pull/166)

## September 2022

### [0.17.0]

- Use qualified id for features. (https://github.com/microsoft/vscode-remote-release/issues/7253)
- Avoid changing metadata order. (https://github.com/microsoft/vscode-remote-release/issues/7254)
- Include version in all override files. (https://github.com/microsoft/vscode-remote-release/issues/7244)

### [0.16.0]

- Image metadata. (https://github.com/devcontainers/cli/issues/188)

### [0.15.0]

- Fix typo in 'installsAfter'. (https://github.com/devcontainers/cli/issues/163)
- Add --skip-post-attach. (https://github.com/devcontainers/cli/pull/174)
- Improve feature installation logs. (https://github.com/devcontainers/cli/pull/178)

## August 2022

### [0.14.2]

- Properly source feature options. (https://github.com/devcontainers/cli/issues/148)

### [0.14.1]

- Replace containerEnv in entire config and in read-configuration command. (https://github.com/microsoft/vscode-remote-release/issues/7121)

### [0.14.0]

- Update to vscode-dev-containers 0.245.2.

### [0.13.0]

- Updates to `devcontainer features test` command
	- Can now specify a `scenarios.json` per-feature
- Introduces `devcontainer features info` command

### [0.12.1]

- Pick up v0.10.2 related to container ENV output.

### [0.12.0]

- Native implementation for pushing a dev container feature to an OCI registry
- `features publish` command

### [0.11.0]

- WIP on features v2:
	- Auto map old feature ids to OCI features. (https://github.com/devcontainers/cli/pull/100)

### [0.10.2]

- Fix malformed container ENV output for 'v1' features (https://github.com/devcontainers/cli/issues/131) 

### [0.10.1]

- Fixes regression where some dev container feature properties were not being applied properly (https://github.com/devcontainers/cli/pull/126)
- Fixes undesired behavior with dev container features and multi-stage builds (https://github.com/devcontainers/cli/issues/120)

### [0.10.0]

- Implement optional default values in localEnv/containerEnv expansions. (https://github.com/devcontainers/cli/issues/50)
- Log version and install location at the end of `--help`. (https://github.com/devcontainers/cli/issues/114)
- WIP on features v2:
	- Update `direct-tarball` to follow spec. (https://github.com/devcontainers/cli/pull/105)
	- Add `features package` command. (https://github.com/devcontainers/cli/pull/93)
	- Fix cwd for building with local features. (https://github.com/devcontainers/cli/issues/116)

### [0.9.0]

- WIP on features v2:
	- Contributable features in OCI registries.

## July 2022

### [0.8.0]

- Build command: Support multiple --image-name parameters  (#61)
- WIP on features v2:
	- Contributable features.
	- `features test` command.

## June 2022

### [0.7.0]

- Multi-platform build support. (https://github.com/devcontainers/cli/pull/24)
- User-scoped tmp folder on Linux. (https://github.com/microsoft/vscode-remote-release/issues/2347)

## May 2022

### [0.6.0]

- Handle undefined context. (https://github.com/microsoft/vscode-remote-release/issues/6815)
- Avoid comment after ARG for Podman. (https://github.com/microsoft/vscode-remote-release/issues/6819)
- Update to vscode-dev-containers 0.238.1.

### [0.5.0]

- Update to vscode-dev-containers 0.238.0.

### [0.4.0]

- Merge user and features Dockerfile to simplify cache and multi-platform handling.
- Use PTY for `--log-format-json`.

### [0.3.0]

- BuildKit version check for `--build-context`.

### [0.2.0]

- Use single Dockerfile to build image for single container using BuildKit.

### [0.1.0]

- Initial version.
</file>

<file path="CODEOWNERS">
* @devcontainers/maintainers
</file>

<file path="CONTRIBUTING.md">
# Contributing

We're excited for your contributions to the development container CLI! This document outlines how you can get involved. 

## Contribution approaches

- Propose the change via an issue in the [specification repository](https://github.com/microsoft/dev-container-spec/issues). Try to get early feedback before spending too much effort formalizing it.
- More formally document the proposed change in terms of properties and their semantics. Look to format your proposal like our [devcontainer.json reference](https://aka.ms/devcontainer.json), which is a JSON with Comments (jsonc) format.

Here is a sample:

| Property | Type | Description |
|----------|------|-------------|
| `image` | string | **Required** when [using an image](/docs/remote/create-dev-container.md#using-an-image-or-dockerfile). The name of an image in a container registry ([DockerHub](https://hub.docker.com), [GitHub Container Registry](https://docs.github.com/packages/guides/about-github-container-registry), [Azure Container Registry](https://azure.microsoft.com/services/container-registry/)) that VS Code and other `devcontainer.json` supporting services / tools should use to create the dev container. |

- You may open a PR, i.e code or shell scripts demonstrating approaches for implementation.
- Once there is discussion on your proposal, please also open and link a PR to update the [devcontainer.json reference doc](https://aka.ms/devcontainer.json). When your proposal is merged, the docs will be kept up-to-date with the latest spec.

## Review process

The specification repo uses the following [labels](https://github.com/microsoft/dev-container-spec/labels):

- `proposal`: Issues under discussion, still collecting feedback.
- `finalization`: Proposals we intend to make part of the spec.

[Milestones](https://github.com/microsoft/dev-container-spec/milestones) use a "month year" pattern (i.e. January 2022). If a finalized proposal is added to a milestone, it is intended to be merged during that milestone.

## Release CLI package

- Create a PR:
	- Updating the package version in the `package.json`.
	- List notable changes in the `CHANGELOG.md`.
	- Update ThirdPartyNotices.txt with any new dependencies.
- After the PR is merged to `main` wait for the CI workflow to succeed (this builds the artifact that will be published). (TBD: Let the `publish-dev-containers` workflow wait for the CI workflow.)
- Push a new tag, e.g., v0.10.0:
	- `git tag v0.10.0`
	- `git push origin v0.10.0`
- Pushing of a tag will trigger the `publish-dev-containers` workflow which will publish the new version to npm: https://www.npmjs.com/package/@devcontainers/cli

## Miscellaneous

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

This project is under an [MIT license](LICENSE.txt).
</file>

<file path="devcontainer.js">
#!/usr/bin/env node
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

require('./dist/spec-node/devContainersSpecCLI');
</file>

<file path="esbuild.js">
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *--------------------------------------------------------------------------------------------*/

// @ts-check

const esbuild = require('esbuild');
const fs = require('fs');
const path = require('path');
const uri = require('vscode-uri');

const minify = process.argv.indexOf('--production') !== -1;
const watch = process.argv.indexOf('--watch') !== -1;

(async () => {

	/** @type esbuild.Plugin */
	const plugin = {
		name: 'patch up',
		setup(build) {
			build.onLoad({ filter: /node_modules[\/\\]yargs[\/\\]lib[\/\\]platform-shims[\/\\]esm\.mjs$/ }, async (args) => {
				let text = await fs.promises.readFile(args.path, 'utf8');
				let fileUri = uri.URI.file(args.path);
				fileUri = fileUri.with({
					path: path.posix.join('/C:', fileUri.path)
				});
				return {
					contents: text.replace(/import\.meta\.url/g, `'${fileUri.toString()}'`),
					loader: 'js',
				};
			});
			build.onLoad({ filter: /node_modules[\/\\]vm2[\/\\]lib[\/\\]vm.js$/ }, async (args) => {
				const text = await fs.promises.readFile(args.path, 'utf8');
				const regex = /fs\.readFileSync\(`\$\{__dirname\}\/([^`]+)`, 'utf8'\)/g;
				const files = await [...new Set(text.matchAll(regex))]
					.reduce(async (prevP, m) => {
						const text = (await fs.promises.readFile(path.join(path.dirname(args.path), m[1]), 'utf8'));
						const prev = await prevP;
						prev[m[1]] = text;
						return prev;
					}, Promise.resolve({}));
				const contents = text.replace(regex, (_sub, file) => {
					return `\`${files[file].replace(/[`$]/g, '\\$&')}\``;
				});
				return {
					contents,
					loader: 'js',
				};
			});
			// Work around https://github.com/TooTallNate/node-pac-proxy-agent/issues/21.
			build.onLoad({ filter: /node_modules[\/\\]ftp[\/\\]lib[\/\\]connection.js$/ }, async (args) => {
				const text = await fs.promises.readFile(args.path, 'utf8');
				return {
					contents: text.replace(/\bnew Buffer\(/g, 'Buffer.from('),
					loader: 'js',
				};
			});
		},
	};

	/** @type {import('esbuild').BuildOptions} */
	const options = {
		bundle: true,
		sourcemap: true,
		minify,
		platform: 'node',
		target: 'node14.17.0',
		mainFields: ['module', 'main'],
		outdir: 'dist',
		plugins: [plugin],
		banner: {
			js: `
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/
`.trimStart()
		},
		entryPoints: [
			'./src/spec-node/devContainersSpecCLI.ts',
		],
		tsconfig: 'tsconfig.json',
		outbase: 'src',
	};

	if (watch) {
		(await esbuild.context(options))
			.watch();
	} else {
		await esbuild.build(options);
	}

})().catch(() => process.exit(1));
</file>

<file path="LICENSE.txt">
MIT License

Copyright (c) Microsoft Corporation. 

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</file>

<file path="package.json">
{
	"name": "@devcontainers/cli",
	"description": "Dev Containers CLI",
	"version": "0.80.1",
	"bin": {
		"devcontainer": "devcontainer.js"
	},
	"author": "Microsoft Corporation",
	"repository": {
		"type": "git",
		"url": "https://github.com/devcontainers/cli.git"
	},
	"bugs": {
		"url": "https://github.com/devcontainers/cli/issues"
	},
	"license": "MIT",
	"engines": {
		"node": "^16.13.0 || >=18.0.0"
	},
	"scripts": {
		"compile": "npm-run-all clean-dist compile-dev",
		"watch": "npm-run-all clean-dist compile-watch",
		"package": "npm-run-all clean-dist compile-prod store-packagejson patch-packagejson npm-pack restore-packagejson",
		"store-packagejson": "copyfiles package.json build-tmp/",
		"patch-packagejson": "node build/patch-packagejson.js",
		"restore-packagejson": "copyfiles --up 1 build-tmp/package.json .",
		"type-check": "npm-run-all clean-built tsc-b",
		"type-check-watch": "npm-run-all clean-built tsc-b-w",
		"compile-prod": "node esbuild.js --production",
		"compile-dev": "node esbuild.js",
		"compile-watch": "node esbuild.js --watch",
		"tsc-b": "tsc -b",
		"tsc-b-w": "tsc -b -w",
		"precommit": "node build/hygiene.js",
		"lint": "eslint -c .eslintrc.js --rulesdir ./build/eslint --max-warnings 0 --ext .ts ./src",
		"npm-pack": "npm pack",
		"clean": "npm-run-all clean-dist clean-built",
		"clean-dist": "rimraf dist",
		"clean-built": "rimraf built",
		"test": "env TS_NODE_PROJECT=src/test/tsconfig.json mocha -r ts-node/register --exit src/test/*.test.ts",
		"test-matrix": "env TS_NODE_PROJECT=src/test/tsconfig.json mocha -r ts-node/register --exit",
		"test-container-features": "env TS_NODE_PROJECT=src/test/tsconfig.json mocha -r ts-node/register --exit src/test/container-features/*.test.ts",
		"test-container-features-cli": "env TS_NODE_PROJECT=src/test/tsconfig.json mocha -r ts-node/register --exit src/test/container-features/featuresCLICommands.test.ts",
		"test-container-templates": "env TS_NODE_PROJECT=src/test/tsconfig.json mocha -r ts-node/register --exit src/test/container-templates/*.test.ts"
	},
	"files": [
		"CHANGELOG.md",
		"LICENSE.txt",
		"README.md",
		"ThirdPartyNotices.txt",
		"devcontainer.js",
		"dist/spec-node/devContainersSpecCLI.js",
		"package.json",
		"scripts/updateUID.Dockerfile"
	],
	"devDependencies": {
		"@stylistic/eslint-plugin": "^3.0.1",
		"@types/chai": "^4.3.20",
		"@types/chalk": "^2.2.4",
		"@types/follow-redirects": "^1.14.4",
		"@types/js-yaml": "^4.0.9",
		"@types/mocha": "^10.0.10",
		"@types/ncp": "^2.0.8",
		"@types/node": "^18.19.127",
		"@types/pull-stream": "^3.6.7",
		"@types/recursive-readdir": "^2.2.4",
		"@types/semver": "^7.5.8",
		"@types/shell-quote": "^1.7.5",
		"@types/tar": "^6.1.13",
		"@types/text-table": "^0.2.5",
		"@types/yargs": "^17.0.33",
		"@typescript-eslint/eslint-plugin": "^8.26.0",
		"@typescript-eslint/experimental-utils": "^5.62.0",
		"@typescript-eslint/parser": "^8.26.0",
		"chai": "^4.5.0",
		"copyfiles": "^2.4.1",
		"esbuild": "^0.25.0",
		"eslint": "^8.57.0",
		"event-stream": "^4.0.1",
		"gulp-eslint": "^6.0.0",
		"gulp-filter": "^9.0.1",
		"mocha": "^11.1.0",
		"npm-run-all": "^4.1.5",
		"p-all": "^5.0.0",
		"rimraf": "^5.0.10",
		"ts-node": "^10.9.2",
		"typescript": "^5.8.2",
		"typescript-formatter": "^7.2.2",
		"vinyl": "^3.0.0",
		"vinyl-fs": "^4.0.0"
	},
	"dependencies": {
		"chalk": "^5.4.1",
		"follow-redirects": "^1.15.9",
		"js-yaml": "^4.1.0",
		"jsonc-parser": "^3.3.1",
		"ncp": "^2.0.0",
		"node-pty": "^1.0.0",
		"proxy-agent": "^6.5.0",
		"pull-stream": "^3.7.0",
		"recursive-readdir": "^2.2.3",
		"semver": "^7.7.1",
		"shell-quote": "^1.8.2",
		"stream-to-pull-stream": "^1.7.3",
		"tar": "^6.2.1",
		"text-table": "^0.2.0",
		"vscode-uri": "^3.1.0",
		"yargs": "~17.7.2"
	}
}
</file>

<file path="README.md">
# Dev Container CLI

This repository holds the dev container CLI, which can take a devcontainer.json and create and configure a dev container from it.

## Context

A development container allows you to use a container as a full-featured development environment. It can be used to run an application, to separate tools, libraries, or runtimes needed for working with a codebase, and to aid in continuous integration and testing. Dev containers can be run locally or remotely, in a private or public cloud.

![Diagram of inner and outerloop development with dev containers](/images/dev-container-stages.png)

This CLI is in active development. Current status:

- [x] `devcontainer build` - Enables building/pre-building images
- [x] `devcontainer up` - Spins up containers with `devcontainer.json` settings applied
- [x] `devcontainer run-user-commands` - Runs lifecycle commands like `postCreateCommand`
- [x] `devcontainer read-configuration` - Outputs current configuration for workspace
- [x] `devcontainer exec` - Executes a command in a container with `userEnvProbe`, `remoteUser`, `remoteEnv`, and other properties applied
- [x] `devcontainer features <...>` - Tools to assist in authoring and testing [Dev Container Features](https://containers.dev/implementors/features/)
- [x] `devcontainer templates <...>` - Tools to assist in authoring and testing [Dev Container Templates](https://containers.dev/implementors/templates/)
- [ ] `devcontainer stop` - Stops containers
- [ ] `devcontainer down` - Stops and deletes containers

## Try it out

We'd love for you to try out the dev container CLI and let us know what you think. You can quickly try it out in just a few simple steps, either by installing its npm package or building the CLI repo from sources (see "[Build from sources](#build-from-sources)").

To install the npm package you will need Python and C/C++ installed to build one of the dependencies (see, e.g., [here](https://github.com/microsoft/vscode/wiki/How-to-Contribute) for instructions).

### npm install

```bash
npm install -g @devcontainers/cli
```

Verify you can run the CLI and see its help text:

```bash
devcontainer <command>

Commands:
  devcontainer up                   Create and run dev container
  devcontainer build [path]         Build a dev container image
  devcontainer run-user-commands    Run user commands
  devcontainer read-configuration   Read configuration
  devcontainer features             Features commands
  devcontainer templates            Templates commands
  devcontainer exec <cmd> [args..]  Execute a command on a running dev container

Options:
  --help     Show help                                                 [boolean]
  --version  Show version number                                       [boolean]
```

### Try out the CLI

Once you have the CLI, you can try it out with a sample project, like this [Rust sample](https://github.com/microsoft/vscode-remote-try-rust).

Clone the Rust sample to your machine, and start a dev container with the CLI's `up` command:

```bash
git clone https://github.com/microsoft/vscode-remote-try-rust
devcontainer up --workspace-folder <path-to-vscode-remote-try-rust>
```

This will download the container image from a container registry and start the container. Your Rust container should now be running:

```bash
[88 ms] dev-containers-cli 0.1.0.
[165 ms] Start: Run: docker build -f /home/node/vscode-remote-try-rust/.devcontainer/Dockerfile -t vsc-vscode-remote-try-rust-89420ad7399ba74f55921e49cc3ecfd2 --build-arg VARIANT=bullseye /home/node/vscode-remote-try-rust/.devcontainer
[+] Building 0.5s (5/5) FINISHED
 => [internal] load build definition from Dockerfile                       0.0s
 => => transferring dockerfile: 38B                                        0.0s
 => [internal] load .dockerignore                                          0.0s
 => => transferring context: 2B                                            0.0s
 => [internal] load metadata for mcr.microsoft.com/vscode/devcontainers/r  0.4s
 => CACHED [1/1] FROM mcr.microsoft.com/vscode/devcontainers/rust:1-bulls  0.0s
 => exporting to image                                                     0.0s
 => => exporting layers                                                    0.0s
 => => writing image sha256:39873ccb81e6fb613975e11e37438eee1d49c963a436d  0.0s
 => => naming to docker.io/library/vsc-vscode-remote-try-rust-89420ad7399  0.0s
[1640 ms] Start: Run: docker run --sig-proxy=false -a STDOUT -a STDERR --mount type=bind,source=/home/node/vscode-remote-try-rust,target=/workspaces/vscode-remote-try-rust -l devcontainer.local_folder=/home/node/vscode-remote-try-rust --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --entrypoint /bin/sh vsc-vscode-remote-try-rust-89420ad7399ba74f55921e49cc3ecfd2-uid -c echo Container started
Container started
{"outcome":"success","containerId":"f0a055ff056c1c1bb99cc09930efbf3a0437c54d9b4644695aa23c1d57b4bd11","remoteUser":"vscode","remoteWorkspaceFolder":"/workspaces/vscode-remote-try-rust"}
```

You can then run commands in this dev container:

```bash
devcontainer exec --workspace-folder <path-to-vscode-remote-try-rust> cargo run
```

This will compile and run the Rust sample, outputting:

```bash
[33 ms] dev-containers-cli 0.1.0.
   Compiling hello_remote_world v0.1.0 (/workspaces/vscode-remote-try-rust)
    Finished dev [unoptimized + debuginfo] target(s) in 1.06s
     Running `target/debug/hello_remote_world`
Hello, VS Code Remote - Containers!
{"outcome":"success"}
```

Congrats, you've just run the dev container CLI and seen it in action!

## More CLI examples

The [example-usage](./example-usage) folder contains some simple shell scripts to illustrate how the CLI can be used to:

- Inject tools for use inside a development container
- Use a dev container as your CI build environment to build an application (even if it is not deployed as a container)
- Build a container image from a devcontainer.json file that includes [dev container features](https://containers.dev/implementors/features/#devcontainer-json-properties)

## Build from sources

This repository has a [dev container configuration](https://github.com/devcontainers/cli/tree/main/.devcontainer), which you can use to ensure you have the right dependencies installed.

Compile the CLI with yarn:
```sh
yarn
yarn compile
```

Verify you can run the CLI and see its help text:
```sh
node devcontainer.js --help
```

## Specification

The dev container CLI is part of the [Development Containers Specification](https://github.com/devcontainers/spec). This spec seeks to find ways to enrich existing formats with common development specific settings, tools, and configuration while still providing a simplified, un-orchestrated single container option – so that they can be used as coding environments or for continuous integration and testing.

Learn more on the [dev container spec website](https://devcontainers.github.io/).

## Additional resources

You may review other resources part of the specification in the [`devcontainers` GitHub organization](https://github.com/devcontainers).

### Documentation

- Additional information on using the built-in [Features testing command](./docs/features/test.md).

## Contributing

Check out how to contribute to the CLI in [CONTRIBUTING.md](CONTRIBUTING.md).

## License

This project is under an [MIT license](LICENSE.txt).
</file>

<file path="ThirdPartyNotices.txt">
NOTICES AND INFORMATION
Do Not Translate or Localize

This software incorporates material from third parties.
Microsoft makes certain open source code available at https://3rdpartysource.microsoft.com,
or you may send a check or money order for US $5.00, including the product name,
the open source component name, platform, and version number, to:

Source Code Compliance Team
Microsoft Corporation
One Microsoft Way
Redmond, WA 98052
USA

Notwithstanding any other terms, you may reverse engineer this software to the extent
required to debug changes to any libraries licensed under the GNU Lesser General Public License.

---------------------------------------------------------

tslib 2.4.1 - 0BSD
https://www.typescriptlang.org/

Copyright (c) Microsoft Corporation

Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

escodegen 1.14.3 - BSD-2-Clause
http://github.com/estools/escodegen

Copyright (c) 2014 Ivan Nikulin <ifaaan@gmail.com>
Copyright (c) 2012 Kris Kowal <kris.kowal@cixar.com>
Copyright (c) 2012 John Freeman <jfreeman08@gmail.com>
Copyright (c) 2015 Ingvar Stepanyan <me@rreverser.com>
Copyright (c) 2012 Yusuke Suzuki <utatane.tea@gmail.com>
Copyright (c) 2012-2013 Mathias Bynens <mathias@qiwi.be>
Copyright (c) 2013 Irakli Gozalishvili <rfobic@gmail.com>
Copyright (c) 2012 Arpad Borsos <arpad.borsos@googlemail.com>
Copyright (c) 2012-2014 Yusuke Suzuki <utatane.tea@gmail.com>
Copyright (c) 2011-2012 Ariya Hidayat <ariya.hidayat@gmail.com>
Copyright (c) 2012 Joost-Wim Boekesteijn <joost-wim@boekesteijn.nl>
Copyright (c) 2012 Robert Gust-Bardon <donate@robert.gust-bardon.org>
Copyright (c) 2012 Yusuke Suzuki (twitter Constellation) and other contributors
Copyright (c) 2012-2013 Michael Ficarra <escodegen.copyright@michael.ficarra.me>
Copyright (c) 2012 Yusuke Suzuki (http://github.com/Constellation) (twitter Constellation (http://twitter.com/Constellation)) and other contributors

Copyright (C) 2012 Yusuke Suzuki (twitter: @Constellation) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


---------------------------------------------------------

---------------------------------------------------------

esprima 4.0.1 - BSD-2-Clause
http://esprima.org/

Copyright JS Foundation and other contributors, https://js.foundation

Copyright JS Foundation and other contributors, https://js.foundation/

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


---------------------------------------------------------

---------------------------------------------------------

estraverse 4.3.0 - BSD-2-Clause
https://github.com/estools/estraverse

Copyright (c) 2014 Yusuke Suzuki <utatane.tea@gmail.com>
Copyright (c) 2012 Ariya Hidayat <ariya.hidayat@gmail.com>
Copyright (c) 2012-2013 Yusuke Suzuki <utatane.tea@gmail.com>
Copyright (c) 2012-2016 Yusuke Suzuki (http://github.com/Constellation) (twitter Constellation (http://twitter.com/Constellation)) and other contributors

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


---------------------------------------------------------

---------------------------------------------------------

esutils 2.0.3 - BSD-2-Clause
https://github.com/estools/esutils

Copyright (c) 2014 Ivan Nikulin <ifaaan@gmail.com>
Copyright (c) 2013 Yusuke Suzuki <utatane.tea@gmail.com>
Copyright (c) 2013-2014 Yusuke Suzuki <utatane.tea@gmail.com>
Copyright (c) 2013 Yusuke Suzuki (http://github.com/Constellation) (twitter Constellation (http://twitter.com/Constellation)) and other contributors

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


---------------------------------------------------------

---------------------------------------------------------

source-map 0.6.1 - BSD-3-Clause
https://github.com/mozilla/source-map

Copyright 2011 The Closure Compiler Authors
Copyright 2011 Mozilla Foundation and contributors
Copyright 2014 Mozilla Foundation and contributors
Copyright 2009-2011 Mozilla Foundation and contributors
Copyright (c) 2009-2011, Mozilla Foundation and contributors


Copyright (c) 2009-2011, Mozilla Foundation and contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the names of the Mozilla Foundation nor the names of project
  contributors may be used to endorse or promote products derived from this
  software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


---------------------------------------------------------

---------------------------------------------------------

sprintf-js 1.1.3 - BSD-3-Clause
https://github.com/alexei/sprintf.js#readme

Copyright (c) 2007-present, Alexandru Marasteanu <hello@alexei.ro>

Copyright (c) 2007-present, Alexandru Mărășteanu <hello@alexei.ro>
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:
* Redistributions of source code must retain the above copyright
  notice, this list of conditions and the following disclaimer.
* Redistributions in binary form must reproduce the above copyright
  notice, this list of conditions and the following disclaimer in the
  documentation and/or other materials provided with the distribution.
* Neither the name of this software nor the names of its contributors may be
  used to endorse or promote products derived from this software without
  specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


---------------------------------------------------------

---------------------------------------------------------

chownr 2.0.0 - ISC
https://github.com/isaacs/chownr#readme

Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

cliui 8.0.1 - ISC
https://github.com/yargs/cliui#readme

Copyright (c) 2015, Contributors
Copyright (c) npm, Inc. and Contributors

Copyright (c) 2015, Contributors

Permission to use, copy, modify, and/or distribute this software
for any purpose with or without fee is hereby granted, provided
that the above copyright notice and this permission notice
appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES
OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE
LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES
OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION,
ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

fs-minipass 2.1.0 - ISC
https://github.com/npm/fs-minipass#readme

Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

get-caller-file 2.0.5 - ISC
https://github.com/stefanpenner/get-caller-file#readme

Copyright 2018 Stefan Penner

ISC License (ISC)
Copyright 2018 Stefan Penner

Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

graceful-fs 4.2.10 - ISC
https://github.com/isaacs/node-graceful-fs#readme

Copyright (c) 2011-2022 Isaac Z. Schlueter, Ben Noordhuis, and Contributors

The ISC License

Copyright (c) 2011-2022 Isaac Z. Schlueter, Ben Noordhuis, and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

lru-cache 6.0.0 - ISC
https://github.com/isaacs/node-lru-cache#readme

Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

lru-cache 7.18.3 - ISC
https://github.com/isaacs/node-lru-cache#readme

Copyright (c) Microsoft Corporation
Copyright (c) 2010-2023 Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) 2010-2023 Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

minimatch 3.1.2 - ISC
https://github.com/isaacs/minimatch#readme

Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

minipass 3.3.6 - ISC
https://github.com/isaacs/minipass#readme

Copyright (c) 2017-2022 npm, Inc., Isaac Z. Schlueter, and Contributors

The ISC License

Copyright (c) 2017-2022 npm, Inc., Isaac Z. Schlueter, and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

minipass 5.0.0 - ISC
https://github.com/isaacs/minipass#readme

Copyright (c) 2017-2023 npm, Inc., Isaac Z. Schlueter, and Contributors

The ISC License

Copyright (c) 2017-2023 npm, Inc., Isaac Z. Schlueter, and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

semver 7.6.0 - ISC
https://github.com/npm/node-semver#readme

Copyright Isaac Z. Schlueter
Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

tar 6.2.1 - ISC
https://github.com/isaacs/node-tar#readme

Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

y18n 5.0.8 - ISC
https://github.com/yargs/y18n

Copyright (c) 2015, Contributors

Copyright (c) 2015, Contributors

Permission to use, copy, modify, and/or distribute this software for any purpose
with or without fee is hereby granted, provided that the above copyright notice
and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF
THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

yallist 4.0.0 - ISC
https://github.com/isaacs/yallist#readme

Copyright (c) Isaac Z. Schlueter and Contributors

The ISC License

Copyright (c) Isaac Z. Schlueter and Contributors

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

yargs-parser 21.1.1 - ISC
https://github.com/yargs/yargs-parser#readme

Copyright (c) 2016, Contributors

Copyright (c) 2016, Contributors

Permission to use, copy, modify, and/or distribute this software
for any purpose with or without fee is hereby granted, provided
that the above copyright notice and this permission notice
appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES
OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE
LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES
OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION,
ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

@tootallnate/quickjs-emscripten 0.23.0 - MIT
https://github.com/justjake/quickjs-emscripten#readme

copyright (c) 2019 Jake Teton-Landis

MIT License

quickjs-emscripten copyright (c) 2019 Jake Teton-Landis

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

agent-base 7.0.2 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

agent-base 7.1.0 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

ansi-regex 5.0.1 - MIT
https://github.com/chalk/ansi-regex#readme

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

ansi-styles 4.3.0 - MIT
https://github.com/chalk/ansi-styles#readme

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

ast-types 0.13.4 - MIT
http://github.com/benjamn/ast-types

Copyright (c) 2013 Ben Newman <bn@cs.stanford.edu>

Copyright (c) 2013 Ben Newman <bn@cs.stanford.edu>

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

balanced-match 1.0.2 - MIT
https://github.com/juliangruber/balanced-match

Copyright (c) 2013 Julian Gruber <julian@juliangruber.com>

(MIT)

Copyright (c) 2013 Julian Gruber &lt;julian@juliangruber.com&gt;

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

basic-ftp 5.0.3 - MIT
https://github.com/patrickjuchli/basic-ftp#readme

Copyright (c) 2019 Patrick Juchli

Copyright (c) 2019 Patrick Juchli

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

brace-expansion 1.1.11 - MIT
https://github.com/juliangruber/brace-expansion

Copyright (c) 2013 Julian Gruber <julian@juliangruber.com>

MIT License

Copyright (c) 2013 Julian Gruber <julian@juliangruber.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

chalk 5.3.0 - MIT
https://github.com/chalk/chalk#readme

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

color-convert 2.0.1 - MIT
https://github.com/Qix-/color-convert#readme

Copyright (c) 2011-2016, Heather Arthur and Josh Junon
Copyright (c) 2011-2016 Heather Arthur <fayearthur@gmail.com>

Copyright (c) 2011-2016 Heather Arthur <fayearthur@gmail.com>

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



---------------------------------------------------------

---------------------------------------------------------

color-name 1.1.4 - MIT
https://github.com/colorjs/color-name

Copyright (c) 2015 Dmitry Ivanov

The MIT License (MIT)
Copyright (c) 2015 Dmitry Ivanov

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

concat-map 0.0.1 - MIT
https://github.com/substack/node-concat-map


This software is released under the MIT license:

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

data-uri-to-buffer 5.0.1 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2014 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

debug 4.3.4 - MIT
https://github.com/debug-js/debug#readme

Copyright (c) 2018-2021 Josh Junon
Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca>

(The MIT License)

Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca>
Copyright (c) 2018-2021 Josh Junon

Permission is hereby granted, free of charge, to any person obtaining a copy of this software
and associated documentation files (the 'Software'), to deal in the Software without restriction,
including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



---------------------------------------------------------

---------------------------------------------------------

deep-is 0.1.4 - MIT
https://github.com/thlorenz/deep-is#readme

Copyright (c) 2009 Thomas Robinson <280north.com>
Copyright (c) 2012 James Halliday <mail@substack.net>
Copyright (c) 2012, 2013 Thorsten Lorenz <thlorenz@gmx.de>

Copyright (c) 2012, 2013 Thorsten Lorenz <thlorenz@gmx.de>
Copyright (c) 2012 James Halliday <mail@substack.net>
Copyright (c) 2009 Thomas Robinson <280north.com>

This software is released under the MIT license:

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

degenerator 5.0.0 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

emoji-regex 8.0.0 - MIT
https://mths.be/emoji-regex

Copyright Mathias Bynens <https://mathiasbynens.be/>

Copyright Mathias Bynens <https://mathiasbynens.be/>

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

escalade 3.1.1 - MIT
https://github.com/lukeed/escalade#readme

(c) Luke Edwards (https://lukeed.com)
Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (lukeed.com)

MIT License

Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (lukeed.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

fast-levenshtein 2.0.6 - MIT
https://github.com/hiddentao/fast-levenshtein#readme

Copyright (c) 2013 Ramesh Nair (http://www.hiddentao.com/)

(MIT License)

Copyright (c) 2013 [Ramesh Nair](http://www.hiddentao.com/)

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.



---------------------------------------------------------

---------------------------------------------------------

follow-redirects 1.15.6 - MIT
https://github.com/follow-redirects/follow-redirects

Copyright 2014-present Olivier Lalonde <olalonde@gmail.com> , James Talmage <james@talmage.io> , Ruben Verborgh

Copyright 2014–present Olivier Lalonde <olalonde@gmail.com>, James Talmage <james@talmage.io>, Ruben Verborgh

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR
IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

fs-extra 8.1.0 - MIT
https://github.com/jprichardson/node-fs-extra

Copyright (c) 2011-2017 JP Richardson
Copyright (c) 2011-2017 JP Richardson (https://github.com/jprichardson)
Copyright (c) 2014-2016 Jonathan Ong me@jongleberry.com and Contributors

(The MIT License)

Copyright (c) 2011-2017 JP Richardson

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files
(the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify,
 merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS
OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

get-uri 6.0.1 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2014 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

http-proxy-agent 7.0.0 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

License
-------

(The MIT License)

Copyright (c) 2013 Nathan Rajlich &lt;nathan@tootallnate.net&gt;

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

https-proxy-agent 7.0.2 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

ip-address 9.0.5 - MIT
https://github.com/beaugunderson/ip-address#readme

Copyright (c) 2011 by Beau Gunderson

Copyright (C) 2011 by Beau Gunderson

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

is-fullwidth-code-point 3.0.0 - MIT
https://github.com/sindresorhus/is-fullwidth-code-point#readme

(c) Sindre Sorhus (https://sindresorhus.com)
Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

jsbn 1.1.0 - MIT
https://github.com/andyperlitch/jsbn#readme

Copyright (c) 2005 Tom Wu
Copyright (c) 2003-2005 Tom Wu
Copyright (c) 2005-2009 Tom Wu

Licensing
---------

This software is covered under the following copyright:

/*
 * Copyright (c) 2003-2005  Tom Wu
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS-IS" AND WITHOUT WARRANTY OF ANY KIND, 
 * EXPRESS, IMPLIED OR OTHERWISE, INCLUDING WITHOUT LIMITATION, ANY 
 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.  
 *
 * IN NO EVENT SHALL TOM WU BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
 * INDIRECT OR CONSEQUENTIAL DAMAGES OF ANY KIND, OR ANY DAMAGES WHATSOEVER
 * RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER OR NOT ADVISED OF
 * THE POSSIBILITY OF DAMAGE, AND ON ANY THEORY OF LIABILITY, ARISING OUT
 * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *
 * In addition, the following condition applies:
 *
 * All redistributions must retain an intact copy of this copyright notice
 * and disclaimer.
 */

Address all questions regarding this license to:

  Tom Wu
  tjw@cs.Stanford.EDU


---------------------------------------------------------

---------------------------------------------------------

jsonc-parser 3.2.0 - MIT
https://github.com/microsoft/node-jsonc-parser#readme

Copyright (c) Microsoft
Copyright 2018, Microsoft
Copyright (c) Microsoft Corporation

The MIT License (MIT)

Copyright (c) Microsoft

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

jsonfile 4.0.0 - MIT
https://github.com/jprichardson/node-jsonfile#readme

Copyright 2012-2016, JP Richardson <jprichardson@gmail.com>
Copyright (c) 2012-2015, JP Richardson <jprichardson@gmail.com>

(The MIT License)

Copyright (c) 2012-2015, JP Richardson <jprichardson@gmail.com>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files
(the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify,
 merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS
OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

js-yaml 4.1.0 - MIT
https://github.com/nodeca/js-yaml#readme

Copyright (c) 2011-2015 by Vitaly Puzrin

(The MIT License)

Copyright (C) 2011-2015 by Vitaly Puzrin

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

levn 0.3.0 - MIT
https://github.com/gkz/levn

Copyright (c) George Zahariev

Copyright (c) George Zahariev

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

looper 3.0.0 - MIT
https://github.com/dominictarr/looper

Copyright (c) 2013 Dominic Tarr

Copyright (c) 2013 Dominic Tarr

Permission is hereby granted, free of charge, 
to any person obtaining a copy of this software and 
associated documentation files (the "Software"), to 
deal in the Software without restriction, including 
without limitation the rights to use, copy, modify, 
merge, publish, distribute, sublicense, and/or sell 
copies of the Software, and to permit persons to whom 
the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice 
shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. 
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR 
ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, 
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE 
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

minizlib 2.1.2 - MIT
https://github.com/isaacs/minizlib#readme

Copyright Isaac Z. Schlueter and Contributors
Copyright Joyent, Inc. and other Node contributors

Minizlib was created by Isaac Z. Schlueter.
It is a derivative work of the Node.js project.

"""
Copyright Isaac Z. Schlueter and Contributors
Copyright Node.js contributors. All rights reserved.
Copyright Joyent, Inc. and other Node contributors. All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the "Software"),
to deal in the Software without restriction, including without limitation
the rights to use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
"""


---------------------------------------------------------

---------------------------------------------------------

mkdirp 1.0.4 - MIT
https://github.com/isaacs/node-mkdirp#readme

Copyright James Halliday (mail@substack.net) and Isaac Z. Schlueter (i@izs.me)

Copyright James Halliday (mail@substack.net) and Isaac Z. Schlueter (i@izs.me)

This project is free software released under the MIT license:

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

ms 2.1.2 - MIT
https://github.com/zeit/ms#readme

Copyright (c) 2016 Zeit, Inc.

The MIT License (MIT)

Copyright (c) 2016 Zeit, Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

nan 2.18.0 - MIT
https://github.com/nodejs/nan#readme

Copyright (c) 2018 NAN WG Members
Copyright (c) 2018 NAN contributors
Copyright (c) 2021 NAN contributors
Copyright Joyent, Inc. and other Node contributors
Copyright (c) 2018 NAN contributors - Rod Vagg <https://github.com/rvagg>

The MIT License (MIT)

Copyright (c) 2018 [NAN contributors](<https://github.com/nodejs/nan#wg-members--collaborators>)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

ncp 2.0.0 - MIT
https://github.com/AvianFlu/ncp

Copyright (c) 2011 by Charlie McConnell

# MIT License

###Copyright (C) 2011 by Charlie McConnell

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

netmask 2.0.2 - MIT
https://github.com/rs/node-netmask

Copyright (c) 2011 Olivier Poitrey <rs@rhapsodyk.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

node-pty 1.0.0 - MIT
https://github.com/microsoft/node-pty

Copyright (c) 2016, Daniel Imms
Copyright (c) 2017, Daniel Imms
Copyright (c) 2015 Ryan Prichard
Copyright (c) 2016 Ryan Prichard
Copyright (c) 2011-2012 Ryan Prichard
Copyright (c) 2011-2015 Ryan Prichard
Copyright (c) 2011-2016 Ryan Prichard
Copyright (c) 2009 Microsoft Corporation
Copyright (c) 2018, Microsoft Corporation
Copyright (c) 2019, Microsoft Corporation
Copyright (c) 2020, Microsoft Corporation
Copyright (c) 2012-2015, Christopher Jeffrey
Copyright (c) 2009 Todd Carson <toc@daybefore.net>
Copyright (c) 2018 - present Microsoft Corporation
Copyright (c) 2009 Joshua Elsasser <josh@elsasser.org>
Copyright (c) 2012-2015, Christopher Jeffrey, Peter Sunde
Copyright (c) 2013-2015, Christopher Jeffrey, Peter Sunde
Copyright (c) 2009 Nicholas Marriott <nicm@users.sourceforge.net>
Copyright (c) 2016, Daniel Imms (http://www.growingwiththeweb.com)
Copyright (c) 2012-2015, Christopher Jeffrey (https://github.com/chjj/)

Copyright (c) 2012-2015, Christopher Jeffrey (https://github.com/chjj/)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.



The MIT License (MIT)

Copyright (c) 2016, Daniel Imms (http://www.growingwiththeweb.com)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



MIT License

Copyright (c) 2018 - present Microsoft Corporation

All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


The MIT License (MIT)

Copyright (c) 2011-2016 Ryan Prichard

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to
deal in the Software without restriction, including without limitation the
rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
sell copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

optionator 0.8.3 - MIT
https://github.com/gkz/optionator

Copyright (c) George Zahariev

Copyright (c) George Zahariev

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

pac-proxy-agent 7.0.1 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2014 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

pac-resolver 7.0.1 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

(The MIT License)

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

prelude-ls 1.1.2 - MIT
http://preludels.com/

Copyright (c) George Zahariev

Copyright (c) George Zahariev

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

proxy-agent 6.3.1 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

proxy-from-env 1.1.0 - MIT
https://github.com/Rob--W/proxy-from-env#readme

Copyright (c) 2016-2018 Rob Wu <rob@robwu.nl>

The MIT License

Copyright (C) 2016-2018 Rob Wu <rob@robwu.nl>

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

pull-stream 3.7.0 - MIT
https://pull-stream.github.io/

(c) . To
Copyright (c) 2013 Dominic Tarr

Copyright (c) 2013 Dominic Tarr

Permission is hereby granted, free of charge, 
to any person obtaining a copy of this software and 
associated documentation files (the "Software"), to 
deal in the Software without restriction, including 
without limitation the rights to use, copy, modify, 
merge, publish, distribute, sublicense, and/or sell 
copies of the Software, and to permit persons to whom 
the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice 
shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. 
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR 
ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, 
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE 
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

recursive-readdir 2.2.3 - MIT
https://github.com/jergason/recursive-readdir#readme


The MIT License (MIT)

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

require-directory 2.1.1 - MIT
https://github.com/troygoode/node-require-directory/

Copyright (c) 2011 Troy Goode <troygoode@gmail.com>

The MIT License (MIT)

Copyright (c) 2011 Troy Goode <troygoode@gmail.com>

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

shell-quote 1.8.1 - MIT
https://github.com/ljharb/shell-quote

Copyright (c) 2013 James Halliday (mail@substack.net)

The MIT License

Copyright (c) 2013 James Halliday (mail@substack.net)

Permission is hereby granted, free of charge, 
to any person obtaining a copy of this software and 
associated documentation files (the "Software"), to 
deal in the Software without restriction, including 
without limitation the rights to use, copy, modify, 
merge, publish, distribute, sublicense, and/or sell 
copies of the Software, and to permit persons to whom 
the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice 
shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. 
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR 
ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, 
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE 
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

smart-buffer 4.2.0 - MIT
https://github.com/JoshGlazebrook/smart-buffer/

Copyright (c) 2013-2017 Josh Glazebrook

The MIT License (MIT)

Copyright (c) 2013-2017 Josh Glazebrook

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

socks 2.7.3 - MIT
https://github.com/JoshGlazebrook/socks/

Copyright (c) 2013 Josh Glazebrook

The MIT License (MIT)

Copyright (c) 2013 Josh Glazebrook

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

socks-proxy-agent 8.0.2 - MIT
https://github.com/TooTallNate/proxy-agents#readme

Copyright (c) 2013 Nathan Rajlich <nathan@tootallnate.net>

MIT License

Copyright (c) <year> <copyright holders>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

---------------------------------------------------------

---------------------------------------------------------

stream-to-pull-stream 1.7.3 - MIT
https://github.com/dominictarr/stream-to-pull-stream

Copyright (c) 2013 Dominic Tarr

Copyright (c) 2013 Dominic Tarr

Permission is hereby granted, free of charge, 
to any person obtaining a copy of this software and 
associated documentation files (the "Software"), to 
deal in the Software without restriction, including 
without limitation the rights to use, copy, modify, 
merge, publish, distribute, sublicense, and/or sell 
copies of the Software, and to permit persons to whom 
the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice 
shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. 
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR 
ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, 
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE 
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

string-width 4.2.3 - MIT
https://github.com/sindresorhus/string-width#readme

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

strip-ansi 6.0.1 - MIT
https://github.com/chalk/strip-ansi#readme

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

text-table 0.2.0 - MIT
https://github.com/substack/text-table


This software is released under the MIT license:

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

type-check 0.3.2 - MIT
https://github.com/gkz/type-check

Copyright (c) George Zahariev

Copyright (c) George Zahariev

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

universalify 0.1.2 - MIT
https://github.com/RyanZim/universalify#readme

Copyright (c) 2017, Ryan Zimmerman <opensrc@ryanzim.com>

(The MIT License)

Copyright (c) 2017, Ryan Zimmerman <opensrc@ryanzim.com>

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the 'Software'), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

word-wrap 1.2.5 - MIT
https://github.com/jonschlinkert/word-wrap

Copyright (c) 2014-2016, Jon Schlinkert
Copyright (c) 2014-2023, Jon Schlinkert
Copyright (c) 2023, Jon Schlinkert (https://github.com/jonschlinkert)

The MIT License (MIT)

Copyright (c) 2014-2016, Jon Schlinkert

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

wrap-ansi 7.0.0 - MIT
https://github.com/chalk/wrap-ansi#readme

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)

MIT License

Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (https://sindresorhus.com)

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

yargs 17.7.2 - MIT
https://yargs.js.org/

Copyright 2014 Contributors (ben@npmjs.com)
Copyright 2010 James Halliday (mail@substack.net)

MIT License

Copyright 2010 James Halliday (mail@substack.net); Modified work Copyright 2014 Contributors (ben@npmjs.com)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


---------------------------------------------------------

---------------------------------------------------------

argparse 2.0.1 - Python-2.0
https://github.com/nodeca/argparse#readme

Copyright (c) 2020 argparse.js authors
Copyright (c) 1999-2001 Gregory P. Ward
Copyright (c) 2010-2020 Python Software Foundation
Copyright (c) 2002, 2003 Python Software Foundation
Copyright (c) 1995-2001 Corporation for National Research Initiatives
Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands
Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 Python Software Foundation

A. HISTORY OF THE SOFTWARE
==========================

Python was created in the early 1990s by Guido van Rossum at Stichting
Mathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands
as a successor of a language called ABC.  Guido remains Python's
principal author, although it includes many contributions from others.

In 1995, Guido continued his work on Python at the Corporation for
National Research Initiatives (CNRI, see http://www.cnri.reston.va.us)
in Reston, Virginia where he released several versions of the
software.

In May 2000, Guido and the Python core development team moved to
BeOpen.com to form the BeOpen PythonLabs team.  In October of the same
year, the PythonLabs team moved to Digital Creations, which became
Zope Corporation.  In 2001, the Python Software Foundation (PSF, see
https://www.python.org/psf/) was formed, a non-profit organization
created specifically to own Python-related Intellectual Property.
Zope Corporation was a sponsoring member of the PSF.

All Python releases are Open Source (see http://www.opensource.org for
the Open Source Definition).  Historically, most, but not all, Python
releases have also been GPL-compatible; the table below summarizes
the various releases.

    Release         Derived     Year        Owner       GPL-
                    from                                compatible? (1)

    0.9.0 thru 1.2              1991-1995   CWI         yes
    1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes
    1.6             1.5.2       2000        CNRI        no
    2.0             1.6         2000        BeOpen.com  no
    1.6.1           1.6         2001        CNRI        yes (2)
    2.1             2.0+1.6.1   2001        PSF         no
    2.0.1           2.0+1.6.1   2001        PSF         yes
    2.1.1           2.1+2.0.1   2001        PSF         yes
    2.1.2           2.1.1       2002        PSF         yes
    2.1.3           2.1.2       2002        PSF         yes
    2.2 and above   2.1.1       2001-now    PSF         yes

Footnotes:

(1) GPL-compatible doesn't mean that we're distributing Python under
    the GPL.  All Python licenses, unlike the GPL, let you distribute
    a modified version without making your changes open source.  The
    GPL-compatible licenses make it possible to combine Python with
    other software that is released under the GPL; the others don't.

(2) According to Richard Stallman, 1.6.1 is not GPL-compatible,
    because its license has a choice of law clause.  According to
    CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1
    is "not incompatible" with the GPL.

Thanks to the many outside volunteers who have worked under Guido's
direction to make these releases possible.


B. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON
===============================================================

PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
--------------------------------------------

1. This LICENSE AGREEMENT is between the Python Software Foundation
("PSF"), and the Individual or Organization ("Licensee") accessing and
otherwise using this software ("Python") in source or binary form and
its associated documentation.

2. Subject to the terms and conditions of this License Agreement, PSF hereby
grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,
analyze, test, perform and/or display publicly, prepare derivative works,
distribute, and otherwise use Python alone or in any derivative version,
provided, however, that PSF's License Agreement and PSF's notice of copyright,
i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 Python Software Foundation;
All Rights Reserved" are retained in Python alone or in any derivative version
prepared by Licensee.

3. In the event Licensee prepares a derivative work that is based on
or incorporates Python or any part thereof, and wants to make
the derivative work available to others as provided herein, then
Licensee hereby agrees to include in any such work a brief summary of
the changes made to Python.

4. PSF is making Python available to Licensee on an "AS IS"
basis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND
DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT
INFRINGE ANY THIRD PARTY RIGHTS.

5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON
FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS
A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,
OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.

6. This License Agreement will automatically terminate upon a material
breach of its terms and conditions.

7. Nothing in this License Agreement shall be deemed to create any
relationship of agency, partnership, or joint venture between PSF and
Licensee.  This License Agreement does not grant permission to use PSF
trademarks or trade name in a trademark sense to endorse or promote
products or services of Licensee, or any third party.

8. By copying, installing or otherwise using Python, Licensee
agrees to be bound by the terms and conditions of this License
Agreement.


BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
-------------------------------------------

BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1

1. This LICENSE AGREEMENT is between BeOpen.com ("BeOpen"), having an
office at 160 Saratoga Avenue, Santa Clara, CA 95051, and the
Individual or Organization ("Licensee") accessing and otherwise using
this software in source or binary form and its associated
documentation ("the Software").

2. Subject to the terms and conditions of this BeOpen Python License
Agreement, BeOpen hereby grants Licensee a non-exclusive,
royalty-free, world-wide license to reproduce, analyze, test, perform
and/or display publicly, prepare derivative works, distribute, and
otherwise use the Software alone or in any derivative version,
provided, however, that the BeOpen Python License is retained in the
Software, alone or in any derivative version prepared by Licensee.

3. BeOpen is making the Software available to Licensee on an "AS IS"
basis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND
DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT
INFRINGE ANY THIRD PARTY RIGHTS.

4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE
SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS
AS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY
DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.

5. This License Agreement will automatically terminate upon a material
breach of its terms and conditions.

6. This License Agreement shall be governed by and interpreted in all
respects by the law of the State of California, excluding conflict of
law provisions.  Nothing in this License Agreement shall be deemed to
create any relationship of agency, partnership, or joint venture
between BeOpen and Licensee.  This License Agreement does not grant
permission to use BeOpen trademarks or trade names in a trademark
sense to endorse or promote products or services of Licensee, or any
third party.  As an exception, the "BeOpen Python" logos available at
http://www.pythonlabs.com/logos.html may be used according to the
permissions granted on that web page.

7. By copying, installing or otherwise using the software, Licensee
agrees to be bound by the terms and conditions of this License
Agreement.


CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1
---------------------------------------

1. This LICENSE AGREEMENT is between the Corporation for National
Research Initiatives, having an office at 1895 Preston White Drive,
Reston, VA 20191 ("CNRI"), and the Individual or Organization
("Licensee") accessing and otherwise using Python 1.6.1 software in
source or binary form and its associated documentation.

2. Subject to the terms and conditions of this License Agreement, CNRI
hereby grants Licensee a nonexclusive, royalty-free, world-wide
license to reproduce, analyze, test, perform and/or display publicly,
prepare derivative works, distribute, and otherwise use Python 1.6.1
alone or in any derivative version, provided, however, that CNRI's
License Agreement and CNRI's notice of copyright, i.e., "Copyright (c)
1995-2001 Corporation for National Research Initiatives; All Rights
Reserved" are retained in Python 1.6.1 alone or in any derivative
version prepared by Licensee.  Alternately, in lieu of CNRI's License
Agreement, Licensee may substitute the following text (omitting the
quotes): "Python 1.6.1 is made available subject to the terms and
conditions in CNRI's License Agreement.  This Agreement together with
Python 1.6.1 may be located on the Internet using the following
unique, persistent identifier (known as a handle): 1895.22/1013.  This
Agreement may also be obtained from a proxy server on the Internet
using the following URL: http://hdl.handle.net/1895.22/1013".

3. In the event Licensee prepares a derivative work that is based on
or incorporates Python 1.6.1 or any part thereof, and wants to make
the derivative work available to others as provided herein, then
Licensee hereby agrees to include in any such work a brief summary of
the changes made to Python 1.6.1.

4. CNRI is making Python 1.6.1 available to Licensee on an "AS IS"
basis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND
DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT
INFRINGE ANY THIRD PARTY RIGHTS.

5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON
1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS
A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,
OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.

6. This License Agreement will automatically terminate upon a material
breach of its terms and conditions.

7. This License Agreement shall be governed by the federal
intellectual property law of the United States, including without
limitation the federal copyright law, and, to the extent such
U.S. federal law does not apply, by the law of the Commonwealth of
Virginia, excluding Virginia's conflict of law provisions.
Notwithstanding the foregoing, with regard to derivative works based
on Python 1.6.1 that incorporate non-separable material that was
previously distributed under the GNU General Public License (GPL), the
law of the Commonwealth of Virginia shall govern this License
Agreement only as to issues arising under or with respect to
Paragraphs 4, 5, and 7 of this License Agreement.  Nothing in this
License Agreement shall be deemed to create any relationship of
agency, partnership, or joint venture between CNRI and Licensee.  This
License Agreement does not grant permission to use CNRI trademarks or
trade name in a trademark sense to endorse or promote products or
services of Licensee, or any third party.

8. By clicking on the "ACCEPT" button where indicated, or by copying,
installing or otherwise using Python 1.6.1, Licensee agrees to be
bound by the terms and conditions of this License Agreement.

        ACCEPT


CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
--------------------------------------------------

Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,
The Netherlands.  All rights reserved.

Permission to use, copy, modify, and distribute this software and its
documentation for any purpose and without fee is hereby granted,
provided that the above copyright notice appear in all copies and that
both that copyright notice and this permission notice appear in
supporting documentation, and that the name of Stichting Mathematisch
Centrum or CWI not be used in advertising or publicity pertaining to
distribution of the software without specific, written prior
permission.

STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO
THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE
FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


---------------------------------------------------------
</file>

<file path="tsconfig.base.json">
{
	"compilerOptions": {
		"composite": true,
		"rootDir": "./src",
		"outDir": "./built",
		"target": "es2021",
		"module": "commonjs",
		"esModuleInterop": true,
		"strict": true,
		"alwaysStrict": true,
		"noImplicitAny": true,
		"noImplicitReturns": true,
		"noUnusedLocals": true,
		"noUnusedParameters": true,
		"useUnknownInCatchVariables": false,
		"newLine": "LF",
		"sourceMap": true
	}
}
</file>

<file path="tsconfig.json">
{
	"references": [
		{
			"path": "./src/spec-common"
		},
		{
			"path": "./src/spec-configuration"
		},
		{
			"path": "./src/spec-node"
		},
		{
			"path": "./src/spec-shutdown"
		},
		{
			"path": "./src/spec-utils"
		}
	],
	"files": []
}
</file>

<file path="tsfmt.json">
{
	"tabSize": 4,
	"indentSize": 4,
	"convertTabsToSpaces": false,
	"insertSpaceAfterCommaDelimiter": true,
	"insertSpaceAfterSemicolonInForStatements": true,
	"insertSpaceBeforeAndAfterBinaryOperators": true,
	"insertSpaceAfterKeywordsInControlFlowStatements": true,
	"insertSpaceAfterFunctionKeywordForAnonymousFunctions": true,
	"insertSpaceAfterOpeningAndBeforeClosingNonemptyParenthesis": false,
	"insertSpaceAfterOpeningAndBeforeClosingNonemptyBrackets": false,
	"insertSpaceAfterOpeningAndBeforeClosingTemplateStringBraces": false,
	"insertSpaceBeforeFunctionParenthesis": false,
	"placeOpenBraceOnNewLineForFunctions": false,
	"placeOpenBraceOnNewLineForControlBlocks": false
}
</file>

</files>
